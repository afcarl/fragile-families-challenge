{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../results/model_params_and_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['score'] = df['score']*-1 # Converting negative MSE to positive MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.584747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>relu</td>\n",
       "      <td>7.227311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.625803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tanh</td>\n",
       "      <td>3.625803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.289578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.297948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.310448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.279975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.259806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.277095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.309183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.542272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.324746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.255906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.304221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.275565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.350884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.305775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.309397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.269394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.565389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.286249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.308745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>linear</td>\n",
       "      <td>1.954614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.851779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.265914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>256</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.378844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.301218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.314987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.291307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.310032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.259853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.329742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.281479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.316033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>linear</td>\n",
       "      <td>27.577955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.519604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0.266296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.339618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    num_hidden_layers  hidden_layer_size activation_function      score\n",
       "0                   0                  0              linear   2.584747\n",
       "1                   0                  0                relu   7.227311\n",
       "2                   0                  0             sigmoid   3.625803\n",
       "3                   0                  0                tanh   3.625803\n",
       "4                   1                 64              linear   0.289578\n",
       "5                   1                 64                relu   0.497862\n",
       "6                   1                 64             sigmoid   0.297948\n",
       "7                   1                 64                tanh   0.310448\n",
       "8                   1                128              linear   0.279975\n",
       "9                   1                128                relu   0.259806\n",
       "10                  1                128             sigmoid   0.277095\n",
       "11                  1                128                tanh   0.309183\n",
       "12                  1                256              linear   0.542272\n",
       "13                  1                256                relu   0.324746\n",
       "14                  1                256             sigmoid   0.255906\n",
       "15                  1                256                tanh   0.304221\n",
       "16                  2                 64              linear   0.275565\n",
       "17                  2                 64                relu   0.350884\n",
       "18                  2                 64             sigmoid   0.305775\n",
       "19                  2                 64                tanh   0.309397\n",
       "20                  2                128              linear   0.269394\n",
       "21                  2                128                relu   0.565389\n",
       "22                  2                128             sigmoid   0.286249\n",
       "23                  2                128                tanh   0.308745\n",
       "24                  2                256              linear   1.954614\n",
       "25                  2                256                relu   0.851779\n",
       "26                  2                256             sigmoid   0.265914\n",
       "27                  2                256                tanh   0.378844\n",
       "28                  3                 64              linear   0.301218\n",
       "29                  3                 64                relu   0.314987\n",
       "30                  3                 64             sigmoid   0.291307\n",
       "31                  3                 64                tanh   0.310032\n",
       "32                  3                128              linear   0.259853\n",
       "33                  3                128                relu   0.329742\n",
       "34                  3                128             sigmoid   0.281479\n",
       "35                  3                128                tanh   0.316033\n",
       "36                  3                256              linear  27.577955\n",
       "37                  3                256                relu   0.519604\n",
       "38                  3                256             sigmoid   0.266296\n",
       "39                  3                256                tanh   0.339618"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can now look at some descriptive statistics for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x10ba4aa58>]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b9bbef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame.hist(data=df, column='score',bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10bd066d8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnIUAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10baebd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=df.num_hidden_layers, y=df.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10bdff0b8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIgh0AEjE/wHB8bmhRSpztQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10bd28828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=df.hidden_layer_size, y=df.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>activation_function</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>linear</td>\n",
       "      <td>2.584747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>relu</td>\n",
       "      <td>7.227311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>3.625803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tanh</td>\n",
       "      <td>3.625803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>linear</td>\n",
       "      <td>0.289578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_hidden_layers  hidden_layer_size activation_function     score\n",
       "0                  0                  0              linear  2.584747\n",
       "1                  0                  0                relu  7.227311\n",
       "2                  0                  0             sigmoid  3.625803\n",
       "3                  0                  0                tanh  3.625803\n",
       "4                  1                 64              linear  0.289578"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "activation_dummies = pd.get_dummies(df.activation_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df['layers_and_size_interaction'] = df.num_hidden_layers + df.hidden_layer_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df,activation_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_hidden_layers', 'hidden_layer_size', 'activation_function',\n",
       "       'score', 'layers_and_size_interaction', 'linear', 'relu', 'sigmoid',\n",
       "       'tanh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now to run an OLS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  score   R-squared:                       0.079\n",
      "Model:                            OLS   Adj. R-squared:                 -0.056\n",
      "Method:                 Least Squares   F-statistic:                    0.5854\n",
      "Date:                Mon, 02 Oct 2017   Prob (F-statistic):              0.711\n",
      "Time:                        15:58:39   Log-Likelihood:                -114.24\n",
      "No. Observations:                  40   AIC:                             240.5\n",
      "Df Residuals:                      34   BIC:                             250.6\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                       2.8043      2.090      1.342      0.188      -1.442       7.051\n",
      "num_hidden_layers              -0.0114      0.518     -0.022      0.983      -1.064       1.041\n",
      "hidden_layer_size               0.0082      0.260      0.031      0.975      -0.521       0.537\n",
      "layers_and_size_interaction    -0.0033      0.258     -0.013      0.990      -0.527       0.520\n",
      "relu                           -2.3093      2.041     -1.131      0.266      -6.457       1.839\n",
      "sigmoid                        -2.8181      2.041     -1.381      0.176      -6.966       1.330\n",
      "tanh                           -2.7823      2.041     -1.363      0.182      -6.930       1.366\n",
      "==============================================================================\n",
      "Omnibus:                       73.094   Durbin-Watson:                   1.938\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              927.780\n",
      "Skew:                           4.453   Prob(JB):                    3.43e-202\n",
      "Kurtosis:                      24.848   Cond. No.                     1.67e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 7.48e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(formula='score ~ num_hidden_layers + hidden_layer_size + layers_and_size_interaction \\\n",
    "                + relu + sigmoid + tanh', data=df)\n",
    "\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the coefficients are significant, making it difficult to interpret the results of the model. Overall it appears that all of the activation functions have a stronger negative effect on mean squared error (thus improving the predictions) than the reference category, the linear activation function. The number of hidden layers and the interaction between this and the hidden layer size (the number of neurons in the layer) are both also negative, which hidden layer size alone is positive.\n",
    "\n",
    "An issue with the current data is that the outliers with extremely high MSE, where the model was never able to converge towards sensible predictions, may be biasing the results. To assess whether this is the case I can re-run the models excluding these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ = df[df['score'] <= 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  score   R-squared:                       0.374\n",
      "Model:                            OLS   Adj. R-squared:                  0.263\n",
      "Method:                 Least Squares   F-statistic:                     3.352\n",
      "Date:                Mon, 02 Oct 2017   Prob (F-statistic):             0.0170\n",
      "Time:                        15:58:39   Log-Likelihood:                 32.054\n",
      "No. Observations:                  34   AIC:                            -52.11\n",
      "Df Residuals:                      28   BIC:                            -42.95\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================================\n",
      "                                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                       0.2664      0.064      4.168      0.000       0.135       0.397\n",
      "num_hidden_layers              -0.0013      0.015     -0.091      0.928      -0.031       0.028\n",
      "hidden_layer_size               0.0009      0.007      0.122      0.904      -0.014       0.016\n",
      "layers_and_size_interaction    -0.0004      0.007     -0.060      0.953      -0.015       0.014\n",
      "relu                            0.1157      0.053      2.186      0.037       0.007       0.224\n",
      "sigmoid                        -0.0495      0.053     -0.935      0.358      -0.158       0.059\n",
      "tanh                           -0.0096      0.053     -0.182      0.857      -0.118       0.099\n",
      "==============================================================================\n",
      "Omnibus:                       20.198   Durbin-Watson:                   2.193\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               36.691\n",
      "Skew:                           1.369   Prob(JB):                     1.08e-08\n",
      "Kurtosis:                       7.290   Cond. No.                     1.88e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.16e-27. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(formula='score ~ num_hidden_layers + hidden_layer_size + layers_and_size_interaction \\\n",
    "                + relu + sigmoid + tanh', data=df_)\n",
    "\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the overall model fit has improved, with the R-squared value increasing from 0.079 to 0.374. The coefficient for the ReLU activation is also positive now, consistent with the observation that its performance tends to fluctuate more than the other functions.\n",
    "\n",
    "Overall these results show that there are no clear, statistically significant, effects of basic architecture on model performance. Nonetheless the observed differences in the results elsewhere provide some evidence that models with more layers and node and non-linear activation are better able to generalize to out-of-sample data. The small number of observations may also be preventing us from seeing statistically significant relationships. Future work should assess the performance of models over a greater range of architectures to better assess how these choices affect predictive performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
