{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Predicting GPA with Deep Learning\n",
    "This notebook reproduces the models and all figures and tables contained in my paper on the Fragile Familes Challenge.\n",
    "\n",
    "***Please note the following if you intend to run this notebook***\n",
    "\n",
    "- To the best of my knowledge this notebook will reproduce all the results accurately but due to stochastic nature of many of the processes used the results may differ. Where possible I have created static copies of objects that can be loaded directly. Some of these are too large to store on Github, for example the pickled versions of the final 5 classifiers. Please email me directly if you would like copies of these.\n",
    "\n",
    "- This notebook is contains process that are computationally intensive and take some time to run. As is it will take at least 24 hours to run on a top spec laptop computer. I have noted the cells that take most time to run. If possible you may consider editing the notebook where appropriate to run processes in paraellel or using a GPU.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Loading packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Set up to ensure reproducibility following https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers\n",
    "# in a well-defined initial state.\n",
    "np.random.seed(42)\n",
    "\n",
    "# The below is necessary for starting core Python generated random numbers\n",
    "# in a well-defined state.\n",
    "random.seed(54321)\n",
    "\n",
    "# Force TensorFlow to use single thread.\n",
    "# Multiple threads are a potential source of\n",
    "# non-reproducible results.\n",
    "# For further details, see: https://stackoverflow.com/questions/42022950/which-seeds-have-to-be-set-where-to-realize-100-reproducibility-of-training-res\n",
    "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "from keras import backend as K\n",
    "# The below tf.set_random_seed() will make random number generation\n",
    "# in the TensorFlow backend have a well-defined initial state.\n",
    "# For further details, see: https://www.tensorflow.org/api_docs/python/tf/set_random_seed\n",
    "tf.set_random_seed(6789)\n",
    "\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, History\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Loading the files\n",
    "\n",
    "***Note: These data cannot be provided on Github and I will delete my copies in accordance with the FFC agreement. If you would like copies of the data to replicate these analyses please contact the Fragile Familes survey.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('../../ff_data/train.csv',low_memory=False, index_col='challengeID')\n",
    "predictions=pd.read_csv('../../ff_data/prediction.csv',low_memory=False, index_col='challengeID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To generate `full_imputed.p` the script `clean_files.py` must first be run. If necessary it can be executed and run by uncommenting the line below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#! python clean_files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_pickle('full_imputed.p') # load imputed data output after running the clean_files.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4242, 4568)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract the outcomes from the imputed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = data[['gpa','grit','materialHardship','eviction','layoff','jobTraining']]\n",
    "X = data\n",
    "for c in X.columns:\n",
    "    if c in list(y.columns):\n",
    "        del X[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data processing\n",
    "\n",
    "Before modelling the data there are two types of transformations that I use to optimize them for the neural network.\n",
    "\n",
    "Categorical variables are transformed using one-hot encoding. Continuous variables are also normalized to have a mean of zero.\n",
    "\n",
    "To identify which columns belong to which group I use same heuristic as in the imputation script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "cat_cols = []\n",
    "non_cat_cols = []\n",
    "for i, c in enumerate(X.columns):\n",
    "    is_categorical = False\n",
    "    vals = set(list(X[c]))\n",
    "    vals = {x for x in vals if x==x} # Removes nans, otherwise treated as unique\n",
    "    if X[c].dtype == 'float64': # if float and low num distinct then treat as cat\n",
    "        if len(vals) <= 20:\n",
    "            is_categorical = True\n",
    "        else:\n",
    "            pass\n",
    "    else:\n",
    "        is_categorical = True\n",
    "    \n",
    "    # Now append to relevant list of columns\n",
    "    if is_categorical:\n",
    "        cat_cols.append(c)\n",
    "        \n",
    "    else:\n",
    "        non_cat_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_dummies = pd.get_dummies(X, columns=cat_cols)\n",
    "# Note that sklearn also has one-hot encoding but doesn't relabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1lenmin</th>\n",
       "      <th>m1citywt</th>\n",
       "      <th>m1e1d1</th>\n",
       "      <th>m1e1d2</th>\n",
       "      <th>m1e1d3</th>\n",
       "      <th>m1i2a</th>\n",
       "      <th>m1i2b</th>\n",
       "      <th>m1j2a</th>\n",
       "      <th>m1j2b</th>\n",
       "      <th>cm1hhinc</th>\n",
       "      <th>...</th>\n",
       "      <th>hv4mflag_1.0</th>\n",
       "      <th>hv4mflag_2.0</th>\n",
       "      <th>hv4mflag_3.0</th>\n",
       "      <th>hv4mompreg_0.0</th>\n",
       "      <th>hv4mompreg_1.0</th>\n",
       "      <th>hv4selfht_0.0</th>\n",
       "      <th>hv4selfht_1.0</th>\n",
       "      <th>hv4selfht_2.0</th>\n",
       "      <th>hv4selfwt_0.0</th>\n",
       "      <th>hv4selfwt_1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>challengeID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.0</td>\n",
       "      <td>202.485367</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.723174</td>\n",
       "      <td>13.260396</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1682.415602</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>2.211822</td>\n",
       "      <td>29579.694329</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>45.608219</td>\n",
       "      <td>43.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>3050.504448</td>\n",
       "      <td>0.110909</td>\n",
       "      <td>1.985703</td>\n",
       "      <td>20829.093487</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>39.060299</td>\n",
       "      <td>49.0</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.158179</td>\n",
       "      <td>1.386592</td>\n",
       "      <td>132483.450592</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.0</td>\n",
       "      <td>22.304855</td>\n",
       "      <td>23.0</td>\n",
       "      <td>23.169628</td>\n",
       "      <td>5.699719</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.165048</td>\n",
       "      <td>1.157385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>35.518272</td>\n",
       "      <td>90.0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1974.812374</td>\n",
       "      <td>12.212538</td>\n",
       "      <td>2.965919</td>\n",
       "      <td>49026.982561</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             m1lenmin    m1citywt  m1e1d1     m1e1d2     m1e1d3  m1i2a  \\\n",
       "challengeID                                                              \n",
       "1                40.0  202.485367    25.0   6.723174  13.260396   38.0   \n",
       "2                40.0   45.608219    43.0  16.000000   3.000000   25.0   \n",
       "3                35.0   39.060299    49.0  46.000000  23.000000   20.0   \n",
       "4                30.0   22.304855    23.0  23.169628   5.699719   20.0   \n",
       "5                25.0   35.518272    90.0  64.000000  58.000000   12.0   \n",
       "\n",
       "                   m1i2b      m1j2a     m1j2b       cm1hhinc      ...        \\\n",
       "challengeID                                                       ...         \n",
       "1            1682.415602   0.038262  2.211822   29579.694329      ...         \n",
       "2            3050.504448   0.110909  1.985703   20829.093487      ...         \n",
       "3               0.000000  12.158179  1.386592  132483.450592      ...         \n",
       "4               0.000000   4.165048  1.157385       0.000000      ...         \n",
       "5            1974.812374  12.212538  2.965919   49026.982561      ...         \n",
       "\n",
       "             hv4mflag_1.0  hv4mflag_2.0  hv4mflag_3.0  hv4mompreg_0.0  \\\n",
       "challengeID                                                             \n",
       "1                       0             0             0               1   \n",
       "2                       0             0             0               0   \n",
       "3                       0             0             0               1   \n",
       "4                       0             0             0               1   \n",
       "5                       0             0             0               1   \n",
       "\n",
       "             hv4mompreg_1.0  hv4selfht_0.0  hv4selfht_1.0  hv4selfht_2.0  \\\n",
       "challengeID                                                                \n",
       "1                         0              1              0              0   \n",
       "2                         1              1              0              0   \n",
       "3                         0              1              0              0   \n",
       "4                         0              1              0              0   \n",
       "5                         0              1              0              0   \n",
       "\n",
       "             hv4selfwt_0.0  hv4selfwt_1.0  \n",
       "challengeID                                \n",
       "1                        1              0  \n",
       "2                        1              0  \n",
       "3                        1              0  \n",
       "4                        1              0  \n",
       "5                        1              0  \n",
       "\n",
       "[5 rows x 16391 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "normalizer = StandardScaler()\n",
    "for c in non_cat_cols:\n",
    "    normed = normalizer.fit_transform(X_dummies[c].values.reshape(-1,1))\n",
    "    X_dummies[c] = normed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1lenmin</th>\n",
       "      <th>m1citywt</th>\n",
       "      <th>m1e1d1</th>\n",
       "      <th>m1e1d2</th>\n",
       "      <th>m1e1d3</th>\n",
       "      <th>m1i2a</th>\n",
       "      <th>m1i2b</th>\n",
       "      <th>m1j2a</th>\n",
       "      <th>m1j2b</th>\n",
       "      <th>cm1hhinc</th>\n",
       "      <th>...</th>\n",
       "      <th>hv4mflag_1.0</th>\n",
       "      <th>hv4mflag_2.0</th>\n",
       "      <th>hv4mflag_3.0</th>\n",
       "      <th>hv4mompreg_0.0</th>\n",
       "      <th>hv4mompreg_1.0</th>\n",
       "      <th>hv4selfht_0.0</th>\n",
       "      <th>hv4selfht_1.0</th>\n",
       "      <th>hv4selfht_2.0</th>\n",
       "      <th>hv4selfwt_0.0</th>\n",
       "      <th>hv4selfwt_1.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>challengeID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364267</td>\n",
       "      <td>0.675623</td>\n",
       "      <td>-0.545055</td>\n",
       "      <td>-0.788818</td>\n",
       "      <td>0.183309</td>\n",
       "      <td>0.255698</td>\n",
       "      <td>-0.245954</td>\n",
       "      <td>-1.512365</td>\n",
       "      <td>0.017524</td>\n",
       "      <td>-0.105330</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.364267</td>\n",
       "      <td>-0.197911</td>\n",
       "      <td>0.606432</td>\n",
       "      <td>-0.149595</td>\n",
       "      <td>-1.041256</td>\n",
       "      <td>-0.986483</td>\n",
       "      <td>-0.080941</td>\n",
       "      <td>-1.497946</td>\n",
       "      <td>-0.168142</td>\n",
       "      <td>-0.377045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.071568</td>\n",
       "      <td>-0.234372</td>\n",
       "      <td>0.990261</td>\n",
       "      <td>1.917563</td>\n",
       "      <td>1.345718</td>\n",
       "      <td>-1.464245</td>\n",
       "      <td>-0.448880</td>\n",
       "      <td>0.893159</td>\n",
       "      <td>-0.660072</td>\n",
       "      <td>3.089933</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.507403</td>\n",
       "      <td>-0.327670</td>\n",
       "      <td>-0.672998</td>\n",
       "      <td>0.344430</td>\n",
       "      <td>-0.719048</td>\n",
       "      <td>-1.464245</td>\n",
       "      <td>-0.448880</td>\n",
       "      <td>-0.693293</td>\n",
       "      <td>-0.848273</td>\n",
       "      <td>-1.023809</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.943238</td>\n",
       "      <td>-0.254094</td>\n",
       "      <td>3.613094</td>\n",
       "      <td>3.157858</td>\n",
       "      <td>5.522921</td>\n",
       "      <td>-2.228664</td>\n",
       "      <td>-0.210687</td>\n",
       "      <td>0.903948</td>\n",
       "      <td>0.636712</td>\n",
       "      <td>0.498527</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16391 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             m1lenmin  m1citywt    m1e1d1    m1e1d2    m1e1d3     m1i2a  \\\n",
       "challengeID                                                               \n",
       "1            0.364267  0.675623 -0.545055 -0.788818  0.183309  0.255698   \n",
       "2            0.364267 -0.197911  0.606432 -0.149595 -1.041256 -0.986483   \n",
       "3           -0.071568 -0.234372  0.990261  1.917563  1.345718 -1.464245   \n",
       "4           -0.507403 -0.327670 -0.672998  0.344430 -0.719048 -1.464245   \n",
       "5           -0.943238 -0.254094  3.613094  3.157858  5.522921 -2.228664   \n",
       "\n",
       "                m1i2b     m1j2a     m1j2b  cm1hhinc      ...        \\\n",
       "challengeID                                              ...         \n",
       "1           -0.245954 -1.512365  0.017524 -0.105330      ...         \n",
       "2           -0.080941 -1.497946 -0.168142 -0.377045      ...         \n",
       "3           -0.448880  0.893159 -0.660072  3.089933      ...         \n",
       "4           -0.448880 -0.693293 -0.848273 -1.023809      ...         \n",
       "5           -0.210687  0.903948  0.636712  0.498527      ...         \n",
       "\n",
       "             hv4mflag_1.0  hv4mflag_2.0  hv4mflag_3.0  hv4mompreg_0.0  \\\n",
       "challengeID                                                             \n",
       "1                       0             0             0               1   \n",
       "2                       0             0             0               0   \n",
       "3                       0             0             0               1   \n",
       "4                       0             0             0               1   \n",
       "5                       0             0             0               1   \n",
       "\n",
       "             hv4mompreg_1.0  hv4selfht_0.0  hv4selfht_1.0  hv4selfht_2.0  \\\n",
       "challengeID                                                                \n",
       "1                         0              1              0              0   \n",
       "2                         1              1              0              0   \n",
       "3                         0              1              0              0   \n",
       "4                         0              1              0              0   \n",
       "5                         0              1              0              0   \n",
       "\n",
       "             hv4selfwt_0.0  hv4selfwt_1.0  \n",
       "challengeID                                \n",
       "1                        1              0  \n",
       "2                        1              0  \n",
       "3                        1              0  \n",
       "4                        1              0  \n",
       "5                        1              0  \n",
       "\n",
       "[5 rows x 16391 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = X_dummies # rename X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now splitting the X and y matrices to separate cases in the training set and the prediction set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_training=X.loc[X.index.isin(train.index)]\n",
    "X_pred=X.loc[~X.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_training=y.loc[y.index.isin(train.index)]\n",
    "y_pred=y.loc[~y.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Randomly splitting the data into training and test sets, where 20% of data is held out for validation and testing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y_training.gpa, test_size=0.20, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Making a function that can be used to return Keras models with different parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def make_model(activation_function, num_hidden_layers, hidden_layer_size):\n",
    "    '''\n",
    "    A function to create a Keras sequential model based on input parameters.\n",
    "    \n",
    "    Parameters\n",
    "    -----------\n",
    "        activation_function: str\n",
    "            Activation function to be used in model.\n",
    "        \n",
    "        num_hidden_layers: int\n",
    "            Number of hidden layers in model\n",
    "        \n",
    "        hidden_layer_size: int\n",
    "            Number of units/neurons in each hidden layer\n",
    "            \n",
    "    Returns\n",
    "    ---------\n",
    "    \n",
    "    Keras Sequential model object\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    # Single layer model\n",
    "    if num_hidden_layers == 0: # then just specify a single layer, 1 is size of output\n",
    "        model.add(Dense(1, \n",
    "                        input_dim=X_train.shape[1], \n",
    "                        activation=activation_function,\n",
    "                        use_bias=True))\n",
    "        \n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # Specify initial layer with a hidden layer\n",
    "    if num_hidden_layers >= 1: \n",
    "        model.add(Dense(hidden_layer_size, \n",
    "                        input_dim=X_train.shape[1], \n",
    "                        activation=activation_function,\n",
    "                        use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    # Now add additional hidden layers\n",
    "    for i in range(0,num_hidden_layers-1):\n",
    "        model.add(Dense(hidden_layer_size, \n",
    "                        activation=activation_function, \n",
    "                        use_bias=True))\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "    if num_hidden_layers > 0:       \n",
    "        model.add(Dense(1)) # Final output layer, don't add if no hidden layers\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now I take the model object and use it to initialize a classifier using the scikit-learn Keras wrapped object `KerasRegressor`.\n",
    "\n",
    "I then define the parameter space to search over and pass both to a `GridSearchCV` object. \n",
    "\n",
    "Once the `fit` method is called the grid search will begin and a model will fit for every parameter combination and fold (40 x 5). \n",
    "\n",
    "***Note: This will take 12 hours or more to complete***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 0s - loss: 6.1142 - val_loss: 2.1755\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8160 - val_loss: 4.7218\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7045 - val_loss: 2.1697\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.3532 - val_loss: 2.6221\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.2107 - val_loss: 1.2855\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.2742 - val_loss: 2.9198\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5380 - val_loss: 1.6328\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.4179 - val_loss: 1.7968\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7831 - val_loss: 2.9256\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6302 - val_loss: 1.7297\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6459 - val_loss: 1.8230\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6861 - val_loss: 2.3496\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5597 - val_loss: 2.8047\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7140 - val_loss: 2.4051\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8832 - val_loss: 3.3339\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s - loss: 5.0752 - val_loss: 4.7925\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s - loss: 5.7396 - val_loss: 2.0757\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s - loss: 5.7495 - val_loss: 1.6552\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s - loss: 6.3722 - val_loss: 3.2801\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s - loss: 6.6611 - val_loss: 2.9041\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s - loss: 6.3237 - val_loss: 4.8171\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s - loss: 6.0616 - val_loss: 1.8039\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s - loss: 5.1433 - val_loss: 2.6962\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.9149 - val_loss: 4.5525\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.9380 - val_loss: 2.2238\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5104 - val_loss: 3.1099\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6748 - val_loss: 3.2555\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8454 - val_loss: 1.6463\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5932 - val_loss: 2.0588\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.4797 - val_loss: 1.6254\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.3117 - val_loss: 2.8076\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  10.5s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.8739 - val_loss: 1.3018\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0096 - val_loss: 1.4999\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8760 - val_loss: 3.2300\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6433 - val_loss: 1.6896\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7495 - val_loss: 1.3174\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6480 - val_loss: 1.7594\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2823 - val_loss: 2.8059\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8710 - val_loss: 2.5564\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4257 - val_loss: 2.5013\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9956 - val_loss: 2.1681\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4777 - val_loss: 1.4436\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5355 - val_loss: 2.5010\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6903 - val_loss: 4.1465\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6455 - val_loss: 3.5815\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7263 - val_loss: 1.2624\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8072 - val_loss: 4.7229\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3290 - val_loss: 1.5245\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7800 - val_loss: 1.7858\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9281 - val_loss: 2.0428\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0186 - val_loss: 1.6817\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7419 - val_loss: 1.9924\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4485 - val_loss: 1.2489\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5008 - val_loss: 3.8825\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5984 - val_loss: 2.5557\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4456 - val_loss: 2.8421\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4709 - val_loss: 0.9878\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5008 - val_loss: 3.7125\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8125 - val_loss: 1.3628\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8134 - val_loss: 2.0502\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8319 - val_loss: 1.6446\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0620 - val_loss: 1.2614\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7067 - val_loss: 2.9901\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5295 - val_loss: 1.6952\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0470 - val_loss: 2.5940\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0201 - val_loss: 2.4828\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9020 - val_loss: 2.6758\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5176 - val_loss: 1.8061\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3136 - val_loss: 1.8768\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.7560 - val_loss: 2.9057\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.7549 - val_loss: 0.8812\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.9313 - val_loss: 1.4444\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3930 - val_loss: 3.7250\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.1601 - val_loss: 3.5282\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7904 - val_loss: 1.2492\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6814 - val_loss: 2.7989\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.1119 - val_loss: 2.0577\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0479 - val_loss: 3.6723\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8148 - val_loss: 3.1142\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.2308 - val_loss: 1.5044\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8530 - val_loss: 2.1695\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7549 - val_loss: 1.3177\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0266 - val_loss: 5.1984\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3969 - val_loss: 2.9555\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3221 - val_loss: 1.0614\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9193 - val_loss: 3.6937\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6260 - val_loss: 1.5790\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4734 - val_loss: 2.9625\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6766 - val_loss: 3.1006\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4166 - val_loss: 3.1779\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5000 - val_loss: 3.4170\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6502 - val_loss: 3.3475\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.1795 - val_loss: 2.1649\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2879 - val_loss: 1.1788\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2456 - val_loss: 2.9093\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2737 - val_loss: 2.6886\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.0279 - val_loss: 2.4538\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  20.9s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.4141 - val_loss: 2.1693\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8935 - val_loss: 2.4466\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4976 - val_loss: 1.4204\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5056 - val_loss: 2.2588\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.1701 - val_loss: 3.7543\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5114 - val_loss: 1.2731\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6033 - val_loss: 3.0601\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7738 - val_loss: 1.9098\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4921 - val_loss: 2.8617\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5965 - val_loss: 1.5968\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6123 - val_loss: 4.2698\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4655 - val_loss: 3.1198\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3820 - val_loss: 3.0637\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7549 - val_loss: 3.4003\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8273 - val_loss: 2.2586\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.6173 - val_loss: 0.8490\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3228 - val_loss: 2.3408\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9664 - val_loss: 5.8161\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5534 - val_loss: 2.0843\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4376 - val_loss: 1.3032\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7308 - val_loss: 2.8310\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4482 - val_loss: 3.3091\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7182 - val_loss: 1.1154\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5578 - val_loss: 2.8660\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9567 - val_loss: 2.0345\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0381 - val_loss: 0.8536\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.0334 - val_loss: 3.0848\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 7.3110 - val_loss: 5.4854\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.1204 - val_loss: 3.1011\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.7522 - val_loss: 4.1791\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5617 - val_loss: 2.8075\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7934 - val_loss: 4.0856\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8493 - val_loss: 1.3892\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6796 - val_loss: 2.4819\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3256 - val_loss: 2.6843\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3012 - val_loss: 2.0035\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2974 - val_loss: 2.5839\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3493 - val_loss: 2.6684\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4661 - val_loss: 1.9715\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3541 - val_loss: 2.1909\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2623 - val_loss: 2.7264\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.2369 - val_loss: 2.9730\n",
      "Epoch 00041: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  13.5s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.8379 - val_loss: 2.6062\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7969 - val_loss: 2.1877\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7470 - val_loss: 1.9222\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7823 - val_loss: 3.7556\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7958 - val_loss: 1.5941\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6661 - val_loss: 4.1074\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5906 - val_loss: 1.5529\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5444 - val_loss: 3.8831\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7745 - val_loss: 3.1650\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.1275 - val_loss: 4.1002\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0673 - val_loss: 3.0896\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8255 - val_loss: 1.3601\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8363 - val_loss: 1.2428\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0816 - val_loss: 3.1206\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4972 - val_loss: 2.3146\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8991 - val_loss: 3.0008\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6058 - val_loss: 2.6302\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8469 - val_loss: 3.2141\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7310 - val_loss: 2.2975\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.1103 - val_loss: 2.7289\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5304 - val_loss: 3.1784\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5033 - val_loss: 3.8564\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.8581 - val_loss: 1.2628\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.2201 - val_loss: 6.2897\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3519 - val_loss: 1.7637\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9823 - val_loss: 1.4028\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9899 - val_loss: 1.7960\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7092 - val_loss: 2.8762\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4275 - val_loss: 2.2732\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3245 - val_loss: 3.3420\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5184 - val_loss: 2.2226\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6316 - val_loss: 2.0977\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.1732 - val_loss: 2.1850\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0615 - val_loss: 2.3384\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.1307 - val_loss: 1.7012\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0267 - val_loss: 1.6927\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4770 - val_loss: 3.1582\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4765 - val_loss: 2.1880\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4104 - val_loss: 2.4013\n",
      "Epoch 00038: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  12.2s\n",
      "[CV] activation_function=linear, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5829 - val_loss: 3.6678\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6009 - val_loss: 1.3231\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5665 - val_loss: 2.2461\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9503 - val_loss: 4.7438\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8728 - val_loss: 3.4456\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7071 - val_loss: 2.1802\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6372 - val_loss: 2.4581\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7008 - val_loss: 2.7056\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6466 - val_loss: 2.9607\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 4.908 - 0s - loss: 4.8574 - val_loss: 2.0009\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0391 - val_loss: 2.9549\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9257 - val_loss: 3.5136\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8386 - val_loss: 2.8664\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6817 - val_loss: 2.8047\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5422 - val_loss: 5.0047\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 7.0694 - val_loss: 3.0597\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3059 - val_loss: 3.0958\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.2205 - val_loss: 2.2372\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6782 - val_loss: 1.3870\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5392 - val_loss: 2.0004\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5725 - val_loss: 3.0369\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6730 - val_loss: 2.5686\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3488 - val_loss: 4.4119\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4824 - val_loss: 4.2038\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7008 - val_loss: 3.0550\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4337 - val_loss: 4.1832\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8218 - val_loss: 2.5746\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5571 - val_loss: 1.9600\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=0, num_hidden_layers=0, total=  10.8s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5948 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7131 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6991 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8178 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6821 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5177 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6106 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6098 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5671 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5870 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7654 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7618 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7330 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6025 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5921 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6401 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5914 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7477 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6084 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5825 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6098 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5958 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8156 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5457 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5265 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7005 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5125 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=   9.6s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7202 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5316 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4963 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7991 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6812 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6812 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5626 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7078 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5375 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6171 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7277 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6798 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4882 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5818 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5228 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7078 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6333 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6761 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5169 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6238 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6031 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7277 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5729 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5648 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5434 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5641 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7395 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=   9.2s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5411 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6096 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6177 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6582 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7039 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6781 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6530 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5499 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5889 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4357 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7687 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7570 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5071 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4541 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6744 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 4.671 - 0s - loss: 4.6501 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6398 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5602 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7282 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4865 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7216 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4895 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7312 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4968 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4917 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4614 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5970 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=  10.6s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5964 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6357 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6792 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6328 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4014 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5289 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5945 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6674 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5584 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6232 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7242 - val_loss: 3.5916ss: 4.90\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7131 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6910 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6357 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6063 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5097 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6976 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6932 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6696 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6564 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5694 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5075 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5576 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6881 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5473 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7175 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5031 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=   8.5s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5098 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6102 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6492 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7472 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6035 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5637 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8600 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6404 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7730 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7369 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3935 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3324 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6264 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4444 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6912 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5453 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5564 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8452 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4539 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7561 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6706 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5438 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7752 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6529 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6065 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7097 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5505 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=0, num_hidden_layers=0, total=   6.1s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2219 - val_loss: 8.1999\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 564s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 0s - loss: 8.2935 - val_loss: 8.1999\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total= 9.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.4999 - val_loss: 8.1999\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2465 - val_loss: 8.1999\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  11.8s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.4401 - val_loss: 8.1999\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 8.231 - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2640 - val_loss: 8.1999\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  11.2s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 7.7875 - val_loss: 6.3278\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.7232 - val_loss: 2.8427\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3701 - val_loss: 4.9961\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0073 - val_loss: 2.7342\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8740 - val_loss: 3.7872\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6663 - val_loss: 1.0960\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8349 - val_loss: 1.9221\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9001 - val_loss: 2.1091\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.2992 - val_loss: 1.4364\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.1350 - val_loss: 2.2589\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9162 - val_loss: 2.7608\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7276 - val_loss: 3.3036\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6377 - val_loss: 4.7156\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.3080 - val_loss: 1.5223\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9292 - val_loss: 2.7607\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0022 - val_loss: 1.5253\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7440 - val_loss: 2.5336\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8603 - val_loss: 2.1631\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5834 - val_loss: 3.5971\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5400 - val_loss: 2.6101\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6391 - val_loss: 2.5047\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3942 - val_loss: 2.2819\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5014 - val_loss: 2.5185\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6817 - val_loss: 2.8665\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3152 - val_loss: 1.8257\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4724 - val_loss: 2.1906\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7254 - val_loss: 2.2613\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4638 - val_loss: 3.0738\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8612 - val_loss: 1.9424\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.0392 - val_loss: 4.6747\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.6689 - val_loss: 6.2443\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5877 - val_loss: 3.3778\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=  12.2s\n",
      "[CV] activation_function=relu, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.4647 - val_loss: 8.1999\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.2918 - val_loss: 8.1999\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=0, num_hidden_layers=0, total=   9.0s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8121 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6592 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.3989 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7566 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5457 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5715 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.3960 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7315 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7684 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6194 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6371 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5907 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5877 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7625 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6637 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6570 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8185 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5914 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.7492 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6312 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5213 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6467 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6187 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6747 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.8775 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.6703 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 0s - loss: 4.5331 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=   8.5s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7815 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5700 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6488 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5670 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6238 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5287 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6554 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5744 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5921 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6488 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7137 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4837 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7918 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5722 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3496 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6201 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6437 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7402 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5515 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7262 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5560 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6215 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7505 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8176 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7137 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7085 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6134 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  10.7s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6812 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7120 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6398 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7614 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8019 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6413 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6420 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7503 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8159 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7223 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6442 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5035 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7068 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7216 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 4.801 - 0s - loss: 4.6523 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8115 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6184 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4924 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6892 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5093 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4644 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5963 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7894 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7164 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6752 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5875 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8513 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  10.7s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8011 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4876 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7094 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4773 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7138 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5606 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4029 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5502 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4699 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4692 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6689 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6711 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4714 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4633 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4950 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5377 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4699 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6586 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5348 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6881 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5945 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7146 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7175 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7374 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6998 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7124 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5959 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=  10.9s\n",
      "[CV] activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6970 - val_loss: 3.5916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6559 - val_loss: 3.5916\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6787 - val_loss: 3.5916\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5313 - val_loss: 3.5916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6411 - val_loss: 3.5916\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6205 - val_loss: 3.5916\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6116 - val_loss: 3.5916\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5490 - val_loss: 3.5916\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5726 - val_loss: 3.5916\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7561 - val_loss: 3.5916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6993 - val_loss: 3.5916\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6043 - val_loss: 3.5916\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7222 - val_loss: 3.5916\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7030 - val_loss: 3.5916\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6684 - val_loss: 3.5916\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7472 - val_loss: 3.5916\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5593 - val_loss: 3.5916\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4761 - val_loss: 3.5916\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6161 - val_loss: 3.5916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7141 - val_loss: 3.5916\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7804 - val_loss: 3.5916\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6396 - val_loss: 3.5916\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5276 - val_loss: 3.5916\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5431 - val_loss: 3.5916\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7170 - val_loss: 3.5916\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6861 - val_loss: 3.5916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.4282 - val_loss: 3.5916\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=0, num_hidden_layers=0, total=   9.7s\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 1s - loss: 135.0291 - val_loss: 10.0238\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 9.2268 - val_loss: 1.9664\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.8030 - val_loss: 1.7802\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.3496 - val_loss: 1.4920\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3683 - val_loss: 1.6717\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.1981 - val_loss: 1.7088\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.2703 - val_loss: 1.3494\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.2216 - val_loss: 2.6727\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.5852 - val_loss: 2.4069\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 7.3564 - val_loss: 2.5627\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 6.5450 - val_loss: 7.2476\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 5.0943 - val_loss: 1.8584\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.8044 - val_loss: 2.2182\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.6856 - val_loss: 1.5015\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.0444 - val_loss: 1.1990\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.7871 - val_loss: 3.2548\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 12.2224 - val_loss: 2.4242\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 5.9473 - val_loss: 2.2314\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.0393 - val_loss: 1.1196\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.7707 - val_loss: 0.8854\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.7682 - val_loss: 1.4206\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.1559 - val_loss: 1.9759\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.2758 - val_loss: 0.7488\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.0861 - val_loss: 1.6886\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.1321 - val_loss: 1.0634\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.0494 - val_loss: 0.6492\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3842 - val_loss: 1.1937\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.4849 - val_loss: 0.6914\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.6117 - val_loss: 0.5639\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4286 - val_loss: 0.6635\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0295 - val_loss: 0.7364\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1083 - val_loss: 0.7727\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1198 - val_loss: 0.5005\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1846 - val_loss: 0.8744\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2330 - val_loss: 0.5611\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1480 - val_loss: 0.4756\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0806 - val_loss: 0.5552\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0746 - val_loss: 0.5884\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8916 - val_loss: 0.4696\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8674 - val_loss: 0.4950\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.7606 - val_loss: 0.8825\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0067 - val_loss: 0.6614\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8248 - val_loss: 0.4467\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5767 - val_loss: 0.4543\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5746 - val_loss: 0.4182\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4753 - val_loss: 0.4508\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5289 - val_loss: 0.4373\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6132 - val_loss: 0.3944\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4700 - val_loss: 0.4026\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5405 - val_loss: 0.6591\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5033 - val_loss: 0.4610\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7991 - val_loss: 0.6520\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4885 - val_loss: 0.4461\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5798 - val_loss: 0.4271\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5109 - val_loss: 0.3837\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5000 - val_loss: 0.4580\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4055 - val_loss: 0.3758\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4073 - val_loss: 0.3794\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3725 - val_loss: 0.3834\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3637 - val_loss: 0.4660\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4282 - val_loss: 0.3757\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.3469 - val_loss: 0.4313\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.3356 - val_loss: 0.3890\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.3866 - val_loss: 0.4228\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.3799 - val_loss: 0.3721\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3471 - val_loss: 0.3955\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.3080 - val_loss: 0.3803\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.3420 - val_loss: 0.3945\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.2798 - val_loss: 0.3549\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.2522 - val_loss: 0.3547\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.2734 - val_loss: 0.3682\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3060 - val_loss: 0.3446\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2560 - val_loss: 0.3544\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3472 - val_loss: 0.4252\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2458 - val_loss: 0.3434\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2317 - val_loss: 0.3477\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2918 - val_loss: 0.3675\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2380 - val_loss: 0.3590\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2557 - val_loss: 0.3505\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2220 - val_loss: 0.3595\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1942 - val_loss: 0.3316\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1997 - val_loss: 0.3280\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2097 - val_loss: 0.3410\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2144 - val_loss: 0.3346\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2028 - val_loss: 0.3276\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2141 - val_loss: 0.3339\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1898 - val_loss: 0.3358\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1985 - val_loss: 0.3316\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1859 - val_loss: 0.3273\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1817 - val_loss: 0.3297\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1791 - val_loss: 0.3214\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1711 - val_loss: 0.3283\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1742 - val_loss: 0.3237\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1883 - val_loss: 0.3369\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1964 - val_loss: 0.3316\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2145 - val_loss: 0.3302\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1942 - val_loss: 0.3140\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1760 - val_loss: 0.3763\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1828 - val_loss: 0.3182\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1785 - val_loss: 0.3084\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1795 - val_loss: 0.3124\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1645 - val_loss: 0.3178\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1756 - val_loss: 0.3457\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1674 - val_loss: 0.3267\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1800 - val_loss: 0.3414\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1704 - val_loss: 0.3378\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1542 - val_loss: 0.3135\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1534 - val_loss: 0.3152\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1450 - val_loss: 0.3186\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1573 - val_loss: 0.3112\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1671 - val_loss: 0.3110\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1452 - val_loss: 0.3249\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1508 - val_loss: 0.3164\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1524 - val_loss: 0.3302\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1516 - val_loss: 0.3136\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 0s - loss: 0.1475 - val_loss: 0.3105\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1544 - val_loss: 0.3194\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1500 - val_loss: 0.3120\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1470 - val_loss: 0.3207\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1447 - val_loss: 0.3248\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1365 - val_loss: 0.3114\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1355 - val_loss: 0.3163\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1347 - val_loss: 0.3135\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1438 - val_loss: 0.3278\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1353 - val_loss: 0.3178\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1592 - val_loss: 0.3197\n",
      "Epoch 00125: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 160.0851 - val_loss: 4.2555\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.8352 - val_loss: 2.4513\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.5414 - val_loss: 1.6429\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.4567 - val_loss: 4.9208\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.6486 - val_loss: 2.2084\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.2878 - val_loss: 2.5323\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0884 - val_loss: 0.9829\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.5573 - val_loss: 0.9137\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.3653 - val_loss: 1.0582\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 3.3856 - val_loss: 1.1759\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.8018 - val_loss: 2.7218\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 6.5673 - val_loss: 8.5795\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 21.9159 - val_loss: 6.8086\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 13.5965 - val_loss: 5.4032\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 8.7843 - val_loss: 3.1054\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.9353 - val_loss: 0.9734\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.7346 - val_loss: 1.0200\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.5590 - val_loss: 0.8867\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 3.6694 - val_loss: 5.6255\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.1839 - val_loss: 1.3718\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.8474 - val_loss: 1.3797\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.8535 - val_loss: 1.3345\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.7209 - val_loss: 1.2489\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.7130 - val_loss: 0.6120\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6760 - val_loss: 1.9069\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 3.2600 - val_loss: 0.8836\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.9975 - val_loss: 1.0989\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.8467 - val_loss: 1.0277\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.7433 - val_loss: 0.9329\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.3162 - val_loss: 0.5801\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.1107 - val_loss: 0.8837\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.3800 - val_loss: 0.7318\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3875 - val_loss: 0.6214\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3172 - val_loss: 0.5268\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3217 - val_loss: 0.6715\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9736 - val_loss: 1.2070\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8833 - val_loss: 0.5890\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0884 - val_loss: 0.6925\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9066 - val_loss: 0.4846\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7526 - val_loss: 0.6632\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1850 - val_loss: 0.4893\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8756 - val_loss: 0.9133\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9223 - val_loss: 1.0424\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9042 - val_loss: 0.4810\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9167 - val_loss: 0.7767\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9997 - val_loss: 0.5271\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6876 - val_loss: 0.5088\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8576 - val_loss: 0.9125\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0007 - val_loss: 0.7435\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7905 - val_loss: 0.4773\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7738 - val_loss: 0.4463\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5645 - val_loss: 0.4102\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6202 - val_loss: 0.5942\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4826 - val_loss: 0.6187\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5919 - val_loss: 0.4134\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4981 - val_loss: 0.4086\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4478 - val_loss: 0.6762\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5197 - val_loss: 0.7023\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5463 - val_loss: 0.4552\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3925 - val_loss: 0.4110\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4454 - val_loss: 0.4714\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5163 - val_loss: 0.4432\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3706 - val_loss: 0.3970\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3376 - val_loss: 0.4224\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4600 - val_loss: 0.5693\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3767 - val_loss: 0.3979\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3355 - val_loss: 0.4987\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3427 - val_loss: 0.4134\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4961 - val_loss: 0.3862\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3881 - val_loss: 0.4844\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4129 - val_loss: 0.3873\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3266 - val_loss: 0.4028\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3079 - val_loss: 0.4136\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3151 - val_loss: 0.3779\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2929 - val_loss: 0.4584\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2701 - val_loss: 0.3899\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2970 - val_loss: 0.3672\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3467 - val_loss: 0.4469\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2567 - val_loss: 0.3788\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2262 - val_loss: 0.4455\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2484 - val_loss: 0.3728\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2617 - val_loss: 0.3938\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2854 - val_loss: 0.3654\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2567 - val_loss: 0.3424\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2401 - val_loss: 0.3751\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2481 - val_loss: 0.3573\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2291 - val_loss: 0.3510\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2195 - val_loss: 0.3421\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2234 - val_loss: 0.3490\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2178 - val_loss: 0.3452\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2057 - val_loss: 0.3595\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1905 - val_loss: 0.3713\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2072 - val_loss: 0.3427\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2014 - val_loss: 0.3636\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2113 - val_loss: 0.3410\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1862 - val_loss: 0.3867\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2027 - val_loss: 0.3506\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1904 - val_loss: 0.3403\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1943 - val_loss: 0.3312\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1715 - val_loss: 0.3364\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1915 - val_loss: 0.3361\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1800 - val_loss: 0.3325\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1878 - val_loss: 0.3372\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1848 - val_loss: 0.3676\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1850 - val_loss: 0.3546\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1632 - val_loss: 0.3529\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1710 - val_loss: 0.3422\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1641 - val_loss: 0.3705\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1779 - val_loss: 0.3401\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1808 - val_loss: 0.3385\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1671 - val_loss: 0.3540\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1704 - val_loss: 0.3298\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1621 - val_loss: 0.3294\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1670 - val_loss: 0.3333\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1669 - val_loss: 0.3288\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1550 - val_loss: 0.3256\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1486 - val_loss: 0.3503\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1553 - val_loss: 0.3251\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1511 - val_loss: 0.3233\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1420 - val_loss: 0.3291\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1427 - val_loss: 0.3281\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1429 - val_loss: 0.3272\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1496 - val_loss: 0.3470\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1382 - val_loss: 0.3602\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1701 - val_loss: 0.3192\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1478 - val_loss: 0.3268\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1453 - val_loss: 0.3438\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1430 - val_loss: 0.3268\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1468 - val_loss: 0.3285\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1366 - val_loss: 0.3264\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1332 - val_loss: 0.3562\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1371 - val_loss: 0.3260\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1362 - val_loss: 0.3288\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1369 - val_loss: 0.3726\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1425 - val_loss: 0.3379\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1369 - val_loss: 0.3237\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1317 - val_loss: 0.3303\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1401 - val_loss: 0.4041\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1364 - val_loss: 0.3207\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1149 - val_loss: 0.3273\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1359 - val_loss: 0.3286\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1371 - val_loss: 0.3238\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1181 - val_loss: 0.3265\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1261 - val_loss: 0.3518\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1309 - val_loss: 0.3161\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1143 - val_loss: 0.3243\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1239 - val_loss: 0.3227\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1367 - val_loss: 0.3260\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1133 - val_loss: 0.3215\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1192 - val_loss: 0.3618\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1090 - val_loss: 0.3143\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1214 - val_loss: 0.3347\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1185 - val_loss: 0.3160\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1224 - val_loss: 0.3165\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1084 - val_loss: 0.3139\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1044 - val_loss: 0.3217\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1078 - val_loss: 0.3148\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1174 - val_loss: 0.3183\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1194 - val_loss: 0.3242\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1061 - val_loss: 0.3598\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1266 - val_loss: 0.3267\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1076 - val_loss: 0.3241\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1122 - val_loss: 0.3177\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1011 - val_loss: 0.3186\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1035 - val_loss: 0.3186\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0971 - val_loss: 0.3131\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0944 - val_loss: 0.3175\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1045 - val_loss: 0.3176\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1063 - val_loss: 0.3365\n",
      "Epoch 170/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1096 - val_loss: 0.3268\n",
      "Epoch 171/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0878 - val_loss: 0.3196\n",
      "Epoch 172/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1010 - val_loss: 0.3197\n",
      "Epoch 173/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1150 - val_loss: 0.3204\n",
      "Epoch 174/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0980 - val_loss: 0.3112\n",
      "Epoch 175/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1050 - val_loss: 0.3094\n",
      "Epoch 176/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0842 - val_loss: 0.3114\n",
      "Epoch 177/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1009 - val_loss: 0.3152\n",
      "Epoch 178/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0998 - val_loss: 0.3147\n",
      "Epoch 179/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0908 - val_loss: 0.3184\n",
      "Epoch 180/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0860 - val_loss: 0.3215\n",
      "Epoch 181/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0874 - val_loss: 0.3228\n",
      "Epoch 182/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0908 - val_loss: 0.3173\n",
      "Epoch 183/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0975 - val_loss: 0.3165\n",
      "Epoch 184/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0939 - val_loss: 0.3453\n",
      "Epoch 185/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0963 - val_loss: 0.3212\n",
      "Epoch 186/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0829 - val_loss: 0.3467\n",
      "Epoch 187/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0861 - val_loss: 0.3318\n",
      "Epoch 188/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0805 - val_loss: 0.3112\n",
      "Epoch 189/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0821 - val_loss: 0.3167\n",
      "Epoch 190/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1027 - val_loss: 0.3397\n",
      "Epoch 191/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0951 - val_loss: 0.3199\n",
      "Epoch 192/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0804 - val_loss: 0.3287\n",
      "Epoch 193/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0838 - val_loss: 0.3543\n",
      "Epoch 194/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0864 - val_loss: 0.3190\n",
      "Epoch 195/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0831 - val_loss: 0.3684\n",
      "Epoch 196/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0866 - val_loss: 0.3158\n",
      "Epoch 197/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0851 - val_loss: 0.3159\n",
      "Epoch 198/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0790 - val_loss: 0.3266\n",
      "Epoch 199/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0770 - val_loss: 0.3149\n",
      "Epoch 200/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0712 - val_loss: 0.3290\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 3.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 182.3218 - val_loss: 15.1993\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.5732 - val_loss: 2.0320\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.9533 - val_loss: 1.4396\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2755 - val_loss: 1.4930\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.0082 - val_loss: 2.7450\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9717 - val_loss: 2.2093\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2011 - val_loss: 5.6902\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.4910 - val_loss: 9.6564\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.6645 - val_loss: 2.0497\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.1090 - val_loss: 1.2192\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.7354 - val_loss: 2.4278\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4733 - val_loss: 2.0024\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.0170 - val_loss: 2.1150\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.5005 - val_loss: 4.4006\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.5617 - val_loss: 2.0321\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.7108 - val_loss: 2.9288\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.7797 - val_loss: 2.5672\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 17.2649 - val_loss: 29.0445\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.8399 - val_loss: 2.3454\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.3280 - val_loss: 0.8027\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.1876 - val_loss: 0.8404\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9242 - val_loss: 1.8333\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.4858 - val_loss: 1.6110\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3625 - val_loss: 1.3099\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4717 - val_loss: 1.0776\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7573 - val_loss: 1.8479\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7956 - val_loss: 1.8184\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6231 - val_loss: 0.6403\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2771 - val_loss: 0.5153\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2465 - val_loss: 0.8378\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9003 - val_loss: 1.2959\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2334 - val_loss: 0.6999\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2109 - val_loss: 0.8555\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9973 - val_loss: 0.5299\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8933 - val_loss: 0.7427\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3581 - val_loss: 0.9824\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0052 - val_loss: 0.6109\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1341 - val_loss: 0.6131\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8412 - val_loss: 0.7226ss:\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9505 - val_loss: 0.5019\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7354 - val_loss: 0.4971\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9978 - val_loss: 0.6532\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8831 - val_loss: 0.7406\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1390 - val_loss: 0.7433\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0133 - val_loss: 0.6503\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7620 - val_loss: 0.7119\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8281 - val_loss: 0.5666\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5343 - val_loss: 0.4309\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6324 - val_loss: 0.4753\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5934 - val_loss: 0.6978\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5162 - val_loss: 0.4229\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5776 - val_loss: 0.4268\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4746 - val_loss: 0.4220\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5688 - val_loss: 0.6869\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7248 - val_loss: 0.4289\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4642 - val_loss: 0.6199\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4978 - val_loss: 0.4341\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4742 - val_loss: 0.5321\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4746 - val_loss: 0.4697\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4696 - val_loss: 0.3922\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4704 - val_loss: 0.5659\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4484 - val_loss: 0.4339ss:\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4162 - val_loss: 0.4414\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4750 - val_loss: 0.6991\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4539 - val_loss: 0.4730\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3726 - val_loss: 0.3896\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4084 - val_loss: 0.4722\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3776 - val_loss: 0.3945\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3546 - val_loss: 0.3802\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3546 - val_loss: 0.3855\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3254 - val_loss: 0.4360\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3684 - val_loss: 0.4231\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2929 - val_loss: 0.3962\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2813 - val_loss: 0.3738\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2600 - val_loss: 0.3948\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2887 - val_loss: 0.3648\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3034 - val_loss: 0.3531\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2607 - val_loss: 0.3847\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2683 - val_loss: 0.3571\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2586 - val_loss: 0.4023\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2899 - val_loss: 0.4022\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2660 - val_loss: 0.3803\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2551 - val_loss: 0.3600\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2310 - val_loss: 0.3532\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2148 - val_loss: 0.3527ss: 0.2\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2223 - val_loss: 0.3533\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2193 - val_loss: 0.3503\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2168 - val_loss: 0.3556\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2004 - val_loss: 0.3488\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2006 - val_loss: 0.3877\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1849 - val_loss: 0.3704\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2052 - val_loss: 0.3527\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2034 - val_loss: 0.3701\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1948 - val_loss: 0.3503\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2102 - val_loss: 0.3352\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1731 - val_loss: 0.3388\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1872 - val_loss: 0.3750\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1900 - val_loss: 0.3560\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1920 - val_loss: 0.3454\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1666 - val_loss: 0.3381\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1785 - val_loss: 0.3651\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1587 - val_loss: 0.3499\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1739 - val_loss: 0.3325\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1816 - val_loss: 0.3326\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1631 - val_loss: 0.3484\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1656 - val_loss: 0.3298\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1673 - val_loss: 0.3499\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1681 - val_loss: 0.3506\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1769 - val_loss: 0.3254\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1608 - val_loss: 0.3367\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1559 - val_loss: 0.3235\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1615 - val_loss: 0.3264\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1496 - val_loss: 0.3297\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1677 - val_loss: 0.3308\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1515 - val_loss: 0.3212\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1520 - val_loss: 0.3201\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1466 - val_loss: 0.3257\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1461 - val_loss: 0.3249\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1385 - val_loss: 0.3506\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1480 - val_loss: 0.3487\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1493 - val_loss: 0.3218\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1426 - val_loss: 0.3262\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1404 - val_loss: 0.3275\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1407 - val_loss: 0.3692\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1322 - val_loss: 0.3283\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1425 - val_loss: 0.3237\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1361 - val_loss: 0.3276\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1338 - val_loss: 0.3241\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1266 - val_loss: 0.3287\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1354 - val_loss: 0.3271\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1262 - val_loss: 0.3284\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1319 - val_loss: 0.3212\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1296 - val_loss: 0.3276\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1291 - val_loss: 0.3343\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1387 - val_loss: 0.3247\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1351 - val_loss: 0.3245s\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1179 - val_loss: 0.3285\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1263 - val_loss: 0.3254\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1259 - val_loss: 0.3460\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1256 - val_loss: 0.3303\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1208 - val_loss: 0.3276\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1188 - val_loss: 0.3284\n",
      "Epoch 00141: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 2.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 143.3046 - val_loss: 11.6330\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.6306 - val_loss: 3.7189\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.6401 - val_loss: 4.0047\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.1661 - val_loss: 4.1305\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4427 - val_loss: 2.2809\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9141 - val_loss: 1.3906\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1488 - val_loss: 2.0934\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2824 - val_loss: 2.1851\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.3566 - val_loss: 4.5366\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.2085 - val_loss: 1.3655\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.7552 - val_loss: 1.6531\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.6916 - val_loss: 4.7241\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.3275 - val_loss: 2.0435\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.2406 - val_loss: 3.2023\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.1820 - val_loss: 1.2262\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.4625 - val_loss: 3.4898\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.1019 - val_loss: 7.0390\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.3545 - val_loss: 2.4567\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.5161 - val_loss: 2.5113\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.8743 - val_loss: 1.3467\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.1595 - val_loss: 1.2380\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2570 - val_loss: 1.8703\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.8336 - val_loss: 1.9393\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.3058 - val_loss: 0.8606\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.9143 - val_loss: 2.4984\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3240 - val_loss: 0.8220\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7657 - val_loss: 1.6264\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6230 - val_loss: 0.6991\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5842 - val_loss: 0.9895\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8615 - val_loss: 1.0017\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2365 - val_loss: 0.7334\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1490 - val_loss: 0.7098\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8868 - val_loss: 0.7878\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0260 - val_loss: 0.5392\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9124 - val_loss: 0.4917\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9902 - val_loss: 0.4777\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6491 - val_loss: 0.5319\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7436 - val_loss: 0.4452\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6069 - val_loss: 0.5825\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2005 - val_loss: 0.8484\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6518 - val_loss: 0.4332\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6321 - val_loss: 1.0745\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8329 - val_loss: 0.6901\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3237 - val_loss: 0.7285\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2202 - val_loss: 0.5901\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6193 - val_loss: 0.5558\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5016 - val_loss: 0.5271\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0352 - val_loss: 0.5737\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5210 - val_loss: 0.5258\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4375 - val_loss: 0.5658\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4647 - val_loss: 0.3681\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4282 - val_loss: 0.4138\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4852 - val_loss: 0.4929\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4522 - val_loss: 0.4043\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3481 - val_loss: 0.3708\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3159 - val_loss: 0.4119\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3124 - val_loss: 0.3707\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2976 - val_loss: 0.3973\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3027 - val_loss: 0.3793\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3241 - val_loss: 0.5569\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3108 - val_loss: 0.3648\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2893 - val_loss: 0.3952\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2641 - val_loss: 0.3638\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3132 - val_loss: 0.3868\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2465 - val_loss: 0.3693\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2392 - val_loss: 0.3642\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2463 - val_loss: 0.3689\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2519 - val_loss: 0.3744\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2289 - val_loss: 0.3903\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2615 - val_loss: 0.3638\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3511 - val_loss: 0.3942\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2410 - val_loss: 0.3630\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2440 - val_loss: 0.3620\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2321 - val_loss: 0.3758\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2441 - val_loss: 0.3598\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2367 - val_loss: 0.3457\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2218 - val_loss: 0.4064\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2158 - val_loss: 0.3395\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1977 - val_loss: 0.3457\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2072 - val_loss: 0.3499\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2100 - val_loss: 0.3519\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2052 - val_loss: 0.3467\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1868 - val_loss: 0.3521\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1956 - val_loss: 0.3472\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2147 - val_loss: 0.3748\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2046 - val_loss: 0.3933\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2233 - val_loss: 0.3549\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1850 - val_loss: 0.3422\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1997 - val_loss: 0.3732\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1962 - val_loss: 0.3474\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1987 - val_loss: 0.3443\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1605 - val_loss: 0.3487\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1893 - val_loss: 0.3310\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1633 - val_loss: 0.3494\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1683 - val_loss: 0.3825\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1894 - val_loss: 0.3551\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1776 - val_loss: 0.3411\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1767 - val_loss: 0.3453\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1722 - val_loss: 0.3352\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1679 - val_loss: 0.3510\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1750 - val_loss: 0.3352\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1721 - val_loss: 0.3436\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1574 - val_loss: 0.3448\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1730 - val_loss: 0.3325\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1516 - val_loss: 0.3308\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1584 - val_loss: 0.3289\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1482 - val_loss: 0.3284\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1480 - val_loss: 0.3360\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1559 - val_loss: 0.3397\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1590 - val_loss: 0.3494\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1599 - val_loss: 0.3390\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1565 - val_loss: 0.3316\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1512 - val_loss: 0.3286\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1494 - val_loss: 0.3284\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1534 - val_loss: 0.3330\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1472 - val_loss: 0.3281\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1427 - val_loss: 0.3357\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1415 - val_loss: 0.3419\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1600 - val_loss: 0.3276\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1514 - val_loss: 0.3415\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1314 - val_loss: 0.3343\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1319 - val_loss: 0.3274\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1384 - val_loss: 0.3225\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1440 - val_loss: 0.3318\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1294 - val_loss: 0.3264\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1287 - val_loss: 0.3360\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1358 - val_loss: 0.3466\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1363 - val_loss: 0.3243\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1249 - val_loss: 0.3248\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1313 - val_loss: 0.3540\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1394 - val_loss: 0.3241\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1268 - val_loss: 0.3243\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1246 - val_loss: 0.3376\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1197 - val_loss: 0.3273\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1204 - val_loss: 0.3305\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1189 - val_loss: 0.3242\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1286 - val_loss: 0.3444\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1185 - val_loss: 0.3249\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1325 - val_loss: 0.3288\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1242 - val_loss: 0.3272\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1281 - val_loss: 0.3256\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1236 - val_loss: 0.3288\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1274 - val_loss: 0.3273\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1153 - val_loss: 0.3292\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1125 - val_loss: 0.3316\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1077 - val_loss: 0.3274\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1124 - val_loss: 0.3280\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1264 - val_loss: 0.3598\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1300 - val_loss: 0.3259\n",
      "Epoch 00148: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 2.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 133.2643 - val_loss: 11.9995\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.6252 - val_loss: 6.0407\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.9008 - val_loss: 2.3063\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.2874 - val_loss: 1.3898\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4496 - val_loss: 0.9007\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3412 - val_loss: 1.1992\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.6442 - val_loss: 2.0211\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4043 - val_loss: 1.3240\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.2728 - val_loss: 1.3148\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.0498 - val_loss: 2.3456\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.9856 - val_loss: 3.5662\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.5875 - val_loss: 3.5457\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.2694 - val_loss: 1.4356\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4438 - val_loss: 0.8216\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7428 - val_loss: 2.1304\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5216 - val_loss: 0.9543\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.5110 - val_loss: 1.7542\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1804 - val_loss: 2.8242\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.4414 - val_loss: 1.5767\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6166 - val_loss: 0.7797\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.8045 - val_loss: 0.9972\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7103 - val_loss: 1.0763\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.3917 - val_loss: 1.0127\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4427 - val_loss: 0.9603\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3056 - val_loss: 1.1638ss: 2.3\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0175 - val_loss: 0.9214\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6892 - val_loss: 1.0020ss: 1\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6067 - val_loss: 1.1299\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9409 - val_loss: 1.1703\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6762 - val_loss: 1.0696\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.4794 - val_loss: 0.7781\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.2362 - val_loss: 0.5659\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.4988 - val_loss: 0.6466\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.0941 - val_loss: 0.6554\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.0169 - val_loss: 0.9014\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8726 - val_loss: 0.4991\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8626 - val_loss: 0.6758\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7862 - val_loss: 0.5059\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7619 - val_loss: 0.5343\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6524 - val_loss: 0.4964\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7372 - val_loss: 0.7145\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.9330 - val_loss: 0.6593\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8968 - val_loss: 0.9980\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7794 - val_loss: 0.5675\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.9463 - val_loss: 0.4618\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7956 - val_loss: 0.4510\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5367 - val_loss: 0.7830\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7502 - val_loss: 0.8758\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7744 - val_loss: 0.5995\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7444 - val_loss: 0.4366\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4658 - val_loss: 0.4380\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4148 - val_loss: 0.4301\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3844 - val_loss: 0.5376\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5009 - val_loss: 0.4046\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4220 - val_loss: 0.4098\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3900 - val_loss: 0.4034\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3392 - val_loss: 0.4112\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3743 - val_loss: 0.5207\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4104 - val_loss: 0.3902\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3124 - val_loss: 0.3907\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3216 - val_loss: 0.3877\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2940 - val_loss: 0.3776\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3080 - val_loss: 0.3914\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2942 - val_loss: 0.3975\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3194 - val_loss: 0.3791\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2469 - val_loss: 0.3997\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2790 - val_loss: 0.4209\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2800 - val_loss: 0.3655\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2459 - val_loss: 0.3620\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2179 - val_loss: 0.3616\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2224 - val_loss: 0.3496\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2717 - val_loss: 0.3490\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2366 - val_loss: 0.3684\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2244 - val_loss: 0.3621\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2473 - val_loss: 0.3944\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2229 - val_loss: 0.3820\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2220 - val_loss: 0.3539\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2166 - val_loss: 0.3540\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2361 - val_loss: 0.3527\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2328 - val_loss: 0.3394\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2263 - val_loss: 0.3523\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1862 - val_loss: 0.3591\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2080 - val_loss: 0.3794\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2023 - val_loss: 0.3555\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2133 - val_loss: 0.3417\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1929 - val_loss: 0.3556\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2066 - val_loss: 0.3434\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1906 - val_loss: 0.3429\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1745 - val_loss: 0.3503\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1937 - val_loss: 0.3394\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1828 - val_loss: 0.3312\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2011 - val_loss: 0.3491\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1732 - val_loss: 0.3523\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1792 - val_loss: 0.3362\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1615 - val_loss: 0.3319\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.169 - 0s - loss: 0.1696 - val_loss: 0.3503\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1650 - val_loss: 0.3542\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1835 - val_loss: 0.3305\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1799 - val_loss: 0.3301\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1647 - val_loss: 0.3360\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.189 - 0s - loss: 0.1885 - val_loss: 0.3683\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1735 - val_loss: 0.3369\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1667 - val_loss: 0.3626\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1825 - val_loss: 0.3522\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1547 - val_loss: 0.3792\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1602 - val_loss: 0.3412\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1449 - val_loss: 0.3478\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1584 - val_loss: 0.3372\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1565 - val_loss: 0.3388\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1704 - val_loss: 0.3713\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1558 - val_loss: 0.3384\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1512 - val_loss: 0.3336\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1436 - val_loss: 0.3249\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1400 - val_loss: 0.3260\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1445 - val_loss: 0.3440\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1318 - val_loss: 0.3262\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1474 - val_loss: 0.3608\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1376 - val_loss: 0.3310\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1469 - val_loss: 0.3298\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1342 - val_loss: 0.3269\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1346 - val_loss: 0.3298\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1431 - val_loss: 0.3365\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1272 - val_loss: 0.3307\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1366 - val_loss: 0.3243\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1265 - val_loss: 0.3857\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1461 - val_loss: 0.3266\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1332 - val_loss: 0.3247\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1242 - val_loss: 0.3291\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1389 - val_loss: 0.3362\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1219 - val_loss: 0.3310\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1276 - val_loss: 0.3245\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1214 - val_loss: 0.3259\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1160 - val_loss: 0.3264\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1423 - val_loss: 0.3230\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1163 - val_loss: 0.3248\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1169 - val_loss: 0.3344\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1268 - val_loss: 0.3268\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1182 - val_loss: 0.3226\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1318 - val_loss: 0.3396\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1246 - val_loss: 0.3277\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1195 - val_loss: 0.3251\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1233 - val_loss: 0.3505\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1168 - val_loss: 0.3217\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1283 - val_loss: 0.3274\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1325 - val_loss: 0.3296\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1134 - val_loss: 0.3263\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1115 - val_loss: 0.3299\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1081 - val_loss: 0.3267\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1249 - val_loss: 0.3310\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1085 - val_loss: 0.3264\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1120 - val_loss: 0.3430\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1043 - val_loss: 0.3275\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1152 - val_loss: 0.3898\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1175 - val_loss: 0.3339\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1033 - val_loss: 0.3316\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1214 - val_loss: 0.3324\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1099 - val_loss: 0.3345\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.0985 - val_loss: 0.3403\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1124 - val_loss: 0.3517\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1078 - val_loss: 0.3589\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1058 - val_loss: 0.3235\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1052 - val_loss: 0.3238\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1083 - val_loss: 0.3485\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.0987 - val_loss: 0.3215\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1016 - val_loss: 0.3359\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1038 - val_loss: 0.3227\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.0909 - val_loss: 0.3207\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.0882 - val_loss: 0.3209\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1134 - val_loss: 0.3819\n",
      "Epoch 00168: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=1, total= 2.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 1s - loss: 105.9271 - val_loss: 1.1404\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 10.9981 - val_loss: 1.0053\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 9.4747 - val_loss: 0.7167\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 9.3733 - val_loss: 0.7399\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 10.5029 - val_loss: 0.8869\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 11.4645 - val_loss: 1.0677\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 12.4000 - val_loss: 0.8740\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 11.6994 - val_loss: 0.5414\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 11.4154 - val_loss: 0.5398\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 13.1264 - val_loss: 0.6347\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 13.9441 - val_loss: 0.5516\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 10.7965 - val_loss: 1.2716\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 10.7272 - val_loss: 0.5702\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 9.1643 - val_loss: 0.4002\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 7.1737 - val_loss: 0.6191\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 7.0451 - val_loss: 0.7781\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 7.8132 - val_loss: 0.4692\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 5.5337 - val_loss: 0.3628\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 5.7771 - val_loss: 0.5030\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.2046 - val_loss: 0.4444\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.6258 - val_loss: 0.4218\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.4910 - val_loss: 0.5337\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.5592 - val_loss: 0.4457\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.1579 - val_loss: 0.5123\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.7717 - val_loss: 0.8996\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.6277 - val_loss: 0.3492\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3706 - val_loss: 0.4031\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.2707 - val_loss: 0.6300\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.1193 - val_loss: 0.2994\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.9560 - val_loss: 0.3381\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.9672 - val_loss: 0.3232\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.6239 - val_loss: 0.4797\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.6539 - val_loss: 0.3877\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4331 - val_loss: 0.3445\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4540 - val_loss: 0.4431\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.5345 - val_loss: 0.4136\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4792 - val_loss: 0.3302\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2631 - val_loss: 0.3315\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1975 - val_loss: 0.4195\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1800 - val_loss: 0.3231\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3027 - val_loss: 0.3096\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9899 - val_loss: 0.3307\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8403 - val_loss: 0.3427\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0347 - val_loss: 0.3020\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9050 - val_loss: 0.3258\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7849 - val_loss: 0.2949\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8808 - val_loss: 0.3287\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7394 - val_loss: 0.3329\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6904 - val_loss: 0.3411\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6618 - val_loss: 0.2996\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6651 - val_loss: 0.3397\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6141 - val_loss: 0.3639\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6043 - val_loss: 0.2916\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5689 - val_loss: 0.2942\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5662 - val_loss: 0.2938\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5760 - val_loss: 0.2992\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6102 - val_loss: 0.3125\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5201 - val_loss: 0.2972\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5415 - val_loss: 0.3109\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4690 - val_loss: 0.3158\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4568 - val_loss: 0.3168\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5239 - val_loss: 0.3396\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4365 - val_loss: 0.2913\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4312 - val_loss: 0.3209\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4090 - val_loss: 0.2882\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4301 - val_loss: 0.2960\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3793 - val_loss: 0.3126\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3702 - val_loss: 0.2855\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3688 - val_loss: 0.3539\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3739 - val_loss: 0.2897\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3567 - val_loss: 0.2880\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3823 - val_loss: 0.3500\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3480 - val_loss: 0.2971\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3324 - val_loss: 0.3171\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3309 - val_loss: 0.2945\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3403 - val_loss: 0.2934\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2927 - val_loss: 0.3200\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3337 - val_loss: 0.3597\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3176 - val_loss: 0.3224\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3104 - val_loss: 0.3006\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2955 - val_loss: 0.3396\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3027 - val_loss: 0.3008\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2959 - val_loss: 0.2969\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2894 - val_loss: 0.3034\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2783 - val_loss: 0.3152\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2744 - val_loss: 0.3458\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2702 - val_loss: 0.3086\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2631 - val_loss: 0.3162\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2632 - val_loss: 0.3024\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2683 - val_loss: 0.3051\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2425 - val_loss: 0.2950\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2370 - val_loss: 0.3362\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2443 - val_loss: 0.2968\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2386 - val_loss: 0.3050\n",
      "Epoch 00093: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 1.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 158.3242 - val_loss: 0.8731\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.6162 - val_loss: 0.5811\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.6005 - val_loss: 0.7430\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.1497 - val_loss: 0.5853\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.1919 - val_loss: 0.6876\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.8765 - val_loss: 0.6984\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.4742 - val_loss: 2.3866\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.4473 - val_loss: 0.4338\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.9052 - val_loss: 0.6029\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.5810 - val_loss: 1.3212\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.0654 - val_loss: 2.2273\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.4089 - val_loss: 0.6175\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 18.5550 - val_loss: 1.1101\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.2278 - val_loss: 0.8187\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.2347 - val_loss: 0.4906\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.5864 - val_loss: 1.4457\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.8167 - val_loss: 1.0223\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.9559 - val_loss: 1.2809\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.2032 - val_loss: 1.0828\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.5040 - val_loss: 1.0423\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.3514 - val_loss: 1.6256\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.0824 - val_loss: 0.5886\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.7954 - val_loss: 0.3862\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.7564 - val_loss: 0.6158\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.5961 - val_loss: 0.4757\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.0720 - val_loss: 1.1404\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.7497 - val_loss: 0.4569\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1696 - val_loss: 0.3346\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9982 - val_loss: 0.5678\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.0901 - val_loss: 0.4303\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6301 - val_loss: 0.3175\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4456 - val_loss: 0.4360\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0758 - val_loss: 0.3873\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5260 - val_loss: 0.4433\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3966 - val_loss: 0.3151\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8615 - val_loss: 0.7437\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0420 - val_loss: 0.3244\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9409 - val_loss: 0.4536\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4469 - val_loss: 0.6604\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0640 - val_loss: 0.4121\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8110 - val_loss: 0.4354\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8545 - val_loss: 0.3289\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6252 - val_loss: 0.4600\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8192 - val_loss: 0.3570\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3830 - val_loss: 0.3152\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3310 - val_loss: 0.3603\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2004 - val_loss: 0.3633\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1650 - val_loss: 0.4621\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1059 - val_loss: 0.3107\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1145 - val_loss: 0.3409\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9990 - val_loss: 0.3829\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9483 - val_loss: 0.3760\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9575 - val_loss: 0.4086\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0520 - val_loss: 0.4137\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8712 - val_loss: 0.3447\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8147 - val_loss: 0.3684\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7797 - val_loss: 0.3928\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7436 - val_loss: 0.3399\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7520 - val_loss: 0.3506\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7519 - val_loss: 0.4409\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7077 - val_loss: 0.3147\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6539 - val_loss: 0.3151\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6650 - val_loss: 0.3251\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6529 - val_loss: 0.3623\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6334 - val_loss: 0.3166\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6092 - val_loss: 0.3196\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6437 - val_loss: 0.3380\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6415 - val_loss: 0.3653\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5396 - val_loss: 0.3457\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5175 - val_loss: 0.3435\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5117 - val_loss: 0.4145\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4880 - val_loss: 0.3516\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5416 - val_loss: 0.3196\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4755 - val_loss: 0.3327\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4654 - val_loss: 0.3471\n",
      "Epoch 00074: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 1.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 85.0476 - val_loss: 2.4765\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.6027 - val_loss: 1.2116\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.1824 - val_loss: 0.4570\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.3139 - val_loss: 0.6999\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.7398 - val_loss: 0.5271\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.3470 - val_loss: 0.4501\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.4622 - val_loss: 0.4744\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.5505 - val_loss: 0.3727ss: 7.93 - ETA: 0s - loss: 8.\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.1175 - val_loss: 0.4390\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.2146 - val_loss: 0.5203\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.5197 - val_loss: 1.0258\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.0288 - val_loss: 0.9020\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 7.9049 - val_loss: 0.8428\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 7.0127 - val_loss: 0.3810\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.5524 - val_loss: 1.2385\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.6618 - val_loss: 0.6561\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 5.4078 - val_loss: 0.4585\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.3264 - val_loss: 0.5453\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 4.5231 - val_loss: 0.3754\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 3.6330 - val_loss: 0.4363\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 3.4855 - val_loss: 0.6388\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.9863 - val_loss: 0.3553\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.6984 - val_loss: 0.4533\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.2171 - val_loss: 0.3430\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.1310 - val_loss: 0.5668\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.2672 - val_loss: 0.4556\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.8897 - val_loss: 0.4958\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.9456 - val_loss: 0.4502\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8703 - val_loss: 0.3712\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 332s - loss: 1.5102 - val_loss: 0.4719\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4837 - val_loss: 0.3285\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4158 - val_loss: 0.3804\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3499 - val_loss: 0.4279\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2681 - val_loss: 0.4950\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0785 - val_loss: 0.3714\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0086 - val_loss: 0.3823\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0233 - val_loss: 0.4387\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0534 - val_loss: 0.4227\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 10s - loss: 0.9526 - val_loss: 0.3638\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8554 - val_loss: 0.3889\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8278 - val_loss: 0.3851\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7284 - val_loss: 0.4326\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7334 - val_loss: 0.3201\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6855 - val_loss: 0.3379\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7026 - val_loss: 0.3394\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6511 - val_loss: 0.3205\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5870 - val_loss: 0.3194\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6065 - val_loss: 0.3316\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5524 - val_loss: 0.3315\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5298 - val_loss: 0.3241\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5551 - val_loss: 0.4080\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5411 - val_loss: 0.3604\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4691 - val_loss: 0.3152\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5122 - val_loss: 0.3130\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4751 - val_loss: 0.3301\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4383 - val_loss: 0.3315\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4437 - val_loss: 0.3181\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4246 - val_loss: 0.4271\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4559 - val_loss: 0.3298\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2413s - loss: 0.4236 - val_loss: 0.3241\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4031 - val_loss: 0.3193\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4058 - val_loss: 0.3080\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4055 - val_loss: 0.3067\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3775 - val_loss: 0.3120\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3478 - val_loss: 0.3081\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3798 - val_loss: 0.3063\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3611 - val_loss: 0.3079\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3578 - val_loss: 0.3495\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3287 - val_loss: 0.3055\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 7s - loss: 0.3324 - val_loss: 0.3157\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3489 - val_loss: 0.3107\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3168 - val_loss: 0.3287\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3313 - val_loss: 0.3218\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3043 - val_loss: 0.3149\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2846 - val_loss: 0.3130\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2735 - val_loss: 0.3531\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2962 - val_loss: 0.3744\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2899 - val_loss: 0.3977\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3117 - val_loss: 0.3476\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2629 - val_loss: 0.3231\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2503 - val_loss: 0.3300\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2789 - val_loss: 0.3410\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2577 - val_loss: 0.3257\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2631 - val_loss: 0.3587\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 85s - loss: 0.2542 - val_loss: 0.3173\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2737 - val_loss: 0.3390\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2404 - val_loss: 0.3971\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2627 - val_loss: 0.3311\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2485 - val_loss: 0.3223\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2256 - val_loss: 0.3169\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2417 - val_loss: 0.3289\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2402 - val_loss: 0.3262\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.2139 - val_loss: 0.3176\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2086 - val_loss: 0.3208\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2136 - val_loss: 0.3186\n",
      "Epoch 00094: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total=49.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 108.9917 - val_loss: 3.5219\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.5202 - val_loss: 0.7679\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.1501 - val_loss: 0.8734\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.4240 - val_loss: 1.1014\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.6447 - val_loss: 0.5558\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.5257 - val_loss: 0.7640\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 18.8099 - val_loss: 0.7283\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 23.3009 - val_loss: 0.4554\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 21.6992 - val_loss: 1.0794\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 19.9798 - val_loss: 0.9790\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 16.8949 - val_loss: 2.9607\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.9340 - val_loss: 0.5119\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.6591 - val_loss: 0.5427\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.7627 - val_loss: 0.7911\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.6540 - val_loss: 2.6776\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.3094 - val_loss: 1.0357\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.0772 - val_loss: 0.4436\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.1492 - val_loss: 0.5296\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.3648 - val_loss: 0.6773\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.0422 - val_loss: 0.4123\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.7682 - val_loss: 0.3699\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.6390 - val_loss: 0.4999\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.5624 - val_loss: 0.4645\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9864 - val_loss: 0.8888\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.8164 - val_loss: 0.4599\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1261 - val_loss: 0.3691\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9934 - val_loss: 0.7695\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.8353 - val_loss: 0.4901\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.8581 - val_loss: 0.3973\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2158 - val_loss: 0.4017\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2534 - val_loss: 0.5366\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0606 - val_loss: 0.3382\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0640 - val_loss: 0.4201\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7759 - val_loss: 0.4665\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7898 - val_loss: 0.4081\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5738 - val_loss: 0.4199\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4985 - val_loss: 0.4015\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4153 - val_loss: 0.4417\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3400 - val_loss: 0.3731\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5613 - val_loss: 0.3294\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3554 - val_loss: 0.4062\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2294 - val_loss: 0.3771\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1501 - val_loss: 0.4382\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0650 - val_loss: 0.3337\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9481 - val_loss: 0.3331\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0586 - val_loss: 0.3932\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9649 - val_loss: 0.3217\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9123 - val_loss: 0.3665\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8319 - val_loss: 0.3319\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8853 - val_loss: 0.3367\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7891 - val_loss: 0.3306\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8741 - val_loss: 0.5154\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7797 - val_loss: 0.3428\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6641 - val_loss: 0.3526\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6574 - val_loss: 0.3484\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6253 - val_loss: 0.3246\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5780 - val_loss: 0.3282\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6252 - val_loss: 0.3448\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5573 - val_loss: 0.3183\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5531 - val_loss: 0.3332\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5611 - val_loss: 0.3177\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5697 - val_loss: 0.3711\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4931 - val_loss: 0.3137\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4794 - val_loss: 0.3144\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4678 - val_loss: 0.3423\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4880 - val_loss: 0.3473\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4634 - val_loss: 0.3274\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4783 - val_loss: 0.3201\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4760 - val_loss: 0.3255\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4840 - val_loss: 0.3452\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3921 - val_loss: 0.3456\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4184 - val_loss: 0.3238\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3782 - val_loss: 0.3219\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3710 - val_loss: 0.3343\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3745 - val_loss: 0.3328\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3440 - val_loss: 0.3439\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3374 - val_loss: 0.3251\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3321 - val_loss: 0.3530\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3202 - val_loss: 0.3376\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3165 - val_loss: 0.3507\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3197 - val_loss: 0.3187\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3075 - val_loss: 0.3661\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3082 - val_loss: 0.3157\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2800 - val_loss: 0.3147\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2881 - val_loss: 0.3651\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2762 - val_loss: 0.3303\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2948 - val_loss: 0.3109\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2831 - val_loss: 0.3093\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2581 - val_loss: 0.3240\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2600 - val_loss: 0.3435\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2544 - val_loss: 0.3139\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2535 - val_loss: 0.3221\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2520 - val_loss: 0.3173\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2470 - val_loss: 0.3226\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2453 - val_loss: 0.3327\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2374 - val_loss: 0.3335\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2440 - val_loss: 0.3168\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2168 - val_loss: 0.3314\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2306 - val_loss: 0.3418\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2221 - val_loss: 0.3333\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2155 - val_loss: 0.3417\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2119 - val_loss: 0.3200\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2139 - val_loss: 0.3237\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2063 - val_loss: 0.3621\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2066 - val_loss: 0.3261\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1881 - val_loss: 0.3257\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1903 - val_loss: 0.3222\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1999 - val_loss: 0.3333ss: \n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1973 - val_loss: 0.3131\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1857 - val_loss: 0.3499\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1824 - val_loss: 0.3174\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1758 - val_loss: 0.3210\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1730 - val_loss: 0.3154\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1685 - val_loss: 0.3224\n",
      "Epoch 00113: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 117.9484 - val_loss: 3.0752\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.2046 - val_loss: 0.9312\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.9961 - val_loss: 0.7363\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.0685 - val_loss: 0.7172\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.8602 - val_loss: 1.3306\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.7634 - val_loss: 0.7580\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.6576 - val_loss: 0.5731\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 14.1543 - val_loss: 0.5548\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.9475 - val_loss: 0.9079\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.9661 - val_loss: 0.5419\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.8748 - val_loss: 0.6411\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.8553 - val_loss: 0.7700\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.1919 - val_loss: 0.6399\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 11.4595 - val_loss: 0.4421\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.5080 - val_loss: 0.4693\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.4496 - val_loss: 0.6207\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.6463 - val_loss: 1.3831\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.1554 - val_loss: 0.4046\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.0524 - val_loss: 0.7769\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.3114 - val_loss: 0.3979\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.6569 - val_loss: 0.4310\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.3917 - val_loss: 0.3442\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4808 - val_loss: 0.5169\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2871 - val_loss: 0.4449\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4346 - val_loss: 0.5096\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.3483 - val_loss: 0.7892\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.5444 - val_loss: 0.4333\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7536 - val_loss: 0.6196\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4477 - val_loss: 0.5842\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4423 - val_loss: 0.6396\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9702 - val_loss: 0.3615\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8228 - val_loss: 0.3521\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7490 - val_loss: 0.5019\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5495 - val_loss: 0.3652\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8007 - val_loss: 0.3656\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5599 - val_loss: 0.3568\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5516 - val_loss: 0.3595\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3405 - val_loss: 0.3323\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3652 - val_loss: 0.4632\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5970 - val_loss: 0.5560\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1848 - val_loss: 0.3451\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1199 - val_loss: 0.3221\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1415 - val_loss: 0.3463\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9473 - val_loss: 0.3267\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0646 - val_loss: 0.3252\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8728 - val_loss: 0.3274\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9236 - val_loss: 0.3309\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8880 - val_loss: 0.3709\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7763 - val_loss: 0.3379\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7906 - val_loss: 0.3426\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7619 - val_loss: 0.4198\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7072 - val_loss: 0.3848\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7021 - val_loss: 0.3399\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6759 - val_loss: 0.3304\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6926 - val_loss: 0.3303\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6673 - val_loss: 0.3405\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5524 - val_loss: 0.3696\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5309 - val_loss: 0.3173\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5829 - val_loss: 0.4133\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5417 - val_loss: 0.3176\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5472 - val_loss: 0.3556\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5289 - val_loss: 0.3178\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5228 - val_loss: 0.3605\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4748 - val_loss: 0.3294\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4685 - val_loss: 0.3759\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4820 - val_loss: 0.3279\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4544 - val_loss: 0.3768\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4083 - val_loss: 0.3138\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4748 - val_loss: 0.4043\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4195 - val_loss: 0.3165\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3896 - val_loss: 0.3511\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3651 - val_loss: 0.3182\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3867 - val_loss: 0.3916\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3641 - val_loss: 0.3186\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3502 - val_loss: 0.3286\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3447 - val_loss: 0.3122\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3384 - val_loss: 0.3258\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3155 - val_loss: 0.3220\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3154 - val_loss: 0.3235\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3181 - val_loss: 0.3123\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3062 - val_loss: 0.3439\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3156 - val_loss: 0.3471\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3024 - val_loss: 0.3702\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3068 - val_loss: 0.3143\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2924 - val_loss: 0.3126\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2927 - val_loss: 0.3550\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2750 - val_loss: 0.3148\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2711 - val_loss: 0.3135\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2745 - val_loss: 0.3179ss: 0.\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2517 - val_loss: 0.3276\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2532 - val_loss: 0.3157\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2689 - val_loss: 0.3378\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2527 - val_loss: 0.3138\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2417 - val_loss: 0.3271\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2554 - val_loss: 0.3119\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2228 - val_loss: 0.3178\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2582 - val_loss: 0.3410\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2397 - val_loss: 0.3127\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2341 - val_loss: 0.3121\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2317 - val_loss: 0.3165\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2283 - val_loss: 0.3125\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2139 - val_loss: 0.3264\n",
      "Epoch 00101: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=2, total= 2.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 2s - loss: 107.1297 - val_loss: 3.6909\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 28.2097 - val_loss: 1.8232\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 26.7646 - val_loss: 1.4068\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 21.9207 - val_loss: 3.9080\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 17.9623 - val_loss: 1.5270\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 15.0986 - val_loss: 2.8514\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 15.2535 - val_loss: 1.5768\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 15.5796 - val_loss: 0.8180\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 14.4447 - val_loss: 1.8640\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 11.0424 - val_loss: 0.7894\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 8.6740 - val_loss: 0.3700\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 6.6652 - val_loss: 0.5395\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 6.9815 - val_loss: 0.7947\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 5.8472 - val_loss: 0.3911\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 5.1718 - val_loss: 0.6784\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.4231 - val_loss: 0.7952\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 4.1393 - val_loss: 0.4113\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.8394 - val_loss: 0.9596\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.1735 - val_loss: 0.4418\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.5690 - val_loss: 0.3229\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.9411 - val_loss: 0.4794\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.8703 - val_loss: 0.8102\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.7419 - val_loss: 0.4075\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.5905 - val_loss: 0.4431\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3452 - val_loss: 0.6092\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.2847 - val_loss: 0.3338\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.0336 - val_loss: 0.3190\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.8820 - val_loss: 0.3566\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.8139 - val_loss: 0.4254\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.7141 - val_loss: 0.6955\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.6179 - val_loss: 0.5253\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4542 - val_loss: 0.3677\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3338 - val_loss: 0.4293\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3621 - val_loss: 0.3771\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3607 - val_loss: 0.3247\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2747 - val_loss: 0.3126\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1659 - val_loss: 0.4306\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3231 - val_loss: 0.4489\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1413 - val_loss: 0.3652\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0438 - val_loss: 0.3433\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0229 - val_loss: 0.2855\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9119 - val_loss: 0.4164\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8740 - val_loss: 0.3979\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8146 - val_loss: 0.2893\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8667 - val_loss: 0.3231\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7930 - val_loss: 0.3589\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7484 - val_loss: 0.3121\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7512 - val_loss: 0.3696\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7447 - val_loss: 0.3825\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7990 - val_loss: 0.2917\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6862 - val_loss: 0.3479\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6515 - val_loss: 0.3226\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5760 - val_loss: 0.3302\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6055 - val_loss: 0.3179\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6525 - val_loss: 0.3681\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5678 - val_loss: 0.3333\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5465 - val_loss: 0.3850\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5348 - val_loss: 0.3097\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5213 - val_loss: 0.2978\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4907 - val_loss: 0.3565\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4911 - val_loss: 0.3152\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4738 - val_loss: 0.3137\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4936 - val_loss: 0.3630\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4527 - val_loss: 0.2969\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4625 - val_loss: 0.3466\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4614 - val_loss: 0.3288\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4004 - val_loss: 0.2962\n",
      "Epoch 00066: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 1.5min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 152.2082 - val_loss: 2.9254\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 44.7589 - val_loss: 1.9358\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 35.7954 - val_loss: 2.7560\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 31.4104 - val_loss: 6.3670\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 32.5057 - val_loss: 0.7865\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 23.1702 - val_loss: 1.2102\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 17.8324 - val_loss: 0.8733\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 16.2215 - val_loss: 1.7449\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 16.4929 - val_loss: 2.2930\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 18.6525 - val_loss: 0.4666s: 1\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.8497 - val_loss: 1.2288\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 14.3140 - val_loss: 0.4425\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.0506 - val_loss: 1.2248\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.1896 - val_loss: 0.6272\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.4905 - val_loss: 0.9373\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.5093 - val_loss: 0.5136\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.7296 - val_loss: 0.6289\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.4096 - val_loss: 0.5192\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.2865 - val_loss: 0.5071\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.4510 - val_loss: 0.5132\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.5664 - val_loss: 0.7099\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.9325 - val_loss: 0.8020\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.8426 - val_loss: 1.0086\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.6072 - val_loss: 0.6884\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.5580 - val_loss: 0.5090\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9150 - val_loss: 0.5666\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9637 - val_loss: 0.5729\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6197 - val_loss: 0.5286\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5998 - val_loss: 0.8325\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1122 - val_loss: 0.8126\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0439 - val_loss: 0.4262\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3754 - val_loss: 0.4365\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1765 - val_loss: 0.3935\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6847 - val_loss: 0.6434\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9969 - val_loss: 0.3187\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7067 - val_loss: 0.3794\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4786 - val_loss: 0.3260\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6010 - val_loss: 0.3263\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7777 - val_loss: 0.3333\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5884 - val_loss: 0.5754\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4491 - val_loss: 0.3403\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2595 - val_loss: 0.3354\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2111 - val_loss: 0.3198\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2888 - val_loss: 0.3677\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1648 - val_loss: 0.3901\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0741 - val_loss: 0.3132\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9869 - val_loss: 0.3498\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0519 - val_loss: 0.3628\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1172 - val_loss: 0.4373\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0426 - val_loss: 0.3330\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8987 - val_loss: 0.3677\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8911 - val_loss: 0.4608\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8633 - val_loss: 0.4113\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9327 - val_loss: 0.3683\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8129 - val_loss: 0.4605\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9051 - val_loss: 0.3230\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9100 - val_loss: 0.3583\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8300 - val_loss: 0.3314\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7328 - val_loss: 0.3813\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7242 - val_loss: 0.3435\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6407 - val_loss: 0.3415\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6262 - val_loss: 0.3156\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6046 - val_loss: 0.3277\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6012 - val_loss: 0.3162\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6126 - val_loss: 0.3797\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5843 - val_loss: 0.3142\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5254 - val_loss: 0.3604\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5212 - val_loss: 0.3565\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5201 - val_loss: 0.3141\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4953 - val_loss: 0.3104\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4933 - val_loss: 0.4313\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4792 - val_loss: 0.3140\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4627 - val_loss: 0.3263\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4439 - val_loss: 0.4267\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4450 - val_loss: 0.3343\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4157 - val_loss: 0.3053\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3833 - val_loss: 0.4444\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3989 - val_loss: 0.3066\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3713 - val_loss: 0.3657\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4063 - val_loss: 0.3080\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3793 - val_loss: 0.3249\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3910 - val_loss: 0.3704\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3550 - val_loss: 0.3136\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3441 - val_loss: 0.3226\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3297 - val_loss: 0.3277\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3154 - val_loss: 0.3242\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3016 - val_loss: 0.3420\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2872 - val_loss: 0.3395\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3065 - val_loss: 0.3372\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3003 - val_loss: 0.3337\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2792 - val_loss: 0.3331\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2760 - val_loss: 0.3662\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3046 - val_loss: 0.3275\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2539 - val_loss: 0.3454\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2614 - val_loss: 0.3100\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2574 - val_loss: 0.3200\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2574 - val_loss: 0.3087\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2974 - val_loss: 0.3181\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2499 - val_loss: 0.3173\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2241 - val_loss: 0.3565\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2266 - val_loss: 0.3410\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2182 - val_loss: 0.3358\n",
      "Epoch 00101: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 2.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 109.6102 - val_loss: 0.8829\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 30.7472 - val_loss: 1.6544\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 20.8656 - val_loss: 0.7627\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 20.5392 - val_loss: 1.5282\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.5431 - val_loss: 0.6510\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 14.0113 - val_loss: 1.6146\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 17.4758 - val_loss: 2.6919\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 14.3935 - val_loss: 0.4033\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.9416 - val_loss: 2.8641\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 9.9625 - val_loss: 0.7410\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.4090 - val_loss: 1.3950\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 10.1235 - val_loss: 0.6523\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.6318 - val_loss: 0.9716\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.4747 - val_loss: 0.4602\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.2311 - val_loss: 0.8342\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.7353 - val_loss: 1.0516\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.7903 - val_loss: 0.5202\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.3606 - val_loss: 0.4992\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1424 - val_loss: 0.3530\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1352 - val_loss: 0.6044\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5026 - val_loss: 0.7356\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3994 - val_loss: 0.5143\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4262 - val_loss: 0.5378\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2090 - val_loss: 0.3753\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9999 - val_loss: 0.6260\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8515 - val_loss: 0.4038\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9757 - val_loss: 0.4510\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7290 - val_loss: 0.3820\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7055 - val_loss: 0.7431\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5802 - val_loss: 0.5523\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6411 - val_loss: 0.3833\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5453 - val_loss: 0.3636\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3228 - val_loss: 0.4476\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2602 - val_loss: 0.4694\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1061 - val_loss: 0.3159\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1973 - val_loss: 0.3852\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0542 - val_loss: 0.3657\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0653 - val_loss: 0.3268\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9836 - val_loss: 0.3294\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9869 - val_loss: 0.3423\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8998 - val_loss: 0.3683\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8857 - val_loss: 0.3363\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8730 - val_loss: 0.3920\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7906 - val_loss: 0.3151\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7821 - val_loss: 0.3875\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7721 - val_loss: 0.3919\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6928 - val_loss: 0.3954\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6801 - val_loss: 0.3338\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7195 - val_loss: 0.3445\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5956 - val_loss: 0.3376\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5964 - val_loss: 0.3409\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5608 - val_loss: 0.3386\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6039 - val_loss: 0.4104\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5383 - val_loss: 0.3186\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5795 - val_loss: 0.4148\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5486 - val_loss: 0.4388\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5448 - val_loss: 0.3351\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4648 - val_loss: 0.3106\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4645 - val_loss: 0.3160\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4763 - val_loss: 0.4062\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4510 - val_loss: 0.3473\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4616 - val_loss: 0.3234\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4209 - val_loss: 0.3093\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3965 - val_loss: 0.3086\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4311 - val_loss: 0.3243\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3954 - val_loss: 0.3764\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3892 - val_loss: 0.3444\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4030 - val_loss: 0.3751\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3869 - val_loss: 0.3162\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3907 - val_loss: 0.3366\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3541 - val_loss: 0.3101\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3659 - val_loss: 0.3542\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3512 - val_loss: 0.3094\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2851 - val_loss: 0.3131\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3179 - val_loss: 0.4180\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3325 - val_loss: 0.3474\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3167 - val_loss: 0.3112\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3153 - val_loss: 0.3142\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2945 - val_loss: 0.3402\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2803 - val_loss: 0.3523\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2720 - val_loss: 0.3130\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2537 - val_loss: 0.3259\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2699 - val_loss: 0.3275\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2464 - val_loss: 0.3132\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2570 - val_loss: 0.3833\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2446 - val_loss: 0.3304\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2169 - val_loss: 0.3743\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2462 - val_loss: 0.3250\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2601 - val_loss: 0.3430\n",
      "Epoch 00088: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 1.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 134.4213 - val_loss: 4.5134\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 35.8955 - val_loss: 2.3349\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 25.0641 - val_loss: 1.7638\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 21.6570 - val_loss: 1.1229\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 19.8279 - val_loss: 1.1754\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 15.2661 - val_loss: 0.5064\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 18.8190 - val_loss: 1.2414\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 16.1374 - val_loss: 2.6638\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.1470 - val_loss: 0.8491\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.5094 - val_loss: 0.8364\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 13.0973 - val_loss: 1.2369\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 10.8479 - val_loss: 0.7236\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.2368 - val_loss: 1.6487\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.6852 - val_loss: 0.6066\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.2556 - val_loss: 0.9378\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.8163 - val_loss: 0.4726\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.1244 - val_loss: 0.5493\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.0484 - val_loss: 0.3181\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.3929 - val_loss: 0.4262\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.0163 - val_loss: 0.4672\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.3905 - val_loss: 0.7806\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.6831 - val_loss: 0.5104\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.3846 - val_loss: 0.8067\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.6029 - val_loss: 0.7253\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.5134 - val_loss: 0.4751\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1086 - val_loss: 0.4241\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3569 - val_loss: 0.4048\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2300 - val_loss: 0.4864\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2921 - val_loss: 0.7125\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9146 - val_loss: 0.3528\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9819 - val_loss: 0.3888\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.1041 - val_loss: 0.5093\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.8996 - val_loss: 0.3662\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6359 - val_loss: 0.4968\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6583 - val_loss: 0.3337\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.4555 - val_loss: 0.3889\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6784 - val_loss: 0.4567\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4212 - val_loss: 0.3600\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2844 - val_loss: 0.3396\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2754 - val_loss: 0.4192\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1281 - val_loss: 0.3493\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0684 - val_loss: 0.3419\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1023 - val_loss: 0.3245\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2050 - val_loss: 0.3759\n",
      "Epoch 00043: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total=  51.4s\n",
      "[CV] activation_function=linear, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 1s - loss: 96.8220 - val_loss: 5.1037\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 28.3612 - val_loss: 1.6085\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 21.6743 - val_loss: 1.3933\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 25.2813 - val_loss: 1.0312\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 21.3450 - val_loss: 0.4227\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 18.3934 - val_loss: 1.5953\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 13.5555 - val_loss: 0.7845\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 12.3447 - val_loss: 0.5070\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 9.5657 - val_loss: 0.7882\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.6793 - val_loss: 0.8960\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.9397 - val_loss: 0.4307\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.8459 - val_loss: 0.8192\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.1263 - val_loss: 0.8119\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.3293 - val_loss: 0.6332\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.9285 - val_loss: 0.4668\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.6196 - val_loss: 0.6198\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9313 - val_loss: 0.4649\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9001 - val_loss: 0.6746\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.2965 - val_loss: 0.5517\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6827 - val_loss: 0.4431\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6370 - val_loss: 0.4072\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4175 - val_loss: 0.4058\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2057 - val_loss: 0.6572\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2923 - val_loss: 0.4459\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0327 - val_loss: 0.4358\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9596 - val_loss: 0.4272\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9487 - val_loss: 0.3135\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6074 - val_loss: 0.5184\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6198 - val_loss: 0.5867\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4642 - val_loss: 0.3451\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4795 - val_loss: 0.3261\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4565 - val_loss: 0.7726\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4804 - val_loss: 0.6432\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1628 - val_loss: 0.2967\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2579 - val_loss: 0.3389\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1658 - val_loss: 0.3936\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0375 - val_loss: 0.3063\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9888 - val_loss: 0.3458\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9268 - val_loss: 0.3070\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8611 - val_loss: 0.3243\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8550 - val_loss: 0.5209\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8622 - val_loss: 0.3118\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8717 - val_loss: 0.3563\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8360 - val_loss: 0.3976\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7620 - val_loss: 0.3568\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6888 - val_loss: 0.3639\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6425 - val_loss: 0.3216\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6563 - val_loss: 0.3347\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6989 - val_loss: 0.3823\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7059 - val_loss: 0.3598\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6014 - val_loss: 0.3229\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5700 - val_loss: 0.4146\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5482 - val_loss: 0.3286\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6025 - val_loss: 0.4043\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5088 - val_loss: 0.3564\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5204 - val_loss: 0.3434\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5422 - val_loss: 0.3324\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4981 - val_loss: 0.3120\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4730 - val_loss: 0.3193\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4744 - val_loss: 0.3743\n",
      "Epoch 00059: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=64, num_hidden_layers=3, total= 1.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 2s - loss: 205.3231 - val_loss: 14.3546\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 15.7965 - val_loss: 3.1413s: 1\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 6.3509 - val_loss: 1.7054\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.2325 - val_loss: 1.4406\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.7419 - val_loss: 1.9961\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.1252 - val_loss: 1.8302\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.1745 - val_loss: 1.1205\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.6081 - val_loss: 1.6333\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.7795 - val_loss: 1.6033\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.9898 - val_loss: 5.0518\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.7872 - val_loss: 1.5910\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 9.2744 - val_loss: 3.1533\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 8.5600 - val_loss: 16.9155\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 12.0208 - val_loss: 3.9496\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 13.2309 - val_loss: 4.4388\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 6.5732 - val_loss: 1.9410\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 12.1771 - val_loss: 6.8094\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 6.4667 - val_loss: 1.8006\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.1542 - val_loss: 1.1216\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.3256 - val_loss: 0.8310\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.0557 - val_loss: 0.6788\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3089 - val_loss: 3.8855\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 13.1054 - val_loss: 3.2954\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.2926 - val_loss: 0.7411\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.5976 - val_loss: 0.7982\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.8226 - val_loss: 1.1665\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5417 - val_loss: 2.1326\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4689 - val_loss: 0.9857\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0565 - val_loss: 1.1976\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1661 - val_loss: 0.5769\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9668 - val_loss: 0.5119\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.4609 - val_loss: 2.0188\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.7323 - val_loss: 3.8171\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0059 - val_loss: 0.6866\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4194 - val_loss: 1.1540\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0518 - val_loss: 0.4699\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7797 - val_loss: 0.6663\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6794 - val_loss: 0.4307\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7919 - val_loss: 0.4763\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5793 - val_loss: 0.4297\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6222 - val_loss: 0.5536\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7418 - val_loss: 0.5128\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1273 - val_loss: 1.2507\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0708 - val_loss: 1.4224\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7177 - val_loss: 0.4948\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5034 - val_loss: 0.4866\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5268 - val_loss: 0.7535\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4501 - val_loss: 0.5015\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4016 - val_loss: 0.4287\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4116 - val_loss: 0.8335\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4565 - val_loss: 0.4843\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5290 - val_loss: 0.6122\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4796 - val_loss: 0.3858\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6836 - val_loss: 0.5640\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3692 - val_loss: 0.8271\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5028 - val_loss: 0.4483\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4996 - val_loss: 0.4387\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7525 - val_loss: 0.4878\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4153 - val_loss: 0.5714\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6760 - val_loss: 0.4520\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2931 - val_loss: 0.3789\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6679 - val_loss: 0.5567\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8173 - val_loss: 0.3757\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3298 - val_loss: 0.4588\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2689 - val_loss: 0.3704\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2560 - val_loss: 0.3877\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2807 - val_loss: 0.4522\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2796 - val_loss: 0.3665\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2373 - val_loss: 0.4059\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2780 - val_loss: 0.4556\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3609 - val_loss: 0.3988\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1959 - val_loss: 0.3960\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2383 - val_loss: 0.4131\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4934 - val_loss: 0.4223\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2106 - val_loss: 0.3644\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2595 - val_loss: 0.4453\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2083 - val_loss: 0.3586\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1701 - val_loss: 0.3426\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1722 - val_loss: 0.3722\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3448 - val_loss: 0.4298\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2296 - val_loss: 0.3510\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1596 - val_loss: 0.3420\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1613 - val_loss: 0.3414\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1721 - val_loss: 0.3497\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2776 - val_loss: 0.3808\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3304 - val_loss: 0.3881\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2089 - val_loss: 0.3362\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1461 - val_loss: 0.3394\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1636 - val_loss: 0.3441\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1382 - val_loss: 0.3404\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1635 - val_loss: 0.3328\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1606 - val_loss: 0.3423\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1432 - val_loss: 0.3498\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2518 - val_loss: 0.3697\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1372 - val_loss: 0.3404\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1521 - val_loss: 0.3389\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1348 - val_loss: 0.3507\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1402 - val_loss: 0.3526\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1244 - val_loss: 0.3215\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1181 - val_loss: 0.3505\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1473 - val_loss: 0.3191\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1455 - val_loss: 0.3266\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1038 - val_loss: 0.3388\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1933 - val_loss: 0.4201\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1413 - val_loss: 0.3235\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1819 - val_loss: 0.3343\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1187 - val_loss: 0.3186\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1282 - val_loss: 0.3274\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1670 - val_loss: 0.3297\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1182 - val_loss: 0.3266\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1085 - val_loss: 0.3367\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1053 - val_loss: 0.3121\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1436 - val_loss: 0.3481\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1224 - val_loss: 0.3339\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1426 - val_loss: 0.3341\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1035 - val_loss: 0.3194\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1128 - val_loss: 0.3207\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1031 - val_loss: 0.3168\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0963 - val_loss: 0.3307\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1043 - val_loss: 0.3203ss: 0.103 - ETA: 0s - loss: 0.104\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1041 - val_loss: 0.3313\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0951 - val_loss: 0.3112\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1020 - val_loss: 0.3220\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1049 - val_loss: 0.3292\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0917 - val_loss: 0.3138\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0973 - val_loss: 0.3555\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1048 - val_loss: 0.3318\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0910 - val_loss: 0.3228\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1008 - val_loss: 0.3157s\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0972 - val_loss: 0.3158A: 0s - loss: 0.0 - ETA: 0s - loss: 0.09\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0907 - val_loss: 0.3128ss: 0.0\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0915 - val_loss: 0.3118\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0962 - val_loss: 0.3136ss: 0.09\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0929 - val_loss: 0.3144\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1004 - val_loss: 0.3052\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0993 - val_loss: 0.3202\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0893 - val_loss: 0.3152\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0830 - val_loss: 0.3127\n",
      "Epoch 139/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0876 - val_loss: 0.3159\n",
      "Epoch 140/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0952 - val_loss: 0.3313\n",
      "Epoch 141/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0914 - val_loss: 0.3300\n",
      "Epoch 142/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0976 - val_loss: 0.3294\n",
      "Epoch 143/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0864 - val_loss: 0.3188\n",
      "Epoch 144/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0846 - val_loss: 0.3172\n",
      "Epoch 145/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0908 - val_loss: 0.3184\n",
      "Epoch 146/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0857 - val_loss: 0.3397\n",
      "Epoch 147/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0954 - val_loss: 0.3146\n",
      "Epoch 148/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1009 - val_loss: 0.3489\n",
      "Epoch 149/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2450 - val_loss: 0.3342\n",
      "Epoch 150/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1687 - val_loss: 0.3420\n",
      "Epoch 151/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1062 - val_loss: 0.3131\n",
      "Epoch 152/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0988 - val_loss: 0.3785\n",
      "Epoch 153/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0902 - val_loss: 0.3188\n",
      "Epoch 154/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0879 - val_loss: 0.3245\n",
      "Epoch 155/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0943 - val_loss: 0.3091\n",
      "Epoch 156/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0966 - val_loss: 0.3239\n",
      "Epoch 157/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0874 - val_loss: 0.3266\n",
      "Epoch 158/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0953 - val_loss: 0.3139\n",
      "Epoch 159/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0922 - val_loss: 0.3213\n",
      "Epoch 160/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0903 - val_loss: 0.3240\n",
      "Epoch 161/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.0870 - val_loss: 0.3164\n",
      "Epoch 00160: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 6.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 293.1380 - val_loss: 9.2199\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 20.6593 - val_loss: 7.2929\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.2271 - val_loss: 2.0127\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.8780 - val_loss: 1.1854\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4699 - val_loss: 5.0414ss: 4.491\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9429 - val_loss: 6.5179\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.0409 - val_loss: 3.4845\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0921 - val_loss: 1.5905\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7218 - val_loss: 2.1126\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1269 - val_loss: 1.8255\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9994 - val_loss: 6.8546\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.6735 - val_loss: 1.8799\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.4475 - val_loss: 1.0864\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.2965 - val_loss: 2.9283\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.8202 - val_loss: 1.4403\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9734 - val_loss: 3.3899\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2737 - val_loss: 1.3754\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.5238 - val_loss: 6.2287\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4506 - val_loss: 2.1908\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.9010 - val_loss: 2.6426\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2003 - val_loss: 2.8993\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2909 - val_loss: 1.4251\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.0068 - val_loss: 6.6058\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.9172 - val_loss: 8.2421\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.3628 - val_loss: 1.9149\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.4395 - val_loss: 2.1796\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.9544 - val_loss: 1.3358\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.2263 - val_loss: 2.3793\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.2145 - val_loss: 0.7659\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7680 - val_loss: 0.6233\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8303 - val_loss: 0.7531\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1470 - val_loss: 0.8123\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5888 - val_loss: 0.8881\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0486 - val_loss: 1.3181\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6845 - val_loss: 0.6795\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0880 - val_loss: 0.5015\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7520 - val_loss: 0.4076\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1832 - val_loss: 0.4713\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1075 - val_loss: 0.6437\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6397 - val_loss: 0.7139\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1949 - val_loss: 0.4804\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3488 - val_loss: 0.4487\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1855 - val_loss: 1.9483\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3142 - val_loss: 1.1314\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8694 - val_loss: 0.4999\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4444 - val_loss: 0.4174\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4221 - val_loss: 0.4650\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4890 - val_loss: 0.4796\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4322 - val_loss: 0.4100\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5010 - val_loss: 0.4067\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4829 - val_loss: 0.5040\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4122 - val_loss: 0.6598\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3110 - val_loss: 0.5154\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6105 - val_loss: 0.4812\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8208 - val_loss: 0.8577\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8084 - val_loss: 0.4006\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3993 - val_loss: 0.4648\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3015 - val_loss: 0.4315\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3330 - val_loss: 0.4136\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3092 - val_loss: 0.3831\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3010 - val_loss: 0.3949\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3196 - val_loss: 0.3784\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3532 - val_loss: 0.3806\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3010 - val_loss: 0.3935\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2434 - val_loss: 0.4082\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2142 - val_loss: 0.3734\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2342 - val_loss: 0.3733\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2292 - val_loss: 0.3659\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2639 - val_loss: 0.4443\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1983 - val_loss: 0.3908 - ETA: 0s - lo\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2139 - val_loss: 0.3825\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2233 - val_loss: 0.4153\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2580 - val_loss: 0.3574\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1820 - val_loss: 0.3754\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2118 - val_loss: 0.4840\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3541 - val_loss: 0.3720\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1736 - val_loss: 0.4011\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1830 - val_loss: 0.3535\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1862 - val_loss: 0.3978\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1769 - val_loss: 0.3587\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2157 - val_loss: 0.3504\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2068 - val_loss: 0.3848\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1684 - val_loss: 0.3486\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1579 - val_loss: 0.3491\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1743 - val_loss: 0.4157\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1686 - val_loss: 0.3391\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1465 - val_loss: 0.3357\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1293 - val_loss: 0.3371\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1354 - val_loss: 0.3472\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1413 - val_loss: 0.3389\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1522 - val_loss: 0.3705\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1512 - val_loss: 0.3457\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1338 - val_loss: 0.3351\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1699 - val_loss: 0.3484\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1457 - val_loss: 0.3435\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1708 - val_loss: 0.3405\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1330 - val_loss: 0.3464\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1490 - val_loss: 0.3744\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1423 - val_loss: 0.3327\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1299 - val_loss: 0.3269\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1259 - val_loss: 0.3308\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1163 - val_loss: 0.3623\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1177 - val_loss: 0.3816\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1214 - val_loss: 0.3419\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1168 - val_loss: 0.3304\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1227 - val_loss: 0.3275\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1129 - val_loss: 0.3736\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1087 - val_loss: 0.3446\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1091 - val_loss: 0.3298\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1064 - val_loss: 0.3322\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1205 - val_loss: 0.3292\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1159 - val_loss: 0.3226\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1035 - val_loss: 0.3426\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1140 - val_loss: 0.3306\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1013 - val_loss: 0.3392\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1012 - val_loss: 0.3460\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1053 - val_loss: 0.3400\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1038 - val_loss: 0.3187ss: \n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0931 - val_loss: 0.3203\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1118 - val_loss: 0.3696\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1190 - val_loss: 0.3649\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1027 - val_loss: 0.3273\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1005 - val_loss: 0.3263\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1001 - val_loss: 0.3239\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0868 - val_loss: 0.3297\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1005 - val_loss: 0.3213\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0897 - val_loss: 0.3287\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0872 - val_loss: 0.3229\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0965 - val_loss: 0.3299\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0888 - val_loss: 0.3362\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1059 - val_loss: 0.3899\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1095 - val_loss: 0.3235\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1036 - val_loss: 0.3174\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1128 - val_loss: 0.3310\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0980 - val_loss: 0.3235\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0993 - val_loss: 0.3220\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0873 - val_loss: 0.3260\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0911 - val_loss: 0.3229\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0843 - val_loss: 0.3261\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0864 - val_loss: 0.3622\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0890 - val_loss: 0.3169\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0807 - val_loss: 0.3241\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0802 - val_loss: 0.3210\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0823 - val_loss: 0.3183\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0857 - val_loss: 0.3181\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0851 - val_loss: 0.3232\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0873 - val_loss: 0.3158\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0804 - val_loss: 0.3238\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0880 - val_loss: 0.3180\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0869 - val_loss: 0.3128\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0811 - val_loss: 0.3198\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0879 - val_loss: 0.3493\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0832 - val_loss: 0.3289\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0795 - val_loss: 0.3205\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0802 - val_loss: 0.3211\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0910 - val_loss: 0.3142\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0908 - val_loss: 0.3193\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0833 - val_loss: 0.3761\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0911 - val_loss: 0.3202\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0795 - val_loss: 0.3177\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0788 - val_loss: 0.3139\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0879 - val_loss: 0.3113\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0792 - val_loss: 0.3160\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0787 - val_loss: 0.3365\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0818 - val_loss: 0.3160\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0865 - val_loss: 0.3148\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0728 - val_loss: 0.3194\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0770 - val_loss: 0.3198\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0806 - val_loss: 0.3118\n",
      "Epoch 170/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0732 - val_loss: 0.3138\n",
      "Epoch 171/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0778 - val_loss: 0.3174\n",
      "Epoch 172/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0756 - val_loss: 0.3247\n",
      "Epoch 173/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0764 - val_loss: 0.3409\n",
      "Epoch 174/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0788 - val_loss: 0.3104\n",
      "Epoch 175/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0699 - val_loss: 0.3151\n",
      "Epoch 176/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0739 - val_loss: 0.3146\n",
      "Epoch 177/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0764 - val_loss: 0.3419\n",
      "Epoch 178/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0811 - val_loss: 0.3481\n",
      "Epoch 179/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0705 - val_loss: 0.3237\n",
      "Epoch 180/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0847 - val_loss: 0.3177\n",
      "Epoch 181/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0780 - val_loss: 0.3148\n",
      "Epoch 182/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0891 - val_loss: 0.3123\n",
      "Epoch 183/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0771 - val_loss: 0.3375\n",
      "Epoch 184/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0773 - val_loss: 0.3160\n",
      "Epoch 185/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0770 - val_loss: 0.3101\n",
      "Epoch 186/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0686 - val_loss: 0.3182\n",
      "Epoch 187/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0715 - val_loss: 0.3116\n",
      "Epoch 188/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0745 - val_loss: 0.3158\n",
      "Epoch 189/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0755 - val_loss: 0.3502\n",
      "Epoch 190/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0829 - val_loss: 0.3135\n",
      "Epoch 191/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0773 - val_loss: 0.3201\n",
      "Epoch 192/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0797 - val_loss: 0.3567\n",
      "Epoch 193/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0705 - val_loss: 0.3198\n",
      "Epoch 194/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0704 - val_loss: 0.3151\n",
      "Epoch 195/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0716 - val_loss: 0.3148\n",
      "Epoch 196/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0716 - val_loss: 0.3232\n",
      "Epoch 197/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0659 - val_loss: 0.3140\n",
      "Epoch 198/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0677 - val_loss: 0.3197\n",
      "Epoch 199/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0721 - val_loss: 0.3108\n",
      "Epoch 200/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0675 - val_loss: 0.3268\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 8.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 233.7405 - val_loss: 7.0972\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 16.1855 - val_loss: 2.6724\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.8317 - val_loss: 1.1914\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9257 - val_loss: 1.0289\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4610 - val_loss: 0.7670\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4530 - val_loss: 1.5081\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8701 - val_loss: 0.8911\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6733 - val_loss: 2.8339\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7547 - val_loss: 2.0182\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9446 - val_loss: 1.2742\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.1195 - val_loss: 1.4670\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9710 - val_loss: 1.7776\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2524 - val_loss: 0.9252\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0499 - val_loss: 1.3149\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4381 - val_loss: 1.4647\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6760 - val_loss: 5.2782\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6719 - val_loss: 10.1773\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.6692 - val_loss: 2.7877\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 12.3601 - val_loss: 3.2954\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.9140 - val_loss: 1.2485\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.9029 - val_loss: 1.0082\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7087 - val_loss: 1.2123\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5872 - val_loss: 2.2999\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.7039 - val_loss: 2.7173\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.3973 - val_loss: 1.3298\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0813 - val_loss: 1.3711\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4192 - val_loss: 0.7331\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9588 - val_loss: 1.0348\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5296 - val_loss: 2.4712\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6994 - val_loss: 0.9204\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4127 - val_loss: 0.6853\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1122 - val_loss: 0.7135\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9669 - val_loss: 0.5872\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9320 - val_loss: 0.4695\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9505 - val_loss: 0.5793\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7520 - val_loss: 0.7037\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4102 - val_loss: 0.5175\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6859 - val_loss: 0.4284\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1433 - val_loss: 0.9091\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2818 - val_loss: 0.9761\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8542 - val_loss: 0.7801\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7400 - val_loss: 0.4589\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6713 - val_loss: 0.6173\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6417 - val_loss: 0.4830\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5731 - val_loss: 0.7396\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5361 - val_loss: 0.4361\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4590 - val_loss: 0.4518\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6376 - val_loss: 0.4981\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4870 - val_loss: 0.4977\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1309 - val_loss: 0.6881\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6207 - val_loss: 0.4391\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4826 - val_loss: 0.4844\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3736 - val_loss: 0.3832\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3207 - val_loss: 0.3899\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3690 - val_loss: 0.4214\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3544 - val_loss: 0.4030\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9482 - val_loss: 0.4586\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6343 - val_loss: 0.3798\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2954 - val_loss: 0.3647\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3849 - val_loss: 0.3806\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2613 - val_loss: 0.3751\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2385 - val_loss: 0.3864\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2495 - val_loss: 0.3537\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2405 - val_loss: 0.3628\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2881 - val_loss: 0.3734\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2128 - val_loss: 0.3811\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2662 - val_loss: 0.4125\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2278 - val_loss: 0.4020\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2431 - val_loss: 0.3715\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2447 - val_loss: 0.4644\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2913 - val_loss: 0.5006\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5057 - val_loss: 0.3816\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2102 - val_loss: 0.3560\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1931 - val_loss: 0.3495\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1873 - val_loss: 0.3621\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1944 - val_loss: 0.4277\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2121 - val_loss: 0.3921\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1622 - val_loss: 0.3541\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1736 - val_loss: 0.3584\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1739 - val_loss: 0.4018\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1563 - val_loss: 0.3831\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1643 - val_loss: 0.3304\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1581 - val_loss: 0.3386\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1618 - val_loss: 0.3954\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1717 - val_loss: 0.3656\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1411 - val_loss: 0.3940\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1366 - val_loss: 0.3453\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1338 - val_loss: 0.3390\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1263 - val_loss: 0.3292\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1312 - val_loss: 0.3259\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1553 - val_loss: 0.3374\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1375 - val_loss: 0.3361\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1174 - val_loss: 0.3291\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1306 - val_loss: 0.3288\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1509 - val_loss: 0.3323\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1340 - val_loss: 0.3559\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1359 - val_loss: 0.3421\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1393 - val_loss: 0.3350\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1054 - val_loss: 0.3307\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1125 - val_loss: 0.3320\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1206 - val_loss: 0.3314\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1154 - val_loss: 0.3384\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1101 - val_loss: 0.3541\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1213 - val_loss: 0.3248\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1149 - val_loss: 0.3314\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1044 - val_loss: 0.3245\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1075 - val_loss: 0.3358\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1110 - val_loss: 0.3248\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1050 - val_loss: 0.3204\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1072 - val_loss: 0.3355\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0987 - val_loss: 0.3489\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1048 - val_loss: 0.3240\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1134 - val_loss: 0.3250\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0985 - val_loss: 0.3230\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0941 - val_loss: 0.3300\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0982 - val_loss: 0.3255\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0969 - val_loss: 0.3654\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1227 - val_loss: 0.3253\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1035 - val_loss: 0.3558\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1019 - val_loss: 0.3498\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1072 - val_loss: 0.3178\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1086 - val_loss: 0.3214\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0955 - val_loss: 0.3533\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1160 - val_loss: 0.3187\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1057 - val_loss: 0.3198\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0922 - val_loss: 0.3214\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0893 - val_loss: 0.3215\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0913 - val_loss: 0.3144\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1076 - val_loss: 0.3103\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0906 - val_loss: 0.3568\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1025 - val_loss: 0.3130\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0973 - val_loss: 0.3245\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0932 - val_loss: 0.3184\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0991 - val_loss: 0.3145\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0849 - val_loss: 0.3154\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0897 - val_loss: 0.3230\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0882 - val_loss: 0.3199\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0813 - val_loss: 0.3168\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0864 - val_loss: 0.3207\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0872 - val_loss: 0.3242\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0903 - val_loss: 0.3167\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1056 - val_loss: 0.3262\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0954 - val_loss: 0.3174\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0816 - val_loss: 0.3320\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0887 - val_loss: 0.3213\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0875 - val_loss: 0.3151\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0818 - val_loss: 0.3215\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0983 - val_loss: 0.3171\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0837 - val_loss: 0.3187\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1023 - val_loss: 0.3195\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0745 - val_loss: 0.3205\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0820 - val_loss: 0.3222\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0886 - val_loss: 0.3133\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.0857 - val_loss: 0.3140\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0899 - val_loss: 0.3211\n",
      "Epoch 00154: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 5.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 233.1601 - val_loss: 10.0812\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.1096 - val_loss: 4.9599\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.7337 - val_loss: 2.8037\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s - loss: 3.6470 - val_loss: 2.2123\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5831 - val_loss: 1.3316\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9065 - val_loss: 0.7624\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7941 - val_loss: 5.0002\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.0685 - val_loss: 1.5154\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.1904 - val_loss: 6.3993\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.7698 - val_loss: 5.0757\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.9871 - val_loss: 2.0796\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2059 - val_loss: 3.5510\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4500 - val_loss: 2.7943\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4337 - val_loss: 1.0089\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.8180 - val_loss: 4.1907\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.6594 - val_loss: 1.2517\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.8257 - val_loss: 13.3501\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.7149 - val_loss: 1.0749\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1605 - val_loss: 2.0521\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.7998 - val_loss: 1.5264\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6491 - val_loss: 0.9432\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.5161 - val_loss: 1.3466\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4682 - val_loss: 1.3504\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3931 - val_loss: 1.5516\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6579 - val_loss: 0.8439\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5005 - val_loss: 3.0752\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2416 - val_loss: 0.9482\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6703 - val_loss: 0.7318\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6430 - val_loss: 0.5103\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3227 - val_loss: 1.1072\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9716 - val_loss: 1.1352\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6079 - val_loss: 1.0242\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5278 - val_loss: 0.6461\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9386 - val_loss: 0.5144\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8321 - val_loss: 0.4830\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4798 - val_loss: 0.8747\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7209 - val_loss: 0.5120\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8038 - val_loss: 0.5146\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1954 - val_loss: 0.9887\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2157 - val_loss: 0.6993\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1041 - val_loss: 0.8700\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8211 - val_loss: 0.4535\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5653 - val_loss: 0.4501\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8186 - val_loss: 0.3975\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5533 - val_loss: 0.4184\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4726 - val_loss: 0.6629\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4935 - val_loss: 0.3881\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3840 - val_loss: 0.4671\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4737 - val_loss: 0.4622\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3587 - val_loss: 0.3934\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5218 - val_loss: 0.4149\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3716 - val_loss: 0.4036\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5675 - val_loss: 0.7469\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8107 - val_loss: 0.4837\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4523 - val_loss: 0.5973\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3491 - val_loss: 0.4010\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4008 - val_loss: 0.5859\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5397 - val_loss: 0.4413\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3599 - val_loss: 0.5138\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4475 - val_loss: 0.4771\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3213 - val_loss: 0.4229\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2517 - val_loss: 0.4073\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3597 - val_loss: 0.4148\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3585 - val_loss: 0.3927\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3896 - val_loss: 0.4888\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2763 - val_loss: 0.3895\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3666 - val_loss: 0.3532\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2623 - val_loss: 0.3543\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1970 - val_loss: 0.3710\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2384 - val_loss: 0.3910\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2291 - val_loss: 0.3973\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2299 - val_loss: 0.4157\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1837 - val_loss: 0.3507\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1779 - val_loss: 0.3401\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1882 - val_loss: 0.3518\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2140 - val_loss: 0.3596\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1827 - val_loss: 0.4139\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1716 - val_loss: 0.3677\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1802 - val_loss: 0.3420\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2251 - val_loss: 0.4814\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2331 - val_loss: 0.3520\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1546 - val_loss: 0.3532\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1489 - val_loss: 0.4007\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1593 - val_loss: 0.3440\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1426 - val_loss: 0.3728\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1647 - val_loss: 0.3750\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1871 - val_loss: 0.3254\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1460 - val_loss: 0.3445\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1465 - val_loss: 0.3289\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1803 - val_loss: 0.3640\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1500 - val_loss: 0.3518\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1625 - val_loss: 0.3497\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1353 - val_loss: 0.3411\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1254 - val_loss: 0.3711\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1403 - val_loss: 0.3318\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1210 - val_loss: 0.3247\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1128 - val_loss: 0.3223\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1214 - val_loss: 0.3337\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1277 - val_loss: 0.3477\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1327 - val_loss: 0.3286\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1152 - val_loss: 0.3249\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1158 - val_loss: 0.3255\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1083 - val_loss: 0.3385\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1087 - val_loss: 0.3399\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1113 - val_loss: 0.3243\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1220 - val_loss: 0.3311\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1190 - val_loss: 0.3264\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1080 - val_loss: 0.3325\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1096 - val_loss: 0.3258\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0978 - val_loss: 0.3461\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1075 - val_loss: 0.3226\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1021 - val_loss: 0.3257\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1182 - val_loss: 0.3339\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1058 - val_loss: 0.3255\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1141 - val_loss: 0.3269\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0955 - val_loss: 0.3243\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1211 - val_loss: 0.3311\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1023 - val_loss: 0.3228\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1056 - val_loss: 0.3266\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0994 - val_loss: 0.3240\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0837 - val_loss: 0.3266\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0935 - val_loss: 0.3375\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1049 - val_loss: 0.3345\n",
      "Epoch 00122: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 265.0259 - val_loss: 20.4192\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.9636 - val_loss: 3.4456\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.1967 - val_loss: 1.4945\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4289 - val_loss: 1.2821\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.1558 - val_loss: 1.4925\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8266 - val_loss: 1.7393\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2209 - val_loss: 0.9072\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0115 - val_loss: 2.7247\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.2263 - val_loss: 12.3754\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.6695 - val_loss: 2.8388\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.4418 - val_loss: 17.1522\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 25.4482 - val_loss: 3.8178\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.3307 - val_loss: 3.9823\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 12.9641 - val_loss: 7.1847\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.0895 - val_loss: 1.4469\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.4871 - val_loss: 1.1304\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.3836 - val_loss: 3.7376\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9796 - val_loss: 1.4094\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4908 - val_loss: 1.1246\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5421 - val_loss: 0.9323ss:\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.8224 - val_loss: 8.8828\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.9521 - val_loss: 1.6674\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3041 - val_loss: 0.8525\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8955 - val_loss: 0.6462\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3340 - val_loss: 0.9085\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9489 - val_loss: 0.9999\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2483 - val_loss: 0.7992\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2816 - val_loss: 1.2957\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4931 - val_loss: 0.8114\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1963 - val_loss: 1.1052\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1187 - val_loss: 0.8742\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3273 - val_loss: 0.5753\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1943 - val_loss: 0.5133\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4386 - val_loss: 1.0989\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1061 - val_loss: 0.9527\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0129 - val_loss: 0.7838\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8637 - val_loss: 0.5782\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7246 - val_loss: 0.6583\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9491 - val_loss: 0.9115\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8291 - val_loss: 0.5050\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9834 - val_loss: 1.0759\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0306 - val_loss: 0.6299\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4399 - val_loss: 0.6463\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8864 - val_loss: 0.5356\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7934 - val_loss: 0.8965\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7106 - val_loss: 0.4639\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8000 - val_loss: 0.6612\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8678 - val_loss: 0.8755\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6684 - val_loss: 0.7655\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0731 - val_loss: 0.7637\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6455 - val_loss: 0.7600\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8319 - val_loss: 0.9355\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.2409 - val_loss: 0.5762\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5882 - val_loss: 0.4974\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4718 - val_loss: 0.4615\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5710 - val_loss: 0.4904\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0413 - val_loss: 0.4795\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4792 - val_loss: 0.4444\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4421 - val_loss: 0.4518\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7270 - val_loss: 0.4365\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3940 - val_loss: 0.3840\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3000 - val_loss: 0.4674\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3286 - val_loss: 0.4780\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3155 - val_loss: 0.3911\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3572 - val_loss: 0.4248\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3037 - val_loss: 0.4107\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2858 - val_loss: 0.4419\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2724 - val_loss: 0.4105\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2877 - val_loss: 0.5339\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3007 - val_loss: 0.3949\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2156 - val_loss: 0.3667\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2575 - val_loss: 0.4589\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2845 - val_loss: 0.4026\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3099 - val_loss: 0.4200\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2480 - val_loss: 0.3505\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2316 - val_loss: 0.3876\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3915 - val_loss: 0.4843\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2616 - val_loss: 0.4467\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3660 - val_loss: 0.3748\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2459 - val_loss: 0.4885ss: 0. - ETA\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2671 - val_loss: 0.4185\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2791 - val_loss: 0.3878\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2092 - val_loss: 0.3643\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2182 - val_loss: 0.4674\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2595 - val_loss: 0.3483\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1711 - val_loss: 0.3832\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2597 - val_loss: 0.4577\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1744 - val_loss: 0.3455\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2146 - val_loss: 0.4014\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1821 - val_loss: 0.4276\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1948 - val_loss: 0.3556\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1845 - val_loss: 0.3601\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2252 - val_loss: 0.3918\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1581 - val_loss: 0.3320\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1692 - val_loss: 0.3562\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1520 - val_loss: 0.3682\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1688 - val_loss: 0.3701\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1546 - val_loss: 0.3407\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1238 - val_loss: 0.3381\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1515 - val_loss: 0.3438\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1362 - val_loss: 0.3438\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1266 - val_loss: 0.3339\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1150 - val_loss: 0.3355\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1207 - val_loss: 0.3344ss: \n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1127 - val_loss: 0.3369\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1261 - val_loss: 0.3484\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1266 - val_loss: 0.3369\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1245 - val_loss: 0.3524\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1390 - val_loss: 0.3463\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1133 - val_loss: 0.3318\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1151 - val_loss: 0.3353\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1157 - val_loss: 0.3364\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1135 - val_loss: 0.3325\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1072 - val_loss: 0.3387\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1175 - val_loss: 0.3384\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1140 - val_loss: 0.3332\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1076 - val_loss: 0.3304\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0997 - val_loss: 0.3281\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1083 - val_loss: 0.3562\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1113 - val_loss: 0.3399\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1083 - val_loss: 0.3340\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1045 - val_loss: 0.3734\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1002 - val_loss: 0.3334\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1161 - val_loss: 0.3275\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1037 - val_loss: 0.3459\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1052 - val_loss: 0.3281\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0984 - val_loss: 0.3587\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0961 - val_loss: 0.3300\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1092 - val_loss: 0.3632\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1040 - val_loss: 0.3254\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0886 - val_loss: 0.3265\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0952 - val_loss: 0.3364\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0906 - val_loss: 0.3312\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0973 - val_loss: 0.3350\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0936 - val_loss: 0.3246\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0927 - val_loss: 0.3379\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0859 - val_loss: 0.3407\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0958 - val_loss: 0.3233\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0853 - val_loss: 0.3291\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0864 - val_loss: 0.3347\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0869 - val_loss: 0.3463\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0976 - val_loss: 0.3290\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0863 - val_loss: 0.3344\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0975 - val_loss: 0.3390\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0889 - val_loss: 0.3267\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0914 - val_loss: 0.3279\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0906 - val_loss: 0.3786\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0931 - val_loss: 0.3320\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0862 - val_loss: 0.3790\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1006 - val_loss: 0.3342\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1004 - val_loss: 0.3246\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0806 - val_loss: 0.3324\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0777 - val_loss: 0.3304\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0815 - val_loss: 0.3275\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0958 - val_loss: 0.3324\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0915 - val_loss: 0.3245\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0923 - val_loss: 0.3336\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0791 - val_loss: 0.3272\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0914 - val_loss: 0.3299\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0763 - val_loss: 0.3255\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0761 - val_loss: 0.3263\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0804 - val_loss: 0.3504\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0833 - val_loss: 0.3238\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.0963 - val_loss: 0.3311\n",
      "Epoch 00163: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=1, total= 6.5min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 3s - loss: 127.3757 - val_loss: 0.8508\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 21.6427 - val_loss: 0.4467\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 15.6194 - val_loss: 2.6803\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 18.1130 - val_loss: 1.6898\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 22.6866 - val_loss: 0.9398\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 19.2739 - val_loss: 0.6348\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 20.0911 - val_loss: 0.7678\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 19.7082 - val_loss: 0.4891\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 16.3712 - val_loss: 1.3404\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 13.8430 - val_loss: 2.1559\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 13.0707 - val_loss: 0.5318\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 11.2550 - val_loss: 1.5669\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 10.0420 - val_loss: 0.4686\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 8.9339 - val_loss: 0.4146\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 8.3872 - val_loss: 1.5260\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 7.3630 - val_loss: 0.6619\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 5.7878 - val_loss: 0.5073\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 5.0242 - val_loss: 0.3563\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.9162 - val_loss: 0.4199\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.8647 - val_loss: 0.7139\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.6558 - val_loss: 0.7608\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.0264 - val_loss: 0.4233\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.1795 - val_loss: 0.3659\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.3854 - val_loss: 0.3198\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.4781 - val_loss: 0.5807\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.7462 - val_loss: 0.4241\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.5189 - val_loss: 0.8351\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2878 - val_loss: 0.4777\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.8590 - val_loss: 0.3813\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5288 - val_loss: 0.5769\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4832 - val_loss: 0.5375\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3464 - val_loss: 0.3666\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5359 - val_loss: 0.4782\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.6323 - val_loss: 0.4318\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1112 - val_loss: 0.3143\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0967 - val_loss: 0.3575\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9187 - val_loss: 0.3074\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8165 - val_loss: 0.3053\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.2095 - val_loss: 0.4876\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9132 - val_loss: 0.3594\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7781 - val_loss: 0.3048\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7401 - val_loss: 0.3268\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7010 - val_loss: 0.3294\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6250 - val_loss: 0.2977\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5324 - val_loss: 0.4103\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5650 - val_loss: 0.3653\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5366 - val_loss: 0.3388\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5012 - val_loss: 0.3288\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4870 - val_loss: 0.3154\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4578 - val_loss: 0.3133\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4415 - val_loss: 0.2938\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3930 - val_loss: 0.3178\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4594 - val_loss: 0.3088ss\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3830 - val_loss: 0.3069\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4129 - val_loss: 0.3072\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3991 - val_loss: 0.3093\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3608 - val_loss: 0.3184\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3469 - val_loss: 0.3148\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3296 - val_loss: 0.3129\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3357 - val_loss: 0.3097\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3170 - val_loss: 0.3162\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3280 - val_loss: 0.2969\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2791 - val_loss: 0.3027\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2881 - val_loss: 0.3028\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2846 - val_loss: 0.2993\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2917 - val_loss: 0.3027\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2997 - val_loss: 0.3011\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2894 - val_loss: 0.3121\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2851 - val_loss: 0.3139\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2916 - val_loss: 0.3195\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2612 - val_loss: 0.3069\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2447 - val_loss: 0.2982\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2396 - val_loss: 0.3066\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2354 - val_loss: 0.3115\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2390 - val_loss: 0.3045\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2452 - val_loss: 0.3083\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2397 - val_loss: 0.3012ss: 0.239\n",
      "Epoch 00076: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 3.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 171.3508 - val_loss: 1.9585\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.7682 - val_loss: 0.3726\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.3348 - val_loss: 0.6692\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.3118 - val_loss: 0.5780\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.2794 - val_loss: 0.4661\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.1284 - val_loss: 1.5090\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.1655 - val_loss: 0.8709\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 20.2506 - val_loss: 1.1542\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 27.5071 - val_loss: 3.0445\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 23.0957 - val_loss: 1.9865s:\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 18.4241 - val_loss: 1.6574\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 22.5818 - val_loss: 3.3957\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.2682 - val_loss: 5.5088\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 19.3474 - val_loss: 4.6926\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 18.1793 - val_loss: 5.5014\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 12.1722 - val_loss: 4.3657\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.9649 - val_loss: 1.5039\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.1850 - val_loss: 1.5978\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.7962 - val_loss: 0.9363\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.1429 - val_loss: 1.3417\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1171 - val_loss: 0.5271\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.3360 - val_loss: 1.1854\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.8196 - val_loss: 0.9237\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5617 - val_loss: 0.7317\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9459 - val_loss: 0.3340\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3169 - val_loss: 0.4359\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8250 - val_loss: 0.3785\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7945 - val_loss: 0.4422\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7869 - val_loss: 0.4661\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.1480 - val_loss: 0.5375\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0592 - val_loss: 0.3699\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8044 - val_loss: 0.3300\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6404 - val_loss: 0.3980\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2977 - val_loss: 0.4468\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6748 - val_loss: 0.7256\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4476 - val_loss: 0.3695\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4713 - val_loss: 0.4072\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4552 - val_loss: 0.3216\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2291 - val_loss: 0.3118\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2144 - val_loss: 0.4282\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3213 - val_loss: 0.3670\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9739 - val_loss: 0.3119\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0353 - val_loss: 0.3553\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0594 - val_loss: 0.3792\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8993 - val_loss: 0.4297\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0169 - val_loss: 0.3086\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8405 - val_loss: 0.3975\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7389 - val_loss: 0.3485\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8612 - val_loss: 0.3712\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9413 - val_loss: 0.3653\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6403 - val_loss: 0.3801\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7610 - val_loss: 0.4175\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6407 - val_loss: 0.3102\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6671 - val_loss: 0.4138\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5626 - val_loss: 0.3420\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5515 - val_loss: 0.3390\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5838 - val_loss: 0.3210ss:\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4793 - val_loss: 0.3141\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5985 - val_loss: 0.3705s\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5017 - val_loss: 0.3101\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5085 - val_loss: 0.3294\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4463 - val_loss: 0.3099\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4272 - val_loss: 0.3257\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3923 - val_loss: 0.3096\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4105 - val_loss: 0.3092\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3681 - val_loss: 0.3015ss: 0. - ETA: 1s\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3491 - val_loss: 0.3108\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3924 - val_loss: 0.3027\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3778 - val_loss: 0.3888\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3323 - val_loss: 0.3054ss:  - ETA: 0s - loss\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3230 - val_loss: 0.3108\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3175 - val_loss: 0.3224\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2926 - val_loss: 0.3131\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2973 - val_loss: 0.3069\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3517 - val_loss: 0.3131\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2837 - val_loss: 0.3062\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2984 - val_loss: 0.3163\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2724 - val_loss: 0.3184\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2568 - val_loss: 0.3116\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2699 - val_loss: 0.3380\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2759 - val_loss: 0.3292\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2412 - val_loss: 0.3224\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2424 - val_loss: 0.3094\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2295 - val_loss: 0.3041\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2230 - val_loss: 0.3088\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2380 - val_loss: 0.3068\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2361 - val_loss: 0.3057\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2385 - val_loss: 0.3015\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2153 - val_loss: 0.3076\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2208 - val_loss: 0.3038\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2247 - val_loss: 0.3127\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2018 - val_loss: 0.3032\n",
      "Epoch 00091: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 3.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 232.4218 - val_loss: 0.5758\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.9425 - val_loss: 0.8383\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.5388 - val_loss: 1.0498\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.2899 - val_loss: 0.6973\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.7590 - val_loss: 1.0257\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.5396 - val_loss: 0.6096\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.7397 - val_loss: 0.5769\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.7162 - val_loss: 0.5232\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.7804 - val_loss: 1.1773\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.3700 - val_loss: 0.7973\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 17.3379 - val_loss: 3.4135\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 20.6647 - val_loss: 1.1400\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.5329 - val_loss: 3.5108\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.8928 - val_loss: 0.8889\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.5614 - val_loss: 2.0340\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 19.8707 - val_loss: 2.3841\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.8114 - val_loss: 0.9058\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.2702 - val_loss: 3.0854\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.0060 - val_loss: 2.1683\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.6974 - val_loss: 0.9259\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.6038 - val_loss: 0.7144\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.8463 - val_loss: 1.1574\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.3555 - val_loss: 0.8670\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.9544 - val_loss: 0.3832\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1330 - val_loss: 0.5835\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.7095 - val_loss: 0.4456\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.6801 - val_loss: 1.0115\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9120 - val_loss: 0.3550\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6204 - val_loss: 0.4282\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7716 - val_loss: 1.0876\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.4505 - val_loss: 0.6730\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6681 - val_loss: 1.0447\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4489 - val_loss: 0.4365\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5017 - val_loss: 2.1710\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.6045 - val_loss: 0.6944\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.3922 - val_loss: 1.0219\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9007 - val_loss: 0.4663\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0760 - val_loss: 0.4218\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5809 - val_loss: 1.0345\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2402 - val_loss: 1.0311\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1557 - val_loss: 0.3990\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6284 - val_loss: 0.3843\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7248 - val_loss: 0.4450\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6503 - val_loss: 0.6698\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5564 - val_loss: 0.3334\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2240 - val_loss: 0.3344\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0945 - val_loss: 0.3398\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1493 - val_loss: 0.4255\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0112 - val_loss: 0.3888\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1174 - val_loss: 0.3423\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8871 - val_loss: 0.3242\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8766 - val_loss: 0.3117\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0412 - val_loss: 0.4059\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8109 - val_loss: 0.3336\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9520 - val_loss: 0.4555\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.8180 - val_loss: 0.3191\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7093 - val_loss: 0.3143\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6734 - val_loss: 0.3172\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6426 - val_loss: 0.3171\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7442 - val_loss: 0.3666\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6390 - val_loss: 0.3304\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5581 - val_loss: 0.3218\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5426 - val_loss: 0.3145\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5340 - val_loss: 0.4081\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5342 - val_loss: 0.3732\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5669 - val_loss: 0.3277\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4379 - val_loss: 0.3375\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4166 - val_loss: 0.3293\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4054 - val_loss: 0.3102\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4131 - val_loss: 0.3171\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4165 - val_loss: 0.3327\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3807 - val_loss: 0.3418\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3620 - val_loss: 0.3169\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3522 - val_loss: 0.3501\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4109 - val_loss: 0.3204\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3550 - val_loss: 0.3098\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3739 - val_loss: 0.3343\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3847 - val_loss: 0.3157\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3187 - val_loss: 0.3293\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3806 - val_loss: 0.3107\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3484 - val_loss: 0.3243\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2950 - val_loss: 0.3163\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3543 - val_loss: 0.3169\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3248 - val_loss: 0.3061\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3058 - val_loss: 0.3317\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2756 - val_loss: 0.3331\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2888 - val_loss: 0.3206\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2565 - val_loss: 0.3074\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2528 - val_loss: 0.3072\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2415 - val_loss: 0.3200\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2421 - val_loss: 0.3157\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2564 - val_loss: 0.3232\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2522 - val_loss: 0.3631\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2435 - val_loss: 0.3063\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2503 - val_loss: 0.3154\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2310 - val_loss: 0.3126\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2208 - val_loss: 0.3188\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2238 - val_loss: 0.3070\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2093 - val_loss: 0.3141\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2225 - val_loss: 0.3148\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2051 - val_loss: 0.3109\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1979 - val_loss: 0.3126\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2027 - val_loss: 0.3407\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2084 - val_loss: 0.3265\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1853 - val_loss: 0.3098\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2018 - val_loss: 0.3182\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1945 - val_loss: 0.3236\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1871 - val_loss: 0.3151\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1970 - val_loss: 0.3382\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2027 - val_loss: 0.3493\n",
      "Epoch 00109: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 5.1min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 174.2402 - val_loss: 7.3612\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 19.4659 - val_loss: 1.3821\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.3127 - val_loss: 2.0646\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.0105 - val_loss: 0.9552\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.4620 - val_loss: 0.5667\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 23.9261 - val_loss: 1.0927\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 25.5783 - val_loss: 1.8571\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 27.9503 - val_loss: 2.8219\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 29.7613 - val_loss: 1.2264\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.5358 - val_loss: 0.6153\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.0362 - val_loss: 1.5856\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.5927 - val_loss: 2.6012\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.1623 - val_loss: 0.7657\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.8505 - val_loss: 0.5309\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.8410 - val_loss: 0.6723\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.8955 - val_loss: 0.5952\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.0653 - val_loss: 1.1784\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.1177 - val_loss: 0.8612\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.8426 - val_loss: 0.4014\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.3516 - val_loss: 1.1548\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.6224 - val_loss: 0.6823\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.6565 - val_loss: 0.5203\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s - loss: 5.1303 - val_loss: 0.6953\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.8856 - val_loss: 1.2208\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.9130 - val_loss: 1.1711\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5991 - val_loss: 1.4707\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 3.6359 - val_loss: 0.4887\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0052 - val_loss: 0.4058\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s - loss: 3.7197 - val_loss: 0.9225\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 4.6427 - val_loss: 1.0039\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8543 - val_loss: 0.4154\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1861 - val_loss: 0.4275\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8514 - val_loss: 0.4350\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s - loss: 2.0070 - val_loss: 0.4170\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0062 - val_loss: 0.5477\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6809 - val_loss: 0.4199ss: 1.661\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9695 - val_loss: 0.3279\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7495 - val_loss: 0.4162\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4672 - val_loss: 0.4111\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.3116 - val_loss: 0.3757\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.4718 - val_loss: 0.3248\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.1845 - val_loss: 0.4178\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1472 - val_loss: 0.3288\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.1428 - val_loss: 0.3665\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0730 - val_loss: 0.3085\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.0262 - val_loss: 0.3069\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.0172 - val_loss: 0.3137\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8338 - val_loss: 0.3078\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9504 - val_loss: 0.3355\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9143 - val_loss: 0.3130\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7826 - val_loss: 0.3021\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6782 - val_loss: 0.3135\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7472 - val_loss: 0.3081\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7089 - val_loss: 0.3537\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9713 - val_loss: 0.3918\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7479 - val_loss: 0.3288\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6511 - val_loss: 0.3253\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5779 - val_loss: 0.3148\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6027 - val_loss: 0.3507\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4629 - val_loss: 0.3272\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4664 - val_loss: 0.3301\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6769 - val_loss: 0.3252\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4465 - val_loss: 0.3183\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4206 - val_loss: 0.3183\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3705 - val_loss: 0.3108\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4320 - val_loss: 0.3346\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3567 - val_loss: 0.3164\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3587 - val_loss: 0.3203\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3513 - val_loss: 0.3135\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3407 - val_loss: 0.3237\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3164 - val_loss: 0.3256\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3137 - val_loss: 0.3174\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2883 - val_loss: 0.3173\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3393 - val_loss: 0.3194\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3422 - val_loss: 0.3281\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3001 - val_loss: 0.3183\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2940 - val_loss: 0.3207\n",
      "Epoch 00076: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 3.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 172.2005 - val_loss: 6.6065\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 12.2873 - val_loss: 0.8571\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.4374 - val_loss: 0.9155\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.1203 - val_loss: 0.6161\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.7140 - val_loss: 0.4466\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.3352 - val_loss: 0.4118\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.3912 - val_loss: 2.0132\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.4712 - val_loss: 2.2194\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.3838 - val_loss: 3.2859\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 18.3786 - val_loss: 1.3240\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 16.1887 - val_loss: 1.5443\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 13.7179 - val_loss: 1.8814\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 14.6585 - val_loss: 0.5249\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 16.5188 - val_loss: 1.0170\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 13.3430 - val_loss: 0.8911\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.9052 - val_loss: 1.5818\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.8519 - val_loss: 1.0555\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.1652 - val_loss: 1.0992\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 7.6846 - val_loss: 1.3108\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 5.6905 - val_loss: 0.6465\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 6.2739 - val_loss: 0.6081\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.3254 - val_loss: 1.3391\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.7544 - val_loss: 0.9659\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1850 - val_loss: 0.4960\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7254 - val_loss: 0.3610\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1809 - val_loss: 2.1649\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3670 - val_loss: 0.6618\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8026 - val_loss: 0.5629ss: 2.799\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5072 - val_loss: 0.3628\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0745 - val_loss: 0.3488\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2043 - val_loss: 1.0170\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4846 - val_loss: 0.3285\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9447 - val_loss: 0.4295\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7489 - val_loss: 0.3546\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9433 - val_loss: 0.5575\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2964 - val_loss: 0.4737\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8268 - val_loss: 0.3247\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3647 - val_loss: 0.5811\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2715 - val_loss: 0.3475\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0661 - val_loss: 0.3186\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1201 - val_loss: 0.3706\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9508 - val_loss: 0.3226\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9309 - val_loss: 0.3135\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8659 - val_loss: 0.3287\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9144 - val_loss: 0.3230\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7449 - val_loss: 0.3199\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6976 - val_loss: 0.3361\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8013 - val_loss: 0.3366\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7165 - val_loss: 0.3094\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6823 - val_loss: 0.3473\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7103 - val_loss: 0.3591\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6438 - val_loss: 0.3112\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5984 - val_loss: 0.3714\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5422 - val_loss: 0.3342\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5391 - val_loss: 0.3298\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4817 - val_loss: 0.3446\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4610 - val_loss: 0.3246\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6617 - val_loss: 0.3552\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6581 - val_loss: 0.4497\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5327 - val_loss: 0.3119\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4581 - val_loss: 0.3098\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4039 - val_loss: 0.3201\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3675 - val_loss: 0.3092\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3659 - val_loss: 0.3284\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3836 - val_loss: 0.3287\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3429 - val_loss: 0.3097\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3520 - val_loss: 0.3359\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3025 - val_loss: 0.3119\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3313 - val_loss: 0.3175\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3155 - val_loss: 0.3165\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3006 - val_loss: 0.3330\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3064 - val_loss: 0.3150\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3272 - val_loss: 0.3203\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2832 - val_loss: 0.3189\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3236 - val_loss: 0.3112\n",
      "Epoch 00074: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=2, total= 3.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 3s - loss: 197.4837 - val_loss: 5.2051\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 35.7064 - val_loss: 0.5599\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 27.0823 - val_loss: 0.6404\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 24.3193 - val_loss: 0.7848\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 24.7764 - val_loss: 0.5258\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 23.5716 - val_loss: 0.9417\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 23.4950 - val_loss: 1.4163\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 20.8388 - val_loss: 0.6160\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 18.3384 - val_loss: 3.3050\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 16.5687 - val_loss: 0.4342\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 14.0672 - val_loss: 0.9326\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 10.7349 - val_loss: 0.3681\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 9.9746 - val_loss: 1.1300\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 8.9470 - val_loss: 0.3839\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 7.8932 - val_loss: 0.7992\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 8.5701 - val_loss: 0.6326\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 6.6787 - val_loss: 0.6847\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 6.4827 - val_loss: 0.8033\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 5.6635 - val_loss: 1.1131\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.8141 - val_loss: 0.4827\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.4017 - val_loss: 0.6239\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.7989 - val_loss: 0.8130\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.7460 - val_loss: 0.5296\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.4571 - val_loss: 0.5904\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.1113 - val_loss: 0.9134\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.9266 - val_loss: 0.5968\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.6773 - val_loss: 0.4940\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.3581 - val_loss: 0.4143\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2752 - val_loss: 0.3701\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.5030 - val_loss: 0.5705\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2240 - val_loss: 0.3786\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0141 - val_loss: 0.3466\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.1798 - val_loss: 0.3621\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.6434 - val_loss: 0.4883\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5767 - val_loss: 0.3730\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4553 - val_loss: 0.3971\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3258 - val_loss: 0.3128\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1738 - val_loss: 0.3089\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1601 - val_loss: 0.3265\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1681 - val_loss: 0.4043\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0388 - val_loss: 0.3445\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0356 - val_loss: 0.3340ss: 1.\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9888 - val_loss: 0.3390\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9106 - val_loss: 0.3357\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8808 - val_loss: 0.3169\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7655 - val_loss: 0.4681\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8408 - val_loss: 0.3169\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8290 - val_loss: 0.3458\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7041 - val_loss: 0.3289\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7537 - val_loss: 0.3041\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7575 - val_loss: 0.35150s - loss: 0.\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7211 - val_loss: 0.3310\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6299 - val_loss: 0.3423\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6095 - val_loss: 0.3822\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5752 - val_loss: 0.3081\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5569 - val_loss: 0.3724\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5371 - val_loss: 0.3115\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6258 - val_loss: 0.3424\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4890 - val_loss: 0.3013\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4490 - val_loss: 0.3173\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4367 - val_loss: 0.3118\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4647 - val_loss: 0.3027\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4366 - val_loss: 0.3861\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4483 - val_loss: 0.3178\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4040 - val_loss: 0.3021\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4081 - val_loss: 0.3474\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3905 - val_loss: 0.3148\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4144 - val_loss: 0.3155\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3950 - val_loss: 0.3793\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4074 - val_loss: 0.3021\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3657 - val_loss: 0.3027\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3698 - val_loss: 0.3025\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3619 - val_loss: 0.3243\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3206 - val_loss: 0.3000\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3463 - val_loss: 0.3081\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3326 - val_loss: 0.3045\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3242 - val_loss: 0.3533\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3081 - val_loss: 0.3002\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2838 - val_loss: 0.3063\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3006 - val_loss: 0.3007\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2930 - val_loss: 0.3079\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2812 - val_loss: 0.3091\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2765 - val_loss: 0.3024\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2645 - val_loss: 0.3083\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2725 - val_loss: 0.2994\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2436 - val_loss: 0.2967\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2487 - val_loss: 0.3239\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2570 - val_loss: 0.3468\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2708 - val_loss: 0.3007\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2493 - val_loss: 0.3098\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2499 - val_loss: 0.3183\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2513 - val_loss: 0.3086\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2288 - val_loss: 0.3043\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2191 - val_loss: 0.3176\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2271 - val_loss: 0.3066\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2315 - val_loss: 0.3363\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2488 - val_loss: 0.3177\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2283 - val_loss: 0.3146\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2379 - val_loss: 0.3163\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2228 - val_loss: 0.3098\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2065 - val_loss: 0.3139\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1927 - val_loss: 0.3088\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1983 - val_loss: 0.3296\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2024 - val_loss: 0.3059\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1927 - val_loss: 0.3206\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1978 - val_loss: 0.3052\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2223 - val_loss: 0.3046\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1984 - val_loss: 0.3097\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1880 - val_loss: 0.3179\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1930 - val_loss: 0.3235\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1759 - val_loss: 0.3369\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1927 - val_loss: 0.3105\n",
      "Epoch 00111: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 4.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 170.9135 - val_loss: 0.8434\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 47.1535 - val_loss: 1.7805\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 37.5674 - val_loss: 0.9859\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 35.2149 - val_loss: 0.7464\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 32.7060 - val_loss: 1.3499\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 26.5813 - val_loss: 3.6555\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 24.2351 - val_loss: 0.4742\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 19.3405 - val_loss: 0.6315\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.5978 - val_loss: 2.4287\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.0702 - val_loss: 1.0435\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.4676 - val_loss: 3.6003\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.5321 - val_loss: 0.4038\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.5926 - val_loss: 1.0459\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.4689 - val_loss: 0.3571\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 163s - loss: 7.1981 - val_loss: 0.9092\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.6120 - val_loss: 0.7835\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.9133 - val_loss: 0.5235\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.3426 - val_loss: 0.4524\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.6745 - val_loss: 0.5292\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 9s - loss: 5.1649 - val_loss: 0.4529\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6880 - val_loss: 0.8579\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1554 - val_loss: 0.9282\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1834s - loss: 3.5886 - val_loss: 0.6225\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.1304 - val_loss: 0.5044\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6693 - val_loss: 0.3227\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8050 - val_loss: 0.3310\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5430 - val_loss: 0.5128\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4096 - val_loss: 0.3368\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7469 - val_loss: 0.4938\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.9947 - val_loss: 0.3528\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1307 - val_loss: 0.3256\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6363 - val_loss: 0.3802\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5691 - val_loss: 0.3270\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3761 - val_loss: 0.3567\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5470 - val_loss: 0.4066\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1709 - val_loss: 0.4149\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0959 - val_loss: 0.3327\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0377 - val_loss: 0.3932\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9943 - val_loss: 0.3745\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9225 - val_loss: 0.3917\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8528 - val_loss: 0.4208\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8228 - val_loss: 0.3376\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8815 - val_loss: 0.3233\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7556 - val_loss: 0.3519\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7903 - val_loss: 0.3521\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7239 - val_loss: 0.3236\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7116 - val_loss: 0.3202\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6149 - val_loss: 0.3169\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6637 - val_loss: 0.3078\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6539 - val_loss: 0.3608\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5200 - val_loss: 0.3495\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5933 - val_loss: 0.3204\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5364 - val_loss: 0.3572\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5075 - val_loss: 0.3592\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4726 - val_loss: 0.3344\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4826 - val_loss: 0.3280\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4646 - val_loss: 0.3253\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4367 - val_loss: 0.3160\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4089 - val_loss: 0.3474\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4140 - val_loss: 0.3170\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4175 - val_loss: 0.3421\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3709 - val_loss: 0.3285\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4074 - val_loss: 0.3829\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4120 - val_loss: 0.3122\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3803 - val_loss: 0.3233\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3469 - val_loss: 0.3186\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3628 - val_loss: 0.3161\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3758 - val_loss: 0.3105\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3358 - val_loss: 0.3238\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3238 - val_loss: 0.3275\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3131 - val_loss: 0.3201\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3296 - val_loss: 0.3360ss: 0.3\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3350 - val_loss: 0.3064\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3115 - val_loss: 0.3124\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3251 - val_loss: 0.3064\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3082 - val_loss: 0.3070\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2976 - val_loss: 0.3139\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2953 - val_loss: 0.3097\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2585 - val_loss: 0.3689\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2984 - val_loss: 0.3369\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2792 - val_loss: 0.3128\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2581 - val_loss: 0.3113\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2451 - val_loss: 0.3220\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2370 - val_loss: 0.3151\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2609 - val_loss: 0.3671\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2850 - val_loss: 0.4060\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2557 - val_loss: 0.3302\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2440 - val_loss: 0.3109\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2576 - val_loss: 0.3327\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2420 - val_loss: 0.3153\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2235 - val_loss: 0.3192\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2226 - val_loss: 0.3153\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2274 - val_loss: 0.3208\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2194 - val_loss: 0.3186\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2220 - val_loss: 0.3208\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2191 - val_loss: 0.3161\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2233 - val_loss: 0.3187\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2183 - val_loss: 0.3292\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2041 - val_loss: 0.3123\n",
      "Epoch 00098: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total=37.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 189.7995 - val_loss: 4.1769\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 57.5788 - val_loss: 1.0197\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 44.7334 - val_loss: 2.0450\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 43.9040 - val_loss: 7.0492\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 44.3703 - val_loss: 2.2338\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 33.8271 - val_loss: 4.2344\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 30.0192 - val_loss: 3.1149\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.3015 - val_loss: 1.9486\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 18.7214 - val_loss: 1.0529\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.4693 - val_loss: 0.6322\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.3911 - val_loss: 3.0673\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.8626 - val_loss: 1.7090\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.9543 - val_loss: 1.0344\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.8633 - val_loss: 0.6781\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.9258 - val_loss: 0.5248\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.5986 - val_loss: 0.8043\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.1460 - val_loss: 1.6567\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.2264 - val_loss: 0.7265\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1197 - val_loss: 0.5421\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.4974 - val_loss: 1.5137\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.2282 - val_loss: 0.4819\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.0087 - val_loss: 0.8376\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.3330 - val_loss: 0.3489\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5141 - val_loss: 0.4933\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.3215 - val_loss: 0.3403\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9928 - val_loss: 0.4187\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7871 - val_loss: 0.3461\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.1624 - val_loss: 0.4092\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3926 - val_loss: 0.4919\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2720 - val_loss: 0.3478\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0382 - val_loss: 0.3665\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9963 - val_loss: 0.3169\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7969 - val_loss: 0.5379ss:  - ETA: 1s -\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8933 - val_loss: 0.5077\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6080 - val_loss: 0.4224\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6068 - val_loss: 0.3166\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3713 - val_loss: 0.3182\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3114 - val_loss: 0.4079\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1352 - val_loss: 0.3228\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1030 - val_loss: 0.3142\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1912 - val_loss: 0.3220\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1494 - val_loss: 0.4384\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0125 - val_loss: 0.3237\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9863 - val_loss: 0.3218\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8887 - val_loss: 0.3055\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8837 - val_loss: 0.4022\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8389 - val_loss: 0.3558\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8949 - val_loss: 0.4911\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7880 - val_loss: 0.4001\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7498 - val_loss: 0.3349\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7435 - val_loss: 0.3321\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7058 - val_loss: 0.3206\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6565 - val_loss: 0.3941\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7463 - val_loss: 0.3371\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6248 - val_loss: 0.3236\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6987 - val_loss: 0.3406\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5809 - val_loss: 0.3562\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5067 - val_loss: 0.3500\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4936 - val_loss: 0.3445\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5017 - val_loss: 0.3361\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5004 - val_loss: 0.3157\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4511 - val_loss: 0.3236\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4114 - val_loss: 0.3455s\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4070 - val_loss: 0.3129\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4115 - val_loss: 0.3111\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3822 - val_loss: 0.3225\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4109 - val_loss: 0.3165\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4184 - val_loss: 0.3320\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4066 - val_loss: 0.3215\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3577 - val_loss: 0.3131\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3875 - val_loss: 0.3193\n",
      "Epoch 00070: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 2.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 229.6962 - val_loss: 5.1727\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 54.5674 - val_loss: 0.6215\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 35.9210 - val_loss: 1.0225\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 32.3680 - val_loss: 2.1280\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 25.9210 - val_loss: 0.4241\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.8352 - val_loss: 0.9592\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 25.7662 - val_loss: 0.6024\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 24.7869 - val_loss: 1.6317\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 20.0210 - val_loss: 0.8310\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 19.5646 - val_loss: 0.7916\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 22.3130 - val_loss: 0.6184\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.4922 - val_loss: 0.8136\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.9366 - val_loss: 0.4482\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.6432 - val_loss: 0.6211\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.9750 - val_loss: 0.6211\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.5288 - val_loss: 1.1407\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.1077 - val_loss: 7.6217\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.1798 - val_loss: 1.5734\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.4140 - val_loss: 0.6835\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.4181 - val_loss: 0.9469\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.8100 - val_loss: 0.4885\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.6925 - val_loss: 1.7005\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.2029 - val_loss: 0.5615\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2928 - val_loss: 0.4723\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4702 - val_loss: 0.4347\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5122 - val_loss: 0.5659\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3010 - val_loss: 1.0205\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7803 - val_loss: 0.3534\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0363 - val_loss: 0.6054\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.0041 - val_loss: 0.6089\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6419 - val_loss: 0.5030\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5908 - val_loss: 0.4022\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9206 - val_loss: 0.6443\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9191 - val_loss: 0.3646\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7070 - val_loss: 0.4500\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5393 - val_loss: 0.3082\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8873 - val_loss: 0.7079\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1997 - val_loss: 0.4255\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5199 - val_loss: 0.3472\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2797 - val_loss: 0.4110\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3969 - val_loss: 0.3586\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2127 - val_loss: 0.4782\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1473 - val_loss: 0.3927\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1597 - val_loss: 0.3257\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9832 - val_loss: 0.4450\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1753 - val_loss: 0.4408\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9203 - val_loss: 0.3559\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4393 - val_loss: 0.3890\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0321 - val_loss: 0.3255\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9892 - val_loss: 0.4229\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8895 - val_loss: 0.3166\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8433 - val_loss: 0.3180\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7797 - val_loss: 0.3675\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6737 - val_loss: 0.3292\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7054 - val_loss: 0.3072\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6897 - val_loss: 0.3090\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6509 - val_loss: 0.3016\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5476 - val_loss: 0.3169\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5336 - val_loss: 0.3072\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5616 - val_loss: 0.3525\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5396 - val_loss: 0.3179\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4744 - val_loss: 0.3038\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4857 - val_loss: 0.3295\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4831 - val_loss: 0.3239\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4774 - val_loss: 0.3424\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4650 - val_loss: 0.3063\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4153 - val_loss: 0.3044\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4391 - val_loss: 0.3094\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4350 - val_loss: 0.3758\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4809 - val_loss: 0.3521\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4030 - val_loss: 0.3340\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3955 - val_loss: 0.3731\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4283 - val_loss: 0.3695\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4177 - val_loss: 0.3089\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4027 - val_loss: 0.3114\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3744 - val_loss: 0.3116\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3760 - val_loss: 0.3098\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3436 - val_loss: 0.3141\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3749 - val_loss: 0.3049\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3286 - val_loss: 0.3247\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3286 - val_loss: 0.3083\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3058 - val_loss: 0.3157\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3211 - val_loss: 0.3196\n",
      "Epoch 00082: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 3.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 252.2297 - val_loss: 8.2172\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 41.2848 - val_loss: 0.7720\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 36.9806 - val_loss: 4.4225\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 34.2271 - val_loss: 2.5117\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 34.9701 - val_loss: 4.5281\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 34.6042 - val_loss: 15.0675\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 35.4201 - val_loss: 1.0526\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 30.1101 - val_loss: 0.6001\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 26.4651 - val_loss: 3.0865\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.6445 - val_loss: 1.3146\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.4219 - val_loss: 0.6304\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.6231 - val_loss: 1.5898\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.1937 - val_loss: 0.9447\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 12.3924 - val_loss: 0.4922\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.1662 - val_loss: 0.9656\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.5440 - val_loss: 0.3919\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.7084 - val_loss: 0.5053\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.9647 - val_loss: 0.5556\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.4874 - val_loss: 0.4741\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.7631 - val_loss: 0.5287\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.6911 - val_loss: 0.6100\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.7622 - val_loss: 0.6690\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.9575 - val_loss: 0.4128\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.0584 - val_loss: 0.3654\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1520 - val_loss: 0.4032\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.9417 - val_loss: 0.6516\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4897 - val_loss: 0.4810\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.1354 - val_loss: 0.4882\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2525 - val_loss: 0.3771\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8956 - val_loss: 0.4361\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4816 - val_loss: 0.5515\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4059 - val_loss: 0.5047\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5353 - val_loss: 0.3400\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1008 - val_loss: 0.6206ss: \n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5855 - val_loss: 0.4142\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3638 - val_loss: 0.4295\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8565 - val_loss: 0.4519\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7910 - val_loss: 0.4188\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5886 - val_loss: 0.4970\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4134 - val_loss: 0.3186\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4405 - val_loss: 0.4168\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2688 - val_loss: 0.3691\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1778 - val_loss: 0.3311\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1675 - val_loss: 0.3865\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2828 - val_loss: 0.3280\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0248 - val_loss: 0.3431\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1193 - val_loss: 0.3302\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9221 - val_loss: 0.3489\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9365 - val_loss: 0.3182\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9590 - val_loss: 0.3522ss:\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8620 - val_loss: 0.3342\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8364 - val_loss: 0.4016\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7938 - val_loss: 0.3152\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7343 - val_loss: 0.3399\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6930 - val_loss: 0.3845\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5624 - val_loss: 0.3098\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6024 - val_loss: 0.3151\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6194 - val_loss: 0.3926\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5528 - val_loss: 0.3443\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5446 - val_loss: 0.3095\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5335 - val_loss: 0.3113\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5035 - val_loss: 0.3077\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5365 - val_loss: 0.4011ss: \n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5166 - val_loss: 0.3089\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4540 - val_loss: 0.3166\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4436 - val_loss: 0.3035\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4450 - val_loss: 0.3102\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4298 - val_loss: 0.3378\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4436 - val_loss: 0.3610\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4436 - val_loss: 0.3093\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3669 - val_loss: 0.3183ss: 0.3\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3996 - val_loss: 0.3485\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4062 - val_loss: 0.2966\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3886 - val_loss: 0.3445ss: 0.391 - ETA: 1s\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3617 - val_loss: 0.3274\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3734 - val_loss: 0.3246\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3513 - val_loss: 0.3139\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3448 - val_loss: 0.3133ss: 0.\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3315 - val_loss: 0.3315\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3315 - val_loss: 0.3046\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3319 - val_loss: 0.3062\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3284 - val_loss: 0.3259\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3154 - val_loss: 0.3263\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2979 - val_loss: 0.3082\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2865 - val_loss: 0.3128\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2733 - val_loss: 0.3060\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3514 - val_loss: 0.3021\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2886 - val_loss: 0.3829\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2910 - val_loss: 0.3038s\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2817 - val_loss: 0.3104\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2830 - val_loss: 0.3051\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2771 - val_loss: 0.3244\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2777 - val_loss: 0.3063\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2752 - val_loss: 0.3409\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2643 - val_loss: 0.3230\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2556 - val_loss: 0.3331\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2493 - val_loss: 0.3198\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2386 - val_loss: 0.3092\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2487 - val_loss: 0.3136\n",
      "Epoch 00098: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 3.9min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 449.0827 - val_loss: 15.7667\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s - loss: 21.8049 - val_loss: 2.3775\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s - loss: 9.3020 - val_loss: 1.6661\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s - loss: 5.4575 - val_loss: 5.5737\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s - loss: 4.3876 - val_loss: 2.4200\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 3s - loss: 3.4739 - val_loss: 1.2188\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.1242 - val_loss: 1.5136\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.5635 - val_loss: 1.0178\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.2060 - val_loss: 1.7544\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.9095 - val_loss: 1.7535\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.4888 - val_loss: 0.9434\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s - loss: 1.9289 - val_loss: 0.9030\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.3277 - val_loss: 4.4545\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 3s - loss: 4.3369 - val_loss: 3.0390\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s - loss: 4.9479 - val_loss: 1.1104\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 3s - loss: 4.6783 - val_loss: 2.0298\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.8159 - val_loss: 0.9985\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.7148 - val_loss: 1.4187\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s - loss: 3.4307 - val_loss: 5.4580\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 3s - loss: 7.8332 - val_loss: 6.2679\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s - loss: 8.4533 - val_loss: 2.9904\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s - loss: 5.3317 - val_loss: 1.2963\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 3.8370 - val_loss: 2.4101\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 3.6353 - val_loss: 2.3887\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 5.3260 - val_loss: 5.2404\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 4.7517 - val_loss: 1.2046\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 8.1009 - val_loss: 5.8856\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 8.4684 - val_loss: 3.0979\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 4.9507 - val_loss: 3.8226\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 10.3787 - val_loss: 1.3066\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.7916 - val_loss: 1.3233\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.7846 - val_loss: 0.7089\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.5965 - val_loss: 1.3835\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.2329 - val_loss: 0.8150\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.8765 - val_loss: 1.0786\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9959 - val_loss: 0.6022\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9178 - val_loss: 0.9987\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0554 - val_loss: 0.7579\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7409 - val_loss: 0.4477\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0638 - val_loss: 1.4536\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8563 - val_loss: 0.5994\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.1016 - val_loss: 1.2723\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8224 - val_loss: 0.8954\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6729 - val_loss: 0.5255\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6206 - val_loss: 0.6840\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7392 - val_loss: 0.6101\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5034 - val_loss: 0.6694\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5148 - val_loss: 0.4346\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8928 - val_loss: 0.6254\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0271 - val_loss: 1.2426\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5738 - val_loss: 0.4018\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4690 - val_loss: 0.3974\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4585 - val_loss: 0.4350\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3482 - val_loss: 0.4272\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3068 - val_loss: 0.3871\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0479 - val_loss: 0.9967\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6701 - val_loss: 0.7257\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4634 - val_loss: 0.3924\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5851 - val_loss: 0.3719\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2707 - val_loss: 0.3704\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2794 - val_loss: 0.3507\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2580 - val_loss: 0.3559\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2655 - val_loss: 0.4427\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5798 - val_loss: 0.3939\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2570 - val_loss: 0.3562\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2326 - val_loss: 0.3714\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2677 - val_loss: 0.3873\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2324 - val_loss: 0.3867\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3102 - val_loss: 0.5046\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2634 - val_loss: 0.3623\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1787 - val_loss: 0.3264\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2224 - val_loss: 0.5746\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2359 - val_loss: 0.3370\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1699 - val_loss: 0.3715\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6620 - val_loss: 1.3099\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6138 - val_loss: 0.3716\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2327 - val_loss: 0.3307\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2766 - val_loss: 0.7979\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6181 - val_loss: 0.7702\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2333 - val_loss: 0.3996\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3534 - val_loss: 0.3347\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1989 - val_loss: 0.3374\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2304 - val_loss: 0.4644\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1894 - val_loss: 0.3357\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1397 - val_loss: 0.3535\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1553 - val_loss: 0.3751\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1638 - val_loss: 0.3471\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1896 - val_loss: 0.3609\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1391 - val_loss: 0.3203\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1254 - val_loss: 0.3180\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1628 - val_loss: 0.3829\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1323 - val_loss: 0.3495\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1235 - val_loss: 0.3209\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1533 - val_loss: 0.3594\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2188 - val_loss: 0.3617\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1535 - val_loss: 0.3299\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1022 - val_loss: 0.3238\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0899 - val_loss: 0.3218\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1138 - val_loss: 0.3178\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1121 - val_loss: 0.3285\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0870 - val_loss: 0.3114\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1012 - val_loss: 0.3364\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1144 - val_loss: 0.3499\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1892 - val_loss: 0.4574\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1344 - val_loss: 0.3322\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1238 - val_loss: 0.3770\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1280 - val_loss: 0.3864\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1614 - val_loss: 0.3843\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1698 - val_loss: 0.3599\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2217 - val_loss: 0.4463ss: 0\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1638 - val_loss: 0.3700\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1017 - val_loss: 0.3144\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0769 - val_loss: 0.3208\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0726 - val_loss: 0.3199\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0858 - val_loss: 0.3176\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0762 - val_loss: 0.3243\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0717 - val_loss: 0.3101\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0668 - val_loss: 0.3308\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0741 - val_loss: 0.3305\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0652 - val_loss: 0.3153\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1006 - val_loss: 0.3887\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0931 - val_loss: 0.3081\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0747 - val_loss: 0.3216\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0688 - val_loss: 0.3157\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0822 - val_loss: 0.3160\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0645 - val_loss: 0.3040\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0820 - val_loss: 0.3351\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0842 - val_loss: 0.3169\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1039 - val_loss: 0.3298\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1073 - val_loss: 0.3212\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1349 - val_loss: 0.3186\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1118 - val_loss: 0.3130\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0773 - val_loss: 0.3258\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0973 - val_loss: 0.3443\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1072 - val_loss: 0.3288\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1000 - val_loss: 0.3655\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0964 - val_loss: 0.3197\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0751 - val_loss: 0.3211\n",
      "Epoch 139/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0585 - val_loss: 0.3097\n",
      "Epoch 140/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0711 - val_loss: 0.3270\n",
      "Epoch 141/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0530 - val_loss: 0.3191\n",
      "Epoch 142/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0618 - val_loss: 0.3083\n",
      "Epoch 143/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0617 - val_loss: 0.3128\n",
      "Epoch 144/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0539 - val_loss: 0.3094\n",
      "Epoch 145/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0555 - val_loss: 0.3153\n",
      "Epoch 146/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0534 - val_loss: 0.3294\n",
      "Epoch 147/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0580 - val_loss: 0.3065\n",
      "Epoch 148/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0549 - val_loss: 0.3164\n",
      "Epoch 149/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0615 - val_loss: 0.3264\n",
      "Epoch 150/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.0634 - val_loss: 0.3259\n",
      "Epoch 151/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.0864 - val_loss: 0.3149\n",
      "Epoch 152/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.0784 - val_loss: 0.3341\n",
      "Epoch 00151: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total=10.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 453.6971 - val_loss: 18.5452\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 31.5742 - val_loss: 3.4154\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.8030 - val_loss: 3.0368\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.3712 - val_loss: 1.5171\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.1228 - val_loss: 3.4878\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.2032 - val_loss: 1.8153\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9461 - val_loss: 0.9127\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.4620 - val_loss: 3.4467\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6671 - val_loss: 6.2662\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6922 - val_loss: 2.2047\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.8736 - val_loss: 0.9576\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.4973 - val_loss: 0.9495\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.1970 - val_loss: 4.3369\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.9357 - val_loss: 21.0284\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.3891 - val_loss: 1.5757\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.8770 - val_loss: 1.0700\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.1671 - val_loss: 6.4721\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.2670 - val_loss: 3.5840\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6626 - val_loss: 1.6586\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9919 - val_loss: 3.2485\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6586 - val_loss: 2.7760\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3579 - val_loss: 4.7947\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.2997 - val_loss: 4.5744\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.7804 - val_loss: 1.0488\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9529 - val_loss: 0.8846\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9130 - val_loss: 1.0883\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9251 - val_loss: 0.6522\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7691 - val_loss: 0.6388\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6514 - val_loss: 1.9430\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6271 - val_loss: 0.6262\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1185 - val_loss: 1.7764\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6391 - val_loss: 0.7594\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1390 - val_loss: 0.5613\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.5028 - val_loss: 1.8423\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.2270 - val_loss: 0.6275\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7853 - val_loss: 5.1991\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6937 - val_loss: 0.8774\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1990 - val_loss: 0.5309\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5883 - val_loss: 2.5685\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.5201 - val_loss: 1.0499\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1637 - val_loss: 0.7632\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2517 - val_loss: 0.7473\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8032 - val_loss: 0.4655\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.1708 - val_loss: 0.5306\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8661 - val_loss: 0.4740\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5528 - val_loss: 0.4330\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4150 - val_loss: 0.4518\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4070 - val_loss: 0.4361\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5180 - val_loss: 0.5090\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3957 - val_loss: 0.4694\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3924 - val_loss: 0.5054\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4921 - val_loss: 0.4372\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6970 - val_loss: 0.5304\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4068 - val_loss: 0.4124\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4021 - val_loss: 0.4030\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4001 - val_loss: 0.4078\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2836 - val_loss: 0.3630\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3770 - val_loss: 0.4229\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4709 - val_loss: 0.6773\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4750 - val_loss: 0.5905\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3728 - val_loss: 0.4688\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2755 - val_loss: 0.4412\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2929 - val_loss: 0.5061\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2706 - val_loss: 0.4042\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2751 - val_loss: 0.4226\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2493 - val_loss: 0.3674\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4248 - val_loss: 0.5061\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3510 - val_loss: 0.3783\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2229 - val_loss: 0.3787\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2092 - val_loss: 0.3813\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1915 - val_loss: 0.3691\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2316 - val_loss: 0.3690\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2365 - val_loss: 0.5530\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2490 - val_loss: 0.3799\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1847 - val_loss: 0.3911\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2000 - val_loss: 0.3891\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2144 - val_loss: 0.4065\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2649 - val_loss: 0.3823\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3957 - val_loss: 0.3808\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1913 - val_loss: 0.3570\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1278 - val_loss: 0.3613\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1651 - val_loss: 0.3498\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1456 - val_loss: 0.3518\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1465 - val_loss: 0.3603\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2320 - val_loss: 0.4474\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2355 - val_loss: 0.3638\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1579 - val_loss: 0.3424\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1106 - val_loss: 0.3459\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1371 - val_loss: 0.3685\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1244 - val_loss: 0.3473\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1167 - val_loss: 0.3646\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1206 - val_loss: 0.3676\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2309 - val_loss: 0.4014\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1989 - val_loss: 0.4115\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1245 - val_loss: 0.3372\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1067 - val_loss: 0.3381\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0993 - val_loss: 0.3494\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0875 - val_loss: 0.3373\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1228 - val_loss: 0.3668\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1050 - val_loss: 0.3506\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0904 - val_loss: 0.3449\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0902 - val_loss: 0.3458\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1047 - val_loss: 0.3664\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0952 - val_loss: 0.3404\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0963 - val_loss: 0.3291\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0863 - val_loss: 0.3468\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0873 - val_loss: 0.3922\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1080 - val_loss: 0.3401\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0896 - val_loss: 0.3352\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0744 - val_loss: 0.3337\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0780 - val_loss: 0.3392\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0761 - val_loss: 0.3287\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1277 - val_loss: 0.3306\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1444 - val_loss: 0.3278\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0865 - val_loss: 0.3326\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0619 - val_loss: 0.3282\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0762 - val_loss: 0.3289\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0848 - val_loss: 0.3359\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0837 - val_loss: 0.3564\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1015 - val_loss: 0.3512\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0842 - val_loss: 0.3789\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0885 - val_loss: 0.3527\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0760 - val_loss: 0.3199\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0659 - val_loss: 0.3306\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0659 - val_loss: 0.3213\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0846 - val_loss: 0.3385\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1093 - val_loss: 0.3295\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0881 - val_loss: 0.3569\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0873 - val_loss: 0.3258\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0722 - val_loss: 0.3541\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0828 - val_loss: 0.3453\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0685 - val_loss: 0.3152\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0642 - val_loss: 0.3382\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0612 - val_loss: 0.3315\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1031 - val_loss: 0.3186\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0771 - val_loss: 0.3192\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0717 - val_loss: 0.3223\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0675 - val_loss: 0.3154\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0653 - val_loss: 0.3207\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0652 - val_loss: 0.3297\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0706 - val_loss: 0.3338\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0782 - val_loss: 0.3274\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0800 - val_loss: 0.3446\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0838 - val_loss: 0.3478\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0726 - val_loss: 0.3318\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0723 - val_loss: 0.3252\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0713 - val_loss: 0.3256\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0607 - val_loss: 0.3277\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0752 - val_loss: 0.3198\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0675 - val_loss: 0.3291\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0722 - val_loss: 0.3272\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0704 - val_loss: 0.3159\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0605 - val_loss: 0.3278\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.0538 - val_loss: 0.3209\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0618 - val_loss: 0.3193\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0741 - val_loss: 0.3245\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0601 - val_loss: 0.3219\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0696 - val_loss: 0.3274\n",
      "Epoch 00157: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total=10.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 544.7760 - val_loss: 30.9363\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 33.2311 - val_loss: 3.5239\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.7729 - val_loss: 4.6335\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.8710 - val_loss: 6.2487\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.1045 - val_loss: 15.3896\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.2812 - val_loss: 1.1339\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.2993 - val_loss: 2.2065\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.2116 - val_loss: 1.8261\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6457 - val_loss: 1.2251\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.0960 - val_loss: 1.1592\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9159 - val_loss: 4.2319\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.5439 - val_loss: 0.9833\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.7085 - val_loss: 3.4329\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.1038 - val_loss: 2.0551\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6421 - val_loss: 6.8743\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.6365 - val_loss: 19.9237\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.2274 - val_loss: 14.7834\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.0698 - val_loss: 2.0290\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.8805 - val_loss: 4.2379\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.1820 - val_loss: 8.5705\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 20.8824 - val_loss: 9.6105\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.6379 - val_loss: 14.8807\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.6375 - val_loss: 1.7642\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6122 - val_loss: 7.0881\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.9618 - val_loss: 0.7548\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.1311 - val_loss: 1.8406\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.4788 - val_loss: 2.1861\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.4906 - val_loss: 1.9348\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7880 - val_loss: 0.7047\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2897 - val_loss: 0.6571\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0878 - val_loss: 0.5168\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3349 - val_loss: 0.5951\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1778 - val_loss: 0.5423\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2534 - val_loss: 0.6966\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2676 - val_loss: 0.5161\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9689 - val_loss: 0.5351\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8886 - val_loss: 0.5578\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8144 - val_loss: 0.5235\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7620 - val_loss: 0.4820\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2766 - val_loss: 2.0335\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1686 - val_loss: 0.4810\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0664 - val_loss: 0.4557\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8163 - val_loss: 1.1481\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8868 - val_loss: 0.7379\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8658 - val_loss: 0.6336\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6205 - val_loss: 0.5084\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5626 - val_loss: 1.1677\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9080 - val_loss: 0.5945\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7126 - val_loss: 0.7898\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7446 - val_loss: 0.4550\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7511 - val_loss: 0.8268\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6957 - val_loss: 0.4424\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7069 - val_loss: 2.9074\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1482 - val_loss: 0.5172\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3611 - val_loss: 1.1022\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6291 - val_loss: 0.4274\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5315 - val_loss: 0.4989\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7509 - val_loss: 0.5928\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3618 - val_loss: 0.3913\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3413 - val_loss: 0.3946\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3154 - val_loss: 0.3763\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4735 - val_loss: 0.4947\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7075 - val_loss: 0.6677\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4000 - val_loss: 0.4120\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3428 - val_loss: 0.3727\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7262 - val_loss: 0.4576\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3987 - val_loss: 0.3824\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2857 - val_loss: 0.4201\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5759 - val_loss: 0.3912\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6742 - val_loss: 0.3666\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3485 - val_loss: 0.4733\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2712 - val_loss: 0.3876\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2281 - val_loss: 0.3442\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2172 - val_loss: 0.4797\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2969 - val_loss: 0.5561\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2397 - val_loss: 0.3508\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2216 - val_loss: 0.3623\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2064 - val_loss: 0.3342\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1859 - val_loss: 0.3548\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1779 - val_loss: 0.4472\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1921 - val_loss: 0.4457\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2062 - val_loss: 0.4018\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4060 - val_loss: 0.3561\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2460 - val_loss: 0.4241\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1913 - val_loss: 0.3450\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1486 - val_loss: 0.3494\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1816 - val_loss: 0.3343\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1321 - val_loss: 0.3319\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1267 - val_loss: 0.3448\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1316 - val_loss: 0.3306\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1329 - val_loss: 0.3283\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1233 - val_loss: 0.3734\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1937 - val_loss: 0.3473\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1289 - val_loss: 0.3351\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1186 - val_loss: 0.3440\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1098 - val_loss: 0.3441\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1148 - val_loss: 0.3404\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1468 - val_loss: 0.3510\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1017 - val_loss: 0.3263\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0919 - val_loss: 0.3287\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1236 - val_loss: 0.3785\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1045 - val_loss: 0.3583\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0972 - val_loss: 0.3287\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1215 - val_loss: 0.3772\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1107 - val_loss: 0.3387\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0953 - val_loss: 0.3243\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0929 - val_loss: 0.3350\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0900 - val_loss: 0.3582\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0955 - val_loss: 0.3866\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0843 - val_loss: 0.3279\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0817 - val_loss: 0.3274\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0897 - val_loss: 0.3211\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0756 - val_loss: 0.3153\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0779 - val_loss: 0.3218\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0938 - val_loss: 0.3455\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0826 - val_loss: 0.3324\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0710 - val_loss: 0.3185\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0859 - val_loss: 0.3273\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0906 - val_loss: 0.3242\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0815 - val_loss: 0.3265\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0992 - val_loss: 0.3320\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0899 - val_loss: 0.3176\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0987 - val_loss: 0.3357\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0958 - val_loss: 0.3462\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0743 - val_loss: 0.3199\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0748 - val_loss: 0.3241\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0687 - val_loss: 0.3279\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0683 - val_loss: 0.3214\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0639 - val_loss: 0.3179\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0690 - val_loss: 0.3284\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0832 - val_loss: 0.3338\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0672 - val_loss: 0.3222\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0664 - val_loss: 0.3276\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0641 - val_loss: 0.3313\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0598 - val_loss: 0.3229\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0597 - val_loss: 0.3534\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0651 - val_loss: 0.3299\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0638 - val_loss: 0.3280\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0645 - val_loss: 0.3186\n",
      "Epoch 00138: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 9.6min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 503.2861 - val_loss: 11.0894\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 28.2871 - val_loss: 3.7556\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.3321 - val_loss: 4.2078\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.0359 - val_loss: 1.5798\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.1596 - val_loss: 2.3562\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.1108 - val_loss: 3.2460\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.4733 - val_loss: 1.0868\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0517 - val_loss: 0.8486\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.3713 - val_loss: 7.0962\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.9504 - val_loss: 1.1977\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.4870 - val_loss: 7.8648\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.6382 - val_loss: 3.0889\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.9231 - val_loss: 9.7087\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.7914 - val_loss: 3.3662\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.7684 - val_loss: 1.4270\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.8251 - val_loss: 37.2399\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.9113 - val_loss: 12.8990\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.1662 - val_loss: 1.8360\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.4767 - val_loss: 1.3436\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.7419 - val_loss: 1.6200\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.4003 - val_loss: 2.5664\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3831 - val_loss: 1.1255\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.1439 - val_loss: 3.3512\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.0081 - val_loss: 1.0685\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6930 - val_loss: 5.6021\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.9865 - val_loss: 1.9332\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.5273 - val_loss: 6.3477\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.0859 - val_loss: 2.1142\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3997 - val_loss: 1.8710\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.1699 - val_loss: 1.2555\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3889 - val_loss: 1.3375\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0187 - val_loss: 0.5701\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3553 - val_loss: 0.6264\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2687 - val_loss: 0.5240\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.5171 - val_loss: 2.1489\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7155 - val_loss: 0.8460\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2582 - val_loss: 0.8864\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1584 - val_loss: 0.4514\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6618 - val_loss: 1.6095\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8282 - val_loss: 0.9279\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9170 - val_loss: 1.1770\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8960 - val_loss: 0.9272\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8081 - val_loss: 0.5912\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9701 - val_loss: 0.7293\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4721 - val_loss: 0.4569\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5960 - val_loss: 0.4240\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3845 - val_loss: 0.4374\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4091 - val_loss: 0.4619\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3758 - val_loss: 0.4584\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3617 - val_loss: 0.4405\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3741 - val_loss: 0.3835\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3434 - val_loss: 0.3925\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3782 - val_loss: 0.4028\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4645 - val_loss: 0.4450\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3338 - val_loss: 0.6150\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3775 - val_loss: 0.4230\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3906 - val_loss: 0.4018\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5132 - val_loss: 0.4950\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5739 - val_loss: 0.4923\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4833 - val_loss: 0.4044\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3997 - val_loss: 0.4034\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2812 - val_loss: 0.4385\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2232 - val_loss: 0.4355\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2363 - val_loss: 0.4028\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2010 - val_loss: 0.4152\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1887 - val_loss: 0.4394\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1867 - val_loss: 0.4098\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1900 - val_loss: 0.5025\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2062 - val_loss: 0.4908\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2394 - val_loss: 0.3917\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2193 - val_loss: 0.3676\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1583 - val_loss: 0.4099\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2481 - val_loss: 0.5966\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2392 - val_loss: 0.3991\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2373 - val_loss: 0.5817\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2141 - val_loss: 0.3566\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1653 - val_loss: 0.3579\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2082 - val_loss: 0.3537\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1611 - val_loss: 0.3693\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1254 - val_loss: 0.3682\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1918 - val_loss: 0.4088\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1478 - val_loss: 0.3755\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1214 - val_loss: 0.3784\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1502 - val_loss: 0.3795\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1938 - val_loss: 0.4411\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2020 - val_loss: 0.4036\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2076 - val_loss: 0.5808\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1831 - val_loss: 0.3936\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1530 - val_loss: 0.3667\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1106 - val_loss: 0.3811\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1599 - val_loss: 0.3577\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1486 - val_loss: 0.3603\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1145 - val_loss: 0.3754\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1599 - val_loss: 0.3697\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1213 - val_loss: 0.3664\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1581 - val_loss: 0.3819\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1074 - val_loss: 0.3640\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0936 - val_loss: 0.3358\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1179 - val_loss: 0.3876\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0941 - val_loss: 0.3390\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0873 - val_loss: 0.3714\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1223 - val_loss: 0.3762\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1308 - val_loss: 0.3478ss: \n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1001 - val_loss: 0.3521\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1433 - val_loss: 0.3914\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1072 - val_loss: 0.3542\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0984 - val_loss: 0.3620\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1103 - val_loss: 0.3657\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0936 - val_loss: 0.3410\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0834 - val_loss: 0.3437\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0856 - val_loss: 0.3389\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0728 - val_loss: 0.3477\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0892 - val_loss: 0.3424\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0894 - val_loss: 0.3498\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0961 - val_loss: 0.3381\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0737 - val_loss: 0.3648\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.0776 - val_loss: 0.3405\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1078 - val_loss: 0.3417\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0793 - val_loss: 0.3548\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0820 - val_loss: 0.3563\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0919 - val_loss: 0.3452\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0787 - val_loss: 0.3555 0s - loss: 0.\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1027 - val_loss: 0.3532\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.0706 - val_loss: 0.3469\n",
      "Epoch 00123: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 9.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 531.7612 - val_loss: 26.2467\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 27.4704 - val_loss: 6.4689\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.2236 - val_loss: 3.4722s: 1\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.6429 - val_loss: 1.3497\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.1446 - val_loss: 1.6880\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6528 - val_loss: 1.2241\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.4974 - val_loss: 0.9728\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0151 - val_loss: 0.9566\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2789 - val_loss: 1.0295\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7697 - val_loss: 1.0535\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8588 - val_loss: 1.1696\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.8293 - val_loss: 1.6346\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6179 - val_loss: 11.8588\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.1406 - val_loss: 3.8444\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.3327 - val_loss: 9.4452\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.1752 - val_loss: 17.2913\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.3015 - val_loss: 2.1423\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.7950 - val_loss: 2.4122\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.6088 - val_loss: 10.4914\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.8817 - val_loss: 2.2125\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.8478 - val_loss: 3.6570\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.2044 - val_loss: 2.5812\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.9635 - val_loss: 2.1439\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.8423 - val_loss: 5.3824\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.8148 - val_loss: 1.1951\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.8568 - val_loss: 2.3253\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.5296 - val_loss: 5.8912\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.0456 - val_loss: 2.8719\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.3068 - val_loss: 1.1475\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6089 - val_loss: 2.7403\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.3557 - val_loss: 1.0657\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.7877 - val_loss: 1.4234\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.4318 - val_loss: 1.2682\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6641 - val_loss: 2.3158\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=1, total= 2.7min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s - loss: 327.7413 - val_loss: 8.2850\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 23.4982 - val_loss: 0.6301\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 12.0282 - val_loss: 0.8997\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 10.8589 - val_loss: 0.4115\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 13.0854 - val_loss: 0.6915\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 14.9041 - val_loss: 0.9078\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 15.9142 - val_loss: 1.2977\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 19.3177 - val_loss: 0.5364\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 24.1371 - val_loss: 0.8246\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 5s - loss: 22.9308 - val_loss: 0.6953\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 22.9367 - val_loss: 7.3563\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 33.8234 - val_loss: 1.4306\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 34.4886 - val_loss: 2.1138\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 28.9614 - val_loss: 1.2110\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 16.4277 - val_loss: 1.5256\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 14.0884 - val_loss: 4.4548\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 17.3705 - val_loss: 0.6483\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 11.3892 - val_loss: 3.5206\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 14.1717 - val_loss: 0.8444\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 9.2462 - val_loss: 5.7716\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 19.0797 - val_loss: 2.1325\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 9.8824 - val_loss: 2.0983\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 8.0087 - val_loss: 10.9678\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 8.0365 - val_loss: 1.7208\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 15.6277 - val_loss: 2.0178\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 7.5480 - val_loss: 8.9600\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 5.6131 - val_loss: 0.9225\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 4.0499 - val_loss: 1.0723\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 4.4209 - val_loss: 1.2601\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 5.8998 - val_loss: 10.7238\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 2.4min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 327.0414 - val_loss: 7.6487\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 25.7909 - val_loss: 1.1014\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.2256 - val_loss: 1.5764\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.8586 - val_loss: 0.6975\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.6937 - val_loss: 0.9017\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.0851 - val_loss: 1.4697\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 25.3365 - val_loss: 2.2262\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.7397 - val_loss: 13.8392\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 63.7424 - val_loss: 19.8527\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 41.2815 - val_loss: 5.8044\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 57.2046 - val_loss: 4.9371\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 46.3801 - val_loss: 2.3117\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 28.4319 - val_loss: 1.9457\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 25.4800 - val_loss: 11.2855\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 26.9531 - val_loss: 9.7456\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 25.4006 - val_loss: 8.2496\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.5650 - val_loss: 1.9686\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 26.9160 - val_loss: 7.8545\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 24.6259 - val_loss: 2.6241\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.7316 - val_loss: 0.6862\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.5061 - val_loss: 11.9933\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.8892 - val_loss: 1.4782\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.7587 - val_loss: 2.2480\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.4323 - val_loss: 3.6835\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.6066 - val_loss: 2.8801\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.3107 - val_loss: 0.3988\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6731 - val_loss: 0.9747\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.1570 - val_loss: 0.4183\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3402 - val_loss: 1.6171\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.5568 - val_loss: 0.4960\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.5890 - val_loss: 1.3494\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.2651 - val_loss: 0.7337\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.0884 - val_loss: 1.1521\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6412 - val_loss: 1.1197\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9188 - val_loss: 0.4298\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.0844 - val_loss: 0.9010\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.1537 - val_loss: 1.0904\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1559 - val_loss: 0.5521\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6277 - val_loss: 0.4906\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7911 - val_loss: 0.3838\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2591 - val_loss: 0.3812\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4307 - val_loss: 0.5629\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5079 - val_loss: 0.3866\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6218 - val_loss: 0.3569\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4651 - val_loss: 0.7017\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1051 - val_loss: 0.3856\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1083 - val_loss: 0.3304\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0074 - val_loss: 0.3296\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8835 - val_loss: 0.4446\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8474 - val_loss: 0.3668\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9031 - val_loss: 0.4103\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8977 - val_loss: 0.3637\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7238 - val_loss: 0.3156\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7295 - val_loss: 0.3156\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8449 - val_loss: 0.3144\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7720 - val_loss: 0.3866\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0784 - val_loss: 0.3137\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6339 - val_loss: 0.3517\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6534 - val_loss: 0.4602\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7633 - val_loss: 0.3538\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5588 - val_loss: 0.3254\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4846 - val_loss: 0.3390\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5264 - val_loss: 0.3798\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6228 - val_loss: 0.4383\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4759 - val_loss: 0.3158\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4371 - val_loss: 0.3244\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3805 - val_loss: 0.3300\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4007 - val_loss: 0.3281\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4271 - val_loss: 0.3248ss: 0\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3690 - val_loss: 0.3148\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3958 - val_loss: 0.3230\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3922 - val_loss: 0.3283\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3531 - val_loss: 0.3396\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3334 - val_loss: 0.3048\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4251 - val_loss: 0.3620\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.8317 - val_loss: 0.5448\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7095 - val_loss: 0.3223\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4382 - val_loss: 0.3090\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3571 - val_loss: 0.3069\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3226 - val_loss: 0.3833\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3118 - val_loss: 0.3089\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2919 - val_loss: 0.3190\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2946 - val_loss: 0.3251\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2511 - val_loss: 0.3077\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2433 - val_loss: 0.3141\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2415 - val_loss: 0.3167\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2342 - val_loss: 0.3103\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2321 - val_loss: 0.3205\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2085 - val_loss: 0.3234\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2476 - val_loss: 0.3113\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2712 - val_loss: 0.3208\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2546 - val_loss: 0.3358\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2168 - val_loss: 0.3082\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2374 - val_loss: 0.3163\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3685 - val_loss: 0.3163\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2421 - val_loss: 0.3097\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2536 - val_loss: 0.3196\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3148 - val_loss: 0.3165\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3015 - val_loss: 0.3039\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2495 - val_loss: 0.3180\n",
      "Epoch 00099: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 7.1min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 330.4589 - val_loss: 10.8625\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 23.1531 - val_loss: 1.4288\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s - loss: 13.8080 - val_loss: 0.8597\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s - loss: 11.0225 - val_loss: 0.3905\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 13.4297 - val_loss: 0.4023\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 15.6903 - val_loss: 0.6516\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 19.6347 - val_loss: 8.0207\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 25.3824 - val_loss: 1.5701\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 20.6914 - val_loss: 0.4771\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 20.3212 - val_loss: 4.0250\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 23.8988 - val_loss: 3.5901\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 31.4154 - val_loss: 5.4298\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 26.7177 - val_loss: 7.9148\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 22.8553 - val_loss: 2.2782\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 17.5124 - val_loss: 3.2262\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.8387 - val_loss: 1.6279\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.1536 - val_loss: 1.3344\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.3004 - val_loss: 5.0450\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.3075 - val_loss: 3.4565\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.3590 - val_loss: 0.7791\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.1221 - val_loss: 1.0313\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.5765 - val_loss: 0.9808\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.6536 - val_loss: 0.5263\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 22.0815 - val_loss: 2.0299\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.3197 - val_loss: 1.3780\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.4734 - val_loss: 0.5099\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.1342 - val_loss: 1.5239\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.6561 - val_loss: 2.8420\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.2463 - val_loss: 0.4624\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s - loss: 3.1548 - val_loss: 0.4346\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 2.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 408.0711 - val_loss: 2.1598\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 20.4479 - val_loss: 0.6195\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.5724 - val_loss: 0.5590\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.1692 - val_loss: 1.3648\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.5295 - val_loss: 0.8655\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.6368 - val_loss: 0.6763\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.1436 - val_loss: 0.8489\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 29.8358 - val_loss: 3.3129\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 41.6497 - val_loss: 1.3018\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 62.3399 - val_loss: 4.7342\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 53.8265 - val_loss: 30.6886\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 67.6845 - val_loss: 6.1555\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s - loss: 46.7112 - val_loss: 4.0041\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 31.5736 - val_loss: 1.7219\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 72.6246 - val_loss: 29.3570\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s - loss: 27.6057 - val_loss: 0.6870\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 29.7214 - val_loss: 13.8813\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.7922 - val_loss: 0.8234\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.6214 - val_loss: 4.8789\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.8578 - val_loss: 2.4736\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.9610 - val_loss: 0.9037\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.4958 - val_loss: 1.1290\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.4134 - val_loss: 0.6126\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 4.0879 - val_loss: 0.6150\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.2649 - val_loss: 2.1106\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.0373 - val_loss: 1.2516\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.3343 - val_loss: 0.7661\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.1657 - val_loss: 0.4318\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s - loss: 6.4025 - val_loss: 3.1005\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.4903 - val_loss: 3.9677ss: - ETA: 1s\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.0393 - val_loss: 3.8319\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.0735 - val_loss: 0.6481\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.5894 - val_loss: 0.6560\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.5337 - val_loss: 2.4182\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s - loss: 5.0328 - val_loss: 0.9844\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.6520 - val_loss: 0.5706\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.1293 - val_loss: 0.4626\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.7017 - val_loss: 0.6153\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1932 - val_loss: 0.3540\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7990 - val_loss: 0.6493\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5369 - val_loss: 0.4013\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0351 - val_loss: 0.9214\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.9764 - val_loss: 0.9200\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.5596 - val_loss: 0.3532\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.6816 - val_loss: 0.6811ss: 1.87 - ETA: 0s - loss: 1.817 - ETA: 0s - los\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4452 - val_loss: 0.3322\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0382 - val_loss: 0.4326\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7995 - val_loss: 0.3951\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4488 - val_loss: 0.5368ss: \n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9946 - val_loss: 0.3117\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3556 - val_loss: 0.4791\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8595 - val_loss: 0.4737\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8476 - val_loss: 0.3352\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8492 - val_loss: 0.3932\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6820 - val_loss: 0.3762\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8413 - val_loss: 0.3320\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8994 - val_loss: 0.6111\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7836 - val_loss: 0.3653\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6619 - val_loss: 0.3361\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6332 - val_loss: 0.4466\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7334 - val_loss: 0.3237\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5953 - val_loss: 0.3512\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5812 - val_loss: 0.3290\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5143 - val_loss: 0.3346\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4736 - val_loss: 0.3153\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5034 - val_loss: 0.3195\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5404 - val_loss: 0.3564\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7811 - val_loss: 0.3591\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6682 - val_loss: 0.3239\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4481 - val_loss: 0.3148\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3877 - val_loss: 0.3261\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3944 - val_loss: 0.3229\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3881 - val_loss: 0.3127\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3849 - val_loss: 0.3235\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3209 - val_loss: 0.3170\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3415 - val_loss: 0.3191\n",
      "Epoch 00075: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 6.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 409.2108 - val_loss: 7.3012\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 23.7291 - val_loss: 0.6190\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.7225 - val_loss: 0.9631\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.9073 - val_loss: 0.4970\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 13.9329 - val_loss: 0.8089\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 18.5429 - val_loss: 1.2600\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 20.4688 - val_loss: 0.4872\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 35.1330 - val_loss: 2.8524\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 28.3260 - val_loss: 0.7307\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 26.7587 - val_loss: 4.9089\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 23.2177 - val_loss: 1.8366\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 27.8682 - val_loss: 1.0394\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 27.6178 - val_loss: 1.9473\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 32.5098 - val_loss: 1.3559\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 28.2818 - val_loss: 2.9633\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 27.2586 - val_loss: 2.3551\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.7484 - val_loss: 8.7744\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 23.5369 - val_loss: 4.2581\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 46.5471 - val_loss: 1.3701\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 24.9153 - val_loss: 2.9923\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.2888 - val_loss: 2.3124\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.0796 - val_loss: 2.7107\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.7967 - val_loss: 2.2670\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.6939 - val_loss: 5.5109\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 18.2441 - val_loss: 2.6066\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.2862 - val_loss: 2.2004\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.9562 - val_loss: 1.7945\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.4088 - val_loss: 0.7616\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.0883 - val_loss: 1.5301\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.0871 - val_loss: 2.1936\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.5056 - val_loss: 0.5975ss: 3\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9895 - val_loss: 0.9786\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.3501 - val_loss: 1.4621\n",
      "Epoch 00032: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=2, total= 2.5min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s - loss: 516.9707 - val_loss: 2.4789\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 89.3770 - val_loss: 1.0222\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 46.9258 - val_loss: 1.6488\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 44.0218 - val_loss: 1.3981\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 50.1957 - val_loss: 1.4907\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 47.2417 - val_loss: 4.5130\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 52.0744 - val_loss: 3.6640\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 52.5454 - val_loss: 3.1564\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 45.9707 - val_loss: 1.3616\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 42.2268 - val_loss: 5.0915\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 39.3093 - val_loss: 0.7559\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 31.4596 - val_loss: 3.0063\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 29.5355 - val_loss: 24.6639\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 36.5677 - val_loss: 3.2204\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 20.4440 - val_loss: 1.6459\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 15.5822 - val_loss: 1.3122\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 14.9116 - val_loss: 0.4771\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 12.1210 - val_loss: 0.7096\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 14.4251 - val_loss: 1.7162\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 12.8753 - val_loss: 1.7415\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 23.8941 - val_loss: 0.9440\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 37.2960 - val_loss: 6.1905\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 16.3367 - val_loss: 3.7607\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 37.9968 - val_loss: 7.1738\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 15.0168 - val_loss: 1.2913\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 46.2703 - val_loss: 6.3447\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 17.4587 - val_loss: 38.7508\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 22.0834 - val_loss: 18.4825\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 16.9011 - val_loss: 1.8976\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 15.3007 - val_loss: 8.1519\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 10.6091 - val_loss: 7.4288\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 62.7095 - val_loss: 51.9979\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 36.7579 - val_loss: 12.4926\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 14.6715 - val_loss: 46.6446\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 20.3032 - val_loss: 1.7508\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 7.4660 - val_loss: 1.8502\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 19.2728 - val_loss: 96.6556\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 57.5386 - val_loss: 79.3895\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 120.2768 - val_loss: 2.1781\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 84.0175 - val_loss: 31.2977\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 37.9646 - val_loss: 100.8468\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 33.3270 - val_loss: 273.0516\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 248.0048 - val_loss: 87.2667\n",
      "Epoch 00042: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 3.2min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 539.0162 - val_loss: 6.2317\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 87.2555 - val_loss: 2.0656\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 40.9001 - val_loss: 1.3295\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 39.4222 - val_loss: 2.6497\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 80.1502 - val_loss: 28.3302\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 99.9750 - val_loss: 20.9854\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 81.9032 - val_loss: 1.8467\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 75.1694 - val_loss: 18.0443\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 161.7932 - val_loss: 15.2613\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 182.1322 - val_loss: 21.1995\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 84.0028 - val_loss: 7.8340\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 31.8063 - val_loss: 45.4097\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 66.6889 - val_loss: 16.7442\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 53.1478 - val_loss: 14.0378\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 92.4241 - val_loss: 1.1965\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 46.4322 - val_loss: 112.4112\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 188.4214 - val_loss: 146.0782\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 72.9477 - val_loss: 97.9717\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 36.3149 - val_loss: 15.0296\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 115.2001 - val_loss: 29.0363\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 31.8798 - val_loss: 5.1671\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.6201 - val_loss: 0.7413\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.9578 - val_loss: 6.7729\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 102.5378 - val_loss: 9.4148\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 28.9679 - val_loss: 7.4881\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 44.3660 - val_loss: 39.1670\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 38.2391 - val_loss: 56.4049\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 29.9324 - val_loss: 16.2742\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.2213 - val_loss: 3.7404\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.9237 - val_loss: 2.1005\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.7932 - val_loss: 0.6061\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.4935 - val_loss: 9.3602\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.3932 - val_loss: 3.9640\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 22.4573 - val_loss: 1.4184\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.5427 - val_loss: 3.1853\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.9079 - val_loss: 6.0624\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.5655 - val_loss: 5.0107\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.1575 - val_loss: 10.0885\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 20.8473 - val_loss: 10.4186\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.6494 - val_loss: 9.2949\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 17.8214 - val_loss: 3.0394\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.5289 - val_loss: 5.8039\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 24.5613 - val_loss: 8.0219\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.4360 - val_loss: 1.0491\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.2608 - val_loss: 15.9039\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.7366 - val_loss: 2.4872\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 22.6256 - val_loss: 12.3718\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.9129 - val_loss: 0.4459\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.4896 - val_loss: 5.8039\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 42.2341 - val_loss: 3.0881\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 17.0919 - val_loss: 42.8482\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 32.4748 - val_loss: 12.8346\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.2160 - val_loss: 1.5517\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.3292 - val_loss: 6.2604\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.6514 - val_loss: 4.6305\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.3331 - val_loss: 1.3343\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.3488 - val_loss: 1.0960\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.2712 - val_loss: 0.3226\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.3879 - val_loss: 9.6142\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 39.9459 - val_loss: 7.5075\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 39.7161 - val_loss: 13.0693\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 21.9747 - val_loss: 5.0011\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 103.6214 - val_loss: 102.0379\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 81.6026 - val_loss: 6.8989\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s - loss: 52.7338 - val_loss: 11.7657\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 3s - loss: 31.0766 - val_loss: 0.9619\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 24.0756 - val_loss: 50.6928\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 41.6545 - val_loss: 97.7145\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 629.6185 - val_loss: 60.8079\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 99.2296 - val_loss: 8.6385\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 34.1889 - val_loss: 2.7323\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.3052 - val_loss: 12.7589\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 132.8688 - val_loss: 3.8260\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 114.5644 - val_loss: 34.3588\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 215.1006 - val_loss: 28.8753\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 105.1433 - val_loss: 55.7970\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 247.4782 - val_loss: 15.3187\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 903.3660 - val_loss: 51.2864\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 353.4260 - val_loss: 71.2449\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 770.6824 - val_loss: 873.8734\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 1717.3866 - val_loss: 269.8755\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 7960.6316 - val_loss: 1414.7259\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 4963.2366 - val_loss: 217.9626\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 5414.1246 - val_loss: 133.0158\n",
      "Epoch 00083: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 6.1min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 415.2443 - val_loss: 4.0566\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 88.5875 - val_loss: 1.4436\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 44.8693 - val_loss: 3.2115\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 40.5740 - val_loss: 0.5537\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 36.3213 - val_loss: 6.3172\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.3043 - val_loss: 3.1055\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.0709 - val_loss: 0.4150\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 33.5812 - val_loss: 1.5320\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 32.1125 - val_loss: 0.7594\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 26.0554 - val_loss: 1.9804\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 30.3907 - val_loss: 2.0963\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 24.8997 - val_loss: 0.6725\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.9542 - val_loss: 0.8425\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 23.1734 - val_loss: 1.5643\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 21.0363 - val_loss: 4.6940\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.8286 - val_loss: 4.9652\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.6993 - val_loss: 7.9214\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.3720 - val_loss: 0.5324\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.8613 - val_loss: 0.9578\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.7101 - val_loss: 0.6062\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.0998 - val_loss: 0.6859\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.1335 - val_loss: 1.0053\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.3550 - val_loss: 0.3209\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.0117 - val_loss: 0.8190\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.8315 - val_loss: 0.9206\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.5006 - val_loss: 1.6272\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.4343 - val_loss: 0.4119\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6044 - val_loss: 0.4710\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.2251 - val_loss: 0.9625\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.7149 - val_loss: 0.3483\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.2583 - val_loss: 0.5856\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.3631 - val_loss: 0.8148\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2431 - val_loss: 0.4140\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8380 - val_loss: 0.5830\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7264 - val_loss: 0.3832\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6345 - val_loss: 0.3399\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8414 - val_loss: 0.5107\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5625 - val_loss: 0.3976\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4286 - val_loss: 0.4082\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3399 - val_loss: 0.4487\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8245 - val_loss: 0.5511\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4728 - val_loss: 0.3917\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2605 - val_loss: 0.4935\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.0377 - val_loss: 0.3545\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9512 - val_loss: 0.2977\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.0947 - val_loss: 0.3346\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.8782 - val_loss: 0.3103\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.8423 - val_loss: 0.3359\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.0944 - val_loss: 0.3145\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.8659 - val_loss: 0.3828\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7246 - val_loss: 0.3060\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7120 - val_loss: 0.2993\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.7824 - val_loss: 0.2959\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.7118 - val_loss: 0.3033\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6653 - val_loss: 0.2967\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6144 - val_loss: 0.2991\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4964 - val_loss: 0.3077\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6189 - val_loss: 0.3073\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5472 - val_loss: 0.2944\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4474 - val_loss: 0.2915\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4595 - val_loss: 0.2913\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5226 - val_loss: 0.3016\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4181 - val_loss: 0.2996\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3784 - val_loss: 0.3038\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3927 - val_loss: 0.3075\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3739 - val_loss: 0.3494\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4326 - val_loss: 0.2962\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3654 - val_loss: 0.2970\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3422 - val_loss: 0.2980\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3775 - val_loss: 0.3014\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3404 - val_loss: 0.3101\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3443 - val_loss: 0.3007\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4353 - val_loss: 0.4020\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7375 - val_loss: 0.3545\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5863 - val_loss: 0.3046\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5398 - val_loss: 0.3145\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4829 - val_loss: 0.3433\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4456 - val_loss: 0.3544\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3761 - val_loss: 0.3083\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3327 - val_loss: 0.3064\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3184 - val_loss: 0.3147\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3002 - val_loss: 0.3086\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3091 - val_loss: 0.3077\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3489 - val_loss: 0.3073\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3209 - val_loss: 0.3070\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2974 - val_loss: 0.3115\n",
      "Epoch 00085: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 6.8min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 535.6925 - val_loss: 4.8302\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 94.6925 - val_loss: 1.3807\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 44.8257 - val_loss: 1.4856\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s - loss: 42.7906 - val_loss: 6.4542\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 52.6769 - val_loss: 13.5396\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 77.7505 - val_loss: 6.6120\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s - loss: 63.1514 - val_loss: 10.3894\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 53.5616 - val_loss: 3.8991\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 50.9514 - val_loss: 3.0432\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 73.4483 - val_loss: 17.6000\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s - loss: 181.5846 - val_loss: 31.2249\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s - loss: 154.8702 - val_loss: 73.5743\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 123.5854 - val_loss: 46.3156\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 94.8835 - val_loss: 32.3235\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 36.4148 - val_loss: 3.2575\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 52.1865 - val_loss: 32.1505\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 42.5567 - val_loss: 1.6725\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 22.5838 - val_loss: 1.1978\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.6244 - val_loss: 2.0657\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.3536 - val_loss: 0.8107\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.6418 - val_loss: 4.5530\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.6128 - val_loss: 3.7117\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 21.4968 - val_loss: 6.8168\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 21.4031 - val_loss: 3.6243\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 34.9105 - val_loss: 15.6698\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 15.9074 - val_loss: 9.7466\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 34.1907 - val_loss: 8.6610\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 34.2908 - val_loss: 2.0300\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.7695 - val_loss: 4.0263\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.4427 - val_loss: 1.8032\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.2926 - val_loss: 1.8048\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.1838 - val_loss: 1.3585\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.9181 - val_loss: 5.1653\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.2428 - val_loss: 1.4001\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.1083 - val_loss: 0.9254\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.6892 - val_loss: 0.8893\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 4.9258 - val_loss: 4.4496\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.2979 - val_loss: 2.0679\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.2541 - val_loss: 3.0164\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3001 - val_loss: 2.0430\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.4674 - val_loss: 1.0414\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.7088 - val_loss: 0.6822\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 5.8319 - val_loss: 0.4323\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.8227 - val_loss: 1.4655\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.8438 - val_loss: 0.6688\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.9465 - val_loss: 1.2100\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9442 - val_loss: 1.0118\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.5071 - val_loss: 0.4152\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.5240 - val_loss: 1.5672\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.5441 - val_loss: 1.8044\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 3.3366 - val_loss: 1.1201\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1837 - val_loss: 0.5321ss: 2.\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7893 - val_loss: 0.4672\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1986 - val_loss: 0.8790\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9903 - val_loss: 0.7308\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6426 - val_loss: 0.3259\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2651 - val_loss: 0.3281\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2576 - val_loss: 0.3531\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7314 - val_loss: 0.6601\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5475 - val_loss: 0.3455\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8863 - val_loss: 0.5616\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1204 - val_loss: 0.4383\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2110 - val_loss: 0.5531\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4782 - val_loss: 0.3016\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0757 - val_loss: 0.3240\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0202 - val_loss: 0.3508\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8060 - val_loss: 0.2998\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8394 - val_loss: 0.3254\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9552 - val_loss: 0.5547\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9807 - val_loss: 0.5901\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4275 - val_loss: 0.3902\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2056 - val_loss: 0.3227\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1347 - val_loss: 0.3811\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8430 - val_loss: 0.3112\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2372 - val_loss: 0.4274\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2727 - val_loss: 0.3809\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0541 - val_loss: 0.3304\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8601 - val_loss: 0.3750\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7824 - val_loss: 0.4275\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1568 - val_loss: 0.4633\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6029 - val_loss: 0.8072\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1855 - val_loss: 0.3414\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9594 - val_loss: 0.4407\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8859 - val_loss: 0.3395\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8417 - val_loss: 0.3582\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6601 - val_loss: 0.3376\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6896 - val_loss: 0.3438\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8121 - val_loss: 0.3565\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5760 - val_loss: 0.3101\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6406 - val_loss: 0.3463\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5394 - val_loss: 0.3069\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6326 - val_loss: 0.4267\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5830 - val_loss: 0.3097\n",
      "Epoch 00092: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 7.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 619.4514 - val_loss: 16.8172\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 100.9977 - val_loss: 1.4042\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 39.2322 - val_loss: 0.8649\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 40.4196 - val_loss: 1.0954\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 54.0992 - val_loss: 2.2561\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 47.2328 - val_loss: 5.6811\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 47.1119 - val_loss: 9.4417\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 50.0683 - val_loss: 6.8030\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 61.0493 - val_loss: 6.9289\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 60.3407 - val_loss: 13.1105\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 48.0914 - val_loss: 2.2176\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 51.0589 - val_loss: 11.4895\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 63.0939 - val_loss: 4.3316\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 192.9867 - val_loss: 18.9526\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 83.8936 - val_loss: 3.7544\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 29.6626 - val_loss: 3.8702\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 53.6116 - val_loss: 84.9592\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 65.0048 - val_loss: 30.6388\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 48.7536 - val_loss: 2.7018\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.7133 - val_loss: 0.9451\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 12.1057 - val_loss: 11.3143\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.7269 - val_loss: 3.5172\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.6758 - val_loss: 5.6543\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 17.6872 - val_loss: 2.7700\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.7000 - val_loss: 6.4550\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 11.1639 - val_loss: 2.4167\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.8393 - val_loss: 1.2683\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 7.6096 - val_loss: 3.8151\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 9.0728 - val_loss: 6.3274\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=256, num_hidden_layers=3, total= 2.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5025 - val_loss: 0.3372\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7307 - val_loss: 0.3402\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7133 - val_loss: 0.3368\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6523 - val_loss: 0.3422\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6392 - val_loss: 0.3379\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6046 - val_loss: 0.3451\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6129 - val_loss: 0.3438\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5794 - val_loss: 0.3381\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5783 - val_loss: 0.3415\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5658 - val_loss: 0.3437\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5330 - val_loss: 0.3377\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5328 - val_loss: 0.3395\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4971 - val_loss: 0.3384\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5327 - val_loss: 0.3379\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5146 - val_loss: 0.3405\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5531 - val_loss: 0.3388\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5038 - val_loss: 0.3383\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5443 - val_loss: 0.3379\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5238 - val_loss: 0.3374ss\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5199 - val_loss: 0.3396\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4803 - val_loss: 0.3378\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4989 - val_loss: 0.3441\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5135 - val_loss: 0.3413\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4950 - val_loss: 0.3470\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5095 - val_loss: 0.3368\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4851 - val_loss: 0.3374\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5227 - val_loss: 0.3433\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total=  38.1s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2365 - val_loss: 0.5363\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8855 - val_loss: 0.3371\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7807 - val_loss: 0.3407\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8502 - val_loss: 0.3390\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7467 - val_loss: 0.3392\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7324 - val_loss: 0.3437\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7504 - val_loss: 0.3431\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6617 - val_loss: 0.3387\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6840 - val_loss: 0.3426\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6227 - val_loss: 0.3409\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5770 - val_loss: 0.3413\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6302 - val_loss: 0.3426\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5878 - val_loss: 0.3441\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5724 - val_loss: 0.3376\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5698 - val_loss: 0.3433\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5571 - val_loss: 0.3396\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5794 - val_loss: 0.3387\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5746 - val_loss: 0.3462\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5498 - val_loss: 0.3375\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5382 - val_loss: 0.3417\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5098 - val_loss: 0.3367\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5360 - val_loss: 0.3443\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5427 - val_loss: 0.3459\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5267 - val_loss: 0.3377\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5316 - val_loss: 0.3486\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5206 - val_loss: 0.3405\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5300 - val_loss: 0.3393\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4929 - val_loss: 0.3369\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total=  37.4s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6526 - val_loss: 1.1242\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1904 - val_loss: 0.3380\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9223 - val_loss: 0.3402\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8782 - val_loss: 0.3342\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8067 - val_loss: 0.3232\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7654 - val_loss: 0.3245\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7521 - val_loss: 0.3232\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6700 - val_loss: 0.3228\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6680 - val_loss: 0.3272\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6581 - val_loss: 0.3267\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6546 - val_loss: 0.3328\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6298 - val_loss: 0.3340\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6061 - val_loss: 0.3338\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6043 - val_loss: 0.3214\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5570 - val_loss: 0.3252ss: 0.555\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5453 - val_loss: 0.3217\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5612 - val_loss: 0.3363\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5379 - val_loss: 0.3333\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5130 - val_loss: 0.3265\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5512 - val_loss: 0.3369\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5542 - val_loss: 0.3179\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4959 - val_loss: 0.3325\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5475 - val_loss: 0.3283\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4609 - val_loss: 0.3165\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5074 - val_loss: 0.3248\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4812 - val_loss: 0.3200\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4969 - val_loss: 0.3260\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4823 - val_loss: 0.3233\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4802 - val_loss: 0.3172\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4606 - val_loss: 0.3250\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4757 - val_loss: 0.3158\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4593 - val_loss: 0.3212\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4509 - val_loss: 0.3107\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4401 - val_loss: 0.3134\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4489 - val_loss: 0.3108\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4249 - val_loss: 0.3106\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4207 - val_loss: 0.3115\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4318 - val_loss: 0.3082\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3992 - val_loss: 0.3123\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4031 - val_loss: 0.3100\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4099 - val_loss: 0.3084\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3985 - val_loss: 0.3262\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4067 - val_loss: 0.3036\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4067 - val_loss: 0.3192\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3929 - val_loss: 0.3293\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3816 - val_loss: 0.3101\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4215 - val_loss: 0.3177\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3786 - val_loss: 0.3191\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3779 - val_loss: 0.3073\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3745 - val_loss: 0.3068\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3540 - val_loss: 0.3268\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3814 - val_loss: 0.3042\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3577 - val_loss: 0.3019\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3721 - val_loss: 0.3050\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3399 - val_loss: 0.3016\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3287 - val_loss: 0.3221\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3536 - val_loss: 0.2981\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3510 - val_loss: 0.3053\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3678 - val_loss: 0.3082\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3318 - val_loss: 0.3131\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3333 - val_loss: 0.3113\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3293 - val_loss: 0.2957\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3423 - val_loss: 0.2976\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3302 - val_loss: 0.3087\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3264 - val_loss: 0.3067\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3236 - val_loss: 0.2973\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3383 - val_loss: 0.3255\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3300 - val_loss: 0.3081\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3276 - val_loss: 0.3181\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3098 - val_loss: 0.3133\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3286 - val_loss: 0.2981\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3189 - val_loss: 0.3149\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3077 - val_loss: 0.3122\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3063 - val_loss: 0.3105\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3045 - val_loss: 0.3224\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3254 - val_loss: 0.3107\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2956 - val_loss: 0.3087\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2887 - val_loss: 0.3109\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3010 - val_loss: 0.3061\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2911 - val_loss: 0.3257\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3044 - val_loss: 0.3033\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2989 - val_loss: 0.2898\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3006 - val_loss: 0.3030\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2869 - val_loss: 0.3061\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2785 - val_loss: 0.3074\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2825 - val_loss: 0.3082\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2603 - val_loss: 0.2964\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2748 - val_loss: 0.3095\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2791 - val_loss: 0.3148\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2666 - val_loss: 0.2917\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2399 - val_loss: 0.3163\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2731 - val_loss: 0.3025\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2703 - val_loss: 0.2919\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2572 - val_loss: 0.2946\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2661 - val_loss: 0.3010\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2563 - val_loss: 0.3052\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2522 - val_loss: 0.3089\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2536 - val_loss: 0.3128\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2629 - val_loss: 0.2992\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2416 - val_loss: 0.2997\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2457 - val_loss: 0.2935\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2443 - val_loss: 0.3044\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2619 - val_loss: 0.2976\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2447 - val_loss: 0.3105\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2359 - val_loss: 0.3236\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2364 - val_loss: 0.3133\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2400 - val_loss: 0.3064\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2240 - val_loss: 0.3012\n",
      "Epoch 00107: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 2.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5463 - val_loss: 1.0443\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1835 - val_loss: 0.3824\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8233 - val_loss: 0.3388\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8009 - val_loss: 0.3422\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7314 - val_loss: 0.3444\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7435 - val_loss: 0.3415\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7407 - val_loss: 0.3404\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7019 - val_loss: 0.3420\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6778 - val_loss: 0.3395\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6551 - val_loss: 0.3464\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6992 - val_loss: 0.3370\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6761 - val_loss: 0.3385\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6172 - val_loss: 0.3470\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6224 - val_loss: 0.3413\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6367 - val_loss: 0.3425\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5824 - val_loss: 0.3366\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6006 - val_loss: 0.3363\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6147 - val_loss: 0.3459\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5982 - val_loss: 0.3315\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6117 - val_loss: 0.3372\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6203 - val_loss: 0.3415\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6049 - val_loss: 0.3319\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5600 - val_loss: 0.3411\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5934 - val_loss: 0.3374\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5532 - val_loss: 0.3360\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5846 - val_loss: 0.3270\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5766 - val_loss: 0.3370\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5654 - val_loss: 0.3375\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5790 - val_loss: 0.3298\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5601 - val_loss: 0.3361\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5027 - val_loss: 0.3388\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5455 - val_loss: 0.3242\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5390 - val_loss: 0.3327\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.525 - 1s - loss: 0.5253 - val_loss: 0.3329\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5154 - val_loss: 0.3198\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5216 - val_loss: 0.3366\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5065 - val_loss: 0.3285\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5303 - val_loss: 0.3282\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5101 - val_loss: 0.3440\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5183 - val_loss: 0.3228\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5162 - val_loss: 0.3363ss: 0.5\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5084 - val_loss: 0.3254\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5050 - val_loss: 0.3326\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4945 - val_loss: 0.3361\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4849 - val_loss: 0.3228\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4963 - val_loss: 0.3235\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4649 - val_loss: 0.3238\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4810 - val_loss: 0.3306\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4618 - val_loss: 0.3311\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4829 - val_loss: 0.3315\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4798 - val_loss: 0.3174\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4526 - val_loss: 0.3196\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4554 - val_loss: 0.3327\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4476 - val_loss: 0.3300\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4353 - val_loss: 0.3255\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4531 - val_loss: 0.3361\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4451 - val_loss: 0.3266\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4288 - val_loss: 0.3293\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4357 - val_loss: 0.3287\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4504 - val_loss: 0.3298\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4306 - val_loss: 0.3333\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4291 - val_loss: 0.3269\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4389 - val_loss: 0.3324\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4469 - val_loss: 0.3356\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4279 - val_loss: 0.3171\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4157 - val_loss: 0.3405\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4007 - val_loss: 0.3320\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4292 - val_loss: 0.3244\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4135 - val_loss: 0.3324\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4038 - val_loss: 0.3377\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3853 - val_loss: 0.3343\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3986 - val_loss: 0.3291\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3750 - val_loss: 0.3299\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4122 - val_loss: 0.3358\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4147 - val_loss: 0.3224\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3735 - val_loss: 0.3259\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3762 - val_loss: 0.3229\n",
      "Epoch 00076: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total= 1.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2325 - val_loss: 0.5485\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8705 - val_loss: 0.3373\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7583 - val_loss: 0.3400\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7243 - val_loss: 0.3417\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7149 - val_loss: 0.3401\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7270 - val_loss: 0.3432\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6853 - val_loss: 0.3435\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6554 - val_loss: 0.3393\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6401 - val_loss: 0.3493\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6178 - val_loss: 0.3369\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6231 - val_loss: 0.3424\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6073 - val_loss: 0.3457\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5842 - val_loss: 0.3415\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5843 - val_loss: 0.3416\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5579 - val_loss: 0.3386\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5966 - val_loss: 0.3422\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5557 - val_loss: 0.3393\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5410 - val_loss: 0.3405\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5397 - val_loss: 0.3437\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5455 - val_loss: 0.3408\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5673 - val_loss: 0.3431\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5518 - val_loss: 0.3398\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5384 - val_loss: 0.3465\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5628 - val_loss: 0.3390\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5213 - val_loss: 0.3454\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5496 - val_loss: 0.3368\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5335 - val_loss: 0.3387\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5033 - val_loss: 0.3402\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=1, total=  39.3s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.8338 - val_loss: 0.3929\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1414 - val_loss: 0.3559\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1638 - val_loss: 0.3544\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0686 - val_loss: 0.3507\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9049 - val_loss: 0.3465\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8400 - val_loss: 0.3388\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7910 - val_loss: 0.3422\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7585 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6950 - val_loss: 0.3370\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7247 - val_loss: 0.3424\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6356 - val_loss: 0.3368\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5981 - val_loss: 0.3382\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6252 - val_loss: 0.3375\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5728 - val_loss: 0.3368\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5733 - val_loss: 0.3412\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5444 - val_loss: 0.3370\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5498 - val_loss: 0.3371\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5309 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5077 - val_loss: 0.3368\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5153 - val_loss: 0.3372\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5592 - val_loss: 0.3388\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4935 - val_loss: 0.3371\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5246 - val_loss: 0.3378\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5140 - val_loss: 0.3368\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5192 - val_loss: 0.3372\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4928 - val_loss: 0.3369\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4968 - val_loss: 0.3372\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4650 - val_loss: 0.3369\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5082 - val_loss: 0.3527\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4867 - val_loss: 0.3452\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4624 - val_loss: 0.3368\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4820 - val_loss: 0.3373\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4622 - val_loss: 0.3374\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4696 - val_loss: 0.3390\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total=  53.8s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3796 - val_loss: 0.3683\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9489 - val_loss: 0.3532\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8374 - val_loss: 0.3410\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7161 - val_loss: 0.3392\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.677 - 1s - loss: 0.6744 - val_loss: 0.3368\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6169 - val_loss: 0.3386\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5929 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5687 - val_loss: 0.3371\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5512 - val_loss: 0.3382\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5221 - val_loss: 0.3368\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5325 - val_loss: 0.3381\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5169 - val_loss: 0.3388\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5258 - val_loss: 0.3375\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5129 - val_loss: 0.3394\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5185 - val_loss: 0.3445\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5113 - val_loss: 0.3387\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4899 - val_loss: 0.3463\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5064 - val_loss: 0.3419\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5082 - val_loss: 0.3376\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4774 - val_loss: 0.3373\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4903 - val_loss: 0.3397\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4801 - val_loss: 0.3421\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4667 - val_loss: 0.3370\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4809 - val_loss: 0.3376\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4564 - val_loss: 0.3384s\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4595 - val_loss: 0.3382\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4736 - val_loss: 0.3401\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4664 - val_loss: 0.3405\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4643 - val_loss: 0.3461\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4556 - val_loss: 0.3512\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4497 - val_loss: 0.3368\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total=  42.6s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4094 - val_loss: 0.3369\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0478 - val_loss: 0.3395\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9091 - val_loss: 0.3368\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7586 - val_loss: 0.3371\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7074 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6665 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5989 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5940 - val_loss: 0.3371\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5673 - val_loss: 0.3438\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5177 - val_loss: 0.3597\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5473 - val_loss: 0.3536\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5337 - val_loss: 0.3386\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5322 - val_loss: 0.3368\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5227 - val_loss: 0.3369\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5428 - val_loss: 0.3374\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4957 - val_loss: 0.3392\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5190 - val_loss: 0.3393\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4975 - val_loss: 0.3426\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4775 - val_loss: 0.3368\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4953 - val_loss: 0.3385\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5070 - val_loss: 0.3385\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5007 - val_loss: 0.3377\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4834 - val_loss: 0.3405\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4831 - val_loss: 0.3381\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4809 - val_loss: 0.3409\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4692 - val_loss: 0.3447\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4673 - val_loss: 0.3389\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total=  43.5s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6537 - val_loss: 0.3788\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0837 - val_loss: 0.3376\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9131 - val_loss: 0.3722\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8884 - val_loss: 0.3380\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7817 - val_loss: 0.3459\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6860 - val_loss: 0.3377\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6525 - val_loss: 0.3379\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6599 - val_loss: 0.3377\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6524 - val_loss: 0.3373\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6144 - val_loss: 0.3369\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5640 - val_loss: 0.3369\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5453 - val_loss: 0.3470\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5525 - val_loss: 0.3368\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5410 - val_loss: 0.3454\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5441 - val_loss: 0.3414\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5393 - val_loss: 0.3425\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5135 - val_loss: 0.3538\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5172 - val_loss: 0.3373\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5083 - val_loss: 0.3386\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5263 - val_loss: 0.3370\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5030 - val_loss: 0.3369\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5210 - val_loss: 0.3382\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5137 - val_loss: 0.3428\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5141 - val_loss: 0.3421\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4890 - val_loss: 0.3383\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5113 - val_loss: 0.3441\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4908 - val_loss: 0.3372\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4934 - val_loss: 0.3419\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total=  41.1s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1171 - val_loss: 0.3920\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9948 - val_loss: 0.3430\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9513 - val_loss: 0.3368\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8923 - val_loss: 0.3368\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7963 - val_loss: 0.3368\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7485 - val_loss: 0.3387\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7101 - val_loss: 0.3369\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6854 - val_loss: 0.3371\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6327 - val_loss: 0.3371\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6359 - val_loss: 0.3368\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5493 - val_loss: 0.3377\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5879 - val_loss: 0.3410\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5787 - val_loss: 0.3372\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5814 - val_loss: 0.3375\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5870 - val_loss: 0.3378\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5294 - val_loss: 0.3368\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5351 - val_loss: 0.3357\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5349 - val_loss: 0.3358\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5774 - val_loss: 0.3386\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5341 - val_loss: 0.3407\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5097 - val_loss: 0.3336\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5349 - val_loss: 0.3316\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5097 - val_loss: 0.3319\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4958 - val_loss: 0.3297\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4615 - val_loss: 0.3290\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4984 - val_loss: 0.3265\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4944 - val_loss: 0.3328\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4708 - val_loss: 0.3241\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4568 - val_loss: 0.3250\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4635 - val_loss: 0.3219\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4595 - val_loss: 0.3259\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4369 - val_loss: 0.3221\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4763 - val_loss: 0.3203\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4549 - val_loss: 0.3254\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4300 - val_loss: 0.3195\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4407 - val_loss: 0.3210\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4390 - val_loss: 0.3182\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4239 - val_loss: 0.3373\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4459 - val_loss: 0.3171\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4235 - val_loss: 0.3245\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4202 - val_loss: 0.3245\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4133 - val_loss: 0.3298\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4193 - val_loss: 0.3227\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4156 - val_loss: 0.3148\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3984 - val_loss: 0.3298\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4011 - val_loss: 0.3328\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4004 - val_loss: 0.3245\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4011 - val_loss: 0.3250\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4046 - val_loss: 0.3270\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4141 - val_loss: 0.3193\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4099 - val_loss: 0.3206\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3751 - val_loss: 0.3157\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3839 - val_loss: 0.3203\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3868 - val_loss: 0.3150\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3718 - val_loss: 0.3335\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3709 - val_loss: 0.3067\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3637 - val_loss: 0.3373\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3766 - val_loss: 0.3089\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3493 - val_loss: 0.3025\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3519 - val_loss: 0.3255\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3428 - val_loss: 0.3126\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3418 - val_loss: 0.3333\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3667 - val_loss: 0.3237\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3400 - val_loss: 0.3281\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3515 - val_loss: 0.3311\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3552 - val_loss: 0.3293\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3620 - val_loss: 0.3336\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3408 - val_loss: 0.3241\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3381 - val_loss: 0.3399\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3592 - val_loss: 0.3205\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3523 - val_loss: 0.3169\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3329 - val_loss: 0.3337\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3217 - val_loss: 0.3243\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3340 - val_loss: 0.3320\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3396 - val_loss: 0.3216\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3382 - val_loss: 0.3107\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3166 - val_loss: 0.3186\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3470 - val_loss: 0.3341\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3240 - val_loss: 0.3268\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3252 - val_loss: 0.3314\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3261 - val_loss: 0.3328\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3226 - val_loss: 0.3330\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3276 - val_loss: 0.3303\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3378 - val_loss: 0.3307\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3204 - val_loss: 0.3216\n",
      "Epoch 00084: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=2, total= 2.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.8424 - val_loss: 0.4767\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0943 - val_loss: 0.3368\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9456 - val_loss: 0.3380\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9052 - val_loss: 0.3392\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8100 - val_loss: 0.3414\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7592 - val_loss: 0.3381\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6746 - val_loss: 0.3370\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6220 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6514 - val_loss: 0.3378\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5785 - val_loss: 0.3368\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5835 - val_loss: 0.3392\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5652 - val_loss: 0.3371\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5652 - val_loss: 0.3460\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5437 - val_loss: 0.3373\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5372 - val_loss: 0.3369\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5386 - val_loss: 0.3456\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5344 - val_loss: 0.3375\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5378 - val_loss: 0.3466\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5013 - val_loss: 0.3416\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5211 - val_loss: 0.3432\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4909 - val_loss: 0.3375\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5097 - val_loss: 0.3368\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5142 - val_loss: 0.3369\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5014 - val_loss: 0.3410\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5239 - val_loss: 0.3390\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5114 - val_loss: 0.3385\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5163 - val_loss: 0.3384\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4922 - val_loss: 0.3372\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total=  39.3s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7356 - val_loss: 0.4115\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0808 - val_loss: 0.3372\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9929 - val_loss: 0.3371\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9112 - val_loss: 0.3428\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7874 - val_loss: 0.3367\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7628 - val_loss: 0.3379\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7177 - val_loss: 0.3350\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6421 - val_loss: 0.3358\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6193 - val_loss: 0.3358\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6102 - val_loss: 0.3360\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6146 - val_loss: 0.3376\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5612 - val_loss: 0.3431\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5895 - val_loss: 0.3389\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5735 - val_loss: 0.3396\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5422 - val_loss: 0.3367\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5479 - val_loss: 0.3378\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5233 - val_loss: 0.3348\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5619 - val_loss: 0.3380\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5169 - val_loss: 0.3451\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5103 - val_loss: 0.3433\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5185 - val_loss: 0.3357\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5035 - val_loss: 0.3486\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5125 - val_loss: 0.3344\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4888 - val_loss: 0.3470\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5221 - val_loss: 0.3373\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4956 - val_loss: 0.3436\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5181 - val_loss: 0.3363\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5016 - val_loss: 0.3343\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4719 - val_loss: 0.3378\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4772 - val_loss: 0.3328\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4864 - val_loss: 0.3370s\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4722 - val_loss: 0.3321\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4842 - val_loss: 0.3311\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4772 - val_loss: 0.3344\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4519 - val_loss: 0.3309\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4624 - val_loss: 0.3515\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4572 - val_loss: 0.3350\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4645 - val_loss: 0.3360\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4467 - val_loss: 0.3304\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4574 - val_loss: 0.3340\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4341 - val_loss: 0.3351\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4428 - val_loss: 0.3388\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4209 - val_loss: 0.3374\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4412 - val_loss: 0.3325\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4322 - val_loss: 0.3189\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4340 - val_loss: 0.3277\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4210 - val_loss: 0.3258\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4460 - val_loss: 0.3436\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4405 - val_loss: 0.3193\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4126 - val_loss: 0.3167\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4012 - val_loss: 0.3132\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3975 - val_loss: 0.3132\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3971 - val_loss: 0.3252\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4055 - val_loss: 0.3231\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4048 - val_loss: 0.3201\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4193 - val_loss: 0.3151\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3903 - val_loss: 0.3119\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3866 - val_loss: 0.3122\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4127 - val_loss: 0.3576\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3932 - val_loss: 0.3264\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3936 - val_loss: 0.3201\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3718 - val_loss: 0.3178\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3833 - val_loss: 0.3272\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3863 - val_loss: 0.3172\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3727 - val_loss: 0.3099\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3769 - val_loss: 0.3063\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3731 - val_loss: 0.3085\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3647 - val_loss: 0.3059\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3610 - val_loss: 0.3071\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3596 - val_loss: 0.3074\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3469 - val_loss: 0.3090\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3625 - val_loss: 0.3135\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3711 - val_loss: 0.3047\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3747 - val_loss: 0.3085\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3641 - val_loss: 0.3070\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3648 - val_loss: 0.3258\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3434 - val_loss: 0.3037\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3363 - val_loss: 0.3082\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3402 - val_loss: 0.3124\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3578 - val_loss: 0.3251\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3413 - val_loss: 0.3174\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3392 - val_loss: 0.3102\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3511 - val_loss: 0.3300\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3368 - val_loss: 0.3079\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3354 - val_loss: 0.3272\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3262 - val_loss: 0.3149\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3342 - val_loss: 0.3047\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3229 - val_loss: 0.3151\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3238 - val_loss: 0.3089\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3395 - val_loss: 0.3087\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3397 - val_loss: 0.3055\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3337 - val_loss: 0.3076\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3307 - val_loss: 0.3064\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3216 - val_loss: 0.3058\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3101 - val_loss: 0.3234\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3160 - val_loss: 0.3051\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3224 - val_loss: 0.3062\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3105 - val_loss: 0.3047\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3275 - val_loss: 0.3093\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3138 - val_loss: 0.3095\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3159 - val_loss: 0.3002\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3163 - val_loss: 0.2987\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2978 - val_loss: 0.3166\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3147 - val_loss: 0.3029\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3084 - val_loss: 0.3035\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3050 - val_loss: 0.3083\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3028 - val_loss: 0.3094\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3082 - val_loss: 0.3144\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3004 - val_loss: 0.3078\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2941 - val_loss: 0.3084\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3161 - val_loss: 0.3018\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3075 - val_loss: 0.3028\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2823 - val_loss: 0.3058\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2910 - val_loss: 0.2969\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3014 - val_loss: 0.3019\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3151 - val_loss: 0.2996\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2881 - val_loss: 0.3014\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2891 - val_loss: 0.2958\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2922 - val_loss: 0.3012\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2891 - val_loss: 0.3109\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2843 - val_loss: 0.3044\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2786 - val_loss: 0.2993\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2783 - val_loss: 0.3026\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2654 - val_loss: 0.3012\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2717 - val_loss: 0.3060\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2821 - val_loss: 0.3167\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2842 - val_loss: 0.2922\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2665 - val_loss: 0.3113\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2623 - val_loss: 0.3060\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2807 - val_loss: 0.2950\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2706 - val_loss: 0.2943\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2731 - val_loss: 0.3075\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2538 - val_loss: 0.3042\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2930 - val_loss: 0.3019\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2618 - val_loss: 0.3097\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2636 - val_loss: 0.3029\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2567 - val_loss: 0.2989\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2526 - val_loss: 0.3179\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2664 - val_loss: 0.3017\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2556 - val_loss: 0.3060\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2563 - val_loss: 0.3029\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2547 - val_loss: 0.2976\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2420 - val_loss: 0.3049\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2523 - val_loss: 0.3015\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2467 - val_loss: 0.3118\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2496 - val_loss: 0.2981\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2471 - val_loss: 0.3080\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2510 - val_loss: 0.3068\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2431 - val_loss: 0.3093\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2521 - val_loss: 0.2996\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2405 - val_loss: 0.3013\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2393 - val_loss: 0.2990\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2387 - val_loss: 0.3069\n",
      "Epoch 00152: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 3.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1829 - val_loss: 0.3420\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7987 - val_loss: 0.3368\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7199 - val_loss: 0.3406\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6444 - val_loss: 0.3378\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6218 - val_loss: 0.3419\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6072 - val_loss: 0.3371\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5379 - val_loss: 0.3370\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5534 - val_loss: 0.3416\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5466 - val_loss: 0.3401\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5341 - val_loss: 0.3406\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5143 - val_loss: 0.3373\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5210 - val_loss: 0.3354\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5192 - val_loss: 0.3399\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5526 - val_loss: 0.3410\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4923 - val_loss: 0.3388\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4735 - val_loss: 0.3351\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5089 - val_loss: 0.3385\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4964 - val_loss: 0.3350\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4798 - val_loss: 0.3641\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5005 - val_loss: 0.3392\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4620 - val_loss: 0.3341\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4589 - val_loss: 0.3368\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4531 - val_loss: 0.3343\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5016 - val_loss: 0.3352\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4635 - val_loss: 0.3355\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4572 - val_loss: 0.3326\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4602 - val_loss: 0.3356\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4448 - val_loss: 0.3442\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4494 - val_loss: 0.3394\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4455 - val_loss: 0.3338\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4650 - val_loss: 0.3349\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4497 - val_loss: 0.3320\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4687 - val_loss: 0.3336\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4543 - val_loss: 0.3303\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4403 - val_loss: 0.3304\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4254 - val_loss: 0.3307\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4410 - val_loss: 0.3310\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4180 - val_loss: 0.3280\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4392 - val_loss: 0.3286\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4314 - val_loss: 0.3279\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4130 - val_loss: 0.3286\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4279 - val_loss: 0.3294\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4136 - val_loss: 0.3227\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4014 - val_loss: 0.3260\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4045 - val_loss: 0.3265\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4011 - val_loss: 0.3315\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4134 - val_loss: 0.3241\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3954 - val_loss: 0.3197\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3834 - val_loss: 0.3198\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3844 - val_loss: 0.3217\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3950 - val_loss: 0.3197\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3692 - val_loss: 0.3229\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3869 - val_loss: 0.3257\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3912 - val_loss: 0.3154\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3809 - val_loss: 0.3150\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3787 - val_loss: 0.3134\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3772 - val_loss: 0.3162\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3684 - val_loss: 0.3140\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3745 - val_loss: 0.3228\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3785 - val_loss: 0.3084\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3512 - val_loss: 0.3223\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3617 - val_loss: 0.3259\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3492 - val_loss: 0.3166\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3496 - val_loss: 0.3331\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3807 - val_loss: 0.3104\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3681 - val_loss: 0.3106\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3537 - val_loss: 0.3144\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3488 - val_loss: 0.3158\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3509 - val_loss: 0.3123\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3425 - val_loss: 0.3262\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3342 - val_loss: 0.3175\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3414 - val_loss: 0.3356\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3690 - val_loss: 0.3110\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3357 - val_loss: 0.3213\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3330 - val_loss: 0.3351\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3406 - val_loss: 0.3249\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3361 - val_loss: 0.3168\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3417 - val_loss: 0.3312\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3265 - val_loss: 0.3354\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3196 - val_loss: 0.3249\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3286 - val_loss: 0.3289\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3172 - val_loss: 0.3098\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3271 - val_loss: 0.3145\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3266 - val_loss: 0.3307\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3308 - val_loss: 0.3363\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3222 - val_loss: 0.3271\n",
      "Epoch 00085: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 2.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3338 - val_loss: 0.4601\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0487 - val_loss: 0.3423\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9623 - val_loss: 0.3373\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8761 - val_loss: 0.3374\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7744 - val_loss: 0.3368\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6975 - val_loss: 0.3372\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7086 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6762 - val_loss: 0.3369\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6488 - val_loss: 0.3368\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6174 - val_loss: 0.3379\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5690 - val_loss: 0.3368\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6051 - val_loss: 0.3381\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5815 - val_loss: 0.3424\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5615 - val_loss: 0.3374\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5578 - val_loss: 0.3445\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5731 - val_loss: 0.3374\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5489 - val_loss: 0.3379\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5536 - val_loss: 0.3423\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5470 - val_loss: 0.3444\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5516 - val_loss: 0.3397\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5303 - val_loss: 0.3479\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5195 - val_loss: 0.3388\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5477 - val_loss: 0.3367\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5098 - val_loss: 0.3378\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5326 - val_loss: 0.3365\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5071 - val_loss: 0.3445\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5303 - val_loss: 0.3519\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4842 - val_loss: 0.3379\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5101 - val_loss: 0.3356\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5202 - val_loss: 0.3643\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5031 - val_loss: 0.3455\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4668 - val_loss: 0.3390\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4922 - val_loss: 0.3408\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4757 - val_loss: 0.3349\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4628 - val_loss: 0.3351\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4641 - val_loss: 0.3384\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4747 - val_loss: 0.3408\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4818 - val_loss: 0.3406\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4408 - val_loss: 0.3376\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4590 - val_loss: 0.3379\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4514 - val_loss: 0.3387\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4355 - val_loss: 0.3403\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4612 - val_loss: 0.3450\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4485 - val_loss: 0.3333\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4459 - val_loss: 0.3334\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4603 - val_loss: 0.3365\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4592 - val_loss: 0.3377\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4596 - val_loss: 0.3374\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4592 - val_loss: 0.3334\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4433 - val_loss: 0.3389\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4364 - val_loss: 0.3323\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4252 - val_loss: 0.3407\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4462 - val_loss: 0.3342\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4175 - val_loss: 0.3293\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4484 - val_loss: 0.3285\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4259 - val_loss: 0.3316\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4231 - val_loss: 0.3260\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4146 - val_loss: 0.3256\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4404 - val_loss: 0.3249\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4142 - val_loss: 0.3240\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4031 - val_loss: 0.3215\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4153 - val_loss: 0.3211\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4123 - val_loss: 0.3277\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4017 - val_loss: 0.3246\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3862 - val_loss: 0.3248\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3857 - val_loss: 0.3188\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4031 - val_loss: 0.3299\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3858 - val_loss: 0.3252\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3943 - val_loss: 0.3251\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3604 - val_loss: 0.3218\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3903 - val_loss: 0.3409\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3755 - val_loss: 0.3276\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3746 - val_loss: 0.3203\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3915 - val_loss: 0.3206\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3818 - val_loss: 0.3167\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3614 - val_loss: 0.3226\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3862 - val_loss: 0.3351\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3854 - val_loss: 0.3159\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3823 - val_loss: 0.3166\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3747 - val_loss: 0.3323\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3700 - val_loss: 0.3304\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3561 - val_loss: 0.3291\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3633 - val_loss: 0.3179\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3576 - val_loss: 0.3166\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3733 - val_loss: 0.3189\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3616 - val_loss: 0.3287\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3561 - val_loss: 0.3305\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3533 - val_loss: 0.3286\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3542 - val_loss: 0.3182\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3495 - val_loss: 0.3496\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3363 - val_loss: 0.3211\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3453 - val_loss: 0.3318\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3460 - val_loss: 0.3316\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3243 - val_loss: 0.3341\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3697 - val_loss: 0.3354\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3284 - val_loss: 0.3321\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3307 - val_loss: 0.3201\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3349 - val_loss: 0.3325\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3309 - val_loss: 0.3113\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3212 - val_loss: 0.3321\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3351 - val_loss: 0.3306\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3213 - val_loss: 0.3275\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3329 - val_loss: 0.3225\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3155 - val_loss: 0.3287\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3238 - val_loss: 0.3154\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3195 - val_loss: 0.3282\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3193 - val_loss: 0.3340\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3256 - val_loss: 0.3360\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3229 - val_loss: 0.3325\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3142 - val_loss: 0.3349\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3233 - val_loss: 0.3325\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3145 - val_loss: 0.3333\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3115 - val_loss: 0.3219\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3094 - val_loss: 0.3360\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3177 - val_loss: 0.3190\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3150 - val_loss: 0.3337\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3011 - val_loss: 0.3215\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3116 - val_loss: 0.3350\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3055 - val_loss: 0.3352\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3040 - val_loss: 0.3309\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3173 - val_loss: 0.3250\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3107 - val_loss: 0.3144\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3135 - val_loss: 0.3376\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3171 - val_loss: 0.3304\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3050 - val_loss: 0.3341\n",
      "Epoch 00124: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total= 3.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 3.1957 - val_loss: 0.5349\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2092 - val_loss: 0.3426\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0603 - val_loss: 0.3623\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9582 - val_loss: 0.3777\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9280 - val_loss: 0.3371\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7608 - val_loss: 0.3377\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7815 - val_loss: 0.3386\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6810 - val_loss: 0.3376\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6620 - val_loss: 0.3408\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6503 - val_loss: 0.3388\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5894 - val_loss: 0.3407\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6030 - val_loss: 0.3368\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5898 - val_loss: 0.3372\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5663 - val_loss: 0.3382\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5986 - val_loss: 0.3370\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5895 - val_loss: 0.3399\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5650 - val_loss: 0.3369\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5776 - val_loss: 0.3369\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5176 - val_loss: 0.3381\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5378 - val_loss: 0.3420\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5407 - val_loss: 0.3384\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5718 - val_loss: 0.3381\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5464 - val_loss: 0.3404\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5289 - val_loss: 0.3384\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5072 - val_loss: 0.3431\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5151 - val_loss: 0.3633\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5390 - val_loss: 0.3372\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5022 - val_loss: 0.3493\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4997 - val_loss: 0.3411\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5233 - val_loss: 0.3369\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5210 - val_loss: 0.3382\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=64, num_hidden_layers=3, total=  48.9s\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 7.3203 - val_loss: 0.8168\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1427 - val_loss: 0.3409\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9507 - val_loss: 0.3279\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9528 - val_loss: 0.3182\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8683 - val_loss: 0.3145\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7865 - val_loss: 0.3165\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8035 - val_loss: 0.3185\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6968 - val_loss: 0.3127\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6574 - val_loss: 0.3051\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6320 - val_loss: 0.2958\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5891 - val_loss: 0.2990\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5405 - val_loss: 0.3041\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5455 - val_loss: 0.3071\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4943 - val_loss: 0.2998\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5190 - val_loss: 0.2907\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4307 - val_loss: 0.2886\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4224 - val_loss: 0.3055\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4062 - val_loss: 0.2901\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3834 - val_loss: 0.2936\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3598 - val_loss: 0.2879\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3614 - val_loss: 0.2826\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3462 - val_loss: 0.2923\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3345 - val_loss: 0.2840\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3471 - val_loss: 0.2863\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3186 - val_loss: 0.2887\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2908 - val_loss: 0.2863\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3291 - val_loss: 0.3017\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3049 - val_loss: 0.2855\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2978 - val_loss: 0.2861\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2943 - val_loss: 0.2963\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2959 - val_loss: 0.2899\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2709 - val_loss: 0.2798\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2818 - val_loss: 0.2837\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2595 - val_loss: 0.2906\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2715 - val_loss: 0.2976\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2617 - val_loss: 0.2957\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2552 - val_loss: 0.3011\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2740 - val_loss: 0.2898\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2660 - val_loss: 0.2998\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2506 - val_loss: 0.2786\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2391 - val_loss: 0.2912\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2463 - val_loss: 0.2989\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2581 - val_loss: 0.2863\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2580 - val_loss: 0.2767\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2421 - val_loss: 0.2800\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2635 - val_loss: 0.2869\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2417 - val_loss: 0.2898\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2375 - val_loss: 0.2968\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2400 - val_loss: 0.3302\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2515 - val_loss: 0.3177\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2392 - val_loss: 0.2872\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2269 - val_loss: 0.2859\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2342 - val_loss: 0.3077\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2446 - val_loss: 0.2886\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2258 - val_loss: 0.2856\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2206 - val_loss: 0.2860\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2339 - val_loss: 0.2962\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2226 - val_loss: 0.2992\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2549 - val_loss: 0.3024\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2432 - val_loss: 0.2899\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2377 - val_loss: 0.2934\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2294 - val_loss: 0.2826\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2348 - val_loss: 0.2912\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2355 - val_loss: 0.3000\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2439 - val_loss: 0.2954\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2495 - val_loss: 0.2944\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2385 - val_loss: 0.2990\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2291 - val_loss: 0.3060\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2365 - val_loss: 0.3036\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2453 - val_loss: 0.2879\n",
      "Epoch 00069: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 3.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 10.6277 - val_loss: 3.1932\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8575 - val_loss: 0.4626\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7200 - val_loss: 0.3375\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7038 - val_loss: 0.3393\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6529 - val_loss: 0.3233\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6631 - val_loss: 0.3201\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6472 - val_loss: 0.3214\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6172 - val_loss: 0.3215\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5839 - val_loss: 0.3250\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5804 - val_loss: 0.3211\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5702 - val_loss: 0.3203\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5325 - val_loss: 0.3194\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5312 - val_loss: 0.3226\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5053 - val_loss: 0.3197\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5355 - val_loss: 0.3190\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4782 - val_loss: 0.3149\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4885 - val_loss: 0.3176\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4586 - val_loss: 0.3151\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4799 - val_loss: 0.3142\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4396 - val_loss: 0.3132\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4074 - val_loss: 0.3063\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4440 - val_loss: 0.3177\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3996 - val_loss: 0.3048\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4003 - val_loss: 0.3064\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3769 - val_loss: 0.2998\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3953 - val_loss: 0.3030\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3792 - val_loss: 0.3024\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3880 - val_loss: 0.2987\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3753 - val_loss: 0.2994\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3786 - val_loss: 0.3109\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3629 - val_loss: 0.3104\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3619 - val_loss: 0.3065\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3419 - val_loss: 0.3014\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3524 - val_loss: 0.3021\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3675 - val_loss: 0.3180\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3740 - val_loss: 0.2923\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3567 - val_loss: 0.2922\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3322 - val_loss: 0.3099\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3353 - val_loss: 0.3046\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3154 - val_loss: 0.3058\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3571 - val_loss: 0.3050\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3365 - val_loss: 0.2942\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3172 - val_loss: 0.2921\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3152 - val_loss: 0.2984\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3118 - val_loss: 0.3057\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3175 - val_loss: 0.2970\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2887 - val_loss: 0.3025\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3150 - val_loss: 0.3034\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.2908\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2975 - val_loss: 0.2991\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2829 - val_loss: 0.2920\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3059 - val_loss: 0.3200\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3106 - val_loss: 0.2910\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3022 - val_loss: 0.2867\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2957 - val_loss: 0.3018\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2924 - val_loss: 0.3012\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3038 - val_loss: 0.2988\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2731 - val_loss: 0.2950\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3106 - val_loss: 0.3065\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2864 - val_loss: 0.3022ss:\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2703 - val_loss: 0.2952\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2983 - val_loss: 0.2987\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2722 - val_loss: 0.2937\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2680 - val_loss: 0.3012\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2695 - val_loss: 0.2885\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2811 - val_loss: 0.3022\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2785 - val_loss: 0.3078\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2853 - val_loss: 0.2874\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2815 - val_loss: 0.2939\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2799 - val_loss: 0.3139\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2510 - val_loss: 0.3009\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2854 - val_loss: 0.2892\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2653 - val_loss: 0.2906\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2591 - val_loss: 0.3079\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2390 - val_loss: 0.2978\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2557 - val_loss: 0.3241\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2569 - val_loss: 0.3030\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2375 - val_loss: 0.3129\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2630 - val_loss: 0.2970\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2606 - val_loss: 0.3057\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 3.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 5.0643 - val_loss: 0.7726\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8187 - val_loss: 0.3375\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6947 - val_loss: 0.3369\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6455 - val_loss: 0.3369\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6587 - val_loss: 0.3403\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6243 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6110 - val_loss: 0.3375\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5705 - val_loss: 0.3392\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5583 - val_loss: 0.3365\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5643 - val_loss: 0.3328\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5247 - val_loss: 0.3272\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5161 - val_loss: 0.3310\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4884 - val_loss: 0.3265\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5073 - val_loss: 0.3203\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4782 - val_loss: 0.3316\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4470 - val_loss: 0.3223\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4403 - val_loss: 0.3197\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4239 - val_loss: 0.3138\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4322 - val_loss: 0.3146\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4057 - val_loss: 0.3126\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4063 - val_loss: 0.3160\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3967 - val_loss: 0.3302\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3907 - val_loss: 0.3228\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3788 - val_loss: 0.3202\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3919 - val_loss: 0.3057\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3892 - val_loss: 0.3211\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4198 - val_loss: 0.3300\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3729 - val_loss: 0.3066\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3684 - val_loss: 0.3152\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3860 - val_loss: 0.3189\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3485 - val_loss: 0.3222\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3759 - val_loss: 0.3103\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3552 - val_loss: 0.3113\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3574 - val_loss: 0.3138\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3373 - val_loss: 0.3113\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3258 - val_loss: 0.3284\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3454 - val_loss: 0.3129\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3222 - val_loss: 0.3233\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3207 - val_loss: 0.3098\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3399 - val_loss: 0.3161\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3178 - val_loss: 0.3088\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3242 - val_loss: 0.3108\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3263 - val_loss: 0.3129\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3150 - val_loss: 0.3100\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3079 - val_loss: 0.3182\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2932 - val_loss: 0.3044\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2989 - val_loss: 0.3101\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3105 - val_loss: 0.3057\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3199 - val_loss: 0.3157\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2974 - val_loss: 0.3118\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3091 - val_loss: 0.3154\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2912 - val_loss: 0.3013\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3052 - val_loss: 0.3063\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3061 - val_loss: 0.3002\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2840 - val_loss: 0.2997\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2918 - val_loss: 0.3058\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2883 - val_loss: 0.3181\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2732 - val_loss: 0.3062\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2818 - val_loss: 0.3131\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3135 - val_loss: 0.2857\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3095 - val_loss: 0.2958\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2835 - val_loss: 0.3063\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2771 - val_loss: 0.2980\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2675 - val_loss: 0.2972\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2919 - val_loss: 0.3150\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2786 - val_loss: 0.3147\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2703 - val_loss: 0.2990\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2782 - val_loss: 0.2894\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2949 - val_loss: 0.2962ss: 0.29\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2976 - val_loss: 0.3094\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2658 - val_loss: 0.2993\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2812 - val_loss: 0.3018\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2702 - val_loss: 0.3109\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2751 - val_loss: 0.2972\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2509 - val_loss: 0.2951\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2580 - val_loss: 0.3013\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2593 - val_loss: 0.2939\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2622 - val_loss: 0.3005\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2569 - val_loss: 0.3018\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2456 - val_loss: 0.3038\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2528 - val_loss: 0.3051\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2576 - val_loss: 0.3141\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2415 - val_loss: 0.2967\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2463 - val_loss: 0.2996\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2402 - val_loss: 0.3000\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2508 - val_loss: 0.2940\n",
      "Epoch 00085: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 3.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 6.2468 - val_loss: 0.3701\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1070 - val_loss: 0.3365\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0018 - val_loss: 0.3303\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0027 - val_loss: 0.3165\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8895 - val_loss: 0.3157\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8794 - val_loss: 0.3081\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8107 - val_loss: 0.3275\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6990 - val_loss: 0.3048\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6583 - val_loss: 0.3045\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6621 - val_loss: 0.3090\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6396 - val_loss: 0.3075\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5719 - val_loss: 0.3175\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5211 - val_loss: 0.2929\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4932 - val_loss: 0.2951\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5084 - val_loss: 0.2927\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4569 - val_loss: 0.2851\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4344 - val_loss: 0.2858\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4353 - val_loss: 0.2849\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3955 - val_loss: 0.2916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3942 - val_loss: 0.2913\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3661 - val_loss: 0.2931\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3572 - val_loss: 0.3017\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3389 - val_loss: 0.2961\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3085 - val_loss: 0.2889\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3312 - val_loss: 0.3025\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3273 - val_loss: 0.3001\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3163 - val_loss: 0.2851\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3017 - val_loss: 0.2938\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2932 - val_loss: 0.2905\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2954 - val_loss: 0.2846\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3030 - val_loss: 0.2881\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2816 - val_loss: 0.2887\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2583 - val_loss: 0.3063\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2582 - val_loss: 0.2934\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2621 - val_loss: 0.2908\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2534 - val_loss: 0.2908\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2533 - val_loss: 0.3040\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2625 - val_loss: 0.2911\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2283 - val_loss: 0.3007\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2516 - val_loss: 0.3051\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2478 - val_loss: 0.3032\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2449 - val_loss: 0.3176\n",
      "Epoch 00041: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 1.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 6.6972 - val_loss: 1.6827\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0851 - val_loss: 0.3421\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6891 - val_loss: 0.3368\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6458 - val_loss: 0.3366\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6550 - val_loss: 0.3382\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6270 - val_loss: 0.3388\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6064 - val_loss: 0.3363\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5850 - val_loss: 0.3377\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5599 - val_loss: 0.3384\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5924 - val_loss: 0.3375\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5485 - val_loss: 0.3379\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5369 - val_loss: 0.3386\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5385 - val_loss: 0.3370\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4979 - val_loss: 0.3396\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4889 - val_loss: 0.3370\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4953 - val_loss: 0.3368\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4817 - val_loss: 0.3376\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4889 - val_loss: 0.3374\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4677 - val_loss: 0.3370\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4753 - val_loss: 0.3369\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4683 - val_loss: 0.3425ss\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4698 - val_loss: 0.3373\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4597 - val_loss: 0.3368\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4462 - val_loss: 0.3370\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4548 - val_loss: 0.3408\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4488 - val_loss: 0.3373\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4429 - val_loss: 0.3368\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4360 - val_loss: 0.3383\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4301 - val_loss: 0.3374\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=1, total= 1.5min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9077 - val_loss: 0.3681\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6511 - val_loss: 0.3581\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6083 - val_loss: 0.3377\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5249 - val_loss: 0.3434\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4730 - val_loss: 0.3387\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4665 - val_loss: 0.3330\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4333 - val_loss: 0.3339\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4356 - val_loss: 0.3376\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4314 - val_loss: 0.3372\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4344 - val_loss: 0.3353\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4270 - val_loss: 0.3516\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4128 - val_loss: 0.3370\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4271 - val_loss: 0.3500\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4035 - val_loss: 0.3309\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4017 - val_loss: 0.3277\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4000 - val_loss: 0.3302\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4140 - val_loss: 0.3388\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3866 - val_loss: 0.3256\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4003 - val_loss: 0.3293\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3886 - val_loss: 0.3231\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3955 - val_loss: 0.3232\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3867 - val_loss: 0.3248\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3699 - val_loss: 0.3377\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3801 - val_loss: 0.3346\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3902 - val_loss: 0.3368\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3989 - val_loss: 0.3421\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3863 - val_loss: 0.3370\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3916 - val_loss: 0.3371\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3856 - val_loss: 0.3373\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3975 - val_loss: 0.3376\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3915 - val_loss: 0.3367\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3781 - val_loss: 0.3482\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3911 - val_loss: 0.3258\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3713 - val_loss: 0.3245\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3605 - val_loss: 0.3237\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3714 - val_loss: 0.3139\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3583 - val_loss: 0.3242\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3486 - val_loss: 0.3194\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3811 - val_loss: 0.3381\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3619 - val_loss: 0.3087\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3445 - val_loss: 0.3079ss: 0.\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3429 - val_loss: 0.3241\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3469 - val_loss: 0.3173\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3443 - val_loss: 0.3275\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3477 - val_loss: 0.3211\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3521 - val_loss: 0.3027\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3370 - val_loss: 0.3110\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3471 - val_loss: 0.3140\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3247 - val_loss: 0.3196\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3427 - val_loss: 0.3149\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3234 - val_loss: 0.3352\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3406 - val_loss: 0.3125\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3343 - val_loss: 0.3199\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3299 - val_loss: 0.3071\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3289 - val_loss: 0.3132\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3177 - val_loss: 0.3209\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3248 - val_loss: 0.3414\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2985 - val_loss: 0.3053\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3257 - val_loss: 0.3053\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3080 - val_loss: 0.3221\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3151 - val_loss: 0.3188\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2951 - val_loss: 0.3125\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2943 - val_loss: 0.3122\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3022 - val_loss: 0.3159\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3071 - val_loss: 0.3097\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2866 - val_loss: 0.3108\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3037 - val_loss: 0.3135\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2995 - val_loss: 0.3091\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2704 - val_loss: 0.3055\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2890 - val_loss: 0.3078\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2877 - val_loss: 0.3059\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2844 - val_loss: 0.3088\n",
      "Epoch 00071: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 3.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4770 - val_loss: 0.3658\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9192 - val_loss: 0.3469\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7532 - val_loss: 0.3995\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5841 - val_loss: 0.3427\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6023 - val_loss: 0.3487\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5022 - val_loss: 0.3377\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4891 - val_loss: 0.3380\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4985 - val_loss: 0.3372\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4401 - val_loss: 0.3378\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4502 - val_loss: 0.3320\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4485 - val_loss: 0.3367\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4233 - val_loss: 0.3255\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4133 - val_loss: 0.3202\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4321 - val_loss: 0.3398\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4227 - val_loss: 0.3173ss: \n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4130 - val_loss: 0.3162\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4232 - val_loss: 0.3259\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4066 - val_loss: 0.3093\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3845 - val_loss: 0.3197\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4063 - val_loss: 0.3137\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3808 - val_loss: 0.3094\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3684 - val_loss: 0.3012\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3905 - val_loss: 0.3058\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3525 - val_loss: 0.3175\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3933 - val_loss: 0.3075\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3844 - val_loss: 0.2957\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3642 - val_loss: 0.3137\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3702 - val_loss: 0.3011\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3453 - val_loss: 0.3103\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3651 - val_loss: 0.3266\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3369 - val_loss: 0.2954\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3296 - val_loss: 0.2960\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3555 - val_loss: 0.3097\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3283 - val_loss: 0.3131\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3260 - val_loss: 0.3084\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3293 - val_loss: 0.3066\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3190 - val_loss: 0.2975\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3164 - val_loss: 0.2987\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3126 - val_loss: 0.3111\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3296 - val_loss: 0.3050\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3138 - val_loss: 0.2945\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3105 - val_loss: 0.2917\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3277 - val_loss: 0.3055\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3218 - val_loss: 0.3177\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3044 - val_loss: 0.3004\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2970 - val_loss: 0.2990\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2894 - val_loss: 0.3371\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3132 - val_loss: 0.3014\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2925 - val_loss: 0.2989\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2808 - val_loss: 0.3003\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2985 - val_loss: 0.3414\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2986 - val_loss: 0.3113\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2845 - val_loss: 0.3043\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3026 - val_loss: 0.3041\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3059 - val_loss: 0.3040\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2843 - val_loss: 0.3074\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2961 - val_loss: 0.2982\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2890 - val_loss: 0.3177\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2979 - val_loss: 0.2922\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2899 - val_loss: 0.3060\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2842 - val_loss: 0.2987\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2758 - val_loss: 0.3157\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2845 - val_loss: 0.2919\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2822 - val_loss: 0.2856\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2607 - val_loss: 0.3124\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2997 - val_loss: 0.3263\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3127 - val_loss: 0.3296\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2923 - val_loss: 0.2965\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2696 - val_loss: 0.2951\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2560 - val_loss: 0.3263\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2758 - val_loss: 0.3043\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2620 - val_loss: 0.3102\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2822 - val_loss: 0.2777\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2719 - val_loss: 0.2985\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2728 - val_loss: 0.3073\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2614 - val_loss: 0.3114\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2527 - val_loss: 0.3082\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2677 - val_loss: 0.3085\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2755 - val_loss: 0.3220\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2660 - val_loss: 0.2912\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2708 - val_loss: 0.2974\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2667 - val_loss: 0.2923\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2580 - val_loss: 0.3185\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2848 - val_loss: 0.3033\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2579 - val_loss: 0.3193\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2829 - val_loss: 0.3203\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2683 - val_loss: 0.3087\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2678 - val_loss: 0.2994\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2634 - val_loss: 0.2958\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2640 - val_loss: 0.2993\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2725 - val_loss: 0.2897\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2456 - val_loss: 0.2963\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2596 - val_loss: 0.2998\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2453 - val_loss: 0.3068\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2614 - val_loss: 0.2967\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2478 - val_loss: 0.2990\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2527 - val_loss: 0.3117\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2455 - val_loss: 0.2895\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2588 - val_loss: 0.2878\n",
      "Epoch 00098: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 4.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.6787 - val_loss: 0.3543\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.9660 - val_loss: 0.3398\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8698 - val_loss: 0.3665\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7393 - val_loss: 0.3417\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7017 - val_loss: 0.3370\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6578 - val_loss: 0.3398\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5680 - val_loss: 0.3393\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5701 - val_loss: 0.3380\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5413 - val_loss: 0.3370\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5162 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5167 - val_loss: 0.3429\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5071 - val_loss: 0.3336\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4484 - val_loss: 0.3348\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4763 - val_loss: 0.3282\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4710 - val_loss: 0.3347\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4730 - val_loss: 0.3316\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4706 - val_loss: 0.3281\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4226 - val_loss: 0.3257\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4677 - val_loss: 0.3186\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4370 - val_loss: 0.3173\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4187 - val_loss: 0.3287\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4396 - val_loss: 0.3188\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4274 - val_loss: 0.3199\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4233 - val_loss: 0.3206\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4149 - val_loss: 0.3106\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4084 - val_loss: 0.3247\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4069 - val_loss: 0.3367\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4202 - val_loss: 0.3171\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3984 - val_loss: 0.3111\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4098 - val_loss: 0.3039\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4113 - val_loss: 0.3118\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4061 - val_loss: 0.3422\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4057 - val_loss: 0.3129\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3856 - val_loss: 0.3121\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4141 - val_loss: 0.3169\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3771 - val_loss: 0.3192\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3759 - val_loss: 0.3264\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3706 - val_loss: 0.3157\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3758 - val_loss: 0.3054\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3755 - val_loss: 0.3147\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3745 - val_loss: 0.3142\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3769 - val_loss: 0.2993\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3635 - val_loss: 0.3187\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3678 - val_loss: 0.3311\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3830 - val_loss: 0.3004\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3662 - val_loss: 0.2967\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3593 - val_loss: 0.2940ss:  - ETA: 0s - loss: 0.35\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3757 - val_loss: 0.3018\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3623 - val_loss: 0.3023\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3666 - val_loss: 0.3085\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3602 - val_loss: 0.2929\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3547 - val_loss: 0.3249\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3349 - val_loss: 0.2971\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3504 - val_loss: 0.3296\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3501 - val_loss: 0.3096\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3427 - val_loss: 0.3062\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3670 - val_loss: 0.2924\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3644 - val_loss: 0.3213ss: 0\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3549 - val_loss: 0.2970\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3473 - val_loss: 0.3015\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3711 - val_loss: 0.3087\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3548 - val_loss: 0.3044\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3372 - val_loss: 0.2983\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3437 - val_loss: 0.3036\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3356 - val_loss: 0.3182\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3371 - val_loss: 0.2976\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3285 - val_loss: 0.3059\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3329 - val_loss: 0.3120\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3310 - val_loss: 0.2976\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3339 - val_loss: 0.3332\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3144 - val_loss: 0.3000\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3338 - val_loss: 0.3107\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3293 - val_loss: 0.3172\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3068 - val_loss: 0.2964\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3239 - val_loss: 0.3029\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3274 - val_loss: 0.3087\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3163 - val_loss: 0.3290\n",
      "Epoch 00076: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 4.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.0792 - val_loss: 0.3790\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7365 - val_loss: 0.3481\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5961 - val_loss: 0.3422\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5533 - val_loss: 0.3397\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5072 - val_loss: 0.3430\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4709 - val_loss: 0.3476\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4599 - val_loss: 0.3449\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4746 - val_loss: 0.3413\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4532 - val_loss: 0.3379\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4416 - val_loss: 0.3394\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4327 - val_loss: 0.3397\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4413 - val_loss: 0.3386\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4450 - val_loss: 0.3370\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4416 - val_loss: 0.3404\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4540 - val_loss: 0.3424\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4259 - val_loss: 0.3426\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4313 - val_loss: 0.3370\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4468 - val_loss: 0.3445\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4157 - val_loss: 0.3529\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4213 - val_loss: 0.3455\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4147 - val_loss: 0.3377\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4231 - val_loss: 0.3371\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4154 - val_loss: 0.3368\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3997 - val_loss: 0.3369\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4107 - val_loss: 0.3371\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4144 - val_loss: 0.3379\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4223 - val_loss: 0.3371\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4167 - val_loss: 0.3369\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4125 - val_loss: 0.3372\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4031 - val_loss: 0.3428\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4048 - val_loss: 0.3373\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4112 - val_loss: 0.3407\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4179 - val_loss: 0.3383\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4263 - val_loss: 0.3417\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4050 - val_loss: 0.3368\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4003 - val_loss: 0.3407\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4003 - val_loss: 0.3368\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4079 - val_loss: 0.3371\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4131 - val_loss: 0.3392\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3830 - val_loss: 0.3414\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4035 - val_loss: 0.3624\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3973 - val_loss: 0.3374\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3895 - val_loss: 0.3537\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3985 - val_loss: 0.3355\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3923 - val_loss: 0.3367\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3920 - val_loss: 0.3579\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4005 - val_loss: 0.3332\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3946 - val_loss: 0.3496\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3993 - val_loss: 0.3389\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3761 - val_loss: 0.3296\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3787 - val_loss: 0.3302\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3822 - val_loss: 0.3303\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3734 - val_loss: 0.3280\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3860 - val_loss: 0.3262\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3638 - val_loss: 0.3278\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3778 - val_loss: 0.3264\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3777 - val_loss: 0.3254\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3835 - val_loss: 0.3342\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3609 - val_loss: 0.3286\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3660 - val_loss: 0.3308\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3696 - val_loss: 0.3254\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3694 - val_loss: 0.3314\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3797 - val_loss: 0.3272\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3755 - val_loss: 0.3243\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3741 - val_loss: 0.3220\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3736 - val_loss: 0.3349\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3610 - val_loss: 0.3180\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3830 - val_loss: 0.3162\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3521 - val_loss: 0.3156\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3498 - val_loss: 0.3176\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3485 - val_loss: 0.3150\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3502 - val_loss: 0.3161\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3541 - val_loss: 0.3197\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3545 - val_loss: 0.3329\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3546 - val_loss: 0.3203\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3455 - val_loss: 0.3153\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3479 - val_loss: 0.3190\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3396 - val_loss: 0.3161\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3511 - val_loss: 0.3080\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3370 - val_loss: 0.3073\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3343 - val_loss: 0.3226\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3430 - val_loss: 0.3409\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3414 - val_loss: 0.3213\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3510 - val_loss: 0.3124\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3478 - val_loss: 0.3208\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3483 - val_loss: 0.3074\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3387 - val_loss: 0.3130\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3206 - val_loss: 0.3255\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3199 - val_loss: 0.3273\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3346 - val_loss: 0.3200\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3349 - val_loss: 0.3436\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3251 - val_loss: 0.3573\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3369 - val_loss: 0.3310\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3110 - val_loss: 0.3296\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3120 - val_loss: 0.3347\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3204 - val_loss: 0.3406\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3061 - val_loss: 0.3169\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3113 - val_loss: 0.3182\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3162 - val_loss: 0.3345\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3149 - val_loss: 0.3337\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3110 - val_loss: 0.3439\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3111 - val_loss: 0.3226\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3265 - val_loss: 0.3265\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3143 - val_loss: 0.3214\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3115 - val_loss: 0.3522\n",
      "Epoch 00104: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 5.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.2021 - val_loss: 0.4106\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7828 - val_loss: 0.3502\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6152 - val_loss: 0.3389\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5388 - val_loss: 0.3402\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5079 - val_loss: 0.3403\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5113 - val_loss: 0.3441\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4771 - val_loss: 0.3488ss: 0.\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4691 - val_loss: 0.3378\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4690 - val_loss: 0.3545\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4457 - val_loss: 0.3368\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4376 - val_loss: 0.3368\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4692 - val_loss: 0.3439\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4404 - val_loss: 0.3400\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4522 - val_loss: 0.3403\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4222 - val_loss: 0.3369\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4220 - val_loss: 0.3380\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4359 - val_loss: 0.3415\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4328 - val_loss: 0.3369\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4223 - val_loss: 0.3386\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4352 - val_loss: 0.3384\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4030 - val_loss: 0.3414\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4202 - val_loss: 0.3369\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4056 - val_loss: 0.3396\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4317 - val_loss: 0.3403\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4231 - val_loss: 0.3382ss - ET\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4109 - val_loss: 0.3368\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4207 - val_loss: 0.3462\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4131 - val_loss: 0.3372\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3975 - val_loss: 0.3471\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4207 - val_loss: 0.3373\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4072 - val_loss: 0.3398\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4093 - val_loss: 0.3425\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4067 - val_loss: 0.3397\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3856 - val_loss: 0.3389\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3952 - val_loss: 0.3445\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4068 - val_loss: 0.3368\n",
      "Epoch 00035: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=2, total= 2.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 6s - loss: 1.1586 - val_loss: 0.3538\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.7370 - val_loss: 0.3407\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.6709 - val_loss: 0.3371\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.5073 - val_loss: 0.3381\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4759 - val_loss: 0.3389\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4907 - val_loss: 0.3440\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4448 - val_loss: 0.3828\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4182 - val_loss: 0.3372\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4418 - val_loss: 0.3385\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4424 - val_loss: 0.3363\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4391 - val_loss: 0.3367\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4424 - val_loss: 0.3438\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4174 - val_loss: 0.3461\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4239 - val_loss: 0.3353\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4047 - val_loss: 0.3398\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4313 - val_loss: 0.3481\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4185 - val_loss: 0.3426\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4185 - val_loss: 0.3354\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4189 - val_loss: 0.3412\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4251 - val_loss: 0.3520\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4107 - val_loss: 0.3534ss: 0.4 - ETA:\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3995 - val_loss: 0.3339\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3961 - val_loss: 0.3335\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4201 - val_loss: 0.3568\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3989 - val_loss: 0.3324\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3974 - val_loss: 0.3417\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4026 - val_loss: 0.3363\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3885 - val_loss: 0.3416\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3973 - val_loss: 0.3332\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3709 - val_loss: 0.3400\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3952 - val_loss: 0.3339\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3718 - val_loss: 0.3358\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3795 - val_loss: 0.3362TA: 1s - los - ETA: 0s - loss\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3635 - val_loss: 0.3681\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.4018 - val_loss: 0.3443\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3853 - val_loss: 0.3239\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3684 - val_loss: 0.3207\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3643 - val_loss: 0.3225\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3534 - val_loss: 0.3228\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3739 - val_loss: 0.3214\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3613 - val_loss: 0.3166\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3693 - val_loss: 0.3243\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3610 - val_loss: 0.3192\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3636 - val_loss: 0.3158\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3598 - val_loss: 0.3116\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3562 - val_loss: 0.3136\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3543 - val_loss: 0.3221\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3647 - val_loss: 0.3246\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3446 - val_loss: 0.3108TA: 0s - lo\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3365 - val_loss: 0.3215\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3415 - val_loss: 0.3305ss: 0.\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3534 - val_loss: 0.3434\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3382 - val_loss: 0.3205\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3177 - val_loss: 0.3324\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3379 - val_loss: 0.3133\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3555 - val_loss: 0.3283\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3461 - val_loss: 0.3220\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3294 - val_loss: 0.3138\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3272 - val_loss: 0.3102\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3410 - val_loss: 0.3137\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3437 - val_loss: 0.3277\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3188 - val_loss: 0.3361\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3202 - val_loss: 0.3077\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3150 - val_loss: 0.3288ss\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3094 - val_loss: 0.3034\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3077 - val_loss: 0.3126\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3088 - val_loss: 0.32230s - loss: 0.31\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3083 - val_loss: 0.3089\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3205 - val_loss: 0.3376\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3135 - val_loss: 0.3251\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3120 - val_loss: 0.3280\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3136 - val_loss: 0.3182\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3133 - val_loss: 0.3223\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3347 - val_loss: 0.3107\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3194 - val_loss: 0.3103\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2973 - val_loss: 0.3088\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3047 - val_loss: 0.3176\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2891 - val_loss: 0.3220\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3023 - val_loss: 0.3097\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3017 - val_loss: 0.3135ss: 0.302\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3059 - val_loss: 0.3049\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2796 - val_loss: 0.3094\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3052 - val_loss: 0.3015\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2972 - val_loss: 0.3146\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2852 - val_loss: 0.3045\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2884 - val_loss: 0.3186\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2845 - val_loss: 0.3173\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2782 - val_loss: 0.3239\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2829 - val_loss: 0.2983\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2924 - val_loss: 0.3032\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2746 - val_loss: 0.3083\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2811 - val_loss: 0.2935\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2888 - val_loss: 0.3175\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2875 - val_loss: 0.3064\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2871 - val_loss: 0.3308\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2683 - val_loss: 0.3095\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2846 - val_loss: 0.3186\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2689 - val_loss: 0.2959\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2664 - val_loss: 0.3173\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2963 - val_loss: 0.3149\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2861 - val_loss: 0.3138\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2559 - val_loss: 0.3198\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2787 - val_loss: 0.3157\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2817 - val_loss: 0.3175\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2523 - val_loss: 0.3097\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2637 - val_loss: 0.3074\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2680 - val_loss: 0.3056\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2609 - val_loss: 0.2953\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2635 - val_loss: 0.2993\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2559 - val_loss: 0.3052\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2646 - val_loss: 0.2895\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2587 - val_loss: 0.2963\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2666 - val_loss: 0.3103\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2631 - val_loss: 0.3044\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2547 - val_loss: 0.3016ss: 0.243 - ETA\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2647 - val_loss: 0.3040\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2467 - val_loss: 0.3193\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2711 - val_loss: 0.3157\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2618 - val_loss: 0.3064\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2517 - val_loss: 0.3062\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2560 - val_loss: 0.3008\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2530 - val_loss: 0.3121\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2497 - val_loss: 0.3044\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2523 - val_loss: 0.3021\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2343 - val_loss: 0.2951\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2273 - val_loss: 0.3017\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2526 - val_loss: 0.3044\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2467 - val_loss: 0.3029\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2550 - val_loss: 0.3033\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2364 - val_loss: 0.3006ss: 0.23\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2413 - val_loss: 0.2936\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2503 - val_loss: 0.2876\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2440 - val_loss: 0.3018\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2331 - val_loss: 0.3089\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2310 - val_loss: 0.3255\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2384 - val_loss: 0.2974\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2420 - val_loss: 0.3012\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2328 - val_loss: 0.3130\n",
      "Epoch 139/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2338 - val_loss: 0.2914\n",
      "Epoch 140/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2302 - val_loss: 0.2890\n",
      "Epoch 141/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2313 - val_loss: 0.2955\n",
      "Epoch 142/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2178 - val_loss: 0.2981\n",
      "Epoch 143/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2306 - val_loss: 0.2977\n",
      "Epoch 144/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2253 - val_loss: 0.2948\n",
      "Epoch 145/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2121 - val_loss: 0.2872\n",
      "Epoch 146/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2298 - val_loss: 0.3026\n",
      "Epoch 147/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2112 - val_loss: 0.2877\n",
      "Epoch 148/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2177 - val_loss: 0.2988\n",
      "Epoch 149/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2207 - val_loss: 0.3016\n",
      "Epoch 150/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2166 - val_loss: 0.2889\n",
      "Epoch 151/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2194 - val_loss: 0.2905\n",
      "Epoch 152/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2207 - val_loss: 0.3103\n",
      "Epoch 153/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2095 - val_loss: 0.2993\n",
      "Epoch 154/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2036 - val_loss: 0.3043\n",
      "Epoch 155/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2016 - val_loss: 0.2995\n",
      "Epoch 156/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2241 - val_loss: 0.2987\n",
      "Epoch 157/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2198 - val_loss: 0.2908\n",
      "Epoch 158/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2127 - val_loss: 0.2908\n",
      "Epoch 00157: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 8.6min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.5709 - val_loss: 0.3408\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.8003 - val_loss: 0.3649\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7192 - val_loss: 0.3482\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6027 - val_loss: 0.3397\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5397 - val_loss: 0.3355\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5163 - val_loss: 0.3416\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4855 - val_loss: 0.3396\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4726 - val_loss: 0.3359\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4649 - val_loss: 0.3368\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4491 - val_loss: 0.3355\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4514 - val_loss: 0.3355\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4531 - val_loss: 0.3489\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4582 - val_loss: 0.3346\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4385 - val_loss: 0.3383\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4355 - val_loss: 0.3381\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4203 - val_loss: 0.3537\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4016 - val_loss: 0.3398\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4354 - val_loss: 0.3332ss: 0.4 - ETA: 1s - loss: 0.4 - ETA: 0s \n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4240 - val_loss: 0.3352\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4100 - val_loss: 0.3410ss:\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3988 - val_loss: 0.3327\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4180 - val_loss: 0.3313\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4198 - val_loss: 0.3339\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4143 - val_loss: 0.3361\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4138 - val_loss: 0.3507\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3894 - val_loss: 0.3343\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4023 - val_loss: 0.3428\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4128 - val_loss: 0.3265\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3877 - val_loss: 0.3288\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3775 - val_loss: 0.3221\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3975 - val_loss: 0.3325\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3774 - val_loss: 0.3112\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3870 - val_loss: 0.3435\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3958 - val_loss: 0.3540\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3951 - val_loss: 0.3247\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3733 - val_loss: 0.3260\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3713 - val_loss: 0.3186\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3723 - val_loss: 0.3136\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3706 - val_loss: 0.3021\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3424 - val_loss: 0.2965\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3390 - val_loss: 0.2966\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3455 - val_loss: 0.3060\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3485 - val_loss: 0.3128\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3383 - val_loss: 0.2941\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3389 - val_loss: 0.3068\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3483 - val_loss: 0.2905\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3225 - val_loss: 0.3039\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3283 - val_loss: 0.2985\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3333 - val_loss: 0.2926\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3357 - val_loss: 0.3045\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3248 - val_loss: 0.2864\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3433 - val_loss: 0.3124\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3298 - val_loss: 0.2993\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3289 - val_loss: 0.2883\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3078 - val_loss: 0.2967\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3300 - val_loss: 0.2857\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3197 - val_loss: 0.2937\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3205 - val_loss: 0.2894\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2963 - val_loss: 0.2957\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3045 - val_loss: 0.2880\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2957 - val_loss: 0.2820\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3190 - val_loss: 0.2897\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2886 - val_loss: 0.3047\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2775 - val_loss: 0.3114\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3062 - val_loss: 0.3122\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2947 - val_loss: 0.2901\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2819 - val_loss: 0.2980\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2773 - val_loss: 0.2899\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2745 - val_loss: 0.2893\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2894 - val_loss: 0.2936\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2604 - val_loss: 0.2915\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2642 - val_loss: 0.3030\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2841 - val_loss: 0.2878\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2580 - val_loss: 0.2886\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2616 - val_loss: 0.2904\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2643 - val_loss: 0.2946\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2515 - val_loss: 0.2979\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2590 - val_loss: 0.3002\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2446 - val_loss: 0.2901\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2624 - val_loss: 0.2912\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2511 - val_loss: 0.2903ss: 0\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2556 - val_loss: 0.2965\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2592 - val_loss: 0.3071\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2534 - val_loss: 0.3056\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2583 - val_loss: 0.2911\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2445 - val_loss: 0.2916\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2328 - val_loss: 0.2903\n",
      "Epoch 00086: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 4.9min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.0757 - val_loss: 0.3717\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7792 - val_loss: 0.3394\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6183 - val_loss: 0.3369\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5475 - val_loss: 0.3370\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4919 - val_loss: 0.3433\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4733 - val_loss: 0.3536\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4851 - val_loss: 0.3582\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4868 - val_loss: 0.3471\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4560 - val_loss: 0.3452\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4582 - val_loss: 0.3425\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4430 - val_loss: 0.3349\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4645 - val_loss: 0.3399\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4271 - val_loss: 0.3463\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4042 - val_loss: 0.3339\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4201 - val_loss: 0.3591\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4258 - val_loss: 0.3460\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4334 - val_loss: 0.3328\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4135 - val_loss: 0.3338\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4334 - val_loss: 0.3328\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4122 - val_loss: 0.3633\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4105 - val_loss: 0.3371\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4146 - val_loss: 0.3338\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4090 - val_loss: 0.3301\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4020 - val_loss: 0.3291\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4140 - val_loss: 0.3362\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4120 - val_loss: 0.3263\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4005 - val_loss: 0.3289\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3860 - val_loss: 0.3205\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3992 - val_loss: 0.3237ss:\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3879 - val_loss: 0.3176\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3770 - val_loss: 0.3262\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3773 - val_loss: 0.3153\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3769 - val_loss: 0.3291\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3861 - val_loss: 0.3152\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3770 - val_loss: 0.3377\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3685 - val_loss: 0.3272\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3526 - val_loss: 0.3179\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3565 - val_loss: 0.3227\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3725 - val_loss: 0.3133\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3516 - val_loss: 0.3374\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3437 - val_loss: 0.3376\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3678 - val_loss: 0.3213\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3637 - val_loss: 0.3156\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3525 - val_loss: 0.3304\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3444 - val_loss: 0.3238\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3391 - val_loss: 0.3222\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3418 - val_loss: 0.3237\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3466 - val_loss: 0.3102\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3405 - val_loss: 0.3093\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3370 - val_loss: 0.3057\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3247 - val_loss: 0.3120\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2997 - val_loss: 0.3150\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3330 - val_loss: 0.3129\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3259 - val_loss: 0.3092\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3345 - val_loss: 0.3067\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3248 - val_loss: 0.3179\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3192 - val_loss: 0.3186\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3089 - val_loss: 0.3450\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3201 - val_loss: 0.3603\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3301 - val_loss: 0.3150\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3114 - val_loss: 0.3174\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2944 - val_loss: 0.3206\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2996 - val_loss: 0.3111\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3090 - val_loss: 0.3398\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3087 - val_loss: 0.3286\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3086 - val_loss: 0.3204\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3135 - val_loss: 0.3305\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3046 - val_loss: 0.3204\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3012 - val_loss: 0.3301\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2951 - val_loss: 0.3255\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2959 - val_loss: 0.3120\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3006 - val_loss: 0.3156\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3021 - val_loss: 0.3302\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2919 - val_loss: 0.3290\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2817 - val_loss: 0.3256\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2818 - val_loss: 0.3285\n",
      "Epoch 00075: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 3.7min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.6873 - val_loss: 0.3372\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8178 - val_loss: 0.3610\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7457 - val_loss: 0.3821\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6388 - val_loss: 0.3378\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5845 - val_loss: 0.3373\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5512 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5218 - val_loss: 0.3630\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4878 - val_loss: 0.3426\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4780 - val_loss: 0.3400\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4816 - val_loss: 0.3376\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4776 - val_loss: 0.3402\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4821 - val_loss: 0.3369\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4574 - val_loss: 0.3493\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4704 - val_loss: 0.3455\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4694 - val_loss: 0.3373\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4580 - val_loss: 0.3388\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4414 - val_loss: 0.3394\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4426 - val_loss: 0.3454\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4424 - val_loss: 0.3373\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4366 - val_loss: 0.3398\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4347 - val_loss: 0.3442\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4309 - val_loss: 0.3488\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4312 - val_loss: 0.3378\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4421 - val_loss: 0.3436\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4316 - val_loss: 0.3397\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4237 - val_loss: 0.3392\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4323 - val_loss: 0.3570\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 1.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9108 - val_loss: 0.3614\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8535 - val_loss: 0.3384\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7618 - val_loss: 0.3517\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6764 - val_loss: 0.3462\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5941 - val_loss: 0.3392\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5681 - val_loss: 0.3381\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5100 - val_loss: 0.3380\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4888 - val_loss: 0.3520\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4895 - val_loss: 0.3373\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4676 - val_loss: 0.3561\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4532 - val_loss: 0.3488\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4469 - val_loss: 0.3488\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4704 - val_loss: 0.3403\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4593 - val_loss: 0.3371\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4614 - val_loss: 0.3503\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4439 - val_loss: 0.3658\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4287 - val_loss: 0.3576\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4469 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4562 - val_loss: 0.3369\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4406 - val_loss: 0.3368\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4312 - val_loss: 0.3612\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4401 - val_loss: 0.3425\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4382 - val_loss: 0.3417\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4383 - val_loss: 0.3443\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4245 - val_loss: 0.3517\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4187 - val_loss: 0.3500\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4182 - val_loss: 0.3396\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4375 - val_loss: 0.3459\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3997 - val_loss: 0.3378\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4140 - val_loss: 0.3362\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4112 - val_loss: 0.3363\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4265 - val_loss: 0.3409\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4240 - val_loss: 0.3351s - ETA: 1s \n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4231 - val_loss: 0.3538\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4285 - val_loss: 0.3346\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4155 - val_loss: 0.3350\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4365 - val_loss: 0.3351\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3979 - val_loss: 0.3416\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4043 - val_loss: 0.3335\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4014 - val_loss: 0.3356\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3931 - val_loss: 0.3309\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4221 - val_loss: 0.3362\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3985 - val_loss: 0.3303\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3849 - val_loss: 0.3290\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3949 - val_loss: 0.3288\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4005 - val_loss: 0.3282\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3726 - val_loss: 0.3197\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3869 - val_loss: 0.3188\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3632 - val_loss: 0.3284\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3921 - val_loss: 0.3229\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3839 - val_loss: 0.3188\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3958 - val_loss: 0.3199\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3810 - val_loss: 0.3175\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3828 - val_loss: 0.3253\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3854 - val_loss: 0.3229\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3820 - val_loss: 0.3127\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3645 - val_loss: 0.3082\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3721 - val_loss: 0.3046\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3687 - val_loss: 0.2988\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3494 - val_loss: 0.2955\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3449 - val_loss: 0.3016\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3519 - val_loss: 0.3029\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3500 - val_loss: 0.2998\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3599 - val_loss: 0.3076\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3460 - val_loss: 0.2994\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3477 - val_loss: 0.2976\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3394 - val_loss: 0.3127\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3314 - val_loss: 0.3014\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3208 - val_loss: 0.3010\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3131 - val_loss: 0.3002\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3046 - val_loss: 0.2949\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3172 - val_loss: 0.3017\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3071 - val_loss: 0.2966\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3129 - val_loss: 0.2945\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2875 - val_loss: 0.2948\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3141 - val_loss: 0.3010s\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3047 - val_loss: 0.3000\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2928 - val_loss: 0.3008\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3070 - val_loss: 0.3077\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2850 - val_loss: 0.3108\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2921 - val_loss: 0.2950\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2869 - val_loss: 0.2898\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2768 - val_loss: 0.3022\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2818 - val_loss: 0.3063\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2880 - val_loss: 0.2931\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2746 - val_loss: 0.3032\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2726 - val_loss: 0.2999\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2774 - val_loss: 0.3065\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2631 - val_loss: 0.3053\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2712 - val_loss: 0.3034\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2763 - val_loss: 0.2983\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2839 - val_loss: 0.3073\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2680 - val_loss: 0.3042\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2673 - val_loss: 0.2922\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2475 - val_loss: 0.3006\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2552 - val_loss: 0.3121\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2644 - val_loss: 0.3079\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2636 - val_loss: 0.3017\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2648 - val_loss: 0.2971\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2386 - val_loss: 0.3068\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2471 - val_loss: 0.3041\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2419 - val_loss: 0.3107\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2572 - val_loss: 0.2953\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2500 - val_loss: 0.3027\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2441 - val_loss: 0.2989\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2414 - val_loss: 0.2967\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2414 - val_loss: 0.2849\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2596 - val_loss: 0.3117\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2340 - val_loss: 0.3069\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2469 - val_loss: 0.3042\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2420 - val_loss: 0.2997\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2417 - val_loss: 0.3384\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2319 - val_loss: 0.3017\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2441 - val_loss: 0.3080\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2402 - val_loss: 0.3148\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2451 - val_loss: 0.2925\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2353 - val_loss: 0.2877\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2121 - val_loss: 0.2996\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2422 - val_loss: 0.2993\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2220 - val_loss: 0.2864\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2274 - val_loss: 0.3073\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2183 - val_loss: 0.2872\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2178 - val_loss: 0.3020\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2334 - val_loss: 0.3026\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2274 - val_loss: 0.3068\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2216 - val_loss: 0.3039\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2162 - val_loss: 0.3106\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2243 - val_loss: 0.3113\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2129 - val_loss: 0.3126\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2277 - val_loss: 0.3084\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2234 - val_loss: 0.3164\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2243 - val_loss: 0.3070\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2257 - val_loss: 0.3261\n",
      "Epoch 00132: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=128, num_hidden_layers=3, total= 6.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 6s - loss: 16.0893 - val_loss: 1.9244\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0841 - val_loss: 0.3374\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7605 - val_loss: 0.3364\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7402 - val_loss: 0.3362\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7325 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6939 - val_loss: 0.3366\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6644 - val_loss: 0.3365\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6500 - val_loss: 0.3366\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6223 - val_loss: 0.3369\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6096 - val_loss: 0.3370\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5783 - val_loss: 0.3341\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5492 - val_loss: 0.3278\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5344 - val_loss: 0.3255\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5194 - val_loss: 0.3284\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4848 - val_loss: 0.3245\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4732 - val_loss: 0.3187\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4406 - val_loss: 0.3151\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4477 - val_loss: 0.3047\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3957 - val_loss: 0.3030\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3988 - val_loss: 0.2971\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3751 - val_loss: 0.2878\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3583 - val_loss: 0.2979\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3555 - val_loss: 0.2897\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3140 - val_loss: 0.2875\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3233 - val_loss: 0.2816\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3028 - val_loss: 0.2810\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3086 - val_loss: 0.2858\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2866 - val_loss: 0.2972\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2770 - val_loss: 0.2826\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2593 - val_loss: 0.2778\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2420 - val_loss: 0.2949\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2571 - val_loss: 0.2869\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2266 - val_loss: 0.2817\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2318 - val_loss: 0.2852\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2185 - val_loss: 0.2878\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1999 - val_loss: 0.2822\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2067 - val_loss: 0.2900\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2012 - val_loss: 0.3015ss: 0.200 - ETA: 1s\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2044 - val_loss: 0.2921\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1892 - val_loss: 0.2864\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1734 - val_loss: 0.2845\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2030 - val_loss: 0.2800\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1723 - val_loss: 0.2832\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1938 - val_loss: 0.2883\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1889 - val_loss: 0.2919\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1978 - val_loss: 0.2941\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2157 - val_loss: 0.2836\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1859 - val_loss: 0.2796s\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1805 - val_loss: 0.2881\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1737 - val_loss: 0.2855\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1744 - val_loss: 0.2904\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1741 - val_loss: 0.2779\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1698 - val_loss: 0.2899\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1638 - val_loss: 0.2864\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1610 - val_loss: 0.2993\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1578 - val_loss: 0.3056\n",
      "Epoch 00055: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 14.2499 - val_loss: 1.8563s: 14.\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0561 - val_loss: 0.3438\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7777 - val_loss: 0.3310\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7280 - val_loss: 0.3289\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6751 - val_loss: 0.3282\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7065 - val_loss: 0.3263\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6830 - val_loss: 0.3222\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6380 - val_loss: 0.3165\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6188 - val_loss: 0.3146\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5691 - val_loss: 0.3107\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5685 - val_loss: 0.3113\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5545 - val_loss: 0.3070\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5539 - val_loss: 0.3100\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5144 - val_loss: 0.3119\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4496 - val_loss: 0.3062\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4322 - val_loss: 0.2954\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4347 - val_loss: 0.2934\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4428 - val_loss: 0.2931\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3964 - val_loss: 0.2980\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3736 - val_loss: 0.3052\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3595 - val_loss: 0.2983\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3703 - val_loss: 0.3017\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3383 - val_loss: 0.2988\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3297 - val_loss: 0.3037\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3261 - val_loss: 0.3227\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3091 - val_loss: 0.3055\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2925 - val_loss: 0.3063\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2852 - val_loss: 0.3126\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2923 - val_loss: 0.3124\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2767 - val_loss: 0.2990\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2713 - val_loss: 0.2978\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2631 - val_loss: 0.3054\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2711 - val_loss: 0.3141\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2690 - val_loss: 0.3047\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2458 - val_loss: 0.2993\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2389 - val_loss: 0.3035\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2514 - val_loss: 0.3088\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2242 - val_loss: 0.2998\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2205 - val_loss: 0.3064\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2366 - val_loss: 0.2980\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2448 - val_loss: 0.3011\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2184 - val_loss: 0.3012\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1984 - val_loss: 0.2872\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2119 - val_loss: 0.2992\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2220 - val_loss: 0.2892\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2215 - val_loss: 0.2979\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2023 - val_loss: 0.3086\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2194 - val_loss: 0.3176\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2299 - val_loss: 0.3108\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2222 - val_loss: 0.3096\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2132 - val_loss: 0.3051\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2232 - val_loss: 0.3125\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2311 - val_loss: 0.3016\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2338 - val_loss: 0.3046\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2107 - val_loss: 0.2968\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2224 - val_loss: 0.3036\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2150 - val_loss: 0.3206\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2114 - val_loss: 0.2942\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2081 - val_loss: 0.3010\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2093 - val_loss: 0.3018\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2106 - val_loss: 0.3067\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2057 - val_loss: 0.2937\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1901 - val_loss: 0.3170\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1960 - val_loss: 0.2978\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2031 - val_loss: 0.3035\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1981 - val_loss: 0.3021\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2099 - val_loss: 0.3065\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2101 - val_loss: 0.3064\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1947 - val_loss: 0.3118\n",
      "Epoch 00068: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 5.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 6.6923 - val_loss: 0.3501\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1689 - val_loss: 0.3263\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0326 - val_loss: 0.3094\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9508 - val_loss: 0.3171\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8525 - val_loss: 0.3052\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8583 - val_loss: 0.3109\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7476 - val_loss: 0.2969\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7163 - val_loss: 0.2953\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6180 - val_loss: 0.3001\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5818 - val_loss: 0.2837\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5520 - val_loss: 0.2858\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5024 - val_loss: 0.2835\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4517 - val_loss: 0.2988\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4175 - val_loss: 0.2907\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3769 - val_loss: 0.2869\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3409 - val_loss: 0.2829\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3243 - val_loss: 0.2968\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3030 - val_loss: 0.2948\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2857 - val_loss: 0.2945\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2456 - val_loss: 0.2988\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2342 - val_loss: 0.2897\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2153 - val_loss: 0.2991\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2091 - val_loss: 0.3040\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2023 - val_loss: 0.2941\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1756 - val_loss: 0.3074\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1776 - val_loss: 0.2912\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1707 - val_loss: 0.2954\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1657 - val_loss: 0.2989\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1656 - val_loss: 0.2941\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1567 - val_loss: 0.2925\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1545 - val_loss: 0.3026\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1478 - val_loss: 0.2976\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1576 - val_loss: 0.3053\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1599 - val_loss: 0.3156\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1443 - val_loss: 0.3109\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1552 - val_loss: 0.2964\n",
      "Epoch 00035: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 2.7min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 8.3853 - val_loss: 0.3772\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1989 - val_loss: 0.3302\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0461 - val_loss: 0.3164\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9363 - val_loss: 0.2938\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8810 - val_loss: 0.2984\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8834 - val_loss: 0.2961\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8302 - val_loss: 0.2924\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7654 - val_loss: 0.2986\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7076 - val_loss: 0.2878\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5968 - val_loss: 0.2895\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5551 - val_loss: 0.3120\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5402 - val_loss: 0.2854\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5036 - val_loss: 0.3021\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4738 - val_loss: 0.2860\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4129 - val_loss: 0.2807\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4234 - val_loss: 0.3048\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3860 - val_loss: 0.2892\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3554 - val_loss: 0.2929\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3480 - val_loss: 0.2783\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2961 - val_loss: 0.3101\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2842 - val_loss: 0.2854\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2650 - val_loss: 0.2809\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2393 - val_loss: 0.2878\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2197 - val_loss: 0.2802\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2192 - val_loss: 0.2845\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2090 - val_loss: 0.2839\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1962 - val_loss: 0.2850\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2060 - val_loss: 0.2927\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1990 - val_loss: 0.3061\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1778 - val_loss: 0.2896\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1699 - val_loss: 0.2858\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1690 - val_loss: 0.2883\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1504 - val_loss: 0.2858\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1560 - val_loss: 0.3020\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1657 - val_loss: 0.2987\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1527 - val_loss: 0.2860\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1442 - val_loss: 0.3108\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1696 - val_loss: 0.2901\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1453 - val_loss: 0.3078\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1505 - val_loss: 0.2853\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1604 - val_loss: 0.2853\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1518 - val_loss: 0.3002\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1477 - val_loss: 0.2929\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1460 - val_loss: 0.2943\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1429 - val_loss: 0.3031\n",
      "Epoch 00044: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 3.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 8.4432 - val_loss: 0.3915\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1183 - val_loss: 0.3241\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9927 - val_loss: 0.2990\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9557 - val_loss: 0.2979\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9235 - val_loss: 0.3148\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8209 - val_loss: 0.2946\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7431 - val_loss: 0.2954\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7109 - val_loss: 0.2886\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6730 - val_loss: 0.2858\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6292 - val_loss: 0.2824\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5835 - val_loss: 0.2881\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5235 - val_loss: 0.2847\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4839 - val_loss: 0.2871\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4157 - val_loss: 0.3009\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4478 - val_loss: 0.2895\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3996 - val_loss: 0.2899\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3538 - val_loss: 0.2816\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3278 - val_loss: 0.3057\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3021 - val_loss: 0.2809\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2836 - val_loss: 0.3016\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2660 - val_loss: 0.2839\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2743 - val_loss: 0.2955\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2379 - val_loss: 0.2883\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2122 - val_loss: 0.2889\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2244 - val_loss: 0.3276\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2007 - val_loss: 0.2884\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1886 - val_loss: 0.2952\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1845 - val_loss: 0.3169\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1598 - val_loss: 0.2938\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1771 - val_loss: 0.2971\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1781 - val_loss: 0.2954\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1858 - val_loss: 0.2871\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1635 - val_loss: 0.2981\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1546 - val_loss: 0.2956\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1576 - val_loss: 0.3096\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1531 - val_loss: 0.3021\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1478 - val_loss: 0.3030\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1585 - val_loss: 0.3109\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1432 - val_loss: 0.3011\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1484 - val_loss: 0.3069\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1436 - val_loss: 0.3136\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1578 - val_loss: 0.3026\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1536 - val_loss: 0.2891\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1407 - val_loss: 0.2978\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1468 - val_loss: 0.2979\n",
      "Epoch 00044: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 3.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 6s - loss: 0.9813 - val_loss: 0.3530\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6769 - val_loss: 0.3306\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5093 - val_loss: 0.3268\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4324 - val_loss: 0.3332\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4198 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3900 - val_loss: 0.3336\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4005 - val_loss: 0.3124\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3696 - val_loss: 0.3613\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3671 - val_loss: 0.3274\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3607 - val_loss: 0.3022\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3528 - val_loss: 0.3178\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3627 - val_loss: 0.2972\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3227 - val_loss: 0.2948\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3090 - val_loss: 0.3051\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3372 - val_loss: 0.2961\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3300 - val_loss: 0.2930\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3158 - val_loss: 0.3167\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3139 - val_loss: 0.2904\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3081 - val_loss: 0.3099\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2972 - val_loss: 0.2892\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2999 - val_loss: 0.3132\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3040 - val_loss: 0.2954\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2980 - val_loss: 0.2959\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2943 - val_loss: 0.2804\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2911 - val_loss: 0.2891\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2764 - val_loss: 0.2874\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3042 - val_loss: 0.2870\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2919 - val_loss: 0.3164\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2887 - val_loss: 0.3262\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2733 - val_loss: 0.3327\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2775 - val_loss: 0.2871\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2584 - val_loss: 0.2821\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2488 - val_loss: 0.2850\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2625 - val_loss: 0.2962\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2554 - val_loss: 0.2886\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2430 - val_loss: 0.2846\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2525 - val_loss: 0.2861\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2391 - val_loss: 0.2961\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2455 - val_loss: 0.2934\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2543 - val_loss: 0.2815\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2393 - val_loss: 0.3202\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2358 - val_loss: 0.2896\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2323 - val_loss: 0.2988\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2497 - val_loss: 0.3039\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2487 - val_loss: 0.2879\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2231 - val_loss: 0.2961\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2277 - val_loss: 0.3171\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2416 - val_loss: 0.2874\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2481 - val_loss: 0.2879\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2395 - val_loss: 0.2927\n",
      "Epoch 00049: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 3.7min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.0755 - val_loss: 0.4322\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6706 - val_loss: 0.3430\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5691 - val_loss: 0.3448\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4609 - val_loss: 0.3411\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4373 - val_loss: 0.3448\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4265 - val_loss: 0.3355\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4336 - val_loss: 0.3599\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3933 - val_loss: 0.3799\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4006 - val_loss: 0.3397\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3903 - val_loss: 0.4724\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3959 - val_loss: 0.3480\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3849 - val_loss: 0.3630\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3681 - val_loss: 0.3241\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3747 - val_loss: 0.3299\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3767 - val_loss: 0.3392\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3860 - val_loss: 0.3464\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3815 - val_loss: 0.3364\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3467 - val_loss: 0.3234\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3364 - val_loss: 0.3222\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3545 - val_loss: 0.3566\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3517 - val_loss: 0.3265\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3381 - val_loss: 0.3188\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3387 - val_loss: 0.3516\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3417 - val_loss: 0.3106\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3222 - val_loss: 0.3351\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3347 - val_loss: 0.3172\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3470 - val_loss: 0.3081\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3480 - val_loss: 0.3186\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3293 - val_loss: 0.3151\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3270 - val_loss: 0.3002\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3160 - val_loss: 0.3083\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3198 - val_loss: 0.3135\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3215 - val_loss: 0.3188\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3238 - val_loss: 0.3294\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3224 - val_loss: 0.3250\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3171 - val_loss: 0.3018\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3103 - val_loss: 0.3248\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3280 - val_loss: 0.3205\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3273 - val_loss: 0.3355\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3294 - val_loss: 0.3121\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3177 - val_loss: 0.3038\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3244 - val_loss: 0.3254\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3197 - val_loss: 0.3066\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3121 - val_loss: 0.3150\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3162 - val_loss: 0.3229\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3176 - val_loss: 0.3069\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3072 - val_loss: 0.3297\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3078 - val_loss: 0.2980\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3078 - val_loss: 0.3317\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3192 - val_loss: 0.3013\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3004 - val_loss: 0.3090\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2965 - val_loss: 0.3105\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3113 - val_loss: 0.3084\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3014 - val_loss: 0.3037\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3159 - val_loss: 0.3025\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3203 - val_loss: 0.3104\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3186 - val_loss: 0.3532\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2988 - val_loss: 0.3033\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2957 - val_loss: 0.3192\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3066 - val_loss: 0.3050\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3082 - val_loss: 0.3013\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3013 - val_loss: 0.3156\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3022 - val_loss: 0.3098\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2980 - val_loss: 0.3085\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3024 - val_loss: 0.3101\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2970 - val_loss: 0.3051\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2987 - val_loss: 0.3110\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3024 - val_loss: 0.3023\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2905 - val_loss: 0.3113\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3070 - val_loss: 0.3065\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2989 - val_loss: 0.3143\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3032 - val_loss: 0.3344\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2950 - val_loss: 0.3116\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2918 - val_loss: 0.3045\n",
      "Epoch 00073: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 5.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.0410 - val_loss: 0.3550\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7333 - val_loss: 0.3612\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5284 - val_loss: 0.3589\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4733 - val_loss: 0.3381\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4452 - val_loss: 0.3331\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4185 - val_loss: 0.3419\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4095 - val_loss: 0.3471\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3990 - val_loss: 0.3381\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3963 - val_loss: 0.3404\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3633 - val_loss: 0.3409\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4038 - val_loss: 0.3777\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3858 - val_loss: 0.3534\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3756 - val_loss: 0.3330\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3893 - val_loss: 0.3311\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3598 - val_loss: 0.3226\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3622 - val_loss: 0.3204\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3725 - val_loss: 0.3196\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3575 - val_loss: 0.3141\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3559 - val_loss: 0.3154\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3606 - val_loss: 0.3156\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3564 - val_loss: 0.3118\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3531 - val_loss: 0.3113\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3444 - val_loss: 0.3092\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3330 - val_loss: 0.3040\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3249 - val_loss: 0.2976\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3443 - val_loss: 0.3240\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3402 - val_loss: 0.3216\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3258 - val_loss: 0.2972\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3319 - val_loss: 0.3220\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3196 - val_loss: 0.3177\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3300 - val_loss: 0.3060\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3131 - val_loss: 0.3202\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3095 - val_loss: 0.3065\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3300 - val_loss: 0.3167\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3170 - val_loss: 0.3150\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3082 - val_loss: 0.2939\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3213 - val_loss: 0.3112\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3133 - val_loss: 0.3752\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3321 - val_loss: 0.2959\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2965 - val_loss: 0.2988\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3162 - val_loss: 0.3123\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3139 - val_loss: 0.2981\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3109 - val_loss: 0.3053\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3214 - val_loss: 0.3056\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3206 - val_loss: 0.2990\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3391 - val_loss: 0.3149\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3050 - val_loss: 0.3184\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3131 - val_loss: 0.3326\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3085 - val_loss: 0.3127\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3077 - val_loss: 0.3019\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3127 - val_loss: 0.3085\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3129 - val_loss: 0.3290\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2924 - val_loss: 0.3370\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2980 - val_loss: 0.3246\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3016 - val_loss: 0.3113\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3059 - val_loss: 0.3025\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2985 - val_loss: 0.3055\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3053 - val_loss: 0.2989\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3111 - val_loss: 0.3171\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3182 - val_loss: 0.3001\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2920 - val_loss: 0.3044\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2960 - val_loss: 0.3079\n",
      "Epoch 00061: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 4.5min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.3357 - val_loss: 0.3429\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7035 - val_loss: 0.3523\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5950 - val_loss: 0.3691\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5077 - val_loss: 0.3414\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4650 - val_loss: 0.3450\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4491 - val_loss: 0.3877\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4206 - val_loss: 0.3328\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4221 - val_loss: 0.3235\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3915 - val_loss: 0.3220\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3996 - val_loss: 0.3229\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3873 - val_loss: 0.3413\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3863 - val_loss: 0.3224\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3824 - val_loss: 0.3334\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3894 - val_loss: 0.3112\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3837 - val_loss: 0.3159\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3908 - val_loss: 0.3106\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3774 - val_loss: 0.3049\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3785 - val_loss: 0.3136\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.3030\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3451 - val_loss: 0.2986\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3480 - val_loss: 0.3065\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3445 - val_loss: 0.3243\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3469 - val_loss: 0.2934\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3517 - val_loss: 0.3096\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3394 - val_loss: 0.3089\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3484 - val_loss: 0.3119\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3407 - val_loss: 0.2975\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3224 - val_loss: 0.3037\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3420 - val_loss: 0.2906\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3312 - val_loss: 0.3098\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3471 - val_loss: 0.3071\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3095 - val_loss: 0.2990\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3256 - val_loss: 0.3138\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3524 - val_loss: 0.3005\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3175 - val_loss: 0.2938\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3205 - val_loss: 0.2912\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3110 - val_loss: 0.2852\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3344 - val_loss: 0.2970\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3059 - val_loss: 0.3008\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3105 - val_loss: 0.2977\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3132 - val_loss: 0.2871\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3040 - val_loss: 0.3007\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3008 - val_loss: 0.2884\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2983 - val_loss: 0.2850\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2945 - val_loss: 0.2963\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2993 - val_loss: 0.2851\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2900 - val_loss: 0.2942\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3001 - val_loss: 0.2885\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2947 - val_loss: 0.3000\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2858 - val_loss: 0.3040\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2880 - val_loss: 0.2846\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2817 - val_loss: 0.3059\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2887 - val_loss: 0.2848\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2855 - val_loss: 0.2901\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2836 - val_loss: 0.2983\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2919 - val_loss: 0.3114\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3092 - val_loss: 0.3024\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2912 - val_loss: 0.2813\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2851 - val_loss: 0.2905\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2954 - val_loss: 0.2775\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2862 - val_loss: 0.2917\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2909 - val_loss: 0.2825\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2787 - val_loss: 0.2869\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2643 - val_loss: 0.2907\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2860 - val_loss: 0.3038\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2807 - val_loss: 0.2821\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2818 - val_loss: 0.2987\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2752 - val_loss: 0.3132\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2777 - val_loss: 0.2981\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2619 - val_loss: 0.3042\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2807 - val_loss: 0.2975\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2728 - val_loss: 0.3209\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2932 - val_loss: 0.2971\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2869 - val_loss: 0.3029\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2869 - val_loss: 0.2930\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2676 - val_loss: 0.2950\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2752 - val_loss: 0.2824\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2790 - val_loss: 0.2989\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2740 - val_loss: 0.3025\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2811 - val_loss: 0.2995\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2652 - val_loss: 0.2807\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2825 - val_loss: 0.2864\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2761 - val_loss: 0.2888\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2806 - val_loss: 0.2979\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2774 - val_loss: 0.2878\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2691 - val_loss: 0.2904\n",
      "Epoch 00085: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 6.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.1308 - val_loss: 0.3376\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7254 - val_loss: 0.4013\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5547 - val_loss: 0.3843\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5195 - val_loss: 0.3612\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4290 - val_loss: 0.3329\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4068 - val_loss: 0.3391\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4108 - val_loss: 0.3387\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3912 - val_loss: 0.3274\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3814 - val_loss: 0.3283\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4068 - val_loss: 0.3145\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3691 - val_loss: 0.3399\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3895 - val_loss: 0.3696\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3847 - val_loss: 0.3137\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3793 - val_loss: 0.3149\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3683 - val_loss: 0.3394\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3979 - val_loss: 0.3331\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3783 - val_loss: 0.3460\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3603 - val_loss: 0.3152\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3641 - val_loss: 0.3123\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3597 - val_loss: 0.3027\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3301 - val_loss: 0.3175\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3429 - val_loss: 0.3082\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3304 - val_loss: 0.3129\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3323 - val_loss: 0.3098\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3393 - val_loss: 0.3230\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3251 - val_loss: 0.3027\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3138 - val_loss: 0.2963\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3168 - val_loss: 0.3258\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3138 - val_loss: 0.3020\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3221 - val_loss: 0.3003\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3143 - val_loss: 0.3304\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2912 - val_loss: 0.2988\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3042 - val_loss: 0.3073\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2701 - val_loss: 0.3083\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2759 - val_loss: 0.3038\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2695 - val_loss: 0.3202\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3124 - val_loss: 0.3583\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3059 - val_loss: 0.3123\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3141 - val_loss: 0.3302\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3048 - val_loss: 0.3074\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3263 - val_loss: 0.3005\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2976 - val_loss: 0.3119\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3047 - val_loss: 0.3043\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3029 - val_loss: 0.3019\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3057 - val_loss: 0.2962\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2982 - val_loss: 0.3080\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2988 - val_loss: 0.3064\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2958 - val_loss: 0.3032\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2775 - val_loss: 0.3000\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2801 - val_loss: 0.3038\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2752 - val_loss: 0.3033\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2748 - val_loss: 0.2992\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2832 - val_loss: 0.3093\n",
      "Epoch 00052: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 4.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 6s - loss: 1.0830 - val_loss: 0.3767\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6704 - val_loss: 0.3403\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5475 - val_loss: 0.3464\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4973 - val_loss: 0.3384\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4438 - val_loss: 0.3559\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4071 - val_loss: 0.3371\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3998 - val_loss: 0.3463\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3925 - val_loss: 0.3576\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4086 - val_loss: 0.3374\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3988 - val_loss: 0.3878\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4088 - val_loss: 0.3369\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3939 - val_loss: 0.3582\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3928 - val_loss: 0.4051\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4006 - val_loss: 0.3493\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3798 - val_loss: 0.3373\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3918 - val_loss: 0.3351\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3952 - val_loss: 0.3406\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3801 - val_loss: 0.3343\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3660 - val_loss: 0.3544\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3701 - val_loss: 0.3508\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3846 - val_loss: 0.3419\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3651 - val_loss: 0.3402\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3629 - val_loss: 0.3338\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3611 - val_loss: 0.3450\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3774 - val_loss: 0.3302\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3553 - val_loss: 0.3387\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3671 - val_loss: 0.3263\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3603 - val_loss: 0.3290\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3534 - val_loss: 0.3315\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3426 - val_loss: 0.3153\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3517 - val_loss: 0.3368\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3604 - val_loss: 0.3248\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3396 - val_loss: 0.3152\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3317 - val_loss: 0.3146\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3318 - val_loss: 0.3120\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3199 - val_loss: 0.3211\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3254 - val_loss: 0.3074\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3088 - val_loss: 0.3121\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3238 - val_loss: 0.3001\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3109 - val_loss: 0.2943\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3310 - val_loss: 0.3031\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3009 - val_loss: 0.3158\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2924 - val_loss: 0.3059\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2922 - val_loss: 0.2985\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3075 - val_loss: 0.3036\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3136 - val_loss: 0.3202\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3009 - val_loss: 0.2954\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3005 - val_loss: 0.3140\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2962 - val_loss: 0.3219\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2931 - val_loss: 0.2946\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2858 - val_loss: 0.3029\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2860 - val_loss: 0.3161\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2807 - val_loss: 0.3039\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.2901 - val_loss: 0.2933\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2710 - val_loss: 0.3083\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2779 - val_loss: 0.3237\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2635 - val_loss: 0.3281\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2881 - val_loss: 0.3024\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2662 - val_loss: 0.2995\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2634 - val_loss: 0.3095\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2688 - val_loss: 0.3007\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2385 - val_loss: 0.3101\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2937 - val_loss: 0.3496\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2560 - val_loss: 0.3141\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2471 - val_loss: 0.3004\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2698 - val_loss: 0.3062\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 5.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 0.7940 - val_loss: 0.3546\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5546 - val_loss: 0.3342\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4378 - val_loss: 0.3493\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4283 - val_loss: 0.3361\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4026 - val_loss: 0.3284\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3851 - val_loss: 0.3495\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3903 - val_loss: 0.3504\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3738 - val_loss: 0.3146\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3747 - val_loss: 0.3114\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3776 - val_loss: 0.3464\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3629 - val_loss: 0.3264\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3442 - val_loss: 0.3168\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3270 - val_loss: 0.2926\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3262 - val_loss: 0.3584\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3384 - val_loss: 0.3100\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3152 - val_loss: 0.2921\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3076 - val_loss: 0.3101\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3239 - val_loss: 0.3006ss: 0.32\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3092 - val_loss: 0.2866\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2797 - val_loss: 0.3059\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2860 - val_loss: 0.3148\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2778 - val_loss: 0.3167\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2763 - val_loss: 0.2832\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2714 - val_loss: 0.2858\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2612 - val_loss: 0.2971\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2672 - val_loss: 0.3030\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2532 - val_loss: 0.3157\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2449 - val_loss: 0.3091\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2373 - val_loss: 0.2987\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2360 - val_loss: 0.2977\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2399 - val_loss: 0.3068\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2160 - val_loss: 0.2974\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2351 - val_loss: 0.3148\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2302 - val_loss: 0.3213\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2160 - val_loss: 0.3027\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2082 - val_loss: 0.3136\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2021 - val_loss: 0.2971\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1876 - val_loss: 0.3244\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1941 - val_loss: 0.3182\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2084 - val_loss: 0.3142\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1932 - val_loss: 0.3256\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1839 - val_loss: 0.3071\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2051 - val_loss: 0.3050\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1825 - val_loss: 0.3223\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2036 - val_loss: 0.3277\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1845 - val_loss: 0.3379\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2020 - val_loss: 0.3042\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1936 - val_loss: 0.3107\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1982 - val_loss: 0.3036\n",
      "Epoch 00048: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 3.7min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.2814 - val_loss: 0.3369\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7168 - val_loss: 0.3375\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5839 - val_loss: 0.3585\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5313 - val_loss: 0.3429\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4448 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4635 - val_loss: 0.3508\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4183 - val_loss: 0.3827\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4299 - val_loss: 0.3633\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3870 - val_loss: 0.3427\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3991 - val_loss: 0.3333\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4140 - val_loss: 0.3569\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3845 - val_loss: 0.3251\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4075 - val_loss: 0.3299\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3788 - val_loss: 0.3603\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3755 - val_loss: 0.3225\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3716 - val_loss: 0.3109\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3401 - val_loss: 0.3052\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3642 - val_loss: 0.3185\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3554 - val_loss: 0.3143\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3422 - val_loss: 0.3371\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3376 - val_loss: 0.3035\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3402 - val_loss: 0.3011\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3278 - val_loss: 0.3131\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3308 - val_loss: 0.3242\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3122 - val_loss: 0.3233\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3272 - val_loss: 0.3059\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3691 - val_loss: 0.3384\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3534 - val_loss: 0.3208\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3474 - val_loss: 0.3067\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3403 - val_loss: 0.2978\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3425 - val_loss: 0.3162\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3279 - val_loss: 0.3032\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3360 - val_loss: 0.3466\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3162 - val_loss: 0.3145\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3331 - val_loss: 0.3038\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2982 - val_loss: 0.3040\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2911 - val_loss: 0.2930\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2769 - val_loss: 0.2946\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2809 - val_loss: 0.3207\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2954 - val_loss: 0.3031\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2744 - val_loss: 0.3210\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2706 - val_loss: 0.3529\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2675 - val_loss: 0.3173\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2613 - val_loss: 0.3120\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2742 - val_loss: 0.2984\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2651 - val_loss: 0.3270\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2623 - val_loss: 0.2977\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2793 - val_loss: 0.3208\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2527 - val_loss: 0.3087\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2355 - val_loss: 0.3206\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2523 - val_loss: 0.3235\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2568 - val_loss: 0.3022\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2423 - val_loss: 0.3052\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2693 - val_loss: 0.3079\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2375 - val_loss: 0.3060\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2434 - val_loss: 0.3127\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2547 - val_loss: 0.3070\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2441 - val_loss: 0.3064\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2563 - val_loss: 0.3119\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2458 - val_loss: 0.3393\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2435 - val_loss: 0.3038\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2510 - val_loss: 0.3057\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2177 - val_loss: 0.3029\n",
      "Epoch 00062: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 4.7min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.4240 - val_loss: 0.3385\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7332 - val_loss: 0.3511\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6110 - val_loss: 0.3385\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5081 - val_loss: 0.3394\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5025 - val_loss: 0.3408\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4584 - val_loss: 0.3502\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4196 - val_loss: 0.3383\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4231 - val_loss: 0.3722\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4177 - val_loss: 0.3405\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4229 - val_loss: 0.3368\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4140 - val_loss: 0.3455\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3977 - val_loss: 0.3428\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4076 - val_loss: 0.3427\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4157 - val_loss: 0.3363\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3948 - val_loss: 0.3437\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3911 - val_loss: 0.3356\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3988 - val_loss: 0.3329\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4022 - val_loss: 0.3670\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4332 - val_loss: 0.3385\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3817 - val_loss: 0.3328\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3716 - val_loss: 0.3419\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3843 - val_loss: 0.3296\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3825 - val_loss: 0.3488\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3880 - val_loss: 0.3574\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3807 - val_loss: 0.3437\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3596 - val_loss: 0.3399\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3755 - val_loss: 0.3183ss: 0.36 - ETA: 1s \n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3593 - val_loss: 0.3177\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3614 - val_loss: 0.3155\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3738 - val_loss: 0.3264\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3521 - val_loss: 0.3117\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3482 - val_loss: 0.3299\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3429 - val_loss: 0.3475\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3544 - val_loss: 0.3124\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3341 - val_loss: 0.3392\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3397 - val_loss: 0.3056\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3635 - val_loss: 0.3134\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3516 - val_loss: 0.3082\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3494 - val_loss: 0.3425\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3408 - val_loss: 0.3011\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3472 - val_loss: 0.3328\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3378 - val_loss: 0.3102\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3145 - val_loss: 0.3063\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3386 - val_loss: 0.3593\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3413 - val_loss: 0.3250\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3315 - val_loss: 0.3165\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3282 - val_loss: 0.3125\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3376 - val_loss: 0.3133\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3212 - val_loss: 0.3102\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3393 - val_loss: 0.3091\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3292 - val_loss: 0.3032\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3362 - val_loss: 0.3189\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3084 - val_loss: 0.2949\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3229 - val_loss: 0.3112\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3182 - val_loss: 0.2959\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3207 - val_loss: 0.3036\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3073 - val_loss: 0.3110\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3325 - val_loss: 0.2977\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3314 - val_loss: 0.3108\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3132 - val_loss: 0.3069\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3161 - val_loss: 0.3071\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3216 - val_loss: 0.3001\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3209 - val_loss: 0.2962\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3250 - val_loss: 0.3267\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2925 - val_loss: 0.2942\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3067 - val_loss: 0.3049\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3027 - val_loss: 0.3031\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3031 - val_loss: 0.2904\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3008 - val_loss: 0.3083\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3055 - val_loss: 0.2890\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2877 - val_loss: 0.3049\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3175 - val_loss: 0.3062\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2883 - val_loss: 0.2942\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3001 - val_loss: 0.2969\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3108 - val_loss: 0.3044\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2993 - val_loss: 0.3041\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3009 - val_loss: 0.2927\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2920 - val_loss: 0.2970\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2973 - val_loss: 0.3149\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2963 - val_loss: 0.3158\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2898 - val_loss: 0.2940\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2973 - val_loss: 0.2892\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2898 - val_loss: 0.3140\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2954 - val_loss: 0.2910\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2883 - val_loss: 0.2968\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2949 - val_loss: 0.2991\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2852 - val_loss: 0.2920\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2899 - val_loss: 0.2996\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2840 - val_loss: 0.2940\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3061 - val_loss: 0.2864\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2887 - val_loss: 0.2986\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2803 - val_loss: 0.3058\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2935 - val_loss: 0.2926\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2844 - val_loss: 0.2933\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2885 - val_loss: 0.3123\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2902 - val_loss: 0.2909\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2669 - val_loss: 0.2866\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2838 - val_loss: 0.2857\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2767 - val_loss: 0.3065\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2897 - val_loss: 0.2891\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2812 - val_loss: 0.2891\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2576 - val_loss: 0.2862\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2853 - val_loss: 0.2986\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2617 - val_loss: 0.2846\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2783 - val_loss: 0.2919\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2678 - val_loss: 0.3023\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2782 - val_loss: 0.2894\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2777 - val_loss: 0.2885\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2525 - val_loss: 0.3047\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2743 - val_loss: 0.2827\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2781 - val_loss: 0.2890\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2773 - val_loss: 0.3535\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2791 - val_loss: 0.2812\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2742 - val_loss: 0.2920\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2456 - val_loss: 0.2913\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2645 - val_loss: 0.2848\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2695 - val_loss: 0.2871\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2713 - val_loss: 0.2929\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2846 - val_loss: 0.3038\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2588 - val_loss: 0.2922\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2604 - val_loss: 0.2918\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2520 - val_loss: 0.3035\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2664 - val_loss: 0.2949\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2398 - val_loss: 0.2832\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2659 - val_loss: 0.2947\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2625 - val_loss: 0.3063\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2595 - val_loss: 0.3081\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2594 - val_loss: 0.2899\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2645 - val_loss: 0.2998\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2537 - val_loss: 0.2934\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2577 - val_loss: 0.2913\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2670 - val_loss: 0.3160\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2661 - val_loss: 0.3017\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2727 - val_loss: 0.2909\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2560 - val_loss: 0.2893\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2590 - val_loss: 0.2865\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2404 - val_loss: 0.2910\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2494 - val_loss: 0.2964\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2548 - val_loss: 0.2956\n",
      "Epoch 00138: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total=10.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.2836 - val_loss: 0.3549\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6905 - val_loss: 0.3406\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5573 - val_loss: 0.3360\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4983 - val_loss: 0.3510\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4534 - val_loss: 0.3376\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4194 - val_loss: 0.3729\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4380 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4325 - val_loss: 0.3410\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3976 - val_loss: 0.3473\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4121 - val_loss: 0.3514\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4137 - val_loss: 0.3359\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4023 - val_loss: 0.3353\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3904 - val_loss: 0.3393\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4114 - val_loss: 0.3368\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3931 - val_loss: 0.3482\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3821 - val_loss: 0.3331\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3807 - val_loss: 0.3427\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3938 - val_loss: 0.3300\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3800 - val_loss: 0.3298\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3746 - val_loss: 0.3251\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3847 - val_loss: 0.3382\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3782 - val_loss: 0.3641\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3787 - val_loss: 0.3248\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3631 - val_loss: 0.3160\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3565 - val_loss: 0.3298\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3541 - val_loss: 0.3047\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3508 - val_loss: 0.2973\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3479 - val_loss: 0.3160\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3436 - val_loss: 0.3091\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3317 - val_loss: 0.2949\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3179 - val_loss: 0.2945\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3445 - val_loss: 0.3163\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3196 - val_loss: 0.2977\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3188 - val_loss: 0.2967\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3141 - val_loss: 0.3147\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3037 - val_loss: 0.3519\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3166 - val_loss: 0.2927\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2946 - val_loss: 0.2961\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2808 - val_loss: 0.3327\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2950 - val_loss: 0.3067\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3005 - val_loss: 0.2929\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2933 - val_loss: 0.3280\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2983 - val_loss: 0.3048\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2777 - val_loss: 0.3036\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2789 - val_loss: 0.3057\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2850 - val_loss: 0.3133\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2704 - val_loss: 0.3557\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2603 - val_loss: 0.3027\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2644 - val_loss: 0.3064\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2749 - val_loss: 0.3040\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2507 - val_loss: 0.3394\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2628 - val_loss: 0.3133\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2534 - val_loss: 0.3279\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2626 - val_loss: 0.3105\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2583 - val_loss: 0.3228\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2596 - val_loss: 0.3389\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2602 - val_loss: 0.3004\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2715 - val_loss: 0.3087\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2533 - val_loss: 0.3224\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2515 - val_loss: 0.3178\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2530 - val_loss: 0.3132\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2514 - val_loss: 0.3053\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2531 - val_loss: 0.3021\n",
      "Epoch 00062: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 4.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 3s - loss: 4.7314 - val_loss: 0.8795\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4653 - val_loss: 0.6092\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3528 - val_loss: 0.5672\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2476 - val_loss: 0.4843\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2757 - val_loss: 0.6079\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1468 - val_loss: 0.5695\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1904 - val_loss: 0.3644\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1694 - val_loss: 0.6516\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1750 - val_loss: 0.5367\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2631 - val_loss: 0.3190\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2093 - val_loss: 0.3487\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1953 - val_loss: 0.5734\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0636 - val_loss: 0.3587\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0757 - val_loss: 0.4026\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1289 - val_loss: 0.4706\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0516 - val_loss: 0.3665\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0445 - val_loss: 0.3218\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0363 - val_loss: 0.3321\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0055 - val_loss: 0.4580\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0448 - val_loss: 0.3783\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8887 - val_loss: 0.3327\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9293 - val_loss: 0.3251\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8446 - val_loss: 0.6610\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9242 - val_loss: 0.3474\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8505 - val_loss: 0.3036\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8581 - val_loss: 0.4616\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7966 - val_loss: 0.3401\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7906 - val_loss: 0.5622\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8238 - val_loss: 0.3459\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7708 - val_loss: 0.4259\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6924 - val_loss: 0.5511\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7005 - val_loss: 0.3467\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7096 - val_loss: 0.3117\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6580 - val_loss: 0.5311\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6682 - val_loss: 0.3258\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6350 - val_loss: 0.3172\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6581 - val_loss: 0.3691\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6670 - val_loss: 0.3008\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6307 - val_loss: 0.4085\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5952 - val_loss: 0.4512\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5397 - val_loss: 0.4489\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5426 - val_loss: 0.3230\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5633 - val_loss: 0.3759\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5240 - val_loss: 0.3291\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5028 - val_loss: 0.4036\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5126 - val_loss: 0.4261\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4605 - val_loss: 0.3390\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4223 - val_loss: 0.3349\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4359 - val_loss: 0.3123\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4329 - val_loss: 0.4193\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4733 - val_loss: 0.3055\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4027 - val_loss: 0.3848\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4197 - val_loss: 0.3431\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4028 - val_loss: 0.3635\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3664 - val_loss: 0.3001\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3572 - val_loss: 0.3390\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3755 - val_loss: 0.3259\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3390 - val_loss: 0.3393\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3316 - val_loss: 0.3297\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3169 - val_loss: 0.3229\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2943 - val_loss: 0.3132\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2967 - val_loss: 0.3053\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2867 - val_loss: 0.3162\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2882 - val_loss: 0.3315\n",
      "Epoch 00063: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 1.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 8.0756 - val_loss: 1.0583\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7032 - val_loss: 0.3369\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6941 - val_loss: 0.9944\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1565 - val_loss: 1.1960\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2239 - val_loss: 0.9127\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1114 - val_loss: 0.7353\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.0993 - val_loss: 0.4998\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.0287 - val_loss: 0.9195\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.1058 - val_loss: 0.6419\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.9365 - val_loss: 0.7327\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.9582 - val_loss: 0.5818\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.9908 - val_loss: 0.7309\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8204 - val_loss: 0.6243\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6791 - val_loss: 0.8572\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.8263 - val_loss: 0.8531\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6481 - val_loss: 0.5501\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6680 - val_loss: 0.5841\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6184 - val_loss: 0.4103\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.6128 - val_loss: 0.7487\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.5219 - val_loss: 0.6178\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.5034 - val_loss: 0.4900\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.3782 - val_loss: 0.8356\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.3536 - val_loss: 0.4175\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.4002 - val_loss: 0.5443\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.3913 - val_loss: 0.6235\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.3362 - val_loss: 0.5601\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.2689 - val_loss: 0.4673\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.1994 - val_loss: 0.6799\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total=  33.6s\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 11.1385 - val_loss: 1.6964\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1587 - val_loss: 1.0227\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3083 - val_loss: 0.4243\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1471 - val_loss: 0.9022\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1242 - val_loss: 0.4663\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1918 - val_loss: 0.8284\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1221 - val_loss: 0.8365\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0678 - val_loss: 0.4280\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0533 - val_loss: 1.3505\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0323 - val_loss: 0.4239\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9805 - val_loss: 0.8965\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1125 - val_loss: 0.9725\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8791 - val_loss: 0.8454\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9420 - val_loss: 0.8053\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8306 - val_loss: 0.6766\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7602 - val_loss: 0.6262\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6904 - val_loss: 0.7431\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7632 - val_loss: 0.7848\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6283 - val_loss: 0.6916\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5387 - val_loss: 0.5366\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5253 - val_loss: 0.6913\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4235 - val_loss: 0.7659\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5107 - val_loss: 0.5949\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4306 - val_loss: 0.5959\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3729 - val_loss: 0.6134\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2870 - val_loss: 0.4916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2685 - val_loss: 0.6132\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2009 - val_loss: 0.6495\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2551 - val_loss: 0.9132\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total=  43.5s\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 11.3051 - val_loss: 0.8996\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.0192 - val_loss: 1.1659\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.1212 - val_loss: 1.2964\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9973 - val_loss: 2.0147\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9919 - val_loss: 1.1501\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9313 - val_loss: 1.0426\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7366 - val_loss: 0.8975\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7406 - val_loss: 1.2521\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7353 - val_loss: 1.5254\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5017 - val_loss: 1.1996\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4980 - val_loss: 1.0233\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4605 - val_loss: 0.7722\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4000 - val_loss: 1.0009\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2319 - val_loss: 0.8711\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1844 - val_loss: 0.8340\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.1970 - val_loss: 1.0179\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.0374 - val_loss: 1.3253\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.0373 - val_loss: 1.2244\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0441 - val_loss: 0.5228\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0536 - val_loss: 0.7150\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8795 - val_loss: 1.4486\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7640 - val_loss: 0.8393\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7146 - val_loss: 0.8246\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7957 - val_loss: 0.6839\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5868 - val_loss: 0.7558\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7100 - val_loss: 0.8900\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6491 - val_loss: 0.7370\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5945 - val_loss: 0.8486\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4933 - val_loss: 0.8420\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3668 - val_loss: 0.7482\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4490 - val_loss: 0.8093\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4572 - val_loss: 0.6164\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3190 - val_loss: 0.7662\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3010 - val_loss: 0.6742\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2665 - val_loss: 0.5973\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2107 - val_loss: 0.6252\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2010 - val_loss: 0.7917\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1620 - val_loss: 0.4791\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1389 - val_loss: 0.6552\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0224 - val_loss: 0.6257\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0420 - val_loss: 0.5871\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9945 - val_loss: 0.5098\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9258 - val_loss: 0.6262\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9423 - val_loss: 0.4112\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9191 - val_loss: 0.5539\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8545 - val_loss: 0.5026\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8367 - val_loss: 0.5642\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7439 - val_loss: 0.4923\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8192 - val_loss: 0.5902\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7553 - val_loss: 0.6107\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7414 - val_loss: 0.5438\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7117 - val_loss: 0.5913\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6688 - val_loss: 0.4717\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7064 - val_loss: 0.4177\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6367 - val_loss: 0.4110\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6426 - val_loss: 0.4050\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5890 - val_loss: 0.3577\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6066 - val_loss: 0.5257\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5379 - val_loss: 0.4386\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5471 - val_loss: 0.4204\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5110 - val_loss: 0.3303\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4827 - val_loss: 0.4138\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4990 - val_loss: 0.4757\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4650 - val_loss: 0.3388\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4641 - val_loss: 0.4193\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4126 - val_loss: 0.4076\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4065 - val_loss: 0.3609\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4269 - val_loss: 0.3837\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3846 - val_loss: 0.3986\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3665 - val_loss: 0.3313\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3848 - val_loss: 0.3278\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3171 - val_loss: 0.3795\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3332 - val_loss: 0.3556\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3047 - val_loss: 0.3742\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3004 - val_loss: 0.3923\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3246 - val_loss: 0.3887\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2734 - val_loss: 0.3436\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2942 - val_loss: 0.3936\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2866 - val_loss: 0.3719\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2855 - val_loss: 0.3489\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2547 - val_loss: 0.3233\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2490 - val_loss: 0.3380\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2674 - val_loss: 0.3243\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2618 - val_loss: 0.3350\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2317 - val_loss: 0.3195\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2503 - val_loss: 0.3372\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2438 - val_loss: 0.3175\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2182 - val_loss: 0.3251\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2175 - val_loss: 0.3146\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1912 - val_loss: 0.3298\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2197 - val_loss: 0.3182\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2043 - val_loss: 0.3148\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1961 - val_loss: 0.3104\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2120 - val_loss: 0.3152\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1948 - val_loss: 0.3182\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1989 - val_loss: 0.3141\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1933 - val_loss: 0.3100\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1954 - val_loss: 0.3122\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1837 - val_loss: 0.3156\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1998 - val_loss: 0.3105\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1966 - val_loss: 0.3141\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1871 - val_loss: 0.3209\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1817 - val_loss: 0.3119\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1859 - val_loss: 0.3053\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1829 - val_loss: 0.3026\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1822 - val_loss: 0.3031\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1976 - val_loss: 0.3091\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1886 - val_loss: 0.3009\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1885 - val_loss: 0.3071\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1832 - val_loss: 0.3040\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1824 - val_loss: 0.3104\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1838 - val_loss: 0.3032\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1851 - val_loss: 0.3042\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1754 - val_loss: 0.2993\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1769 - val_loss: 0.3041\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1741 - val_loss: 0.3055\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1810 - val_loss: 0.3007\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1778 - val_loss: 0.3041\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1819 - val_loss: 0.2993\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1807 - val_loss: 0.3053\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1902 - val_loss: 0.3130\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1824 - val_loss: 0.3020\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1769 - val_loss: 0.3120\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1866 - val_loss: 0.2972\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1825 - val_loss: 0.3018\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1786 - val_loss: 0.3042\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1703 - val_loss: 0.2980\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1845 - val_loss: 0.3066\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1813 - val_loss: 0.3019\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1741 - val_loss: 0.3066\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1869 - val_loss: 0.3015\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1884 - val_loss: 0.3021\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1833 - val_loss: 0.3114\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1791 - val_loss: 0.3046\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1872 - val_loss: 0.3143\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1771 - val_loss: 0.2987\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1951 - val_loss: 0.3044\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1769 - val_loss: 0.3036\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1794 - val_loss: 0.3021\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1872 - val_loss: 0.3090\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1904 - val_loss: 0.3028\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1711 - val_loss: 0.3013\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1768 - val_loss: 0.3034\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1865 - val_loss: 0.3143\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1736 - val_loss: 0.3162\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1754 - val_loss: 0.3031\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1833 - val_loss: 0.3062\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1895 - val_loss: 0.3044\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1859 - val_loss: 0.3069\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1771 - val_loss: 0.2954\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1706 - val_loss: 0.3053\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1872 - val_loss: 0.3009\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1829 - val_loss: 0.3160\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.1823 - val_loss: 0.2979\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1926 - val_loss: 0.2994\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1852 - val_loss: 0.3015\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1710 - val_loss: 0.3091\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1832 - val_loss: 0.3050\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1919 - val_loss: 0.3044\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1959 - val_loss: 0.3021\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1858 - val_loss: 0.3036\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1787 - val_loss: 0.3017\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1874 - val_loss: 0.3121\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1910 - val_loss: 0.3102\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1791 - val_loss: 0.3018\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1797 - val_loss: 0.3052\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1905 - val_loss: 0.3072\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1903 - val_loss: 0.3011\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1833 - val_loss: 0.3025\n",
      "Epoch 170/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1892 - val_loss: 0.3028\n",
      "Epoch 171/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1836 - val_loss: 0.3009\n",
      "Epoch 172/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1869 - val_loss: 0.3066\n",
      "Epoch 173/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1823 - val_loss: 0.3001\n",
      "Epoch 174/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1793 - val_loss: 0.3024\n",
      "Epoch 175/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1875 - val_loss: 0.3028\n",
      "Epoch 176/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1868 - val_loss: 0.3011\n",
      "Epoch 00175: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 3.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 12.5484 - val_loss: 8.0768\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 8.0700 - val_loss: 7.8724\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.8592 - val_loss: 7.6606\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.6451 - val_loss: 7.4477\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.4318 - val_loss: 7.2370\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.2205 - val_loss: 7.0295\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.0128 - val_loss: 6.8255\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.8086 - val_loss: 6.6247\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.6081 - val_loss: 6.4277\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.4117 - val_loss: 6.2352\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.2198 - val_loss: 6.0465\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.0318 - val_loss: 5.8629\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.8481 - val_loss: 5.6826\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.6683 - val_loss: 5.5066\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.4924 - val_loss: 5.3342\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.3207 - val_loss: 5.1668\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 5.1533 - val_loss: 5.0025\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.9894 - val_loss: 4.8431\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.8299 - val_loss: 4.6861\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.6739 - val_loss: 4.5337\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.5217 - val_loss: 4.3854\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.3734 - val_loss: 4.2405\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.2292 - val_loss: 4.0999\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.0886 - val_loss: 3.9625\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.9516 - val_loss: 3.8287\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.8182 - val_loss: 3.6985\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.6885 - val_loss: 3.5716ss:\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.5618 - val_loss: 3.4492\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.4390 - val_loss: 3.3289\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.3190 - val_loss: 3.2124\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.2026 - val_loss: 3.0993\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.0893 - val_loss: 2.9887\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.9792 - val_loss: 2.8817\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.8723 - val_loss: 2.7773\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7684 - val_loss: 2.6771\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6680 - val_loss: 2.5792\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5701 - val_loss: 2.4844\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4752 - val_loss: 2.3924\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3833 - val_loss: 2.3032\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2940 - val_loss: 2.2170\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2078 - val_loss: 2.1327\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1239 - val_loss: 2.0519\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0428 - val_loss: 1.9735\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9645 - val_loss: 1.8976\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8887 - val_loss: 1.8247\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8155 - val_loss: 1.7540\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7448 - val_loss: 1.6857\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6765 - val_loss: 1.6195\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6105 - val_loss: 1.5561\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5469 - val_loss: 1.4949\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4856 - val_loss: 1.4358\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4263 - val_loss: 1.3791\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3695 - val_loss: 1.3235\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3144 - val_loss: 1.2716\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2617 - val_loss: 1.2210\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2111 - val_loss: 1.1723\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1625 - val_loss: 1.1259\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1158 - val_loss: 1.0812\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0709 - val_loss: 1.0383\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0278 - val_loss: 0.9976\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9867 - val_loss: 0.9579\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9472 - val_loss: 0.9205\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9095 - val_loss: 0.8847\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8736 - val_loss: 0.8506\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8392 - val_loss: 0.8180\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8063 - val_loss: 0.7871\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7752 - val_loss: 0.7575\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7455 - val_loss: 0.7294\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7173 - val_loss: 0.7030\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6904 - val_loss: 0.6776\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6649 - val_loss: 0.6538\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6407 - val_loss: 0.6310\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6177 - val_loss: 0.6095\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5959 - val_loss: 0.5892\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5755 - val_loss: 0.5700\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5561 - val_loss: 0.5521\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5378 - val_loss: 0.5354\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5206 - val_loss: 0.5194\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5044 - val_loss: 0.5043\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4892 - val_loss: 0.4904\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4750 - val_loss: 0.4773\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4616 - val_loss: 0.4652\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4491 - val_loss: 0.4538\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4376 - val_loss: 0.4432\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4266 - val_loss: 0.4336\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4165 - val_loss: 0.4242\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4071 - val_loss: 0.4157\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3984 - val_loss: 0.4081\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3903 - val_loss: 0.4009\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3828 - val_loss: 0.3943\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3759 - val_loss: 0.3882\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3695 - val_loss: 0.3826\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3637 - val_loss: 0.3774\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3583 - val_loss: 0.3728\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3534 - val_loss: 0.3686\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3490 - val_loss: 0.3648\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3448 - val_loss: 0.3614\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3411 - val_loss: 0.3582\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3377 - val_loss: 0.3554\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3346 - val_loss: 0.3530\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3320 - val_loss: 0.3507\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3295 - val_loss: 0.3489\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3274 - val_loss: 0.3471\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3253 - val_loss: 0.3456\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3236 - val_loss: 0.3441\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3219 - val_loss: 0.3430\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3206 - val_loss: 0.3419\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3193 - val_loss: 0.3411\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3182 - val_loss: 0.3402\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.3172 - val_loss: 0.3396\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3164 - val_loss: 0.3391\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3156 - val_loss: 0.3386\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3150 - val_loss: 0.3382\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3144 - val_loss: 0.3378\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3140 - val_loss: 0.3375\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3136 - val_loss: 0.3374\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3132 - val_loss: 0.3372\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3129 - val_loss: 0.3371\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3126 - val_loss: 0.3370\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3124 - val_loss: 0.3369\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3122 - val_loss: 0.3368\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3121 - val_loss: 0.3368\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3119 - val_loss: 0.3368\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3118 - val_loss: 0.3368\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3117 - val_loss: 0.3368\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3116 - val_loss: 0.3368\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3116 - val_loss: 0.3368\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3115 - val_loss: 0.3368\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3115 - val_loss: 0.3368\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3115 - val_loss: 0.3369\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3115 - val_loss: 0.3369\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3114 - val_loss: 0.3369\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3114 - val_loss: 0.3370\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3114 - val_loss: 0.3370\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3114 - val_loss: 0.3370\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3114 - val_loss: 0.3370\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3114 - val_loss: 0.3370\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3370\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3113 - val_loss: 0.3371\n",
      "Epoch 00146: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=1, total= 3.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 3s - loss: 4.4007 - val_loss: 1.2879\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3483 - val_loss: 1.5748\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.1221 - val_loss: 2.2307\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.9381 - val_loss: 2.0055\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.6086 - val_loss: 1.7735\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.4593 - val_loss: 1.5449\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2791 - val_loss: 1.7630\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1292 - val_loss: 1.7396\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0528 - val_loss: 1.2932\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7928 - val_loss: 0.9406\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6988 - val_loss: 0.7639\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6693 - val_loss: 0.4245\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5306 - val_loss: 0.3427\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4956 - val_loss: 0.3387\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4904 - val_loss: 0.3438\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5120 - val_loss: 0.3428\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4822 - val_loss: 0.3385\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5061 - val_loss: 0.3380\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4973 - val_loss: 0.3398\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4762 - val_loss: 0.3408\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4664 - val_loss: 0.3392\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4931 - val_loss: 0.3378\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4572 - val_loss: 0.3405\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4767 - val_loss: 0.3409\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4758 - val_loss: 0.3377\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4478 - val_loss: 0.3374\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4590 - val_loss: 0.3379\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4857 - val_loss: 0.3396\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4477 - val_loss: 0.3390\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4557 - val_loss: 0.3388\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4461 - val_loss: 0.3380\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4464 - val_loss: 0.3393\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4534 - val_loss: 0.3375\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4652 - val_loss: 0.3383\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4349 - val_loss: 0.3390\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4367 - val_loss: 0.3384\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4440 - val_loss: 0.3412\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4701 - val_loss: 0.3377\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4330 - val_loss: 0.3386\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4346 - val_loss: 0.3383\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4278 - val_loss: 0.3379\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4601 - val_loss: 0.3369\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4272 - val_loss: 0.3381\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4258 - val_loss: 0.3375\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4298 - val_loss: 0.3400\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4528 - val_loss: 0.3403\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4106 - val_loss: 0.3369\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4182 - val_loss: 0.3376\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4161 - val_loss: 0.3384\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4146 - val_loss: 0.3386\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4312 - val_loss: 0.3391\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4436 - val_loss: 0.3376\n",
      "Epoch 00051: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 7.2270 - val_loss: 1.4982\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.0376 - val_loss: 1.3662\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5003 - val_loss: 0.5999\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7793 - val_loss: 2.0636\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3501 - val_loss: 1.6319\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9372 - val_loss: 1.1631\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5716 - val_loss: 1.0863\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2714 - val_loss: 0.8277\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9721 - val_loss: 0.7100\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7632 - val_loss: 0.4002\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6516 - val_loss: 0.4220\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5748 - val_loss: 0.3293s\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5685 - val_loss: 0.3532\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5552 - val_loss: 0.3460\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5050 - val_loss: 0.3317\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4773 - val_loss: 0.3460\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5127 - val_loss: 0.3476\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5199 - val_loss: 0.3501\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5390 - val_loss: 0.3419\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4908 - val_loss: 0.3455\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5326 - val_loss: 0.3428\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5104 - val_loss: 0.3381\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5023 - val_loss: 0.3371\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4956 - val_loss: 0.3424\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4787 - val_loss: 0.3299\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4932 - val_loss: 0.3216\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4747 - val_loss: 0.3392\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5175 - val_loss: 0.3429ss: 0.4\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5039 - val_loss: 0.3393\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4847 - val_loss: 0.3412ss: 0.484\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5123 - val_loss: 0.3406\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4932 - val_loss: 0.3351\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4886 - val_loss: 0.3433\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4782 - val_loss: 0.3434\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4929 - val_loss: 0.3435\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4715 - val_loss: 0.3409\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4798 - val_loss: 0.3455\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4749 - val_loss: 0.3430\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4837 - val_loss: 0.3394\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4800 - val_loss: 0.3404\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4901 - val_loss: 0.3394\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4758 - val_loss: 0.3395\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4668 - val_loss: 0.3392\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4900 - val_loss: 0.3397\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4544 - val_loss: 0.3415\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4661 - val_loss: 0.3398\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4679 - val_loss: 0.3393\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4549 - val_loss: 0.3388\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4498 - val_loss: 0.3393\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4554 - val_loss: 0.3409\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4550 - val_loss: 0.3373\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4647 - val_loss: 0.3391\n",
      "Epoch 00051: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 4.3990 - val_loss: 1.3549\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6602 - val_loss: 1.1942\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1728 - val_loss: 1.7961\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9735 - val_loss: 1.3971\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7082 - val_loss: 1.7970\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5678 - val_loss: 1.1219\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7199 - val_loss: 1.0681\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2705 - val_loss: 1.3053\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1504 - val_loss: 1.7010\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9412 - val_loss: 1.2094\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8416 - val_loss: 1.0544\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7658 - val_loss: 0.7781\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7249 - val_loss: 0.5145\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5816 - val_loss: 0.3555\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4900 - val_loss: 0.3391\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4852 - val_loss: 0.3382\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4965 - val_loss: 0.3388\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5041 - val_loss: 0.3392\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5000 - val_loss: 0.3400\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5094 - val_loss: 0.3415\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4665 - val_loss: 0.3415\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5009 - val_loss: 0.3402\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4792 - val_loss: 0.3397\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4967 - val_loss: 0.3382\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4850 - val_loss: 0.3385\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4667 - val_loss: 0.3394\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4694 - val_loss: 0.3418\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4704 - val_loss: 0.3388\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4594 - val_loss: 0.3383\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4661 - val_loss: 0.3388\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4685 - val_loss: 0.3380\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4752 - val_loss: 0.3411\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4726 - val_loss: 0.3395\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4847 - val_loss: 0.3395\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4719 - val_loss: 0.3389ss: 0.4\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4486 - val_loss: 0.3398\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4481 - val_loss: 0.3405\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4590 - val_loss: 0.3388\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4431 - val_loss: 0.3376\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4702 - val_loss: 0.3376\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4433 - val_loss: 0.3392\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4479 - val_loss: 0.3380\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4267 - val_loss: 0.3374\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4360 - val_loss: 0.3377\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4538 - val_loss: 0.3377\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4231 - val_loss: 0.3377\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4466 - val_loss: 0.3383\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4184 - val_loss: 0.3373\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4379 - val_loss: 0.3388\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4472 - val_loss: 0.3383\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4203 - val_loss: 0.3390\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4222 - val_loss: 0.3377\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4431 - val_loss: 0.3385\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4407 - val_loss: 0.3377\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4371 - val_loss: 0.3386\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4309 - val_loss: 0.3386\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4311 - val_loss: 0.3387\n",
      "Epoch 00056: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 1.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 4.6842 - val_loss: 0.7323\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 3.0590 - val_loss: 1.0883\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4333 - val_loss: 1.4746\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1255 - val_loss: 1.4903\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7422 - val_loss: 1.6923\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3880 - val_loss: 2.0952\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3148 - val_loss: 1.7926\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1694 - val_loss: 1.3389\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1234 - val_loss: 1.2104\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8877 - val_loss: 1.4605\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8030 - val_loss: 1.1741\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6727 - val_loss: 0.6359\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6531 - val_loss: 0.5504\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5620 - val_loss: 0.3690\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5753 - val_loss: 0.3988\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5780 - val_loss: 0.3553\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5544 - val_loss: 0.3509\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5185 - val_loss: 0.3430\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5204 - val_loss: 0.3385\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5207 - val_loss: 0.3420\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4965 - val_loss: 0.3416\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4902 - val_loss: 0.3413\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4878 - val_loss: 0.3451\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5139 - val_loss: 0.3391\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4700 - val_loss: 0.3413\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4934 - val_loss: 0.3418\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4541 - val_loss: 0.3206\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4642 - val_loss: 0.3320\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4578 - val_loss: 0.3410\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4764 - val_loss: 0.3449\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4788 - val_loss: 0.3395\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4829 - val_loss: 0.3377\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4524 - val_loss: 0.3383\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4855 - val_loss: 0.3370\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4644 - val_loss: 0.3388\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4649 - val_loss: 0.3379\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4647 - val_loss: 0.3379\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4536 - val_loss: 0.3407\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4439 - val_loss: 0.3395\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4514 - val_loss: 0.3400\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4517 - val_loss: 0.3382\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4367 - val_loss: 0.3372\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4637 - val_loss: 0.3387\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4519 - val_loss: 0.3383\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4616 - val_loss: 0.3380\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4473 - val_loss: 0.3400\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4675 - val_loss: 0.3379\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4533 - val_loss: 0.3397\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4409 - val_loss: 0.3380\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4463 - val_loss: 0.3388\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4663 - val_loss: 0.3392\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4485 - val_loss: 0.3385\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4439 - val_loss: 0.3396\n",
      "Epoch 00052: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 7.8858 - val_loss: 3.2286\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.5874 - val_loss: 2.0843\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3208 - val_loss: 2.1449\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0200 - val_loss: 1.7494\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8341 - val_loss: 1.4990\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.8848 - val_loss: 2.1406\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0591 - val_loss: 2.1407\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6408 - val_loss: 2.0844\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3660 - val_loss: 1.7734\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2155 - val_loss: 1.3090\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0225 - val_loss: 1.3171\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7703 - val_loss: 1.2823\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6801 - val_loss: 1.0877\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5829 - val_loss: 0.8932\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5651 - val_loss: 0.5864\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5226 - val_loss: 0.4720\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5078 - val_loss: 0.5908\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4918 - val_loss: 0.5046\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4948 - val_loss: 0.5369\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4653 - val_loss: 0.4292\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4583 - val_loss: 0.4621\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4277 - val_loss: 0.4160\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4473 - val_loss: 0.4850\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4517 - val_loss: 0.4787\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4636 - val_loss: 0.5899\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4187 - val_loss: 0.5606\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4218 - val_loss: 0.5080\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4482 - val_loss: 0.5234\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4246 - val_loss: 0.4903\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4140 - val_loss: 0.5225\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4060 - val_loss: 0.5319\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4095 - val_loss: 0.4895\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3912 - val_loss: 0.5499\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4323 - val_loss: 0.4223\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4078 - val_loss: 0.4948\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4070 - val_loss: 0.4520\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4028 - val_loss: 0.5667\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4048 - val_loss: 0.4787\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3868 - val_loss: 0.4910\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3900 - val_loss: 0.5546\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3918 - val_loss: 0.4858\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3807 - val_loss: 0.5206\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3756 - val_loss: 0.5009\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4060 - val_loss: 0.4550\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3774 - val_loss: 0.5098\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3896 - val_loss: 0.6410\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3813 - val_loss: 0.5634\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3919 - val_loss: 0.5634\n",
      "Epoch 00047: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 3s - loss: 5.1573 - val_loss: 3.3017\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.0514 - val_loss: 3.4467\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.3193 - val_loss: 2.5687\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.5174 - val_loss: 2.0015\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3846 - val_loss: 2.3385\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1809 - val_loss: 0.9334\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6882 - val_loss: 0.3465\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5927 - val_loss: 0.3427\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5661 - val_loss: 0.3439ss: 0\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5631 - val_loss: 0.3453\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4883 - val_loss: 0.3441\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5085 - val_loss: 0.3398\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5445 - val_loss: 0.3396\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4962 - val_loss: 0.3431\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4913 - val_loss: 0.3389\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5005 - val_loss: 0.3384\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4904 - val_loss: 0.3420\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5216 - val_loss: 0.3389\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4812 - val_loss: 0.3395\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4811 - val_loss: 0.3390\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4514 - val_loss: 0.3397\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4685 - val_loss: 0.3382\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4423 - val_loss: 0.3436\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4663 - val_loss: 0.3377\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4567 - val_loss: 0.3372\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4472 - val_loss: 0.3395\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4584 - val_loss: 0.3374\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4599 - val_loss: 0.3372\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4540 - val_loss: 0.3372\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4359 - val_loss: 0.3397\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4582 - val_loss: 0.3370\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4507 - val_loss: 0.3394\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4343 - val_loss: 0.3396\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4389 - val_loss: 0.3370\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4133 - val_loss: 0.3396\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4375 - val_loss: 0.3370\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4335 - val_loss: 0.3401\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4287 - val_loss: 0.3378\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4320 - val_loss: 0.3372\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4326 - val_loss: 0.3440\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4260 - val_loss: 0.3386\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4395 - val_loss: 0.3385ss: 0.4 - ETA: 0s - loss: 0.\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4334 - val_loss: 0.3373\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4125 - val_loss: 0.3370\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4368 - val_loss: 0.3370\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4035 - val_loss: 0.3390\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4278 - val_loss: 0.3393\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4182 - val_loss: 0.3431\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4164 - val_loss: 0.3373\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4217 - val_loss: 0.3384\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4110 - val_loss: 0.3396\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 1.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 5.9824 - val_loss: 2.1119\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7521 - val_loss: 1.7079\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.1321 - val_loss: 1.9325ss:\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0010 - val_loss: 1.8876\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5456 - val_loss: 1.7031\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2521 - val_loss: 1.5645\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9669 - val_loss: 0.4552\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6829 - val_loss: 0.3597\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6409 - val_loss: 0.3290\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6311 - val_loss: 0.3752\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6089 - val_loss: 0.3550\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5827 - val_loss: 0.3510ss: 0.586\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5825 - val_loss: 0.3427\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5666 - val_loss: 0.3459\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5186 - val_loss: 0.3391\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5869 - val_loss: 0.3401\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5583 - val_loss: 0.3422\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5467 - val_loss: 0.3531\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5018 - val_loss: 0.3433\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5108 - val_loss: 0.3417\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5470 - val_loss: 0.3439\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5055 - val_loss: 0.3419\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5225 - val_loss: 0.3452\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4947 - val_loss: 0.3402\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5089 - val_loss: 0.3407\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4843 - val_loss: 0.3465\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4822 - val_loss: 0.3393\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5071 - val_loss: 0.3430\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5011 - val_loss: 0.3396\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5034 - val_loss: 0.3377\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4748 - val_loss: 0.3401\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4626 - val_loss: 0.3392\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4891 - val_loss: 0.3404\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4652 - val_loss: 0.3453\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4773 - val_loss: 0.3455\n",
      "Epoch 00034: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total=  46.9s\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 5.7723 - val_loss: 0.7542\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.8862 - val_loss: 1.6993\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.3882 - val_loss: 2.0722\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0660 - val_loss: 1.1325\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5378 - val_loss: 0.7828\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9171 - val_loss: 0.3477\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6843 - val_loss: 0.3607\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6721 - val_loss: 0.3521\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6951 - val_loss: 0.3534\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6937 - val_loss: 0.3492\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6647 - val_loss: 0.3457\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7068 - val_loss: 0.3558\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6152 - val_loss: 0.3481\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5671 - val_loss: 0.3467\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6015 - val_loss: 0.3490\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6130 - val_loss: 0.3425\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5624 - val_loss: 0.3418\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5797 - val_loss: 0.3466\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5741 - val_loss: 0.3468\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5822 - val_loss: 0.3456\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5699 - val_loss: 0.3396\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5550 - val_loss: 0.3436\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5485 - val_loss: 0.3473\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5569 - val_loss: 0.3395\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5772 - val_loss: 0.3447\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5421 - val_loss: 0.3451\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5302 - val_loss: 0.3426\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5328 - val_loss: 0.3598\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5544 - val_loss: 0.3391\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5312 - val_loss: 0.3423\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5242 - val_loss: 0.3390\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5333 - val_loss: 0.3481\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5089 - val_loss: 0.3438\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5273 - val_loss: 0.3457\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5444 - val_loss: 0.3481\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4833 - val_loss: 0.3427\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4930 - val_loss: 0.3400\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4750 - val_loss: 0.3391\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5002 - val_loss: 0.3442\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4701 - val_loss: 0.3445\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4830 - val_loss: 0.3435\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5113 - val_loss: 0.3420\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4757 - val_loss: 0.3451\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4837 - val_loss: 0.3436\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4738 - val_loss: 0.3377\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5116 - val_loss: 0.3406\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4830 - val_loss: 0.3387\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4675 - val_loss: 0.3430\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4801 - val_loss: 0.3371\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4518 - val_loss: 0.3399\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4630 - val_loss: 0.3398\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4738 - val_loss: 0.3372\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4682 - val_loss: 0.3401\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4754 - val_loss: 0.3435\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4562 - val_loss: 0.3400\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4368 - val_loss: 0.3371\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4631 - val_loss: 0.3374\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4341 - val_loss: 0.3395\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4534 - val_loss: 0.3385\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4486 - val_loss: 0.3396\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4192 - val_loss: 0.3373\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4638 - val_loss: 0.3464\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4363 - val_loss: 0.3380\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4582 - val_loss: 0.3391\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4473 - val_loss: 0.3387\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4334 - val_loss: 0.3380\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4407 - val_loss: 0.3388\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4442 - val_loss: 0.3372\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4344 - val_loss: 0.3388\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4129 - val_loss: 0.3388\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4179 - val_loss: 0.3380\n",
      "Epoch 00070: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 1.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 6.1160 - val_loss: 2.9473\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.6222 - val_loss: 2.5299\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4834 - val_loss: 3.0812\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9028 - val_loss: 1.9270\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9679 - val_loss: 0.6102\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8339 - val_loss: 0.3443\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7019 - val_loss: 0.3503\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6599 - val_loss: 0.3405\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6188 - val_loss: 0.3500\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5877 - val_loss: 0.3153\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6127 - val_loss: 0.3439\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5868 - val_loss: 0.3450\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5668 - val_loss: 0.3451\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5807 - val_loss: 0.3393\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5831 - val_loss: 0.3457\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5654 - val_loss: 0.3379\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5363 - val_loss: 0.3394\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5478 - val_loss: 0.3473\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5165 - val_loss: 0.3395\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5177 - val_loss: 0.3440\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5121 - val_loss: 0.3435\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5136 - val_loss: 0.3455\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5248 - val_loss: 0.3402\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5223 - val_loss: 0.3453\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5029 - val_loss: 0.3401\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4885 - val_loss: 0.3476\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5235 - val_loss: 0.3400\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4968 - val_loss: 0.3426\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4830 - val_loss: 0.3421\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5065 - val_loss: 0.3404\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4790 - val_loss: 0.3406\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4861 - val_loss: 0.3385\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4900 - val_loss: 0.3413\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4547 - val_loss: 0.3394\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4795 - val_loss: 0.3398\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4797 - val_loss: 0.3401\n",
      "Epoch 00035: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total=  57.2s\n",
      "[CV] activation_function=relu, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 6.0645 - val_loss: 3.7498\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.8929 - val_loss: 2.1562\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.4242 - val_loss: 1.7021\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.0463 - val_loss: 2.6143\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.6746 - val_loss: 2.1503\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4070 - val_loss: 1.8599\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2413 - val_loss: 0.8693\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8124 - val_loss: 0.3411\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6084 - val_loss: 0.3514\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6268 - val_loss: 0.3523\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5882 - val_loss: 0.3447\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5638 - val_loss: 0.3436\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5795 - val_loss: 0.3450\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5729 - val_loss: 0.3385\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5980 - val_loss: 0.3553\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5469 - val_loss: 0.3453\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5682 - val_loss: 0.3490\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5219 - val_loss: 0.3410\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5641 - val_loss: 0.3419\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5053 - val_loss: 0.3429\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5286 - val_loss: 0.3411\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5114 - val_loss: 0.3436\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5090 - val_loss: 0.3395\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4905 - val_loss: 0.3435\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5398 - val_loss: 0.3376\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5244 - val_loss: 0.3437\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4905 - val_loss: 0.3393\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5147 - val_loss: 0.3379\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5250 - val_loss: 0.3417\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4875 - val_loss: 0.3425\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4942 - val_loss: 0.3415\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5022 - val_loss: 0.3412\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4774 - val_loss: 0.3378\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5151 - val_loss: 0.3424\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5060 - val_loss: 0.3381\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4745 - val_loss: 0.3391\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4864 - val_loss: 0.3400\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4900 - val_loss: 0.3399\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4748 - val_loss: 0.3370\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4767 - val_loss: 0.3396\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4839 - val_loss: 0.3423\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4863 - val_loss: 0.3397\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4843 - val_loss: 0.3439\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4651 - val_loss: 0.3381\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4717 - val_loss: 0.3401\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4530 - val_loss: 0.3383\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4678 - val_loss: 0.3380\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4573 - val_loss: 0.3387\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4451 - val_loss: 0.3401\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4623 - val_loss: 0.3369\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4670 - val_loss: 0.3412\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4528 - val_loss: 0.3376\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4617 - val_loss: 0.3411\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - ETA: 0s - loss: 0.456 - 0s - loss: 0.4579 - val_loss: 0.3383\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4752 - val_loss: 0.3381\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4349 - val_loss: 0.3377\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4378 - val_loss: 0.3374\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4410 - val_loss: 0.3391\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4608 - val_loss: 0.3400\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4381 - val_loss: 0.3417\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4713 - val_loss: 0.3387\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4472 - val_loss: 0.3380\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4387 - val_loss: 0.3376\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4264 - val_loss: 0.3387\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4262 - val_loss: 0.3369\n",
      "Epoch 00064: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=64, num_hidden_layers=3, total= 1.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 16.6838 - val_loss: 2.3776\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.2414 - val_loss: 2.1372\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 4.1463 - val_loss: 2.2968\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.9672 - val_loss: 2.0821\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.8687 - val_loss: 2.0932\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.7450 - val_loss: 1.9653\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.8018 - val_loss: 1.9657\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 3.5686 - val_loss: 1.9784\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.5859 - val_loss: 2.0101\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.3867 - val_loss: 2.0451\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.4123 - val_loss: 1.8425\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.2367 - val_loss: 1.8037\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.3696 - val_loss: 1.7846\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.1412 - val_loss: 1.8216\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.2076 - val_loss: 1.6859\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 3.0182 - val_loss: 1.6581\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.9575 - val_loss: 1.6424\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.7321 - val_loss: 1.5900\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.6389 - val_loss: 1.6132\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.8222 - val_loss: 1.5614\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.4939 - val_loss: 1.4777\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.5263 - val_loss: 1.4510\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.3317 - val_loss: 1.3650\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.4259 - val_loss: 1.3684\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2888 - val_loss: 1.3493\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2716 - val_loss: 1.2958\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.1053 - val_loss: 1.3109\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0145 - val_loss: 1.2320\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0327 - val_loss: 1.2321\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.8658 - val_loss: 1.1754\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0359 - val_loss: 1.1593\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.8818 - val_loss: 1.1166\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.7129 - val_loss: 1.0959\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.7897 - val_loss: 1.0366\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.8046 - val_loss: 1.0286\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5400 - val_loss: 1.0019\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4989 - val_loss: 1.0165\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4619 - val_loss: 0.9360\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5275 - val_loss: 0.9055\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4219 - val_loss: 0.9076\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.4355 - val_loss: 0.8781\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.2627 - val_loss: 0.8627\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.2748 - val_loss: 0.8744\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.2646 - val_loss: 0.8401\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1747 - val_loss: 0.7740\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1022 - val_loss: 0.7530\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1020 - val_loss: 0.6856\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0998 - val_loss: 0.7164\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0205 - val_loss: 0.7956\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0325 - val_loss: 0.6836\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9683 - val_loss: 0.6074\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9281 - val_loss: 0.7129\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9085 - val_loss: 0.5968\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8486 - val_loss: 0.5925\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8076 - val_loss: 0.6552\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7839 - val_loss: 0.6869\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7583 - val_loss: 0.5262\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7527 - val_loss: 0.5435\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7224 - val_loss: 0.5608\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6732 - val_loss: 0.5473\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6491 - val_loss: 0.5208\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6621 - val_loss: 0.5309\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6308 - val_loss: 0.5049\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5794 - val_loss: 0.5052\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5770 - val_loss: 0.4966\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5089 - val_loss: 0.4748\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5287 - val_loss: 0.4646\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5089 - val_loss: 0.4661\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4531 - val_loss: 0.4515\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4794 - val_loss: 0.4578\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4475 - val_loss: 0.4343\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4294 - val_loss: 0.4182\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3978 - val_loss: 0.4126\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4036 - val_loss: 0.4094\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3706 - val_loss: 0.3976\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3899 - val_loss: 0.3924\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3285 - val_loss: 0.3868\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3453 - val_loss: 0.3826\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3494 - val_loss: 0.3775\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3112 - val_loss: 0.3727\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3081 - val_loss: 0.3614\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3257 - val_loss: 0.3632\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3042 - val_loss: 0.3569\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2847 - val_loss: 0.3515\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2790 - val_loss: 0.3493\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2881 - val_loss: 0.3319\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2770 - val_loss: 0.3457\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2758 - val_loss: 0.3398\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2419 - val_loss: 0.3471\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2406 - val_loss: 0.3466\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2628 - val_loss: 0.3043\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2415 - val_loss: 0.3233\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2568 - val_loss: 0.3324\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2418 - val_loss: 0.3210\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2339 - val_loss: 0.3109\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2322 - val_loss: 0.2997\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2320 - val_loss: 0.3052\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2277 - val_loss: 0.3294\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2190 - val_loss: 0.3093\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2190 - val_loss: 0.3091\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2058 - val_loss: 0.3092\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2116 - val_loss: 0.3060\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2030 - val_loss: 0.3044\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2128 - val_loss: 0.3042\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2072 - val_loss: 0.3031\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2013 - val_loss: 0.3073\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2132 - val_loss: 0.3029\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2107 - val_loss: 0.3058\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2017 - val_loss: 0.3034\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2092 - val_loss: 0.3031\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2136 - val_loss: 0.3016\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2104 - val_loss: 0.3022\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2145 - val_loss: 0.3020\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2188 - val_loss: 0.3006\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2116 - val_loss: 0.3016\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2098 - val_loss: 0.3023\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2045 - val_loss: 0.2996\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2017 - val_loss: 0.3013\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2036 - val_loss: 0.3010\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2027 - val_loss: 0.3009\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2024 - val_loss: 0.3014\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2052 - val_loss: 0.3005\n",
      "Epoch 00121: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 4.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.4563 - val_loss: 1.0166\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9070 - val_loss: 1.5290\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0238 - val_loss: 0.8786\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7337 - val_loss: 1.0633\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8043 - val_loss: 0.8637\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7777 - val_loss: 0.9882\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7293 - val_loss: 1.1816\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6886 - val_loss: 1.2385\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7065 - val_loss: 1.5666\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8363 - val_loss: 1.4166\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5968 - val_loss: 1.3641\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6137 - val_loss: 0.8330\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4854 - val_loss: 1.1382\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4152 - val_loss: 0.9648\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3337 - val_loss: 0.8883\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3232 - val_loss: 0.9289\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2936 - val_loss: 0.8936\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1491 - val_loss: 1.0177\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0734 - val_loss: 1.1477\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0373 - val_loss: 0.8388\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9308 - val_loss: 1.1950\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9935 - val_loss: 0.8269\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9069 - val_loss: 1.2081\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8708 - val_loss: 0.7922\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8982 - val_loss: 0.5946\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6971 - val_loss: 1.0829\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7186 - val_loss: 0.6278\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7604 - val_loss: 0.5742\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6806 - val_loss: 1.1669\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6844 - val_loss: 0.5951\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5839 - val_loss: 0.9555\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4529 - val_loss: 0.8662ss: 1.45 - ETA: 0s -\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3849 - val_loss: 0.6913\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4285 - val_loss: 0.8197\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3316 - val_loss: 0.7120\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3334 - val_loss: 0.9579\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3665 - val_loss: 0.6733\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2491 - val_loss: 0.7335\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2391 - val_loss: 0.8378\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1147 - val_loss: 0.5862\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1881 - val_loss: 0.5741\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0782 - val_loss: 0.6259\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9907 - val_loss: 0.6082\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0452 - val_loss: 0.6846\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0579 - val_loss: 0.6163\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9927 - val_loss: 0.4812\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0185 - val_loss: 0.5469\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8890 - val_loss: 0.5999\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9107 - val_loss: 0.4477\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8486 - val_loss: 0.5917\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8529 - val_loss: 0.5974\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8354 - val_loss: 0.4994\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7870 - val_loss: 0.4997\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7463 - val_loss: 0.4634\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7532 - val_loss: 0.5238\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7482 - val_loss: 0.5197\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6578 - val_loss: 0.5095\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6624 - val_loss: 0.5008\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6512 - val_loss: 0.4816\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6028 - val_loss: 0.5721\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5892 - val_loss: 0.4812\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5972 - val_loss: 0.4662\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5457 - val_loss: 0.4574ss: 0.55\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5419 - val_loss: 0.4233\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5392 - val_loss: 0.4428\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4788 - val_loss: 0.3661\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5074 - val_loss: 0.4973\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4677 - val_loss: 0.4484ss: 0\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4163 - val_loss: 0.4486\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4448 - val_loss: 0.4353\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4319 - val_loss: 0.3624\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4173 - val_loss: 0.3690\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3897 - val_loss: 0.4455\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3578 - val_loss: 0.3637\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3510 - val_loss: 0.4585\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3389 - val_loss: 0.3926\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3209 - val_loss: 0.3612\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3186 - val_loss: 0.3667\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3150 - val_loss: 0.3528\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2891 - val_loss: 0.3397\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2991 - val_loss: 0.3820\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2960 - val_loss: 0.3474\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2853 - val_loss: 0.3585\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2652 - val_loss: 0.3399\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2673 - val_loss: 0.3264\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2627 - val_loss: 0.3356\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2456 - val_loss: 0.3453\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2421 - val_loss: 0.3210\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2200 - val_loss: 0.3333\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2321 - val_loss: 0.3217\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2514 - val_loss: 0.3267\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2261 - val_loss: 0.3410\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2169 - val_loss: 0.3449\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2079 - val_loss: 0.3282\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2093 - val_loss: 0.3472\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1949 - val_loss: 0.3381\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2149 - val_loss: 0.3178\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1837 - val_loss: 0.3237\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2042 - val_loss: 0.3078\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1875 - val_loss: 0.3048\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1952 - val_loss: 0.3013\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1929 - val_loss: 0.3144\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1907 - val_loss: 0.3108\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1720 - val_loss: 0.3134\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1954 - val_loss: 0.3129\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1860 - val_loss: 0.3036\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1814 - val_loss: 0.3236\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1736 - val_loss: 0.3102\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1781 - val_loss: 0.3055\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1712 - val_loss: 0.3056\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1796 - val_loss: 0.3010\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1794 - val_loss: 0.3032\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1683 - val_loss: 0.3182\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1869 - val_loss: 0.3012\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1799 - val_loss: 0.3039\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1867 - val_loss: 0.2987\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1696 - val_loss: 0.3014\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1705 - val_loss: 0.2987\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1662 - val_loss: 0.2967\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1764 - val_loss: 0.2997\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1710 - val_loss: 0.3041\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1790 - val_loss: 0.2986\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1685 - val_loss: 0.2994\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1751 - val_loss: 0.2999\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1772 - val_loss: 0.3104\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1719 - val_loss: 0.3018\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1777 - val_loss: 0.3042\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1705 - val_loss: 0.2977\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1710 - val_loss: 0.3013\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1689 - val_loss: 0.3000\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1717 - val_loss: 0.2963\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1718 - val_loss: 0.2982\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1649 - val_loss: 0.2998\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1762 - val_loss: 0.2990\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1708 - val_loss: 0.3009\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1827 - val_loss: 0.3008\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1748 - val_loss: 0.3016\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1687 - val_loss: 0.3006\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1760 - val_loss: 0.3007\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1734 - val_loss: 0.2968\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1781 - val_loss: 0.2965\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1748 - val_loss: 0.2981\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1782 - val_loss: 0.2966\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1817 - val_loss: 0.3034\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1682 - val_loss: 0.3022\n",
      "Epoch 00144: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 5.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.8330 - val_loss: 2.4079\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.2056 - val_loss: 2.1100\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0061 - val_loss: 0.8972\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9019 - val_loss: 1.8149\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6472 - val_loss: 1.4148\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.7940 - val_loss: 1.0685\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8223 - val_loss: 1.1872\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6670 - val_loss: 1.1727\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6293 - val_loss: 1.0543\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5663 - val_loss: 0.8076\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3839 - val_loss: 0.7886ss: 2.383\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3919 - val_loss: 0.8781\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3541 - val_loss: 1.0350\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3764 - val_loss: 1.0096\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1796 - val_loss: 0.7872\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0900 - val_loss: 0.8380\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0456 - val_loss: 1.0182\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1029 - val_loss: 0.7797\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9442 - val_loss: 1.1075\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9181 - val_loss: 0.9084\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9665 - val_loss: 1.0566\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8778 - val_loss: 1.0413\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8650 - val_loss: 0.6726\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8159 - val_loss: 0.9199\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8423 - val_loss: 1.0723\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6570 - val_loss: 0.9367\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6142 - val_loss: 0.6191\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6561 - val_loss: 0.8570\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5369 - val_loss: 0.7270ss: 1.53\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4332 - val_loss: 0.9019\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4305 - val_loss: 0.5620\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4048 - val_loss: 0.9790\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3629 - val_loss: 0.7249\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3312 - val_loss: 0.6822\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2914 - val_loss: 0.8583\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1668 - val_loss: 0.5551\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2817 - val_loss: 0.5524\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2043 - val_loss: 0.5726\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1423 - val_loss: 0.8085\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1242 - val_loss: 0.6577\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0804 - val_loss: 0.7213\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0135 - val_loss: 0.5201\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0870 - val_loss: 0.5149\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0041 - val_loss: 0.5768\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9349 - val_loss: 0.5889\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9183 - val_loss: 0.4433ss:\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8705 - val_loss: 0.6440\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8769 - val_loss: 0.5893\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8599 - val_loss: 0.4768\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8029 - val_loss: 0.5650\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7936 - val_loss: 0.4579ss: 0\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7442 - val_loss: 0.5288\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7798 - val_loss: 0.5686\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7114 - val_loss: 0.5448\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6342 - val_loss: 0.4663\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6752 - val_loss: 0.4209\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6452 - val_loss: 0.4550\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5944 - val_loss: 0.4650\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5918 - val_loss: 0.4409\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5475 - val_loss: 0.5007\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5644 - val_loss: 0.5148\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5267 - val_loss: 0.4497\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5326 - val_loss: 0.4902\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4744 - val_loss: 0.4726\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4906 - val_loss: 0.4580\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4565 - val_loss: 0.4522\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4925 - val_loss: 0.4320\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4470 - val_loss: 0.4195\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4205 - val_loss: 0.4383\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3630 - val_loss: 0.3653\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3647 - val_loss: 0.4840\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3869 - val_loss: 0.3601\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3864 - val_loss: 0.3785\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3377 - val_loss: 0.3965\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3137 - val_loss: 0.3608\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3314 - val_loss: 0.3347\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3156 - val_loss: 0.3955\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3044 - val_loss: 0.3797\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2952 - val_loss: 0.3284\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2881 - val_loss: 0.3931\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2772 - val_loss: 0.3310\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2675 - val_loss: 0.3302\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2686 - val_loss: 0.3608\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2557 - val_loss: 0.3535\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2388 - val_loss: 0.3709\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2431 - val_loss: 0.3268\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2224 - val_loss: 0.3277\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2280 - val_loss: 0.3197\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2375 - val_loss: 0.3225\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2144 - val_loss: 0.3245\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2158 - val_loss: 0.3185\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2109 - val_loss: 0.3204\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2065 - val_loss: 0.3084\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2011 - val_loss: 0.3125\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2038 - val_loss: 0.3186\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2141 - val_loss: 0.3062\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1966 - val_loss: 0.3145\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2014 - val_loss: 0.3066\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1877 - val_loss: 0.3023\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1965 - val_loss: 0.3020\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1934 - val_loss: 0.3066\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1913 - val_loss: 0.3186\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1876 - val_loss: 0.3188ss:\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1891 - val_loss: 0.3027\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1859 - val_loss: 0.3016\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1781 - val_loss: 0.3079\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1677 - val_loss: 0.3036\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1814 - val_loss: 0.3095\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1821 - val_loss: 0.3043\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1812 - val_loss: 0.3057\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1770 - val_loss: 0.3039\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1798 - val_loss: 0.2998\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1755 - val_loss: 0.3076\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1844 - val_loss: 0.3178\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1911 - val_loss: 0.3021\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1871 - val_loss: 0.2991\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1869 - val_loss: 0.2964\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1718 - val_loss: 0.3051\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1836 - val_loss: 0.3051\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1839 - val_loss: 0.3072\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1782 - val_loss: 0.3018\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1711 - val_loss: 0.3047\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1734 - val_loss: 0.3018\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1812 - val_loss: 0.3074\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1712 - val_loss: 0.3016\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1741 - val_loss: 0.3031\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1721 - val_loss: 0.2978\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1830 - val_loss: 0.3022\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1865 - val_loss: 0.3005\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1983 - val_loss: 0.3087\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1711 - val_loss: 0.3227\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1716 - val_loss: 0.3040\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1856 - val_loss: 0.3031\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1761 - val_loss: 0.2983\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1814 - val_loss: 0.2974\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1730 - val_loss: 0.2979\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1802 - val_loss: 0.2982\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1772 - val_loss: 0.3108\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1752 - val_loss: 0.3050\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1748 - val_loss: 0.2985\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1722 - val_loss: 0.2996\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1731 - val_loss: 0.3073\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1738 - val_loss: 0.3013\n",
      "Epoch 00142: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 5.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 15.8968 - val_loss: 1.2942\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.8368 - val_loss: 1.0747\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0339 - val_loss: 1.1274\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9179 - val_loss: 1.8237\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8747 - val_loss: 0.8895\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7487 - val_loss: 1.5189\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7442 - val_loss: 0.8597\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6718 - val_loss: 1.0428\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6712 - val_loss: 0.8341\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5875 - val_loss: 1.0369\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3861 - val_loss: 0.8597\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4482 - val_loss: 1.2558\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4014 - val_loss: 0.9673\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3647 - val_loss: 1.0649\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2789 - val_loss: 1.2770\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3217 - val_loss: 1.0263\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2321 - val_loss: 1.4056\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1311 - val_loss: 0.8560\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1897 - val_loss: 0.9569\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0044 - val_loss: 1.1378\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9468 - val_loss: 0.7795\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9886 - val_loss: 0.9353\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8153 - val_loss: 0.7090\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7758 - val_loss: 0.7967\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6792 - val_loss: 0.7661\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7076 - val_loss: 0.5047\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6837 - val_loss: 0.8389\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6754 - val_loss: 0.7949\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4848 - val_loss: 0.7542\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5389 - val_loss: 0.6625\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5051 - val_loss: 0.7306\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4852 - val_loss: 0.6466\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3536 - val_loss: 0.8042\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3418 - val_loss: 0.6757\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3253 - val_loss: 0.7162\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3929 - val_loss: 0.6739\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2754 - val_loss: 0.7141\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2393 - val_loss: 0.5060\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1448 - val_loss: 0.5689\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1874 - val_loss: 0.7375\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1559 - val_loss: 0.7200\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0867 - val_loss: 0.4670\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0720 - val_loss: 0.5623\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0003 - val_loss: 0.5904\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0411 - val_loss: 0.5330\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9842 - val_loss: 0.6196\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9175 - val_loss: 0.5662\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8649 - val_loss: 0.5011\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8499 - val_loss: 0.6427\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8724 - val_loss: 0.5078\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8381 - val_loss: 0.4701\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7905 - val_loss: 0.4827\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7550 - val_loss: 0.5169\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7305 - val_loss: 0.5297\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6929 - val_loss: 0.4194\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7344 - val_loss: 0.4902\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6731 - val_loss: 0.5152\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6425 - val_loss: 0.5232\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6650 - val_loss: 0.4188\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5930 - val_loss: 0.4288\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5530 - val_loss: 0.4754\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5409 - val_loss: 0.3791\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5068 - val_loss: 0.4515\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5011 - val_loss: 0.4395\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4775 - val_loss: 0.4650\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4706 - val_loss: 0.4083\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4465 - val_loss: 0.4309\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4615 - val_loss: 0.4465\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4370 - val_loss: 0.4523\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4171 - val_loss: 0.4017\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4156 - val_loss: 0.3784\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3663 - val_loss: 0.4272\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3754 - val_loss: 0.3905\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3521 - val_loss: 0.3494\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3384 - val_loss: 0.4038\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3239 - val_loss: 0.3466\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3275 - val_loss: 0.3930\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3274 - val_loss: 0.3349\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3109 - val_loss: 0.3931\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2799 - val_loss: 0.3418\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3020 - val_loss: 0.3594\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2793 - val_loss: 0.3358\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2800 - val_loss: 0.3413\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2609 - val_loss: 0.3172\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2489 - val_loss: 0.3396\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2457 - val_loss: 0.3498\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2552 - val_loss: 0.3320\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2495 - val_loss: 0.3219\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2449 - val_loss: 0.3502\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2285 - val_loss: 0.3176\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2270 - val_loss: 0.3178\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2301 - val_loss: 0.3252\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2189 - val_loss: 0.3355\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2173 - val_loss: 0.3161\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2222 - val_loss: 0.3095\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2100 - val_loss: 0.3147\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2070 - val_loss: 0.3300\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1994 - val_loss: 0.3213\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2020 - val_loss: 0.3239\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1897 - val_loss: 0.3184\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1890 - val_loss: 0.3204\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1981 - val_loss: 0.3154\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1970 - val_loss: 0.3111\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1837 - val_loss: 0.3085\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1809 - val_loss: 0.3111\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1866 - val_loss: 0.3141\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1987 - val_loss: 0.3262\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1864 - val_loss: 0.3144\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1901 - val_loss: 0.3132\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1906 - val_loss: 0.3094\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1772 - val_loss: 0.3087\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1836 - val_loss: 0.3122\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1850 - val_loss: 0.3082\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1837 - val_loss: 0.3095\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1896 - val_loss: 0.3094\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1721 - val_loss: 0.3051\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1807 - val_loss: 0.3156\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1836 - val_loss: 0.3053\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1860 - val_loss: 0.3234\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1782 - val_loss: 0.3029\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1864 - val_loss: 0.3062\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2035 - val_loss: 0.3042\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1785 - val_loss: 0.3061\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1771 - val_loss: 0.3088\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1770 - val_loss: 0.3039\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1805 - val_loss: 0.3020\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1826 - val_loss: 0.3077 0s - loss: 0.1\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1824 - val_loss: 0.3092\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1770 - val_loss: 0.3095\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1837 - val_loss: 0.3016\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1830 - val_loss: 0.3062\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1778 - val_loss: 0.3085\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1846 - val_loss: 0.3023\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1985 - val_loss: 0.3035\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1663 - val_loss: 0.3061\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1855 - val_loss: 0.3094\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1755 - val_loss: 0.3055\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1748 - val_loss: 0.3034\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1856 - val_loss: 0.3031\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1899 - val_loss: 0.3010\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1738 - val_loss: 0.3018\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1804 - val_loss: 0.3021\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1831 - val_loss: 0.3046\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.1795 - val_loss: 0.3200\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1815 - val_loss: 0.3043\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1924 - val_loss: 0.3033\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1793 - val_loss: 0.3075\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1933 - val_loss: 0.3102\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1871 - val_loss: 0.3064\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1853 - val_loss: 0.3083\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1804 - val_loss: 0.3134\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1877 - val_loss: 0.3044\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1856 - val_loss: 0.3027\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1796 - val_loss: 0.3096\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1899 - val_loss: 0.3130\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1903 - val_loss: 0.3040\n",
      "Epoch 00155: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 6.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.8519 - val_loss: 1.5026\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4996 - val_loss: 1.1817ss: 2.500\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4742 - val_loss: 0.8471\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3677 - val_loss: 0.5742\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2877 - val_loss: 0.9266\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2096 - val_loss: 0.6645\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0530 - val_loss: 0.7956\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1377 - val_loss: 0.7449\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9944 - val_loss: 0.6197\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9229 - val_loss: 0.5986\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.9941 - val_loss: 0.9083\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9289 - val_loss: 0.9500\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0386 - val_loss: 0.5798\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8313 - val_loss: 0.4577\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9880 - val_loss: 0.7835\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7957 - val_loss: 0.7194\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7440 - val_loss: 0.5085\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6847 - val_loss: 0.7123\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6858 - val_loss: 0.9041\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7454 - val_loss: 0.6602\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5812 - val_loss: 0.4147\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5201 - val_loss: 0.6554\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5121 - val_loss: 0.5972\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5636 - val_loss: 0.6120\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5247 - val_loss: 0.5181\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4579 - val_loss: 0.6378\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4192 - val_loss: 0.6606\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2123 - val_loss: 0.4876\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3426 - val_loss: 0.5651\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2386 - val_loss: 0.6446\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2559 - val_loss: 0.5846\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2174 - val_loss: 0.5550\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1383 - val_loss: 0.6142\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1152 - val_loss: 0.6608\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0836 - val_loss: 0.4073\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0569 - val_loss: 0.5222\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0867 - val_loss: 0.6435\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0851 - val_loss: 0.4392\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0131 - val_loss: 0.6942\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9730 - val_loss: 0.5617\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9182 - val_loss: 0.5124\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9473 - val_loss: 0.5514\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9187 - val_loss: 0.3897\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8641 - val_loss: 0.5843\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8544 - val_loss: 0.4801\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8429 - val_loss: 0.5897\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8706 - val_loss: 0.4030\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7602 - val_loss: 0.4469\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7508 - val_loss: 0.4433\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7887 - val_loss: 0.4087\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7103 - val_loss: 0.4912\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6605 - val_loss: 0.4168\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6722 - val_loss: 0.4383\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6248 - val_loss: 0.4212\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6121 - val_loss: 0.3715ss: 0.\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5764 - val_loss: 0.3989\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6129 - val_loss: 0.3882\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6000 - val_loss: 0.3829\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5566 - val_loss: 0.3742\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5203 - val_loss: 0.3800\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5106 - val_loss: 0.3825\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4677 - val_loss: 0.4074\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4831 - val_loss: 0.4107\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4770 - val_loss: 0.3974\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4598 - val_loss: 0.4250\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4599 - val_loss: 0.3687\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4175 - val_loss: 0.3162\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3935 - val_loss: 0.3935\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3771 - val_loss: 0.4073\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3861 - val_loss: 0.3745\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3523 - val_loss: 0.3748\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3579 - val_loss: 0.3690\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3034 - val_loss: 0.3268\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3185 - val_loss: 0.3761\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3149 - val_loss: 0.3209\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3157 - val_loss: 0.3320\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3058 - val_loss: 0.3537ss: 0.30\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2912 - val_loss: 0.3311\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2734 - val_loss: 0.3435\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2518 - val_loss: 0.3301\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2721 - val_loss: 0.3444\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2722 - val_loss: 0.3269\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2282 - val_loss: 0.3190\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2522 - val_loss: 0.3362\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2257 - val_loss: 0.3321\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2117 - val_loss: 0.3060\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2035 - val_loss: 0.3146\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2172 - val_loss: 0.3493\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2006 - val_loss: 0.3147\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2200 - val_loss: 0.3249\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2018 - val_loss: 0.3067\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1896 - val_loss: 0.3181\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2159 - val_loss: 0.3201\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2063 - val_loss: 0.3143\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1760 - val_loss: 0.3278\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1806 - val_loss: 0.3123\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1784 - val_loss: 0.3062\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2044 - val_loss: 0.3148\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1805 - val_loss: 0.3192\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1770 - val_loss: 0.3100\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1771 - val_loss: 0.3157\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1640 - val_loss: 0.3105\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1678 - val_loss: 0.3122\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1756 - val_loss: 0.3179\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1622 - val_loss: 0.3157\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1628 - val_loss: 0.3091\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1681 - val_loss: 0.3141\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1567 - val_loss: 0.3220ss: \n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1708 - val_loss: 0.3069\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1695 - val_loss: 0.3140\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1601 - val_loss: 0.3131\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.1616 - val_loss: 0.3072\n",
      "Epoch 00111: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 4.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 5.4250 - val_loss: 1.2234\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.5318 - val_loss: 1.6094\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3282 - val_loss: 1.2402\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3346 - val_loss: 1.8318\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1370 - val_loss: 1.7331\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0499 - val_loss: 2.1574\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9295 - val_loss: 2.0860\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8893 - val_loss: 2.1982\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7423 - val_loss: 2.2562\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6234 - val_loss: 2.1955\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5947 - val_loss: 2.0853\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5641 - val_loss: 1.3378\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5725 - val_loss: 1.4710\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5751 - val_loss: 1.7679\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4960 - val_loss: 1.3286\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4872 - val_loss: 1.5239\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4272 - val_loss: 1.4172\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3802 - val_loss: 1.3084\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3667 - val_loss: 1.2428\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3192 - val_loss: 1.0517\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2922 - val_loss: 1.1140\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3231 - val_loss: 1.2326\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2729 - val_loss: 1.1613\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2821 - val_loss: 0.8483\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2752 - val_loss: 0.9736\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2804 - val_loss: 0.8767\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3114 - val_loss: 0.9773\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2727 - val_loss: 0.8446\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2678 - val_loss: 0.7767\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2637 - val_loss: 0.9608\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2445 - val_loss: 0.8148\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2454 - val_loss: 0.9447\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2610 - val_loss: 0.8294\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2465 - val_loss: 0.7180\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2356 - val_loss: 0.9329\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2455 - val_loss: 0.8504\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2477 - val_loss: 0.7807\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2360 - val_loss: 0.8068\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2731 - val_loss: 0.7874\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2298 - val_loss: 0.7375\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2258 - val_loss: 0.7721\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2415 - val_loss: 0.8268\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2051 - val_loss: 0.9042\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2244 - val_loss: 0.6433\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2229 - val_loss: 0.7972\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2355 - val_loss: 0.7332\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2052 - val_loss: 0.8143\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1974 - val_loss: 0.8343\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1984 - val_loss: 0.7937\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2166 - val_loss: 0.6343\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2119 - val_loss: 0.7845\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1883 - val_loss: 0.7794\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1902 - val_loss: 0.8457\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1937 - val_loss: 0.7993\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1879 - val_loss: 0.7199\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1960 - val_loss: 0.7820\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2182 - val_loss: 0.6801\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1986 - val_loss: 0.7819\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1955 - val_loss: 0.7864\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2204 - val_loss: 1.0218\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2048 - val_loss: 0.7758\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1898 - val_loss: 0.8375\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1807 - val_loss: 0.7366\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1819 - val_loss: 0.8014\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1843 - val_loss: 0.7358\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1847 - val_loss: 0.6788\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1910 - val_loss: 0.6997\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1838 - val_loss: 0.7677\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1578 - val_loss: 0.7543\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1740 - val_loss: 0.5818\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1982 - val_loss: 0.7816\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1821 - val_loss: 0.7035\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1795 - val_loss: 0.7665\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1657 - val_loss: 0.8273\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.1596 - val_loss: 0.7739\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1842 - val_loss: 0.7949\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1772 - val_loss: 0.7311\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1828 - val_loss: 0.7405\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1703 - val_loss: 0.7300\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1725 - val_loss: 0.6388\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1788 - val_loss: 0.7677\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1862 - val_loss: 0.6203\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1793 - val_loss: 0.6674\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1646 - val_loss: 0.6931\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1668 - val_loss: 0.7032\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1628 - val_loss: 0.7339\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1514 - val_loss: 0.7370\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1715 - val_loss: 0.6762\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1586 - val_loss: 0.7071\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1531 - val_loss: 0.8289\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1741 - val_loss: 0.7256\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1722 - val_loss: 0.6036\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1749 - val_loss: 0.7482\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1646 - val_loss: 0.7806\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1610 - val_loss: 0.6313\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.1610 - val_loss: 0.5991\n",
      "Epoch 00095: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 3.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 8.8321 - val_loss: 2.0338\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0178 - val_loss: 1.6514\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8071 - val_loss: 1.5593\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4763 - val_loss: 1.3611\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3846 - val_loss: 1.6276\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1572 - val_loss: 1.7049\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0747 - val_loss: 1.7222\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0850 - val_loss: 2.2878\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8689 - val_loss: 1.8779\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9059 - val_loss: 2.0709\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8609 - val_loss: 1.7974\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7897 - val_loss: 1.5446\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7071 - val_loss: 1.4863\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6509 - val_loss: 1.5059\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5303 - val_loss: 0.9687\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5693 - val_loss: 0.9452\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4407 - val_loss: 0.7825\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4144 - val_loss: 0.5305\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4595 - val_loss: 0.5227\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4218 - val_loss: 0.4963\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3631 - val_loss: 0.4900\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3918 - val_loss: 0.5148\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3485 - val_loss: 0.4940\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3577 - val_loss: 0.4483\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3357 - val_loss: 0.4907\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3557 - val_loss: 0.5270\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3219 - val_loss: 0.5192\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3186 - val_loss: 0.5180\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3140 - val_loss: 0.5602\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2974 - val_loss: 0.4997\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2998 - val_loss: 0.3941\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3403 - val_loss: 0.5091\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3228 - val_loss: 0.6066\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3028 - val_loss: 0.5133\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3219 - val_loss: 0.5962\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3148 - val_loss: 0.5940\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3106 - val_loss: 0.6407\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3065 - val_loss: 0.6215\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3020 - val_loss: 0.4707\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3112 - val_loss: 0.5996\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2895 - val_loss: 0.7192\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3059 - val_loss: 0.5529\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2896 - val_loss: 0.4815\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3253 - val_loss: 0.6057\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2812 - val_loss: 0.6535\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2716 - val_loss: 0.5624\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2987 - val_loss: 0.6751\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2997 - val_loss: 0.6668\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2750 - val_loss: 0.6403\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2871 - val_loss: 0.5422\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2957 - val_loss: 0.4415\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2858 - val_loss: 0.6393\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2869 - val_loss: 0.5976\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2655 - val_loss: 0.6869\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2765 - val_loss: 0.6952\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2890 - val_loss: 0.6230\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2875 - val_loss: 0.5845\n",
      "Epoch 00056: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 2.5min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 5.5917 - val_loss: 1.3961\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8071 - val_loss: 2.0689\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6576 - val_loss: 2.1929\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3847 - val_loss: 2.5588\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.2464 - val_loss: 2.0407\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.1633 - val_loss: 2.5642\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0353 - val_loss: 1.3929\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9128 - val_loss: 2.3418\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8616 - val_loss: 2.2234\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7658 - val_loss: 2.1052\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6501 - val_loss: 1.9949\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6116 - val_loss: 1.6637\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5865 - val_loss: 2.0518\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5907 - val_loss: 1.6224\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5362 - val_loss: 1.4106TA: 1s - loss - ETA: 0s - lo\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5362 - val_loss: 1.3872\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4911 - val_loss: 1.4679\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4789 - val_loss: 1.3741\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4352 - val_loss: 1.1898\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4048 - val_loss: 1.0709\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3515 - val_loss: 1.1065\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3564 - val_loss: 1.0922\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3760 - val_loss: 1.0150\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3762 - val_loss: 0.8936\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3471 - val_loss: 0.8449\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3581 - val_loss: 0.6959\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3488 - val_loss: 0.6496\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3260 - val_loss: 0.6855\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3442 - val_loss: 0.4819\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3449 - val_loss: 0.4729\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2933 - val_loss: 0.4870\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3109 - val_loss: 0.4792\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2844 - val_loss: 0.5034\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2945 - val_loss: 0.5225\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2893 - val_loss: 0.5130\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2899 - val_loss: 0.6475\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2910 - val_loss: 0.5351\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3010 - val_loss: 0.6364\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2856 - val_loss: 0.4480\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2907 - val_loss: 0.4925\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2844 - val_loss: 0.5600\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2615 - val_loss: 0.6113\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2710 - val_loss: 0.6289\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2512 - val_loss: 0.5919\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2685 - val_loss: 0.5887\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2483 - val_loss: 0.6402\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2594 - val_loss: 0.6678\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2527 - val_loss: 0.7042\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2311 - val_loss: 0.6561\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2507 - val_loss: 0.7003\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2754 - val_loss: 0.7127\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2554 - val_loss: 0.6379\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2303 - val_loss: 0.4763\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2584 - val_loss: 0.4911\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2460 - val_loss: 0.6597\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2515 - val_loss: 0.5927\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2354 - val_loss: 0.5612\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2340 - val_loss: 0.7420\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2139 - val_loss: 0.5372\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2310 - val_loss: 0.6423\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2358 - val_loss: 0.7499\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2369 - val_loss: 0.5360\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2427 - val_loss: 0.5464\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2377 - val_loss: 0.7264\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2326 - val_loss: 0.5766\n",
      "Epoch 00064: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 3.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 9.6411 - val_loss: 0.3585\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4266 - val_loss: 1.2883\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8715 - val_loss: 1.4256\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8433 - val_loss: 1.3804\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3425 - val_loss: 1.4967\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3412 - val_loss: 1.3928\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1576 - val_loss: 1.4318\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1917 - val_loss: 2.5945\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9939 - val_loss: 2.0106\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7790 - val_loss: 1.7061\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8320 - val_loss: 1.9465\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6917 - val_loss: 1.4705\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5600 - val_loss: 1.2551\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5126 - val_loss: 1.0127\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4364 - val_loss: 0.8756\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4046 - val_loss: 0.7081\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3666 - val_loss: 0.7112\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3687 - val_loss: 0.6709\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3588 - val_loss: 0.5907\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3247 - val_loss: 0.7423\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3571 - val_loss: 0.7826\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3326 - val_loss: 0.6673\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3389 - val_loss: 0.6437\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3236 - val_loss: 0.5029\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3300 - val_loss: 0.6872\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3303 - val_loss: 0.6251\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3306 - val_loss: 0.6439\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 1.3min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 4.3203 - val_loss: 1.0449\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8186 - val_loss: 1.2541\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4772 - val_loss: 1.6491\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3072 - val_loss: 1.8916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5021 - val_loss: 2.3289\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2315 - val_loss: 1.8632\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0571 - val_loss: 1.7694\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8895 - val_loss: 1.4111\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8494 - val_loss: 1.7238\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5990 - val_loss: 1.0751\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5306 - val_loss: 1.4049\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4311 - val_loss: 1.1988\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4336 - val_loss: 0.8705\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3488 - val_loss: 0.7165\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3453 - val_loss: 0.7557\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3462 - val_loss: 0.6741\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3358 - val_loss: 0.7381\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3201 - val_loss: 0.7014\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3275 - val_loss: 0.8003\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3311 - val_loss: 0.6633\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2996 - val_loss: 0.6353\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2753 - val_loss: 0.6538\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2840 - val_loss: 0.6869\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2977 - val_loss: 0.5221\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2916 - val_loss: 0.5751\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2783 - val_loss: 0.7278\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2919 - val_loss: 0.6158\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2745 - val_loss: 0.7195\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2763 - val_loss: 0.6903\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2828 - val_loss: 0.6717\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3050 - val_loss: 0.5510\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2826 - val_loss: 0.7687\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2733 - val_loss: 0.6200\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2710 - val_loss: 0.7043\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2487 - val_loss: 0.6695\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2826 - val_loss: 0.7984\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2868 - val_loss: 0.6823\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2801 - val_loss: 0.6542\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2831 - val_loss: 0.7340\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2879 - val_loss: 0.5207\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3003 - val_loss: 0.6246\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3065 - val_loss: 0.6434\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2777 - val_loss: 0.5829\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3079 - val_loss: 0.6924\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2980 - val_loss: 0.7238\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2756 - val_loss: 0.6580\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2724 - val_loss: 0.7268\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2938 - val_loss: 0.6306\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2753 - val_loss: 0.7090\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2718 - val_loss: 0.7560\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2775 - val_loss: 0.5849\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2815 - val_loss: 0.7585\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2883 - val_loss: 0.7050\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2722 - val_loss: 0.6463\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2594 - val_loss: 0.5841\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2698 - val_loss: 0.5156\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2875 - val_loss: 0.6614\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2878 - val_loss: 0.6879\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2687 - val_loss: 0.6663\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2561 - val_loss: 0.8289\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2951 - val_loss: 0.7347\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2718 - val_loss: 0.7082\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2794 - val_loss: 0.6451\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2626 - val_loss: 0.6705\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2562 - val_loss: 0.6193\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2540 - val_loss: 0.6401\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2364 - val_loss: 0.6078\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2681 - val_loss: 0.5279\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2711 - val_loss: 0.6490\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2742 - val_loss: 0.5443\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2550 - val_loss: 0.7064\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2538 - val_loss: 0.6072\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2435 - val_loss: 0.6821\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.2542 - val_loss: 0.6523\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2701 - val_loss: 0.6079\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2667 - val_loss: 0.6060\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2612 - val_loss: 0.5982\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2582 - val_loss: 0.5960\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2431 - val_loss: 0.5617\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2502 - val_loss: 0.5066\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2483 - val_loss: 0.5960\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2453 - val_loss: 0.5560\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2746 - val_loss: 0.6671\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2587 - val_loss: 0.7060\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2462 - val_loss: 0.6514\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2501 - val_loss: 0.5219\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2555 - val_loss: 0.5930\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2501 - val_loss: 0.6919\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2351 - val_loss: 0.5527\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2654 - val_loss: 0.6664\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2502 - val_loss: 0.5343\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2360 - val_loss: 0.6409\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2505 - val_loss: 0.5592\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2560 - val_loss: 0.6048\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2285 - val_loss: 0.5190\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2369 - val_loss: 0.6340\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2525 - val_loss: 0.7250\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2434 - val_loss: 0.5913\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2323 - val_loss: 0.5641\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2395 - val_loss: 0.5854\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2457 - val_loss: 0.6627\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2329 - val_loss: 0.6181\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2503 - val_loss: 0.6377\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2533 - val_loss: 0.5595\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2367 - val_loss: 0.5931\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2560 - val_loss: 0.5824\n",
      "Epoch 00105: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=2, total= 4.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s - loss: 6.1017 - val_loss: 1.1539\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0402 - val_loss: 1.7068\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.6289 - val_loss: 1.7895\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3924 - val_loss: 1.1406\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.3263 - val_loss: 2.6853\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1836 - val_loss: 2.2336\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9569 - val_loss: 2.2376ss: 0.\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7962 - val_loss: 1.7352\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6559 - val_loss: 1.2339\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5863 - val_loss: 0.5659\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4966 - val_loss: 0.3495\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4774 - val_loss: 0.3369\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4561 - val_loss: 0.3394\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4640 - val_loss: 0.3454\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4516 - val_loss: 0.3528\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4395 - val_loss: 0.3500\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4503 - val_loss: 0.3375\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4321 - val_loss: 0.3430\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4236 - val_loss: 0.3381\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4109 - val_loss: 0.3382\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4175 - val_loss: 0.3368\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4031 - val_loss: 0.3371\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4053 - val_loss: 0.3400\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3926 - val_loss: 0.3375\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4169 - val_loss: 0.3372\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4139 - val_loss: 0.3413\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4016 - val_loss: 0.3370\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4243 - val_loss: 0.3385\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3903 - val_loss: 0.3368\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4181 - val_loss: 0.3370\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4283 - val_loss: 0.3368\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4025 - val_loss: 0.3368\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4125 - val_loss: 0.3424\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4150 - val_loss: 0.3373\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3894 - val_loss: 0.3395\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4078 - val_loss: 0.3372\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3868 - val_loss: 0.3405\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3963 - val_loss: 0.3372\n",
      "Epoch 00037: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 1.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 6.0178 - val_loss: 2.5514\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 2.1741 - val_loss: 2.1767\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6563 - val_loss: 2.8115\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4660 - val_loss: 2.5390\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3478 - val_loss: 2.8416\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1503 - val_loss: 1.9464\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9613 - val_loss: 1.4443\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7744 - val_loss: 0.5603\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5531 - val_loss: 0.3388\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5142 - val_loss: 0.3379\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4859 - val_loss: 0.3393\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4833 - val_loss: 0.3423\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4613 - val_loss: 0.3472\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4385 - val_loss: 0.3393\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4651 - val_loss: 0.3372\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4407 - val_loss: 0.3373\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4428 - val_loss: 0.3378\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4544 - val_loss: 0.3371\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4368 - val_loss: 0.3378\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4488 - val_loss: 0.3400\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4349 - val_loss: 0.3371\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4485 - val_loss: 0.3373\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4427 - val_loss: 0.3369\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4186 - val_loss: 0.3368\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4376 - val_loss: 0.3384\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4139 - val_loss: 0.3375\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4311 - val_loss: 0.3370\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4337 - val_loss: 0.3382\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4122 - val_loss: 0.3373\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4313 - val_loss: 0.3378\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4159 - val_loss: 0.3407\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4388 - val_loss: 0.3389\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4310 - val_loss: 0.3369\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4074 - val_loss: 0.3417\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3985 - val_loss: 0.3372\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4201 - val_loss: 0.3372\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4094 - val_loss: 0.3368\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4199 - val_loss: 0.3404\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3967 - val_loss: 0.3369\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4060 - val_loss: 0.3388\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4176 - val_loss: 0.3422\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 1.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 6.6844 - val_loss: 2.7068\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8998 - val_loss: 3.1067\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7406 - val_loss: 2.2417\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6797 - val_loss: 3.5103\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3689 - val_loss: 3.2058\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3423 - val_loss: 2.8394\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9808 - val_loss: 2.1669\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6389 - val_loss: 1.5717\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5862 - val_loss: 0.9582\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5027 - val_loss: 0.5878\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4500 - val_loss: 0.4848\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4708 - val_loss: 0.4609\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4787 - val_loss: 0.4471\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4162 - val_loss: 0.4324\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4225 - val_loss: 0.3512\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4714 - val_loss: 0.3395\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4626 - val_loss: 0.3398\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4445 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4427 - val_loss: 0.3377\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4301 - val_loss: 0.3378\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4157 - val_loss: 0.3374\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4257 - val_loss: 0.3378\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4250 - val_loss: 0.3369\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4086 - val_loss: 0.3372\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4304 - val_loss: 0.3487\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4173 - val_loss: 0.3370\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4189 - val_loss: 0.3404\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4160 - val_loss: 0.3371\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4221 - val_loss: 0.3390\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4263 - val_loss: 0.3368\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4107 - val_loss: 0.3372\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4168 - val_loss: 0.3423\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3914 - val_loss: 0.3369\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4035 - val_loss: 0.3368\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4069 - val_loss: 0.3371\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4053 - val_loss: 0.3389\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4109 - val_loss: 0.3371\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3903 - val_loss: 0.3368\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3905 - val_loss: 0.3369\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3887 - val_loss: 0.3368\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3862 - val_loss: 0.3381\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3971 - val_loss: 0.3368\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3914 - val_loss: 0.3397\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3796 - val_loss: 0.3411\n",
      "Epoch 00043: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 2.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 6.0670 - val_loss: 2.0948\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2478 - val_loss: 1.8684\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7964 - val_loss: 2.1093\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6534 - val_loss: 2.2204\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2085 - val_loss: 1.7013\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9641 - val_loss: 0.3732\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5850 - val_loss: 0.3488\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5525 - val_loss: 0.3468\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5270 - val_loss: 0.3414\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5259 - val_loss: 0.3423\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5150 - val_loss: 0.3475\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5048 - val_loss: 0.3378\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4781 - val_loss: 0.3368\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4904 - val_loss: 0.3417\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4516 - val_loss: 0.3420\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4591 - val_loss: 0.3382\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4624 - val_loss: 0.3374\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4652 - val_loss: 0.3433\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4577 - val_loss: 0.3415\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4510 - val_loss: 0.3377\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4596 - val_loss: 0.3370\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4658 - val_loss: 0.3398\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4411 - val_loss: 0.3398\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4446 - val_loss: 0.3384\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4393 - val_loss: 0.3426\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4504 - val_loss: 0.3374\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4321 - val_loss: 0.3446\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4641 - val_loss: 0.3410\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4187 - val_loss: 0.3405\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4177 - val_loss: 0.3406\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4324 - val_loss: 0.3408\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4355 - val_loss: 0.3395\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4557 - val_loss: 0.3407\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4317 - val_loss: 0.3368\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4288 - val_loss: 0.3374\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4324 - val_loss: 0.3430\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4231 - val_loss: 0.3419\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4225 - val_loss: 0.3371\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4343 - val_loss: 0.3389\n",
      "Epoch 00038: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 1.8min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 6.8768 - val_loss: 2.4458\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0035 - val_loss: 1.7832\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9887 - val_loss: 2.8504\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5003 - val_loss: 2.7212\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3032 - val_loss: 2.3527\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9726 - val_loss: 2.1461\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8702 - val_loss: 1.2926\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6462 - val_loss: 0.6615ss: \n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5492 - val_loss: 0.5523\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5225 - val_loss: 0.7029\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4946 - val_loss: 0.7221\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4620 - val_loss: 0.6833\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4550 - val_loss: 0.4873\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4361 - val_loss: 0.5793\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4323 - val_loss: 0.4719\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4345 - val_loss: 0.5456\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4521 - val_loss: 0.5242\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4397 - val_loss: 0.4616\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4168 - val_loss: 0.4095\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4093 - val_loss: 0.3993\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3902 - val_loss: 0.3960\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4035 - val_loss: 0.3834\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3957 - val_loss: 0.3710\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3840 - val_loss: 0.3851\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3718 - val_loss: 0.3776\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3897 - val_loss: 0.3868\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3705 - val_loss: 0.4400\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3773 - val_loss: 0.3778\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3503 - val_loss: 0.4114\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3507 - val_loss: 0.4238\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3577 - val_loss: 0.3755\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4072 - val_loss: 0.4444\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3577 - val_loss: 0.4160\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3778 - val_loss: 0.4402\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3531 - val_loss: 0.3741\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3820 - val_loss: 0.4186\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3738 - val_loss: 0.4280\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3444 - val_loss: 0.4197\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3467 - val_loss: 0.3659\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4039 - val_loss: 0.3943\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3474 - val_loss: 0.3786\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3399 - val_loss: 0.4019\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3471 - val_loss: 0.3845\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3401 - val_loss: 0.3655\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3352 - val_loss: 0.3918\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3270 - val_loss: 0.4014\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3260 - val_loss: 0.4288\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3235 - val_loss: 0.3806\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3214 - val_loss: 0.4317\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3227 - val_loss: 0.3452\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3195 - val_loss: 0.4083\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3116 - val_loss: 0.3778\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3648 - val_loss: 0.3880\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3313 - val_loss: 0.3178\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3236 - val_loss: 0.4103\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3100 - val_loss: 0.3881\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3244 - val_loss: 0.4273\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3088 - val_loss: 0.3945\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3131 - val_loss: 0.4091\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2916 - val_loss: 0.4065\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3049 - val_loss: 0.3953\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3016 - val_loss: 0.3942\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3288 - val_loss: 0.4154\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3119 - val_loss: 0.4074\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3096 - val_loss: 0.4505\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3367 - val_loss: 0.4047\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2918 - val_loss: 0.4063\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3275 - val_loss: 0.3555\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3308 - val_loss: 0.3543\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3027 - val_loss: 0.4326\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2858 - val_loss: 0.4234\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3036 - val_loss: 0.4305\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2966 - val_loss: 0.3776\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2972 - val_loss: 0.4398\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2898 - val_loss: 0.4394\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2832 - val_loss: 0.4512\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3011 - val_loss: 0.4712\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2838 - val_loss: 0.4398\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2892 - val_loss: 0.4201\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2757 - val_loss: 0.4332\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=3, total= 3.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 24.3400 - val_loss: 1.1302\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.9144 - val_loss: 1.0678\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.9540 - val_loss: 1.1756\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.9794 - val_loss: 1.1857\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.8225 - val_loss: 1.2674\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.6394 - val_loss: 0.9233\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.7699 - val_loss: 1.6158\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.6434 - val_loss: 0.9608ss: 2.6\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.5656 - val_loss: 0.6595\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.6396 - val_loss: 1.2567\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.5496 - val_loss: 0.9737\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.5068 - val_loss: 1.0211\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.5150 - val_loss: 0.8854\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.4334 - val_loss: 0.9454\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.2676 - val_loss: 0.8774\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 5s - loss: 2.4253 - val_loss: 0.7712\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.1979 - val_loss: 0.7211\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.2608 - val_loss: 0.7991\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.2031 - val_loss: 1.0514\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.1337 - val_loss: 0.7212\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.1895 - val_loss: 0.7470\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 5s - loss: 2.0728 - val_loss: 0.7262\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 2.0045 - val_loss: 0.5475\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.8596 - val_loss: 0.6640\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.9898 - val_loss: 0.8446\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.8137 - val_loss: 0.7797\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.7522 - val_loss: 0.8272\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.7758 - val_loss: 0.7801\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.7025 - val_loss: 0.6304ss:\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.7342 - val_loss: 0.7160\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.6253 - val_loss: 0.6146\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.5570 - val_loss: 0.8456\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.5793 - val_loss: 0.7541\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.4361 - val_loss: 0.7241\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 3s - loss: 1.4913 - val_loss: 0.7712\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.4246 - val_loss: 0.6101\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.3594 - val_loss: 0.6690\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 5s - loss: 1.4053 - val_loss: 0.7086\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.2931 - val_loss: 0.5220\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.2712 - val_loss: 0.7344\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.2178 - val_loss: 0.6866\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.1499 - val_loss: 0.6862\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.1788 - val_loss: 0.5903\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.1370 - val_loss: 0.6872\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0575 - val_loss: 0.4370\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0394 - val_loss: 0.6832\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 5s - loss: 1.0155 - val_loss: 0.6231\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 6s - loss: 0.9678 - val_loss: 0.4980\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9168 - val_loss: 0.5726\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9517 - val_loss: 0.5227\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8639 - val_loss: 0.5132\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8762 - val_loss: 0.5526\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8498 - val_loss: 0.6096\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8057 - val_loss: 0.4448\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7704 - val_loss: 0.4535\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7758 - val_loss: 0.4974\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7706 - val_loss: 0.5864\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.6890 - val_loss: 0.4534\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.7157 - val_loss: 0.5454\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6519 - val_loss: 0.4421\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6201 - val_loss: 0.3812\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6131 - val_loss: 0.4554\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6093 - val_loss: 0.3958\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5945 - val_loss: 0.4824\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5438 - val_loss: 0.4543\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5511 - val_loss: 0.4219\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5078 - val_loss: 0.4122\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4727 - val_loss: 0.4444\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5053 - val_loss: 0.3803\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4586 - val_loss: 0.3629\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4601 - val_loss: 0.4027\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4257 - val_loss: 0.3988\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4282 - val_loss: 0.3671\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3964 - val_loss: 0.3945\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4015 - val_loss: 0.3935\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3965 - val_loss: 0.3250\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3535 - val_loss: 0.4088\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3583 - val_loss: 0.3223\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3213 - val_loss: 0.3559\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3341 - val_loss: 0.3930\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3257 - val_loss: 0.3590\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2971 - val_loss: 0.3420\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3112 - val_loss: 0.3715\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2754 - val_loss: 0.3659\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2931 - val_loss: 0.3532\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2789 - val_loss: 0.3326\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2658 - val_loss: 0.3321\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.2450 - val_loss: 0.3305\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2361 - val_loss: 0.3337\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 6s - loss: 0.2389 - val_loss: 0.3000\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.2422 - val_loss: 0.3256\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2210 - val_loss: 0.3105\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2153 - val_loss: 0.3474\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2113 - val_loss: 0.3238\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2205 - val_loss: 0.3376\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2113 - val_loss: 0.3207\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1992 - val_loss: 0.3117\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2002 - val_loss: 0.3077\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2044 - val_loss: 0.3095\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1957 - val_loss: 0.3181\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2078 - val_loss: 0.3085\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1848 - val_loss: 0.3111\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1939 - val_loss: 0.3122\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1787 - val_loss: 0.3211\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1836 - val_loss: 0.3204\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1873 - val_loss: 0.2995\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1791 - val_loss: 0.2964\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1940 - val_loss: 0.3108\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1768 - val_loss: 0.2976\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1797 - val_loss: 0.3089\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1721 - val_loss: 0.3019\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1746 - val_loss: 0.2936\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.1703 - val_loss: 0.3003\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1742 - val_loss: 0.3007\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1717 - val_loss: 0.3075\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1682 - val_loss: 0.3042\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1672 - val_loss: 0.2988\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1642 - val_loss: 0.2997\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1690 - val_loss: 0.2953\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1683 - val_loss: 0.3003\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1705 - val_loss: 0.2962\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1692 - val_loss: 0.2970\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1670 - val_loss: 0.3001\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1715 - val_loss: 0.3022\n",
      "Epoch 125/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1666 - val_loss: 0.3012\n",
      "Epoch 126/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1691 - val_loss: 0.3006\n",
      "Epoch 127/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1585 - val_loss: 0.2975\n",
      "Epoch 128/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1680 - val_loss: 0.3004\n",
      "Epoch 129/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1602 - val_loss: 0.3113\n",
      "Epoch 130/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1704 - val_loss: 0.2981\n",
      "Epoch 131/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1711 - val_loss: 0.2932\n",
      "Epoch 132/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1796 - val_loss: 0.2999\n",
      "Epoch 133/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1728 - val_loss: 0.2964\n",
      "Epoch 134/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1613 - val_loss: 0.2953\n",
      "Epoch 135/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1635 - val_loss: 0.2971\n",
      "Epoch 136/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1629 - val_loss: 0.3000\n",
      "Epoch 137/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1718 - val_loss: 0.2959\n",
      "Epoch 138/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1719 - val_loss: 0.2965\n",
      "Epoch 00137: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total=10.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 32.7037 - val_loss: 1.0634\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.9482 - val_loss: 0.6724\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.8501 - val_loss: 1.2631\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9354 - val_loss: 0.8045\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8484 - val_loss: 0.4767\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7537 - val_loss: 1.0106ss: 1.749\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8127 - val_loss: 0.5428\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7126 - val_loss: 0.5293\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7704 - val_loss: 0.7388\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.6960 - val_loss: 0.6005\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6586 - val_loss: 1.0115\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6885 - val_loss: 0.4588\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6524 - val_loss: 0.4031\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.6233 - val_loss: 0.6576\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.6070 - val_loss: 0.5658\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5960 - val_loss: 0.7484\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5909 - val_loss: 0.5787\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5150 - val_loss: 0.7787\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.5628 - val_loss: 0.5220\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.5007 - val_loss: 0.5882\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5050 - val_loss: 0.5307\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5718 - val_loss: 0.6520\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3819 - val_loss: 0.7766\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3687 - val_loss: 0.5119\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4624 - val_loss: 0.4944\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.3324 - val_loss: 0.5417\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.3853 - val_loss: 0.5817\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3163 - val_loss: 0.5973\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2801 - val_loss: 0.4788\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2806 - val_loss: 0.4148\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2591 - val_loss: 0.5230\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2131 - val_loss: 0.4820\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1547 - val_loss: 0.5488\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1540 - val_loss: 0.4511\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1430 - val_loss: 0.5802\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1121 - val_loss: 0.5266\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0722 - val_loss: 0.4750\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0631 - val_loss: 0.4496\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0482 - val_loss: 0.3942\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0632 - val_loss: 0.5530\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0463 - val_loss: 0.5432\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9657 - val_loss: 0.5006\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.9533 - val_loss: 0.4580\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9880 - val_loss: 0.4251\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.9022 - val_loss: 0.5065\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.8529 - val_loss: 0.3848\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.9008 - val_loss: 0.4719\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7795 - val_loss: 0.4405\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.8705 - val_loss: 0.4686\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.8163 - val_loss: 0.3881\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8487 - val_loss: 0.6209\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8090 - val_loss: 0.4228\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.7433 - val_loss: 0.4917\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.7540 - val_loss: 0.3757\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6847 - val_loss: 0.3388\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6854 - val_loss: 0.4013\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7038 - val_loss: 0.5307\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6431 - val_loss: 0.3501\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6385 - val_loss: 0.4526\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5827 - val_loss: 0.4112\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6180 - val_loss: 0.4906\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6048 - val_loss: 0.3544\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5670 - val_loss: 0.4808\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5287 - val_loss: 0.4047\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5294 - val_loss: 0.4462\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5296 - val_loss: 0.5075\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5270 - val_loss: 0.3420\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5154 - val_loss: 0.3952\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4645 - val_loss: 0.3411\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4811 - val_loss: 0.4001\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4674 - val_loss: 0.4124\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4464 - val_loss: 0.3345\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4134 - val_loss: 0.3842\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4357 - val_loss: 0.4113\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3819 - val_loss: 0.3795\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3710 - val_loss: 0.3585\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3820 - val_loss: 0.3835\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3594 - val_loss: 0.4049\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3577 - val_loss: 0.3440\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3498 - val_loss: 0.3463\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3470 - val_loss: 0.3447\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3617 - val_loss: 0.3828\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3242 - val_loss: 0.3464\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3050 - val_loss: 0.3177\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2930 - val_loss: 0.3640\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2827 - val_loss: 0.3127\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2689 - val_loss: 0.3707\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2750 - val_loss: 0.3527\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2491 - val_loss: 0.3256\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2524 - val_loss: 0.3276\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2431 - val_loss: 0.3590\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2512 - val_loss: 0.3199\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2261 - val_loss: 0.3199\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2165 - val_loss: 0.3635\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2162 - val_loss: 0.3495\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2169 - val_loss: 0.3158\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2019 - val_loss: 0.3329\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2026 - val_loss: 0.3376\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1960 - val_loss: 0.3680\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1899 - val_loss: 0.3111\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1960 - val_loss: 0.3302\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1856 - val_loss: 0.3219\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1744 - val_loss: 0.3117\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1643 - val_loss: 0.3201\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1855 - val_loss: 0.3251\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1592 - val_loss: 0.3434\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1695 - val_loss: 0.3280\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1560 - val_loss: 0.3220\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1545 - val_loss: 0.3386\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1639 - val_loss: 0.3327\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1527 - val_loss: 0.3314\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1472 - val_loss: 0.3104\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1488 - val_loss: 0.3260\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1470 - val_loss: 0.3184\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1369 - val_loss: 0.3192\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1471 - val_loss: 0.3120\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1448 - val_loss: 0.3197\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1455 - val_loss: 0.3017\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1401 - val_loss: 0.3059\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1381 - val_loss: 0.3001\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1320 - val_loss: 0.3023\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1371 - val_loss: 0.3012\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1413 - val_loss: 0.3074\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1400 - val_loss: 0.3017\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1356 - val_loss: 0.3010\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1326 - val_loss: 0.3205\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1467 - val_loss: 0.3015\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1308 - val_loss: 0.3028\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1321 - val_loss: 0.3000\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1351 - val_loss: 0.3054\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1377 - val_loss: 0.3056\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1360 - val_loss: 0.3051\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1374 - val_loss: 0.3020\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1244 - val_loss: 0.3048\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1242 - val_loss: 0.3069\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1306 - val_loss: 0.3047\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1389 - val_loss: 0.3081\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1373 - val_loss: 0.2985\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1309 - val_loss: 0.3081\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1398 - val_loss: 0.2990\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1341 - val_loss: 0.3012\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1365 - val_loss: 0.3018\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1325 - val_loss: 0.3016\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1282 - val_loss: 0.3017\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1371 - val_loss: 0.3013\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1286 - val_loss: 0.3089\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1381 - val_loss: 0.3004\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1317 - val_loss: 0.2992\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1316 - val_loss: 0.3004\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1385 - val_loss: 0.2971\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1262 - val_loss: 0.3082\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1353 - val_loss: 0.2975\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1377 - val_loss: 0.2999ss: 0\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1335 - val_loss: 0.3017\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1314 - val_loss: 0.3033\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1403 - val_loss: 0.2998\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1395 - val_loss: 0.3017\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1439 - val_loss: 0.3120\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1343 - val_loss: 0.3001\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1369 - val_loss: 0.2979\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1257 - val_loss: 0.2965\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1362 - val_loss: 0.3131\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1424 - val_loss: 0.3027\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1315 - val_loss: 0.3061\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1345 - val_loss: 0.3019\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1375 - val_loss: 0.2975\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1358 - val_loss: 0.2968\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1293 - val_loss: 0.2979\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1298 - val_loss: 0.3043\n",
      "Epoch 170/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1391 - val_loss: 0.3023\n",
      "Epoch 171/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1379 - val_loss: 0.3014ss: 0.138\n",
      "Epoch 172/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1317 - val_loss: 0.2986\n",
      "Epoch 173/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1348 - val_loss: 0.3005\n",
      "Epoch 174/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1300 - val_loss: 0.3016\n",
      "Epoch 175/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1330 - val_loss: 0.3088\n",
      "Epoch 176/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1361 - val_loss: 0.3030\n",
      "Epoch 00175: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total=14.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 31.7841 - val_loss: 1.0100\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2722 - val_loss: 1.1473\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0978 - val_loss: 0.9072\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0374 - val_loss: 0.5520\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7657 - val_loss: 0.5073\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.7628 - val_loss: 0.4138\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.8056 - val_loss: 0.9362\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7348 - val_loss: 0.4019\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7631 - val_loss: 0.5100\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6666 - val_loss: 0.6844\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.7651 - val_loss: 0.5252\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7199 - val_loss: 0.3796\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6649 - val_loss: 0.7479\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6118 - val_loss: 0.5981\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5841 - val_loss: 0.4369\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5099 - val_loss: 0.9226\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5607 - val_loss: 0.4689\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5240 - val_loss: 0.6455\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5558 - val_loss: 0.5310\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4600 - val_loss: 0.5252\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3657 - val_loss: 0.5397\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4644 - val_loss: 0.3619\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4478 - val_loss: 1.0372\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4179 - val_loss: 0.7232\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3536 - val_loss: 0.7288\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2706 - val_loss: 0.5428\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2811 - val_loss: 0.5023\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3622 - val_loss: 0.5289\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2903 - val_loss: 0.7775\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2191 - val_loss: 0.4168\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2535 - val_loss: 0.3581\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2612 - val_loss: 0.4868\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1267 - val_loss: 0.5457\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0522 - val_loss: 0.3682\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1805 - val_loss: 0.5925\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0730 - val_loss: 0.4048\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0490 - val_loss: 0.4513\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0565 - val_loss: 0.4988\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0330 - val_loss: 0.5255\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0510 - val_loss: 0.7733\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9842 - val_loss: 0.4313\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9669 - val_loss: 0.5440\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9888 - val_loss: 0.6412\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9912 - val_loss: 0.5470\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9441 - val_loss: 0.4475\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8923 - val_loss: 0.5432\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8412 - val_loss: 0.5132\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8901 - val_loss: 0.5331\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8729 - val_loss: 0.3954\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8415 - val_loss: 0.5304\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7531 - val_loss: 0.4278\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7610 - val_loss: 0.4783\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7192 - val_loss: 0.3628\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7341 - val_loss: 0.3503\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6875 - val_loss: 0.3870\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7003 - val_loss: 0.3766\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7027 - val_loss: 0.5265\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6900 - val_loss: 0.4020\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6416 - val_loss: 0.3413\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6486 - val_loss: 0.4376\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5800 - val_loss: 0.3903\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5920 - val_loss: 0.4337\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5625 - val_loss: 0.4323\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5578 - val_loss: 0.4761\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5729 - val_loss: 0.3444\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5038 - val_loss: 0.3808\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4975 - val_loss: 0.3624\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4872 - val_loss: 0.5085\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4871 - val_loss: 0.3676\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4786 - val_loss: 0.4070\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4161 - val_loss: 0.4384\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4348 - val_loss: 0.3979\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4424 - val_loss: 0.4140\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4354 - val_loss: 0.4467\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4167 - val_loss: 0.3201\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3871 - val_loss: 0.3200\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3916 - val_loss: 0.4320\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3753 - val_loss: 0.3790\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3877 - val_loss: 0.3257\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3517 - val_loss: 0.3327\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3158 - val_loss: 0.3308\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3373 - val_loss: 0.3570\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3258 - val_loss: 0.3635\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3200 - val_loss: 0.3262\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2983 - val_loss: 0.3583\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2831 - val_loss: 0.3600\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2675 - val_loss: 0.3368\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2893 - val_loss: 0.3313\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2713 - val_loss: 0.3873\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2621 - val_loss: 0.3864\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2525 - val_loss: 0.3426\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2307 - val_loss: 0.3352\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2083 - val_loss: 0.3235\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2246 - val_loss: 0.3200\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2341 - val_loss: 0.3181\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2269 - val_loss: 0.3182\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2104 - val_loss: 0.3234\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1996 - val_loss: 0.3146\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1839 - val_loss: 0.3123\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2123 - val_loss: 0.3660\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1763 - val_loss: 0.3283\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1786 - val_loss: 0.3225\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1668 - val_loss: 0.3171\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1849 - val_loss: 0.3130\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1820 - val_loss: 0.3147\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1719 - val_loss: 0.3342\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1683 - val_loss: 0.3185\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1694 - val_loss: 0.3214\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1610 - val_loss: 0.3170\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1538 - val_loss: 0.3095\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1532 - val_loss: 0.3103\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1671 - val_loss: 0.3285\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1637 - val_loss: 0.3132\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1482 - val_loss: 0.3097\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1576 - val_loss: 0.3105\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1523 - val_loss: 0.3036\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1581 - val_loss: 0.3121\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1482 - val_loss: 0.3096\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1456 - val_loss: 0.3042\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1435 - val_loss: 0.3104\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1333 - val_loss: 0.3093\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1419 - val_loss: 0.3049\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1385 - val_loss: 0.3049\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1437 - val_loss: 0.3075\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1423 - val_loss: 0.3219\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1443 - val_loss: 0.3169\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1305 - val_loss: 0.3078\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1361 - val_loss: 0.2998\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1358 - val_loss: 0.3010\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1371 - val_loss: 0.3058\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1339 - val_loss: 0.3204\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1536 - val_loss: 0.3099\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1394 - val_loss: 0.2995\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1317 - val_loss: 0.2995\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1367 - val_loss: 0.3100\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1380 - val_loss: 0.3055\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1359 - val_loss: 0.3063\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1359 - val_loss: 0.3028\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1343 - val_loss: 0.3101\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1325 - val_loss: 0.2987\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1268 - val_loss: 0.3042\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1320 - val_loss: 0.3018\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1324 - val_loss: 0.3006\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1264 - val_loss: 0.2989\n",
      "Epoch 145/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1290 - val_loss: 0.3019\n",
      "Epoch 146/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1413 - val_loss: 0.3016\n",
      "Epoch 147/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1460 - val_loss: 0.2982\n",
      "Epoch 148/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1235 - val_loss: 0.3053\n",
      "Epoch 149/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1389 - val_loss: 0.3058\n",
      "Epoch 150/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1358 - val_loss: 0.3000\n",
      "Epoch 151/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1309 - val_loss: 0.3002\n",
      "Epoch 152/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1400 - val_loss: 0.3005\n",
      "Epoch 153/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1394 - val_loss: 0.2956\n",
      "Epoch 154/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1317 - val_loss: 0.2975\n",
      "Epoch 155/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1448 - val_loss: 0.3033\n",
      "Epoch 156/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1475 - val_loss: 0.3060\n",
      "Epoch 157/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1406 - val_loss: 0.2969\n",
      "Epoch 158/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1465 - val_loss: 0.3003\n",
      "Epoch 159/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1403 - val_loss: 0.2984\n",
      "Epoch 160/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1423 - val_loss: 0.2998\n",
      "Epoch 161/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1268 - val_loss: 0.3000\n",
      "Epoch 162/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1310 - val_loss: 0.3006\n",
      "Epoch 163/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1406 - val_loss: 0.3007\n",
      "Epoch 164/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1301 - val_loss: 0.3046\n",
      "Epoch 165/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1366 - val_loss: 0.2990\n",
      "Epoch 166/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1397 - val_loss: 0.3007\n",
      "Epoch 167/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1392 - val_loss: 0.2993\n",
      "Epoch 168/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1304 - val_loss: 0.2985\n",
      "Epoch 169/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1370 - val_loss: 0.3021\n",
      "Epoch 170/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1446 - val_loss: 0.3075\n",
      "Epoch 171/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1374 - val_loss: 0.3008\n",
      "Epoch 172/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1320 - val_loss: 0.2988\n",
      "Epoch 173/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1385 - val_loss: 0.2977\n",
      "Epoch 174/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1443 - val_loss: 0.2979\n",
      "Epoch 175/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1505 - val_loss: 0.2998\n",
      "Epoch 176/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1437 - val_loss: 0.3054\n",
      "Epoch 177/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1387 - val_loss: 0.3003\n",
      "Epoch 178/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1406 - val_loss: 0.2980\n",
      "Epoch 179/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1343 - val_loss: 0.2988\n",
      "Epoch 00178: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total=13.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 24.0943 - val_loss: 0.3333\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7347 - val_loss: 0.2897\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6677 - val_loss: 0.4533\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5845 - val_loss: 0.5871\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6304 - val_loss: 0.9315\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5561 - val_loss: 0.9920\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6324 - val_loss: 0.3861\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4765 - val_loss: 0.4999\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4974 - val_loss: 0.5148\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5146 - val_loss: 0.5792\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3923 - val_loss: 0.5119\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4138 - val_loss: 0.4148\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3751 - val_loss: 0.4547\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3437 - val_loss: 0.3581\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2939 - val_loss: 0.3711\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2952 - val_loss: 0.7006\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2709 - val_loss: 0.4421\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4041 - val_loss: 0.7240\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3122 - val_loss: 0.4020\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2263 - val_loss: 0.4440\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2060 - val_loss: 0.4352\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2988 - val_loss: 0.3545\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2078 - val_loss: 0.4755\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1658 - val_loss: 0.5542\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2173 - val_loss: 0.7067\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2782 - val_loss: 0.4890\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1894 - val_loss: 0.4114\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1380 - val_loss: 0.6284\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total= 2.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 25.8892 - val_loss: 1.0870\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.7966 - val_loss: 1.1738\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.8138 - val_loss: 1.0664\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.8593 - val_loss: 1.2346\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9558 - val_loss: 1.1448\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.8161 - val_loss: 0.8532\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.9180 - val_loss: 1.5729\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.7355 - val_loss: 1.4432\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6134 - val_loss: 1.3359\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6776 - val_loss: 0.8554\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.5392 - val_loss: 0.6884\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.6155 - val_loss: 1.0073\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.5039 - val_loss: 0.8853\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.3640 - val_loss: 1.1785\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.4733 - val_loss: 0.9122\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2704 - val_loss: 1.0487\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2566 - val_loss: 1.0081\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2641 - val_loss: 0.7925\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1850 - val_loss: 1.1498\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.2141 - val_loss: 1.0100\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1372 - val_loss: 0.8506\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9927 - val_loss: 0.7997\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9993 - val_loss: 1.0631\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.0528 - val_loss: 0.8455\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7742 - val_loss: 0.9326\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8786 - val_loss: 0.6801\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7800 - val_loss: 0.8800\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7107 - val_loss: 0.9086\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.7147 - val_loss: 0.7016\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5835 - val_loss: 0.7998\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6700 - val_loss: 0.7619\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5885 - val_loss: 0.6426\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5813 - val_loss: 0.8005\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6035 - val_loss: 0.6755\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5257 - val_loss: 0.7959\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4329 - val_loss: 0.6433\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3839 - val_loss: 0.4988\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3903 - val_loss: 0.5821\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3376 - val_loss: 0.7185\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2666 - val_loss: 0.7944\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2191 - val_loss: 0.5903\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1888 - val_loss: 0.5975\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1346 - val_loss: 0.6719\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1707 - val_loss: 0.4370\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1903 - val_loss: 0.6528\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0238 - val_loss: 0.5371\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9807 - val_loss: 0.5438\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9964 - val_loss: 0.6144\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0208 - val_loss: 0.5917\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9613 - val_loss: 0.5777\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9435 - val_loss: 0.4310\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8941 - val_loss: 0.5811\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8166 - val_loss: 0.5303\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8188 - val_loss: 0.5294\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8102 - val_loss: 0.5020\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8124 - val_loss: 0.6619\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7369 - val_loss: 0.4152\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7100 - val_loss: 0.4458\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7480 - val_loss: 0.5172\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6504 - val_loss: 0.4686\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6283 - val_loss: 0.4673\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6372 - val_loss: 0.4245\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6223 - val_loss: 0.4330\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5966 - val_loss: 0.4401\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5501 - val_loss: 0.3957\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5742 - val_loss: 0.5092\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4977 - val_loss: 0.4201\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5071 - val_loss: 0.4404\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5283 - val_loss: 0.3942\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5006 - val_loss: 0.4125\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4630 - val_loss: 0.3654\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4281 - val_loss: 0.5288\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4293 - val_loss: 0.3726\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4060 - val_loss: 0.3470\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4313 - val_loss: 0.3662\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3704 - val_loss: 0.3817\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3665 - val_loss: 0.3567\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3546 - val_loss: 0.3587\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3603 - val_loss: 0.3317\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3208 - val_loss: 0.3732\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3528 - val_loss: 0.3417\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3155 - val_loss: 0.3547\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2991 - val_loss: 0.3406\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3044 - val_loss: 0.3560\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2887 - val_loss: 0.3373\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2682 - val_loss: 0.3625\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2767 - val_loss: 0.3547\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2464 - val_loss: 0.3491\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2509 - val_loss: 0.3407\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2536 - val_loss: 0.3366\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2414 - val_loss: 0.3271\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2337 - val_loss: 0.3391\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2551 - val_loss: 0.3261\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2200 - val_loss: 0.3240\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2344 - val_loss: 0.3342\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2269 - val_loss: 0.3250\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2069 - val_loss: 0.3313\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2127 - val_loss: 0.3238\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2162 - val_loss: 0.3242\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2063 - val_loss: 0.3024\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2028 - val_loss: 0.3081\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2046 - val_loss: 0.3143\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1998 - val_loss: 0.3103\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1869 - val_loss: 0.3341\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1833 - val_loss: 0.3070\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1984 - val_loss: 0.3001\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1847 - val_loss: 0.3044\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1945 - val_loss: 0.3050\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1738 - val_loss: 0.3028\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1917 - val_loss: 0.3017\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1911 - val_loss: 0.3067\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1887 - val_loss: 0.3015\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1763 - val_loss: 0.3073\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1835 - val_loss: 0.2984\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1777 - val_loss: 0.3017\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1784 - val_loss: 0.2995\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1864 - val_loss: 0.3064\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1711 - val_loss: 0.3003\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1800 - val_loss: 0.3002\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1681 - val_loss: 0.3023\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1850 - val_loss: 0.3030\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1817 - val_loss: 0.3030\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1860 - val_loss: 0.3086\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1786 - val_loss: 0.3023\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1694 - val_loss: 0.3060\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1787 - val_loss: 0.3036\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1709 - val_loss: 0.3019\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1772 - val_loss: 0.2995\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1798 - val_loss: 0.3039\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1780 - val_loss: 0.3014\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1704 - val_loss: 0.3038\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1798 - val_loss: 0.3001\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1697 - val_loss: 0.3012\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1749 - val_loss: 0.3027\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1825 - val_loss: 0.3032\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1740 - val_loss: 0.3006\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1845 - val_loss: 0.3024\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1743 - val_loss: 0.3039\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1789 - val_loss: 0.3022\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1697 - val_loss: 0.2992\n",
      "Epoch 00139: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=1, total=10.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 13.7760 - val_loss: 0.4167\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.5937 - val_loss: 1.1956\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 3s - loss: 1.3132 - val_loss: 0.3326\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 3s - loss: 1.2640 - val_loss: 1.7646\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9669 - val_loss: 1.4201ss: 0.9\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9615 - val_loss: 1.5897\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9616 - val_loss: 2.6478\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8070 - val_loss: 2.5407\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6960 - val_loss: 2.3854\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6920 - val_loss: 2.6501\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.6098 - val_loss: 2.7184\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5296 - val_loss: 2.3530\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4917 - val_loss: 2.4014\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4877 - val_loss: 2.2173\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4593 - val_loss: 2.0908\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3796 - val_loss: 1.9243\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4094 - val_loss: 1.9675\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3833 - val_loss: 1.6645\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3510 - val_loss: 1.9909\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3725 - val_loss: 1.7856\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3664 - val_loss: 1.6193\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3285 - val_loss: 1.9459\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3052 - val_loss: 1.6591\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3105 - val_loss: 1.5838\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2883 - val_loss: 1.5216\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3191 - val_loss: 1.6598\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2630 - val_loss: 1.4311\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2893 - val_loss: 1.2595\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2448 - val_loss: 1.4307\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 2.2min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 14.1486 - val_loss: 1.2284\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5738 - val_loss: 1.3454\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1500 - val_loss: 1.4552\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0957 - val_loss: 1.9277\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0298 - val_loss: 1.5402\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9096 - val_loss: 1.9504\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8115 - val_loss: 2.4048\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7205 - val_loss: 2.9531\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7068 - val_loss: 2.3680\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7225 - val_loss: 2.6577\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6219 - val_loss: 2.3909\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5280 - val_loss: 2.1987\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4993 - val_loss: 2.0894\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5568 - val_loss: 2.6385\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5473 - val_loss: 2.1812\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5184 - val_loss: 2.1615\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5126 - val_loss: 2.2391\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5300 - val_loss: 2.0712ss: 0.\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4622 - val_loss: 2.0793\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4610 - val_loss: 2.0163\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3820 - val_loss: 1.6092\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3669 - val_loss: 1.6291\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3688 - val_loss: 1.5317\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3873 - val_loss: 1.3869\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3317 - val_loss: 1.4004\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3249 - val_loss: 1.4687\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2932 - val_loss: 1.2067\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3016 - val_loss: 1.1405\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2567 - val_loss: 1.4828\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2807 - val_loss: 1.2473\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2293 - val_loss: 1.1609\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2391 - val_loss: 1.0084\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2508 - val_loss: 1.0118\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2409 - val_loss: 1.0847\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2463 - val_loss: 0.9169\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2114 - val_loss: 0.8186\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2136 - val_loss: 0.9858\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2140 - val_loss: 0.9132\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2014 - val_loss: 0.8448\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2136 - val_loss: 0.9713\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2065 - val_loss: 0.9503\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1939 - val_loss: 0.9273\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2076 - val_loss: 1.0796\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1863 - val_loss: 1.0706\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1807 - val_loss: 0.9894\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1887 - val_loss: 1.0171\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1841 - val_loss: 1.0192\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1804 - val_loss: 0.9964\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1722 - val_loss: 0.9491\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1710 - val_loss: 0.9414\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1671 - val_loss: 0.9573\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1850 - val_loss: 0.8784\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1682 - val_loss: 1.0613\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1788 - val_loss: 1.0075\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1681 - val_loss: 0.8416\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1628 - val_loss: 0.8470\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1480 - val_loss: 0.8566\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1711 - val_loss: 0.9741\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1566 - val_loss: 1.0185\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1629 - val_loss: 0.8635\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1690 - val_loss: 0.9864\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1654 - val_loss: 0.9471\n",
      "Epoch 00061: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 4.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 15.9709 - val_loss: 0.4416\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5576 - val_loss: 0.5875\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2311 - val_loss: 1.8042\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0741 - val_loss: 1.0916\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0265 - val_loss: 1.7799\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9135 - val_loss: 1.5804\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8200 - val_loss: 1.7054\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7797 - val_loss: 2.1631\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6691 - val_loss: 2.0003\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6656 - val_loss: 1.9104\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6608 - val_loss: 1.3969\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6278 - val_loss: 2.3039\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5844 - val_loss: 2.0409\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5380 - val_loss: 1.9191\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6451 - val_loss: 2.1735\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5758 - val_loss: 2.0082\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6395 - val_loss: 1.8461\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6204 - val_loss: 1.5953\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5406 - val_loss: 1.6633\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4882 - val_loss: 1.2646\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4601 - val_loss: 1.4305\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4158 - val_loss: 1.1018\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3374 - val_loss: 0.7494\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2969 - val_loss: 1.0240\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3108 - val_loss: 0.6432\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3467 - val_loss: 0.5351\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3074 - val_loss: 0.6573\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 2.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 15.8640 - val_loss: 0.6222\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.5859 - val_loss: 1.8901\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 3s - loss: 1.4022 - val_loss: 1.7281\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3189 - val_loss: 1.4558\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1192 - val_loss: 2.1988\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9813 - val_loss: 1.9144\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7809 - val_loss: 1.8538\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8350 - val_loss: 2.1450\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9495 - val_loss: 1.9513\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8641 - val_loss: 1.1988\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7818 - val_loss: 2.4218\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7505 - val_loss: 1.7563\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6371 - val_loss: 1.4731\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5686 - val_loss: 1.9279\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4763 - val_loss: 1.7738\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4337 - val_loss: 1.4967\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3909 - val_loss: 1.5618\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3571 - val_loss: 1.3004\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3733 - val_loss: 1.1832\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4029 - val_loss: 0.7392\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3322 - val_loss: 0.6552\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3174 - val_loss: 0.7816\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3284 - val_loss: 0.5823\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3158 - val_loss: 0.6247\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3116 - val_loss: 0.5143\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2930 - val_loss: 0.5390\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3150 - val_loss: 0.4882\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3194 - val_loss: 0.5131\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2882 - val_loss: 0.5570\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2790 - val_loss: 0.6252\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2954 - val_loss: 0.6244\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2892 - val_loss: 0.6842\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2935 - val_loss: 0.6536\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2783 - val_loss: 0.5613\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2875 - val_loss: 0.6355\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2574 - val_loss: 0.7020\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2769 - val_loss: 0.7415\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2829 - val_loss: 0.7806\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2690 - val_loss: 0.6302\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2604 - val_loss: 0.7556\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2666 - val_loss: 0.6568\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2575 - val_loss: 0.6606\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2596 - val_loss: 0.7640\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2656 - val_loss: 0.6282\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2508 - val_loss: 0.6070\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2461 - val_loss: 0.5524\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2698 - val_loss: 0.6472\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2652 - val_loss: 0.7844\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2570 - val_loss: 0.6702\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2627 - val_loss: 0.6095\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2449 - val_loss: 0.6549\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2631 - val_loss: 0.6863\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2517 - val_loss: 0.7131\n",
      "Epoch 00052: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 3.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 11.9431 - val_loss: 1.0481\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6181 - val_loss: 0.7954\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2775 - val_loss: 1.4783\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0394 - val_loss: 2.0057\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9023 - val_loss: 1.5887\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9419 - val_loss: 1.9772\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8559 - val_loss: 1.2521\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8733 - val_loss: 1.8507\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7492 - val_loss: 1.7690\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6212 - val_loss: 2.0562\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7127 - val_loss: 2.2793\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7396 - val_loss: 2.0257\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6843 - val_loss: 1.7352\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5700 - val_loss: 2.1240\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4993 - val_loss: 1.5470\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4891 - val_loss: 1.2590\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4001 - val_loss: 1.0676\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4119 - val_loss: 0.8906\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4523 - val_loss: 0.5729\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3610 - val_loss: 0.4658\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3585 - val_loss: 0.5001\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3166 - val_loss: 0.4894\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3063 - val_loss: 0.4348\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3179 - val_loss: 0.4801\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2892 - val_loss: 0.5231\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3061 - val_loss: 0.5184\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2911 - val_loss: 0.5123\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2865 - val_loss: 0.5250\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2809 - val_loss: 0.4783\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2961 - val_loss: 0.4850\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2732 - val_loss: 0.5683\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2814 - val_loss: 0.5266\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2764 - val_loss: 0.5260\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3096 - val_loss: 0.5097\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2862 - val_loss: 0.5476\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2705 - val_loss: 0.5187\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2467 - val_loss: 0.6204\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2478 - val_loss: 0.6463\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2636 - val_loss: 0.5711\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2598 - val_loss: 0.6191\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2644 - val_loss: 0.6292\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2678 - val_loss: 0.5679\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2327 - val_loss: 0.5342\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2519 - val_loss: 0.5712\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2474 - val_loss: 0.6287\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2575 - val_loss: 0.7039\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2480 - val_loss: 0.6334\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2472 - val_loss: 0.7219\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2414 - val_loss: 0.6850\n",
      "Epoch 00048: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=2, total= 3.7min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 18.0289 - val_loss: 1.6798\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.6086 - val_loss: 2.1997\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.1635 - val_loss: 1.5469\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.1801 - val_loss: 1.9604\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9067 - val_loss: 2.2646\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9571 - val_loss: 2.6147\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9062 - val_loss: 2.8686\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7672 - val_loss: 2.7402\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6896 - val_loss: 3.0886\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6393 - val_loss: 3.3065\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6311 - val_loss: 2.8538\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6630 - val_loss: 2.1812\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7060 - val_loss: 2.4419\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5494 - val_loss: 1.9934\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5268 - val_loss: 1.4650\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4468 - val_loss: 1.2942\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3757 - val_loss: 1.2071\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3901 - val_loss: 0.9123\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3527 - val_loss: 0.8563\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3485 - val_loss: 0.8866\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3396 - val_loss: 0.8728\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3489 - val_loss: 0.8082\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3276 - val_loss: 0.7004\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3036 - val_loss: 0.7087\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3184 - val_loss: 0.5859\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3110 - val_loss: 0.6202\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2997 - val_loss: 0.5945\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2902 - val_loss: 0.6054\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2998 - val_loss: 0.6161\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2747 - val_loss: 0.7151\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2773 - val_loss: 0.5337\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2892 - val_loss: 0.6406\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2906 - val_loss: 0.5903\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2693 - val_loss: 0.7495\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2909 - val_loss: 0.6300\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2680 - val_loss: 0.6380\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2803 - val_loss: 0.5785\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2787 - val_loss: 0.6313\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2802 - val_loss: 0.6095\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2652 - val_loss: 0.6207\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2547 - val_loss: 0.6255\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2712 - val_loss: 0.6231\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2662 - val_loss: 0.5227\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2667 - val_loss: 0.6006ss: 0\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2667 - val_loss: 0.6357\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2624 - val_loss: 0.5843\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2714 - val_loss: 0.5921\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2529 - val_loss: 0.5885\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2577 - val_loss: 0.6220\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2710 - val_loss: 0.5751\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2539 - val_loss: 0.5522\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2462 - val_loss: 0.5710\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2610 - val_loss: 0.5586\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2610 - val_loss: 0.5992\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2603 - val_loss: 0.5621\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2547 - val_loss: 0.5815\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2425 - val_loss: 0.5548\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2524 - val_loss: 0.5894\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2438 - val_loss: 0.6245\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2649 - val_loss: 0.4871\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2724 - val_loss: 0.5660\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2672 - val_loss: 0.5789\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2502 - val_loss: 0.5272\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2662 - val_loss: 0.6687\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2571 - val_loss: 0.7132\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2620 - val_loss: 0.5818\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2617 - val_loss: 0.6384\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2494 - val_loss: 0.5802\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2482 - val_loss: 0.5407\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2609 - val_loss: 0.5561\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2385 - val_loss: 0.5362\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2321 - val_loss: 0.5920\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2418 - val_loss: 0.6369\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2476 - val_loss: 0.5352\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2511 - val_loss: 0.5248\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2325 - val_loss: 0.5507\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2496 - val_loss: 0.4699\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2489 - val_loss: 0.4881\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2643 - val_loss: 0.4661\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2338 - val_loss: 0.5750\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2517 - val_loss: 0.6618\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2464 - val_loss: 0.4974\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2413 - val_loss: 0.5180\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2343 - val_loss: 0.5071\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2519 - val_loss: 0.5916\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2517 - val_loss: 0.5971\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2329 - val_loss: 0.5497\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2446 - val_loss: 0.5428\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2391 - val_loss: 0.5884\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2415 - val_loss: 0.5752\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2425 - val_loss: 0.5237\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2389 - val_loss: 0.5531\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2323 - val_loss: 0.5299\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2335 - val_loss: 0.5143\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2247 - val_loss: 0.5355\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2639 - val_loss: 0.5643\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2339 - val_loss: 0.5111\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2251 - val_loss: 0.5108\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2512 - val_loss: 0.5585\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2350 - val_loss: 0.5561\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2313 - val_loss: 0.5796\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2368 - val_loss: 0.4962\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2338 - val_loss: 0.5533\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2407 - val_loss: 0.5346\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2265 - val_loss: 0.5249\n",
      "Epoch 00104: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 7.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 14.0155 - val_loss: 1.3390\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6025 - val_loss: 2.5344\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3298 - val_loss: 2.5748\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0982 - val_loss: 2.5981\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9230 - val_loss: 2.9788\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8598 - val_loss: 2.6838\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7389 - val_loss: 3.6344\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7810 - val_loss: 3.1148\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8679 - val_loss: 3.3864\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7141 - val_loss: 2.9253\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6587 - val_loss: 3.1473\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5910 - val_loss: 3.0045\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5418 - val_loss: 3.0546\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5117 - val_loss: 2.8158\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5005 - val_loss: 2.6590\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4340 - val_loss: 2.5612\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4429 - val_loss: 2.0021\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4173 - val_loss: 1.2952\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4178 - val_loss: 0.6588\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4139 - val_loss: 0.5064\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3828 - val_loss: 0.4528\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4166 - val_loss: 0.3487\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4005 - val_loss: 0.3412\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3821 - val_loss: 0.3404\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3792 - val_loss: 0.3377\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3923 - val_loss: 0.3370\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.3370\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3796 - val_loss: 0.3370\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3807 - val_loss: 0.3377\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3748 - val_loss: 0.3369\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3729 - val_loss: 0.3372\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3568 - val_loss: 0.3370\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3666 - val_loss: 0.3369\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3796 - val_loss: 0.3370\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3702 - val_loss: 0.3392\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3664 - val_loss: 0.3369\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3503 - val_loss: 0.3381\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3835 - val_loss: 0.3372\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3610 - val_loss: 0.3368\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3716 - val_loss: 0.3370\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3544 - val_loss: 0.3368\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3664 - val_loss: 0.3434\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3560 - val_loss: 0.3369\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3567 - val_loss: 0.3376\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3711 - val_loss: 0.3406\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3681 - val_loss: 0.3368\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3429 - val_loss: 0.3368\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3520 - val_loss: 0.3387\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3630 - val_loss: 0.3370\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3629 - val_loss: 0.3376\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3553 - val_loss: 0.3372\n",
      "Epoch 00050: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 3.9min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 16.0991 - val_loss: 2.7668\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5230 - val_loss: 2.7784\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2377 - val_loss: 2.1363\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0366 - val_loss: 3.4556\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0383 - val_loss: 3.3207\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8439 - val_loss: 3.0286\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8417 - val_loss: 3.5672\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7274 - val_loss: 3.0688\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6924 - val_loss: 3.0856\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6716 - val_loss: 3.1919\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6262 - val_loss: 2.8457\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5431 - val_loss: 2.8873\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5151 - val_loss: 2.5240\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5483 - val_loss: 2.5686\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5004 - val_loss: 2.2432\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4488 - val_loss: 2.1655\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4327 - val_loss: 1.5130\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4342 - val_loss: 0.9382\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4210 - val_loss: 0.6953\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4079 - val_loss: 0.3442\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4144 - val_loss: 0.3367\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4148 - val_loss: 0.3412\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4022 - val_loss: 0.3436\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3799 - val_loss: 0.3370\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3885 - val_loss: 0.3388\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3932 - val_loss: 0.3385\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3740 - val_loss: 0.3415\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3825 - val_loss: 0.3407\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3799 - val_loss: 0.3400\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3771 - val_loss: 0.3381\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3815 - val_loss: 0.3374\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3662 - val_loss: 0.3368\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3605 - val_loss: 0.3368\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3697 - val_loss: 0.3370\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3594 - val_loss: 0.3368\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3699 - val_loss: 0.3379\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3760 - val_loss: 0.3373\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3783 - val_loss: 0.3386\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3679 - val_loss: 0.3371\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3741 - val_loss: 0.3368\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3731 - val_loss: 0.3386\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3609 - val_loss: 0.3419\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3687 - val_loss: 0.3372\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3630 - val_loss: 0.3418\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3632 - val_loss: 0.3369\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3663 - val_loss: 0.3369\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3575 - val_loss: 0.3369\n",
      "Epoch 00046: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 3.6min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 11.6664 - val_loss: 1.7562\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4833 - val_loss: 2.2554\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3100 - val_loss: 2.8348\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1240 - val_loss: 2.7276\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0433 - val_loss: 2.6651\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9194 - val_loss: 3.3850\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9069 - val_loss: 2.8632\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7391 - val_loss: 3.1520\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7097 - val_loss: 2.8784\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6533 - val_loss: 2.9086\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5948 - val_loss: 3.0153\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5503 - val_loss: 2.8411\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5605 - val_loss: 2.1942\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5333 - val_loss: 2.6221\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4200 - val_loss: 2.0781\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3870 - val_loss: 1.7953\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3611 - val_loss: 1.6371\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3771 - val_loss: 1.3696\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3481 - val_loss: 1.4034\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3438 - val_loss: 1.1487\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3615 - val_loss: 1.0223\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2852 - val_loss: 0.9574\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2979 - val_loss: 0.8828\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2885 - val_loss: 1.0918\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2677 - val_loss: 0.8965\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2694 - val_loss: 0.9075\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2885 - val_loss: 1.0882\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2674 - val_loss: 0.8263\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2570 - val_loss: 0.9128\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2598 - val_loss: 0.9554\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2664 - val_loss: 0.9418\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2446 - val_loss: 0.8582\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2398 - val_loss: 0.8049\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2301 - val_loss: 1.0322\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2452 - val_loss: 0.9415\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2506 - val_loss: 0.8852\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2291 - val_loss: 0.8973\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2303 - val_loss: 0.7839\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2428 - val_loss: 0.8450\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2490 - val_loss: 0.9405\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2328 - val_loss: 0.9435\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2576 - val_loss: 0.7825\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2340 - val_loss: 0.7985\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2204 - val_loss: 0.8054\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2255 - val_loss: 0.8179\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2111 - val_loss: 0.7187\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2261 - val_loss: 0.8188\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2122 - val_loss: 0.7385\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2162 - val_loss: 0.8601\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2217 - val_loss: 0.7447\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2132 - val_loss: 0.7911\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2169 - val_loss: 0.7915\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2080 - val_loss: 0.6892\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2054 - val_loss: 0.6860\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2123 - val_loss: 0.7444\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1987 - val_loss: 0.7779\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1946 - val_loss: 0.7790\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2128 - val_loss: 0.7582\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2038 - val_loss: 0.7806\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2070 - val_loss: 0.7346\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2094 - val_loss: 0.6259\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1959 - val_loss: 0.6632\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2187 - val_loss: 0.8282\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2077 - val_loss: 0.7718\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1882 - val_loss: 0.6820\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1995 - val_loss: 0.7097\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1947 - val_loss: 0.7505\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1900 - val_loss: 0.7091\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1951 - val_loss: 0.6125\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1799 - val_loss: 0.6815\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2051 - val_loss: 0.7777\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1965 - val_loss: 0.6847\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1999 - val_loss: 0.7065\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1857 - val_loss: 0.6981\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1827 - val_loss: 0.7001\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2373 - val_loss: 0.7361\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2092 - val_loss: 0.7142\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2028 - val_loss: 0.8112\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2163 - val_loss: 0.6673\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1912 - val_loss: 0.7244\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1989 - val_loss: 0.6500\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2079 - val_loss: 0.6087\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1979 - val_loss: 0.6963\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1927 - val_loss: 0.8136\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1801 - val_loss: 0.8296\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1865 - val_loss: 0.6688\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1893 - val_loss: 0.7950\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1922 - val_loss: 0.7430\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1851 - val_loss: 0.8084\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1914 - val_loss: 0.7662\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1731 - val_loss: 0.7603\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1918 - val_loss: 0.7146\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1720 - val_loss: 0.7097\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1786 - val_loss: 0.7782\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1915 - val_loss: 0.9375\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1916 - val_loss: 0.6982\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1941 - val_loss: 1.1446\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2143 - val_loss: 0.7870\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1958 - val_loss: 0.8357\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1845 - val_loss: 0.8991\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1773 - val_loss: 0.7062\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1987 - val_loss: 0.7365\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1842 - val_loss: 0.7792\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1842 - val_loss: 0.9147\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1914 - val_loss: 0.9172\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1887 - val_loss: 0.7902\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1765 - val_loss: 0.8284\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1775 - val_loss: 0.7923\n",
      "Epoch 00107: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 8.1min\n",
      "[CV] activation_function=relu, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 14.7385 - val_loss: 2.3260\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6577 - val_loss: 2.6513\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1992 - val_loss: 3.1994\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3244 - val_loss: 2.6139\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3791 - val_loss: 3.1666\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3240 - val_loss: 2.7153\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1827 - val_loss: 3.1529\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8730 - val_loss: 3.0937ss: 0.87\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8397 - val_loss: 2.9331\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7799 - val_loss: 3.5504\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7706 - val_loss: 2.6431\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6331 - val_loss: 3.1981\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.5408 - val_loss: 2.7350\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4839 - val_loss: 2.6458\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4841 - val_loss: 2.3311\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4207 - val_loss: 2.2872\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4210 - val_loss: 1.7732\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4054 - val_loss: 1.8512\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3885 - val_loss: 1.6273\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3066 - val_loss: 1.4508\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3213 - val_loss: 1.3995\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2851 - val_loss: 1.4106\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3036 - val_loss: 1.4598\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2927 - val_loss: 1.2111\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3045 - val_loss: 1.3319\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2633 - val_loss: 1.1116\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2613 - val_loss: 1.1080\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2513 - val_loss: 1.0733\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2837 - val_loss: 1.0546\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2611 - val_loss: 1.0395\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2592 - val_loss: 1.1862\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2564 - val_loss: 0.9876\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2644 - val_loss: 0.9705\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2457 - val_loss: 0.9542\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2452 - val_loss: 0.8743\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2402 - val_loss: 0.7683\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2225 - val_loss: 0.8428\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2179 - val_loss: 0.7474\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2026 - val_loss: 0.7808\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2139 - val_loss: 0.7768\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2017 - val_loss: 0.8193\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2187 - val_loss: 0.7123\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2109 - val_loss: 0.7588\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1994 - val_loss: 0.7509\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2206 - val_loss: 0.7588\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2070 - val_loss: 0.7664\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2195 - val_loss: 0.7434\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2136 - val_loss: 0.8063\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2148 - val_loss: 0.7528\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2045 - val_loss: 0.7368\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2023 - val_loss: 0.7596\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2215 - val_loss: 0.6670\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2086 - val_loss: 0.7821\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1970 - val_loss: 0.7492\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1906 - val_loss: 0.8513\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1933 - val_loss: 0.8105\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1918 - val_loss: 0.6554\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2017 - val_loss: 0.7447\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2096 - val_loss: 0.8848\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2138 - val_loss: 0.8769\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1982 - val_loss: 0.7073\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2075 - val_loss: 0.7411\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1995 - val_loss: 0.7269\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2122 - val_loss: 0.7672\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1871 - val_loss: 0.5850\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1918 - val_loss: 0.7464\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1671 - val_loss: 0.6902\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1776 - val_loss: 0.7854\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1817 - val_loss: 0.8288\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1784 - val_loss: 0.7368\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1755 - val_loss: 0.7330\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1661 - val_loss: 0.7955\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1864 - val_loss: 0.7514\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1735 - val_loss: 0.8136\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1774 - val_loss: 0.6932\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1697 - val_loss: 0.8004\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1671 - val_loss: 0.7254\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1567 - val_loss: 0.8260\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1820 - val_loss: 0.8376\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1836 - val_loss: 0.8484\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1787 - val_loss: 0.6332\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1765 - val_loss: 0.7823\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1745 - val_loss: 0.7577\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1637 - val_loss: 0.7412\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1981 - val_loss: 0.8772\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1867 - val_loss: 0.7741\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1482 - val_loss: 0.8913\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1681 - val_loss: 0.6748\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1707 - val_loss: 0.7986\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1776 - val_loss: 0.7584\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1724 - val_loss: 0.7617\n",
      "Epoch 00090: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=256, num_hidden_layers=3, total= 6.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 44.1019 - val_loss: 27.6986\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 19.2455 - val_loss: 9.8897\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 6.6301 - val_loss: 2.9923\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 2.4786 - val_loss: 0.8719\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.2143 - val_loss: 0.4077\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8983 - val_loss: 0.3405\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9084 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8249 - val_loss: 0.3370\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8660 - val_loss: 0.3380\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8216 - val_loss: 0.3376\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8372 - val_loss: 0.3369\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8632 - val_loss: 0.3392\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7990 - val_loss: 0.3381\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8110 - val_loss: 0.3373\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7922 - val_loss: 0.3377\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7978 - val_loss: 0.3372\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7758 - val_loss: 0.3377\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7490 - val_loss: 0.3392\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7529 - val_loss: 0.3369\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7272 - val_loss: 0.3375\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7067 - val_loss: 0.3378\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6734 - val_loss: 0.3378\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6425 - val_loss: 0.3376\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6573 - val_loss: 0.3371\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6362 - val_loss: 0.3395\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6142 - val_loss: 0.3368\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5909 - val_loss: 0.3379\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6035 - val_loss: 0.3368ss: \n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5971 - val_loss: 0.3368\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5934 - val_loss: 0.3368s\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5802 - val_loss: 0.3385\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5473 - val_loss: 0.3374\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5349 - val_loss: 0.3369\n",
      "Epoch 00032: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total=  48.1s\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 25.0533 - val_loss: 12.4025\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 7.9625 - val_loss: 2.9048\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2906 - val_loss: 0.6599\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0974 - val_loss: 0.3556\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9800 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0278 - val_loss: 0.3401\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9982 - val_loss: 0.3370\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9432 - val_loss: 0.3383\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9064 - val_loss: 0.3410\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8874 - val_loss: 0.3375\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8938 - val_loss: 0.3373\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8374 - val_loss: 0.3371\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7595 - val_loss: 0.3406\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7852 - val_loss: 0.3392\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7384 - val_loss: 0.3372\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7540 - val_loss: 0.3385\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6922 - val_loss: 0.3426\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7446 - val_loss: 0.3379\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6555 - val_loss: 0.3367\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6700 - val_loss: 0.3379\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6267 - val_loss: 0.3373\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6443 - val_loss: 0.3373\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5872 - val_loss: 0.3386\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5931 - val_loss: 0.3368\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5732 - val_loss: 0.3378\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5752 - val_loss: 0.3366\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5751 - val_loss: 0.3393\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5258 - val_loss: 0.3369\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5778 - val_loss: 0.3396\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5083 - val_loss: 0.3368\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5140 - val_loss: 0.3381\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total=  42.9s\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 42.7854 - val_loss: 26.5919\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 18.2327 - val_loss: 9.3823\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 6.2778 - val_loss: 2.7888\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2671 - val_loss: 0.8194\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1702 - val_loss: 0.3985\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8948 - val_loss: 0.3411\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8740 - val_loss: 0.3373\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8359 - val_loss: 0.3381\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8317 - val_loss: 0.3374\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8391 - val_loss: 0.3370\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8113 - val_loss: 0.3368\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7880 - val_loss: 0.3369\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7478 - val_loss: 0.3368\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7712 - val_loss: 0.3368\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7764 - val_loss: 0.3369\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7835 - val_loss: 0.3377\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6872 - val_loss: 0.3372\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6926 - val_loss: 0.3369\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7297 - val_loss: 0.3373\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6792 - val_loss: 0.3376\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6732 - val_loss: 0.3396\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6508 - val_loss: 0.3368\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6757 - val_loss: 0.3368\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6265 - val_loss: 0.3394\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5994 - val_loss: 0.3377\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5977 - val_loss: 0.3396\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5997 - val_loss: 0.3389\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5883 - val_loss: 0.3383\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5931 - val_loss: 0.3368\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5674 - val_loss: 0.3383\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5865 - val_loss: 0.3370\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5814 - val_loss: 0.3396\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5550 - val_loss: 0.3373ss:\n",
      "Epoch 00032: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total=  49.8s\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 3s - loss: 27.7114 - val_loss: 14.8200\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 0s - loss: 9.3692 - val_loss: 3.8361\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 0s - loss: 2.7279 - val_loss: 0.8702\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 0s - loss: 1.1947 - val_loss: 0.3771\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.9419 - val_loss: 0.3373\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8404 - val_loss: 0.3372\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8298 - val_loss: 0.3370\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8646 - val_loss: 0.3370\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8676 - val_loss: 0.3377\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8004 - val_loss: 0.3369\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.8225 - val_loss: 0.3374\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7853 - val_loss: 0.3370\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7554 - val_loss: 0.3376\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7904 - val_loss: 0.3377\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7396 - val_loss: 0.3381\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7434 - val_loss: 0.3374\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.7089 - val_loss: 0.3386\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6722 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6711 - val_loss: 0.3376\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6574 - val_loss: 0.3375\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6357 - val_loss: 0.3389\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6458 - val_loss: 0.3384\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6459 - val_loss: 0.3373\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.6199 - val_loss: 0.3375\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5704 - val_loss: 0.3375\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.5556 - val_loss: 0.3389\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5948 - val_loss: 0.3374\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5576 - val_loss: 0.3386\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5471 - val_loss: 0.3382\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5594 - val_loss: 0.3368\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4861 - val_loss: 0.3368\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total=  35.7s\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 37.5954 - val_loss: 22.4013\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 14.8680 - val_loss: 7.2461\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 4.8630 - val_loss: 1.9758\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.7854 - val_loss: 0.6029\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0203 - val_loss: 0.3644\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9364 - val_loss: 0.3377\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9332 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8395 - val_loss: 0.3369\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8508 - val_loss: 0.3371\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8144 - val_loss: 0.3376\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7827 - val_loss: 0.3379\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7701 - val_loss: 0.3375\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7450 - val_loss: 0.3373\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7389 - val_loss: 0.3390\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7766 - val_loss: 0.3368\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7639 - val_loss: 0.3373\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7425 - val_loss: 0.3390\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6978 - val_loss: 0.3395\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7182 - val_loss: 0.3381\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6294 - val_loss: 0.3368\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6491 - val_loss: 0.3371\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6601 - val_loss: 0.3389\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6731 - val_loss: 0.3368\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6246 - val_loss: 0.3369\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6219 - val_loss: 0.3376\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6142 - val_loss: 0.3387\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5921 - val_loss: 0.3388\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5627 - val_loss: 0.3369\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5712 - val_loss: 0.3371\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5683 - val_loss: 0.3374\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5223 - val_loss: 0.3383\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5618 - val_loss: 0.3374\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=1, total=  48.8s\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.9959 - val_loss: 0.9699\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.3625 - val_loss: 0.9152\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1599 - val_loss: 0.9087\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9891 - val_loss: 0.7241\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9156 - val_loss: 0.8424\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8763 - val_loss: 0.8779\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7842 - val_loss: 0.6135\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7296 - val_loss: 0.7648\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6417 - val_loss: 0.7257\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6108 - val_loss: 0.8398\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5874 - val_loss: 0.7227\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5421 - val_loss: 0.6771\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5305 - val_loss: 0.5566\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5325 - val_loss: 0.5379\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4952 - val_loss: 0.5375\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5011 - val_loss: 0.4237\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4695 - val_loss: 0.4996\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4552 - val_loss: 0.4664\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4432 - val_loss: 0.4663\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4470 - val_loss: 0.4097\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4538 - val_loss: 0.3897\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4523 - val_loss: 0.3699\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4151 - val_loss: 0.4077\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4169 - val_loss: 0.3860\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4213 - val_loss: 0.3697\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4345 - val_loss: 0.3910\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4263 - val_loss: 0.3786\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4280 - val_loss: 0.3570\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4142 - val_loss: 0.3687\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4106 - val_loss: 0.3531\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4025 - val_loss: 0.3828\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4090 - val_loss: 0.3437\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4044 - val_loss: 0.3534\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3984 - val_loss: 0.3403\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4094 - val_loss: 0.3573\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3986 - val_loss: 0.3448\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4343 - val_loss: 0.3420\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3946 - val_loss: 0.3416\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3975 - val_loss: 0.3415\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3970 - val_loss: 0.3394\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4000 - val_loss: 0.3419\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3870 - val_loss: 0.3368\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4069 - val_loss: 0.3448\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3802 - val_loss: 0.3384\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3909 - val_loss: 0.3493\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3958 - val_loss: 0.3369\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3984 - val_loss: 0.3376\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3897 - val_loss: 0.3462\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4040 - val_loss: 0.3368\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3868 - val_loss: 0.3493\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3889 - val_loss: 0.3381\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3925 - val_loss: 0.3442\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3936 - val_loss: 0.3376\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3744 - val_loss: 0.3372\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3958 - val_loss: 0.3373\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4012 - val_loss: 0.3379\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3773 - val_loss: 0.3378\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3944 - val_loss: 0.3392\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3872 - val_loss: 0.3404\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3720 - val_loss: 0.3370\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3696 - val_loss: 0.3382\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3913 - val_loss: 0.3369\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3777 - val_loss: 0.3368\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3828 - val_loss: 0.3385\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3781 - val_loss: 0.3380\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3832 - val_loss: 0.3372\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3716 - val_loss: 0.3453\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3556 - val_loss: 0.3369\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 1.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 2.1321 - val_loss: 0.5016\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.5554 - val_loss: 0.8099\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2887 - val_loss: 0.9839\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1540 - val_loss: 0.7320\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0044 - val_loss: 0.8158\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8888 - val_loss: 1.0080\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7737 - val_loss: 1.0044\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7880 - val_loss: 0.6375\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7195 - val_loss: 0.7479\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6622 - val_loss: 0.7168\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6376 - val_loss: 0.6405\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6058 - val_loss: 0.5922\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5790 - val_loss: 0.5337\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5335 - val_loss: 0.5239\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5255 - val_loss: 0.4375\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4961 - val_loss: 0.4920\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5002 - val_loss: 0.4987\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4785 - val_loss: 0.4732ss: 0.\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4861 - val_loss: 0.4515\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4694 - val_loss: 0.4660\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4638 - val_loss: 0.3649\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4546 - val_loss: 0.3978\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4549 - val_loss: 0.4235\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4623 - val_loss: 0.3875\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4238 - val_loss: 0.3490\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4416 - val_loss: 0.3912\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4373 - val_loss: 0.3827\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4206 - val_loss: 0.3727\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4360 - val_loss: 0.3602\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4336 - val_loss: 0.3503\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4220 - val_loss: 0.3413\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4281 - val_loss: 0.3669\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4100 - val_loss: 0.3441\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4161 - val_loss: 0.3467\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 0s - loss: 0.4003 - val_loss: 0.3369\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4128 - val_loss: 0.3495\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4066 - val_loss: 0.3435\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3901 - val_loss: 0.3369\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3911 - val_loss: 0.3534\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4105 - val_loss: 0.3419\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4093 - val_loss: 0.3377\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3863 - val_loss: 0.3423\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4214 - val_loss: 0.3453\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3962 - val_loss: 0.3385\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3805 - val_loss: 0.3509\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4221 - val_loss: 0.3438\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4025 - val_loss: 0.3394\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4066 - val_loss: 0.3376\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3988 - val_loss: 0.3419\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4048 - val_loss: 0.3408\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4029 - val_loss: 0.3405\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3873 - val_loss: 0.3368\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3793 - val_loss: 0.3375\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3847 - val_loss: 0.3437\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3880 - val_loss: 0.3368\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3940 - val_loss: 0.3393\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3984 - val_loss: 0.3368\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3846 - val_loss: 0.3369\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3798 - val_loss: 0.3404\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4028 - val_loss: 0.3369\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4032 - val_loss: 0.3371\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.8555 - val_loss: 0.7216\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4222 - val_loss: 1.1399\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2188 - val_loss: 0.7714\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0292 - val_loss: 0.8833\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9813 - val_loss: 1.0153\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8461 - val_loss: 1.0971\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7871 - val_loss: 0.7784\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6915 - val_loss: 0.8572\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6229 - val_loss: 0.9265\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6693 - val_loss: 0.7041\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5925 - val_loss: 0.7110\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5535 - val_loss: 0.7383\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5485 - val_loss: 0.5873\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5220 - val_loss: 0.5032\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5162 - val_loss: 0.4939\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4856 - val_loss: 0.5021\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4722 - val_loss: 0.4813\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4971 - val_loss: 0.4543\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4503 - val_loss: 0.4083\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4687 - val_loss: 0.3933\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4634 - val_loss: 0.4273\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4572 - val_loss: 0.4365\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4551 - val_loss: 0.3966\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4222 - val_loss: 0.3595\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4343 - val_loss: 0.4212\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4365 - val_loss: 0.4062\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4218 - val_loss: 0.3719\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4445 - val_loss: 0.3487\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4487 - val_loss: 0.3579\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4337 - val_loss: 0.3426\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4232 - val_loss: 0.3422\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4272 - val_loss: 0.3492\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4201 - val_loss: 0.3569\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4420 - val_loss: 0.3461\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4052 - val_loss: 0.3639\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4408 - val_loss: 0.3383\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4486 - val_loss: 0.3574\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4213 - val_loss: 0.3566\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4035 - val_loss: 0.3392\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4092 - val_loss: 0.3420\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4061 - val_loss: 0.3462\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4109 - val_loss: 0.3384\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3923 - val_loss: 0.3455\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4268 - val_loss: 0.3377\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4180 - val_loss: 0.3382\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3983 - val_loss: 0.3379\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4029 - val_loss: 0.3449\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4059 - val_loss: 0.3372\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3886 - val_loss: 0.3369\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4061 - val_loss: 0.3368\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3909 - val_loss: 0.3393\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4082 - val_loss: 0.3416\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3972 - val_loss: 0.3369\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4031 - val_loss: 0.3418\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3952 - val_loss: 0.3372ss:\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3884 - val_loss: 0.3398\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4066 - val_loss: 0.3376\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3907 - val_loss: 0.3521\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3889 - val_loss: 0.3374\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3927 - val_loss: 0.3374\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4064 - val_loss: 0.3386\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3962 - val_loss: 0.3382\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4066 - val_loss: 0.3368\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3934 - val_loss: 0.3375\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3969 - val_loss: 0.3395\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4015 - val_loss: 0.3382\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3826 - val_loss: 0.3371\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3965 - val_loss: 0.3373\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3861 - val_loss: 0.3395\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3826 - val_loss: 0.3387\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3905 - val_loss: 0.3385\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3823 - val_loss: 0.3378\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3703 - val_loss: 0.3376\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3879 - val_loss: 0.3386ss: 0.38\n",
      "Epoch 00073: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 1.7min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6704 - val_loss: 0.7750\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1653 - val_loss: 1.0707ss: \n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0510 - val_loss: 0.4838\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8980 - val_loss: 0.9138\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8459 - val_loss: 0.8330\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7258 - val_loss: 0.7474\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7282 - val_loss: 0.6905\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6291 - val_loss: 0.6985\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5805 - val_loss: 0.6078\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5948 - val_loss: 0.6507\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5569 - val_loss: 0.5517\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5377 - val_loss: 0.5096\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5374 - val_loss: 0.4612\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5057 - val_loss: 0.4336\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5202 - val_loss: 0.4581\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5023 - val_loss: 0.3885\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4805 - val_loss: 0.4127\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4963 - val_loss: 0.4015\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4534 - val_loss: 0.3874\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4304 - val_loss: 0.3791\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4639 - val_loss: 0.3532\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4623 - val_loss: 0.3843\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4570 - val_loss: 0.3389\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4457 - val_loss: 0.3471\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4408 - val_loss: 0.3556\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4486 - val_loss: 0.3468\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4463 - val_loss: 0.3565\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4333 - val_loss: 0.3409\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4244 - val_loss: 0.3509\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4535 - val_loss: 0.3401\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4334 - val_loss: 0.3943\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4507 - val_loss: 0.3588\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4373 - val_loss: 0.3436\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4119 - val_loss: 0.3485\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4197 - val_loss: 0.3437\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4505 - val_loss: 0.3407\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4006 - val_loss: 0.3385\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4139 - val_loss: 0.3564\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4174 - val_loss: 0.3518\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4229 - val_loss: 0.3369\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4347 - val_loss: 0.3428\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4128 - val_loss: 0.3370\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4257 - val_loss: 0.3447\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4296 - val_loss: 0.3381\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3989 - val_loss: 0.3441\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4273 - val_loss: 0.3368\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4112 - val_loss: 0.3368\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4150 - val_loss: 0.3376\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4212 - val_loss: 0.3370\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4044 - val_loss: 0.3376\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4271 - val_loss: 0.3401\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4108 - val_loss: 0.3371\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3974 - val_loss: 0.3375\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4062 - val_loss: 0.3371\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3961 - val_loss: 0.3448ss: 0.37 - ETA: 0s - los\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4226 - val_loss: 0.3397\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3878 - val_loss: 0.3415\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3949 - val_loss: 0.3410\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4052 - val_loss: 0.3383\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3925 - val_loss: 0.3378ss: 0.3\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4040 - val_loss: 0.3372ss: 0.\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3969 - val_loss: 0.3419\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3965 - val_loss: 0.3372\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3881 - val_loss: 0.3387ss: 0\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4053 - val_loss: 0.3408\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3931 - val_loss: 0.3452\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 1.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9334 - val_loss: 0.4081\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4196 - val_loss: 0.6730\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2586 - val_loss: 0.6922\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1032 - val_loss: 0.8993\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9718 - val_loss: 0.8545\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8646 - val_loss: 1.4040\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7848 - val_loss: 0.8836\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7895 - val_loss: 0.8578\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7665 - val_loss: 0.7962\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6515 - val_loss: 0.8541\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5841 - val_loss: 0.7721\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6286 - val_loss: 0.6607\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5445 - val_loss: 0.6604\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5581 - val_loss: 0.6139\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5364 - val_loss: 0.5982\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5399 - val_loss: 0.5668\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5247 - val_loss: 0.4832\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4662 - val_loss: 0.4360\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4650 - val_loss: 0.4189\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4548 - val_loss: 0.4127\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4433 - val_loss: 0.4037\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4589 - val_loss: 0.3802\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4465 - val_loss: 0.3680\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4456 - val_loss: 0.3629\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4409 - val_loss: 0.3573\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4360 - val_loss: 0.3483\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4409 - val_loss: 0.3656\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4393 - val_loss: 0.3734\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4289 - val_loss: 0.3559\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4269 - val_loss: 0.3743\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4050 - val_loss: 0.3610\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4350 - val_loss: 0.3557\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4344 - val_loss: 0.3535\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4224 - val_loss: 0.3613\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4248 - val_loss: 0.3403\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4175 - val_loss: 0.3538\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4138 - val_loss: 0.3487\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4064 - val_loss: 0.3439\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4105 - val_loss: 0.3407\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3953 - val_loss: 0.3375\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4153 - val_loss: 0.3400\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4154 - val_loss: 0.3486\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4186 - val_loss: 0.3471\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4062 - val_loss: 0.3372\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4075 - val_loss: 0.3428\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4075 - val_loss: 0.3399\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4076 - val_loss: 0.3528\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4094 - val_loss: 0.3369\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4096 - val_loss: 0.3430\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3924 - val_loss: 0.3379\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4055 - val_loss: 0.3430\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4002 - val_loss: 0.3497\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4121 - val_loss: 0.3370\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4059 - val_loss: 0.3396\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3905 - val_loss: 0.3528\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4121 - val_loss: 0.3377\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3860 - val_loss: 0.3454\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3895 - val_loss: 0.3371\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3860 - val_loss: 0.3370\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3783 - val_loss: 0.3407\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4075 - val_loss: 0.3403\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4048 - val_loss: 0.3412\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3842 - val_loss: 0.3399\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4123 - val_loss: 0.3370\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3893 - val_loss: 0.3381\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3958 - val_loss: 0.3368\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=2, total= 1.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.6980 - val_loss: 1.3094\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.1954 - val_loss: 0.9761\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 1s - loss: 1.0466 - val_loss: 0.9756\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.9220 - val_loss: 0.8955\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.8726 - val_loss: 1.0090\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.7896 - val_loss: 0.9509\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6769 - val_loss: 0.8152\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6170 - val_loss: 0.7438\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.6413 - val_loss: 0.5820\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5900 - val_loss: 0.5684\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5409 - val_loss: 0.5525\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5358 - val_loss: 0.5339\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5097 - val_loss: 0.5088\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4819 - val_loss: 0.4666\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4722 - val_loss: 0.4644\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4461 - val_loss: 0.4503\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4691 - val_loss: 0.3859\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4476 - val_loss: 0.3950\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4427 - val_loss: 0.3831\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4396 - val_loss: 0.4094\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4305 - val_loss: 0.3860\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4339 - val_loss: 0.3784\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4271 - val_loss: 0.3880\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4357 - val_loss: 0.3505\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4214 - val_loss: 0.3993\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4158 - val_loss: 0.3486\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4023 - val_loss: 0.3696\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4255 - val_loss: 0.3414\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4165 - val_loss: 0.3480\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4059 - val_loss: 0.3553\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4216 - val_loss: 0.3374\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4117 - val_loss: 0.3372\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4159 - val_loss: 0.3521\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3976 - val_loss: 0.3461\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3998 - val_loss: 0.3386\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3843 - val_loss: 0.3569\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3987 - val_loss: 0.3462\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4087 - val_loss: 0.3415\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4008 - val_loss: 0.3415\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4048 - val_loss: 0.3437\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3956 - val_loss: 0.3511\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3831 - val_loss: 0.3378\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3833 - val_loss: 0.3396\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3930 - val_loss: 0.3368\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3970 - val_loss: 0.3426\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3898 - val_loss: 0.3369\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3941 - val_loss: 0.3374\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3907 - val_loss: 0.3436\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3839 - val_loss: 0.3419\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3976 - val_loss: 0.3389\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3838 - val_loss: 0.3391\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3767 - val_loss: 0.3377\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3767 - val_loss: 0.3442\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3864 - val_loss: 0.3377\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.4038 - val_loss: 0.3459\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3899 - val_loss: 0.3373\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3925 - val_loss: 0.3368\n",
      "Epoch 00056: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9116 - val_loss: 1.9131\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4864 - val_loss: 2.0057\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1939 - val_loss: 1.6672\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0596 - val_loss: 1.5825\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9777 - val_loss: 1.0666\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9003 - val_loss: 1.1724\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8043 - val_loss: 0.8245\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7403 - val_loss: 0.9313\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7058 - val_loss: 0.8111\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6650 - val_loss: 0.6890\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6196 - val_loss: 0.6392\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5984 - val_loss: 0.5680\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5276 - val_loss: 0.5663\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5236 - val_loss: 0.4883\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5118 - val_loss: 0.4543\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5136 - val_loss: 0.4849\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4681 - val_loss: 0.4649\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4737 - val_loss: 0.4450\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4730 - val_loss: 0.4158\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4628 - val_loss: 0.4020\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4721 - val_loss: 0.3761\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4446 - val_loss: 0.4059\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4243 - val_loss: 0.3905\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4304 - val_loss: 0.3971\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4347 - val_loss: 0.3754\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4165 - val_loss: 0.3672\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4156 - val_loss: 0.3500\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4244 - val_loss: 0.3683\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4209 - val_loss: 0.3420\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4292 - val_loss: 0.3532\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3988 - val_loss: 0.3467\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4049 - val_loss: 0.3411\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4143 - val_loss: 0.3707\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3779 - val_loss: 0.3473\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4078 - val_loss: 0.3391\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3885 - val_loss: 0.3813\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3881 - val_loss: 0.3589\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4084 - val_loss: 0.3411\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4076 - val_loss: 0.3407\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3890 - val_loss: 0.3425\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3847 - val_loss: 0.3472\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4027 - val_loss: 0.3368\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4214 - val_loss: 0.3460\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3977 - val_loss: 0.3368\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3969 - val_loss: 0.3398\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4091 - val_loss: 0.3547\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4065 - val_loss: 0.3378\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3749 - val_loss: 0.3368\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3945 - val_loss: 0.3385\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3900 - val_loss: 0.3441\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3964 - val_loss: 0.3383\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3927 - val_loss: 0.3368\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3909 - val_loss: 0.3428\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3915 - val_loss: 0.3377\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3824 - val_loss: 0.3430\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3879 - val_loss: 0.3377\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3812 - val_loss: 0.3383\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3730 - val_loss: 0.3385\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3874 - val_loss: 0.3378\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3761 - val_loss: 0.3371\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3763 - val_loss: 0.3368\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3895 - val_loss: 0.3382\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3744 - val_loss: 0.3435\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3802 - val_loss: 0.3427\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3842 - val_loss: 0.3380\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3712 - val_loss: 0.3376\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3794 - val_loss: 0.3416\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3816 - val_loss: 0.3408\n",
      "Epoch 00067: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 1.7min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9029 - val_loss: 1.4344\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4055 - val_loss: 1.2538\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1174 - val_loss: 1.2391\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0642 - val_loss: 1.3961\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9701 - val_loss: 1.1519\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8382 - val_loss: 1.3278\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8123 - val_loss: 1.0481\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7809 - val_loss: 0.8419\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7079 - val_loss: 0.7381\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6435 - val_loss: 0.8125\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6297 - val_loss: 0.7441\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5815 - val_loss: 0.7376\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5426 - val_loss: 0.6442\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5298 - val_loss: 0.6783\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5095 - val_loss: 0.5057\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5391 - val_loss: 0.5568\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4872 - val_loss: 0.4885\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4657 - val_loss: 0.4700\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5028 - val_loss: 0.3887\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4495 - val_loss: 0.4262\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4611 - val_loss: 0.4012\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4504 - val_loss: 0.3853\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4453 - val_loss: 0.4143\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4565 - val_loss: 0.3601\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4311 - val_loss: 0.3526\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4468 - val_loss: 0.3871\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4327 - val_loss: 0.3718\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4317 - val_loss: 0.3429\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4257 - val_loss: 0.4190\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4359 - val_loss: 0.3640\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4194 - val_loss: 0.3445\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4169 - val_loss: 0.3584\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4327 - val_loss: 0.3520\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4104 - val_loss: 0.3469\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4302 - val_loss: 0.3372\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4121 - val_loss: 0.3443\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4219 - val_loss: 0.3430\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4125 - val_loss: 0.3369\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4323 - val_loss: 0.3417\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4139 - val_loss: 0.3458\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4008 - val_loss: 0.3401\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3983 - val_loss: 0.3388\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3955 - val_loss: 0.3381\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4096 - val_loss: 0.3369\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4253 - val_loss: 0.3412\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4089 - val_loss: 0.3377\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4028 - val_loss: 0.3371\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3904 - val_loss: 0.3373\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3986 - val_loss: 0.3391\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4018 - val_loss: 0.3452\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3886 - val_loss: 0.3521\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3958 - val_loss: 0.3368\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3820 - val_loss: 0.3376\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3912 - val_loss: 0.3391\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3953 - val_loss: 0.3519\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3776 - val_loss: 0.3427\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3944 - val_loss: 0.3423\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3893 - val_loss: 0.3370\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3981 - val_loss: 0.3371\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3945 - val_loss: 0.3387\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3886 - val_loss: 0.3372\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 1.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9020 - val_loss: 1.3304\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.3215 - val_loss: 1.1925\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1171 - val_loss: 1.2957\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9470 - val_loss: 1.3783\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9425 - val_loss: 1.0490\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8157 - val_loss: 0.8627\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7305 - val_loss: 1.0156\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6512 - val_loss: 0.7791\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6706 - val_loss: 0.6763\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6117 - val_loss: 0.6129\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6261 - val_loss: 0.4466\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5682 - val_loss: 0.4815\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5569 - val_loss: 0.5246\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5209 - val_loss: 0.4661\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5098 - val_loss: 0.4683\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5085 - val_loss: 0.4074\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4884 - val_loss: 0.3980\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4677 - val_loss: 0.4105\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4544 - val_loss: 0.4039\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4798 - val_loss: 0.3935\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4837 - val_loss: 0.3944\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4394 - val_loss: 0.3872\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4446 - val_loss: 0.3693\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4627 - val_loss: 0.4154\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4667 - val_loss: 0.3734\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4466 - val_loss: 0.3496\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4441 - val_loss: 0.3524\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4313 - val_loss: 0.3375\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4363 - val_loss: 0.3421\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4168 - val_loss: 0.3428\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4428 - val_loss: 0.3460\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4379 - val_loss: 0.3480\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4202 - val_loss: 0.3423\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4218 - val_loss: 0.3462\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4365 - val_loss: 0.3371\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4034 - val_loss: 0.3445\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4146 - val_loss: 0.3416\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4235 - val_loss: 0.3388\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4122 - val_loss: 0.3455\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4182 - val_loss: 0.3547\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4013 - val_loss: 0.3521\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4015 - val_loss: 0.3373\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4192 - val_loss: 0.3372\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3971 - val_loss: 0.3462\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4226 - val_loss: 0.3368\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3971 - val_loss: 0.3383\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4082 - val_loss: 0.3392\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4079 - val_loss: 0.3376\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3997 - val_loss: 0.3368\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4148 - val_loss: 0.3386\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3995 - val_loss: 0.3381\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4165 - val_loss: 0.3375\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3890 - val_loss: 0.3396\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4189 - val_loss: 0.3372\n",
      "Epoch 00053: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 1.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.9242 - val_loss: 1.2524\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.4836 - val_loss: 1.0281\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2815 - val_loss: 1.1755\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.2608 - val_loss: 1.1510\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.0281 - val_loss: 0.9152\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9579 - val_loss: 1.2923\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8497 - val_loss: 1.1810\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7331 - val_loss: 1.1662\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7370 - val_loss: 0.7726\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7250 - val_loss: 0.8121\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6273 - val_loss: 0.6990\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.6078 - val_loss: 0.7340\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5635 - val_loss: 0.6643\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5735 - val_loss: 0.6068\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5513 - val_loss: 0.5938\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4872 - val_loss: 0.5601\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5274 - val_loss: 0.4617\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4944 - val_loss: 0.5083\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4914 - val_loss: 0.4642\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4763 - val_loss: 0.5163\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4643 - val_loss: 0.4220\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4719 - val_loss: 0.4104\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4355 - val_loss: 0.3856\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4537 - val_loss: 0.3755\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4665 - val_loss: 0.3978\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4348 - val_loss: 0.3766\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4453 - val_loss: 0.3770\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4258 - val_loss: 0.3652\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4218 - val_loss: 0.3767\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4123 - val_loss: 0.3787\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4139 - val_loss: 0.3553\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4345 - val_loss: 0.3463\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4195 - val_loss: 0.3478\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4138 - val_loss: 0.3483\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4099 - val_loss: 0.3495\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3940 - val_loss: 0.3424\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4099 - val_loss: 0.3605\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4236 - val_loss: 0.3759\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4170 - val_loss: 0.3488\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4006 - val_loss: 0.3585\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4019 - val_loss: 0.3369\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4055 - val_loss: 0.3421\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4157 - val_loss: 0.3489\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4128 - val_loss: 0.3395\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4031 - val_loss: 0.3415\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4251 - val_loss: 0.3408\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3837 - val_loss: 0.3379\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3856 - val_loss: 0.3477\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4034 - val_loss: 0.3492\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3917 - val_loss: 0.3442\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4092 - val_loss: 0.3371\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3964 - val_loss: 0.3372\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4085 - val_loss: 0.3375\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3885 - val_loss: 0.3385\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4004 - val_loss: 0.3373\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3881 - val_loss: 0.3374\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4020 - val_loss: 0.3369\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3954 - val_loss: 0.3427\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3981 - val_loss: 0.3371\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3955 - val_loss: 0.3368\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4037 - val_loss: 0.3379\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3897 - val_loss: 0.3397\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4119 - val_loss: 0.3379\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3838 - val_loss: 0.3384\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3852 - val_loss: 0.3404\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3894 - val_loss: 0.3368\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3746 - val_loss: 0.3399\n",
      "Epoch 00066: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=64, num_hidden_layers=3, total= 1.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s - loss: 68.8116 - val_loss: 31.8913\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 16.6171 - val_loss: 5.0069\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.7559 - val_loss: 0.6698\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0504 - val_loss: 0.3451\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9221 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8983 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8467 - val_loss: 0.3371\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8461 - val_loss: 0.3370\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8782 - val_loss: 0.3369\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8451 - val_loss: 0.3369\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8527 - val_loss: 0.3378\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7899 - val_loss: 0.3369\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8000 - val_loss: 0.3393\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7790 - val_loss: 0.3368\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6953 - val_loss: 0.3369\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7419 - val_loss: 0.3370\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7315 - val_loss: 0.3371\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7083 - val_loss: 0.3379\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6958 - val_loss: 0.3368\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7313 - val_loss: 0.3374\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6527 - val_loss: 0.3368\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6513 - val_loss: 0.3403\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6352 - val_loss: 0.3369\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6463 - val_loss: 0.3369\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6225 - val_loss: 0.3372\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5836 - val_loss: 0.3369\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5839 - val_loss: 0.3369\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5708 - val_loss: 0.3369\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5592 - val_loss: 0.3368\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5537 - val_loss: 0.3379\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5187 - val_loss: 0.3372\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 85.1683 - val_loss: 40.9737\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 22.7834 - val_loss: 8.0629\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4656 - val_loss: 1.2629\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4279 - val_loss: 0.3866\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0593 - val_loss: 0.3386\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0165 - val_loss: 0.3369\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0255 - val_loss: 0.3373\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9597 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0226 - val_loss: 0.3384\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9765 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9488 - val_loss: 0.3369\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9951 - val_loss: 0.3368\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8585 - val_loss: 0.3368\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8605 - val_loss: 0.3370\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8777 - val_loss: 0.3368\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8700 - val_loss: 0.3436\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8520 - val_loss: 0.3368\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8235 - val_loss: 0.3372\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8378 - val_loss: 0.3368\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8227 - val_loss: 0.3374\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7753 - val_loss: 0.3382\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7571 - val_loss: 0.3368\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8026 - val_loss: 0.3373\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7416 - val_loss: 0.3368\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7161 - val_loss: 0.3377\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7121 - val_loss: 0.3381ss: \n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6498 - val_loss: 0.3371\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6551 - val_loss: 0.3372\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6756 - val_loss: 0.3368\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6097 - val_loss: 0.3376\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5951 - val_loss: 0.3379\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5771 - val_loss: 0.3367\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 89.0696 - val_loss: 45.7130\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 25.5414 - val_loss: 9.6579\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1347 - val_loss: 1.4516\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3678 - val_loss: 0.3946\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9237 - val_loss: 0.3377\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9687 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9136 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9147 - val_loss: 0.3370ss: 0.91\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8698 - val_loss: 0.3369\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8309 - val_loss: 0.3381\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8575 - val_loss: 0.3380\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8441 - val_loss: 0.3380\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7831 - val_loss: 0.3369\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8172 - val_loss: 0.3368\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8134 - val_loss: 0.3372\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7612 - val_loss: 0.3368\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7492 - val_loss: 0.3374\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7407 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7064 - val_loss: 0.3369\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7301 - val_loss: 0.3370\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7048 - val_loss: 0.3368\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6728 - val_loss: 0.3371\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6764 - val_loss: 0.3374\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6971 - val_loss: 0.3368\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6573 - val_loss: 0.3368\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6198 - val_loss: 0.3369\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6135 - val_loss: 0.3372\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6032 - val_loss: 0.3396\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5822 - val_loss: 0.3375\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5613 - val_loss: 0.3373\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5619 - val_loss: 0.3371\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 90.5286 - val_loss: 46.0176\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 25.7104 - val_loss: 9.8509\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1725 - val_loss: 1.5319\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3261 - val_loss: 0.4164\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8725 - val_loss: 0.3386\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8582 - val_loss: 0.3369\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8096 - val_loss: 0.3370\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8157 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8556 - val_loss: 0.3373\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8340 - val_loss: 0.3369\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7879 - val_loss: 0.3386\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7875 - val_loss: 0.3374\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7278 - val_loss: 0.3378\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7178 - val_loss: 0.3368\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7141 - val_loss: 0.3368\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7315 - val_loss: 0.3376\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7355 - val_loss: 0.3368\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7014 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6912 - val_loss: 0.3370\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6661 - val_loss: 0.3368ss: 0.668\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7055 - val_loss: 0.3383\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6298 - val_loss: 0.3373\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6396 - val_loss: 0.3368\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6794 - val_loss: 0.3373\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6162 - val_loss: 0.3369\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6002 - val_loss: 0.3370\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5928 - val_loss: 0.3368\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5769 - val_loss: 0.3390\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5559 - val_loss: 0.3368\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5676 - val_loss: 0.3374\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5436 - val_loss: 0.3368\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5398 - val_loss: 0.3380\n",
      "Epoch 00031: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 69.1464 - val_loss: 31.9260\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.4787 - val_loss: 5.0818\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7966 - val_loss: 0.6941\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0883 - val_loss: 0.3474\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9993 - val_loss: 0.3377\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9407 - val_loss: 0.3369\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9425 - val_loss: 0.3369\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0000 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8849 - val_loss: 0.3372\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9069 - val_loss: 0.3370\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9211 - val_loss: 0.3369\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8806 - val_loss: 0.3368\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8501 - val_loss: 0.3371\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7890 - val_loss: 0.3370\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8182 - val_loss: 0.3377\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7421 - val_loss: 0.3369\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7764 - val_loss: 0.3369\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7817 - val_loss: 0.3368\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7049 - val_loss: 0.3370\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6974 - val_loss: 0.3373\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6977 - val_loss: 0.3374\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6958 - val_loss: 0.3368\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6768 - val_loss: 0.3387\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6471 - val_loss: 0.3373\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6342 - val_loss: 0.3369\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5973 - val_loss: 0.3369\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6061 - val_loss: 0.3368\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5906 - val_loss: 0.3368\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6153 - val_loss: 0.3371\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6068 - val_loss: 0.3380s\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4989 - val_loss: 0.3379\n",
      "Epoch 00030: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s - loss: 2.2507 - val_loss: 1.1894\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.2695 - val_loss: 0.6723\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.1616 - val_loss: 0.8064\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9945 - val_loss: 1.3652\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8678 - val_loss: 0.9838\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7771 - val_loss: 0.7563\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7206 - val_loss: 1.2766\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6914 - val_loss: 1.0871\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6311 - val_loss: 1.1207\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5980 - val_loss: 0.6812\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5400 - val_loss: 0.9285\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5337 - val_loss: 0.6098\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4607 - val_loss: 0.9695\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4825 - val_loss: 0.7223\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4382 - val_loss: 0.7050\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4375 - val_loss: 0.7210\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4073 - val_loss: 0.6944\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4046 - val_loss: 0.5890\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4135 - val_loss: 0.5063\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4005 - val_loss: 0.6022\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3939 - val_loss: 0.4332\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3943 - val_loss: 0.4407\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3860 - val_loss: 0.4764\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3863 - val_loss: 0.3872\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3996 - val_loss: 0.3903\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3578 - val_loss: 0.4039\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3711 - val_loss: 0.3916\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3721 - val_loss: 0.4192\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3678 - val_loss: 0.3513\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3627 - val_loss: 0.3821\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3637 - val_loss: 0.3641\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3732 - val_loss: 0.3483\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3653 - val_loss: 0.3603\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3721 - val_loss: 0.3829\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3787 - val_loss: 0.3464\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3762 - val_loss: 0.3497\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3725 - val_loss: 0.3641\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3479 - val_loss: 0.3457\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3640 - val_loss: 0.3693\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3775 - val_loss: 0.3712\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3643 - val_loss: 0.3705\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3710 - val_loss: 0.3730\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3603 - val_loss: 0.3317\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3644 - val_loss: 0.3478\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3523 - val_loss: 0.3440\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3543 - val_loss: 0.3606\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3589 - val_loss: 0.3449\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3534 - val_loss: 0.3434\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3519 - val_loss: 0.3596\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3647 - val_loss: 0.3583\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3663 - val_loss: 0.4294\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3574 - val_loss: 0.3450\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3668 - val_loss: 0.4058\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3499 - val_loss: 0.3530\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3255 - val_loss: 0.3500\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3491 - val_loss: 0.4224\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3530 - val_loss: 0.3761\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3531 - val_loss: 0.4137\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3382 - val_loss: 0.3599\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3388 - val_loss: 0.3316\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3420 - val_loss: 0.3375\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3371 - val_loss: 0.3219\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3347 - val_loss: 0.3159\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3342 - val_loss: 0.3015\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3408 - val_loss: 0.3396\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3380 - val_loss: 0.3457\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3448 - val_loss: 0.3238\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3275 - val_loss: 0.2989\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3431 - val_loss: 0.2987\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3325 - val_loss: 0.3643\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3270 - val_loss: 0.3317\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3385 - val_loss: 0.3172\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3147 - val_loss: 0.3134\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3218 - val_loss: 0.3207\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3365 - val_loss: 0.2920\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3109 - val_loss: 0.2970\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2995 - val_loss: 0.3041\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3232 - val_loss: 0.2946\n",
      "Epoch 79/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2959 - val_loss: 0.2971\n",
      "Epoch 80/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2941 - val_loss: 0.2880\n",
      "Epoch 81/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3002 - val_loss: 0.3035\n",
      "Epoch 82/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3212 - val_loss: 0.3051\n",
      "Epoch 83/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3005 - val_loss: 0.2993\n",
      "Epoch 84/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3014 - val_loss: 0.2855\n",
      "Epoch 85/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2828 - val_loss: 0.3537\n",
      "Epoch 86/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.3004 - val_loss: 0.2894\n",
      "Epoch 87/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2955 - val_loss: 0.3068\n",
      "Epoch 88/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.2869 - val_loss: 0.2866\n",
      "Epoch 89/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2983 - val_loss: 0.3251\n",
      "Epoch 90/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3010 - val_loss: 0.2834\n",
      "Epoch 91/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2654 - val_loss: 0.2842\n",
      "Epoch 92/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2919 - val_loss: 0.3481\n",
      "Epoch 93/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2804 - val_loss: 0.3017\n",
      "Epoch 94/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2743 - val_loss: 0.3012\n",
      "Epoch 95/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2669 - val_loss: 0.2848\n",
      "Epoch 96/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2812 - val_loss: 0.2838\n",
      "Epoch 97/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2718 - val_loss: 0.2976\n",
      "Epoch 98/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2709 - val_loss: 0.2771\n",
      "Epoch 99/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2678 - val_loss: 0.3543\n",
      "Epoch 100/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2726 - val_loss: 0.2850\n",
      "Epoch 101/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2734 - val_loss: 0.3243\n",
      "Epoch 102/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2849 - val_loss: 0.2862\n",
      "Epoch 103/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2739 - val_loss: 0.2817\n",
      "Epoch 104/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2683 - val_loss: 0.2818\n",
      "Epoch 105/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2559 - val_loss: 0.3521\n",
      "Epoch 106/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2829 - val_loss: 0.2954\n",
      "Epoch 107/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2606 - val_loss: 0.2795\n",
      "Epoch 108/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2596 - val_loss: 0.2783\n",
      "Epoch 109/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2844 - val_loss: 0.2901\n",
      "Epoch 110/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2613 - val_loss: 0.3541\n",
      "Epoch 111/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2645 - val_loss: 0.2929\n",
      "Epoch 112/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2640 - val_loss: 0.2842\n",
      "Epoch 113/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2579 - val_loss: 0.2940\n",
      "Epoch 114/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2640 - val_loss: 0.2770\n",
      "Epoch 115/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2502 - val_loss: 0.2954\n",
      "Epoch 116/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2628 - val_loss: 0.2926\n",
      "Epoch 117/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2726 - val_loss: 0.3089\n",
      "Epoch 118/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2677 - val_loss: 0.3110\n",
      "Epoch 119/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2592 - val_loss: 0.3228\n",
      "Epoch 120/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2642 - val_loss: 0.2805\n",
      "Epoch 121/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2622 - val_loss: 0.3099\n",
      "Epoch 122/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2589 - val_loss: 0.2940\n",
      "Epoch 123/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2528 - val_loss: 0.3011\n",
      "Epoch 124/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.2498 - val_loss: 0.2881\n",
      "Epoch 00123: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 4.9min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.7021 - val_loss: 0.9386\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5152 - val_loss: 0.4633\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2777 - val_loss: 1.0337\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2698 - val_loss: 0.4948\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0406 - val_loss: 0.6984\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9405 - val_loss: 1.0870\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9103 - val_loss: 0.6387\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8011 - val_loss: 0.7919\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7230 - val_loss: 0.7141\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6305 - val_loss: 0.7311\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6294 - val_loss: 0.7991\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6039 - val_loss: 1.1806\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5749 - val_loss: 0.9009\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5032 - val_loss: 0.8770\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5036 - val_loss: 0.5718\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4903 - val_loss: 0.6176\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4491 - val_loss: 0.7253\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4673 - val_loss: 0.6705\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4299 - val_loss: 0.6021\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4376 - val_loss: 0.5971\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4180 - val_loss: 0.6349\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4392 - val_loss: 0.5316\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4164 - val_loss: 0.5166\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4105 - val_loss: 0.4715\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3943 - val_loss: 0.4679\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3948 - val_loss: 0.5017\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3996 - val_loss: 0.4265\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3874 - val_loss: 0.3489\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3878 - val_loss: 0.4039\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3766 - val_loss: 0.4389\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3937 - val_loss: 0.4072\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3847 - val_loss: 0.3662\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3793 - val_loss: 0.3722\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3794 - val_loss: 0.3957\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3899 - val_loss: 0.3596\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3716 - val_loss: 0.3458\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3924 - val_loss: 0.3631\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3703 - val_loss: 0.3975\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3735 - val_loss: 0.3492\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3744 - val_loss: 0.4008\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3748 - val_loss: 0.3542\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3772 - val_loss: 0.3759\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3735 - val_loss: 0.3410\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3764 - val_loss: 0.3415\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3649 - val_loss: 0.3728\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3638 - val_loss: 0.3390\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3691 - val_loss: 0.3474\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3614 - val_loss: 0.3472\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3668 - val_loss: 0.3390\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3666 - val_loss: 0.3401\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3853 - val_loss: 0.4330\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3670 - val_loss: 0.3369\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3738 - val_loss: 0.3589\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3753 - val_loss: 0.3757\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3539 - val_loss: 0.3829\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3694 - val_loss: 0.3425\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3666 - val_loss: 0.3399\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3605 - val_loss: 0.3466\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3685 - val_loss: 0.3478\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3659 - val_loss: 0.3390\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3734 - val_loss: 0.3381\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3542 - val_loss: 0.3579\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3690 - val_loss: 0.3436\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3706 - val_loss: 0.3467\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3528 - val_loss: 0.3462\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3553 - val_loss: 0.3400\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3512 - val_loss: 0.3374\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3757 - val_loss: 0.3450\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3752 - val_loss: 0.3389\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3504 - val_loss: 0.3369\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3634 - val_loss: 0.3373\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3706 - val_loss: 0.3467\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3651 - val_loss: 0.3371\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3645 - val_loss: 0.3391\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3534 - val_loss: 0.3422\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3570 - val_loss: 0.3369\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3614 - val_loss: 0.3375\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3717 - val_loss: 0.3368\n",
      "Epoch 00077: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 3.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.8394 - val_loss: 1.1500\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4070 - val_loss: 0.7395\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3199 - val_loss: 0.8250\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2304 - val_loss: 1.1159\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0962 - val_loss: 0.6461\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9432 - val_loss: 1.4522\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8275 - val_loss: 1.2254\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7244 - val_loss: 1.1885\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7473 - val_loss: 0.9556\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6757 - val_loss: 0.8364\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6323 - val_loss: 0.6645\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5954 - val_loss: 1.0933\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5759 - val_loss: 1.1235\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5867 - val_loss: 0.8997\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5045 - val_loss: 0.7415\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4902 - val_loss: 0.9348\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4920 - val_loss: 0.7177\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4588 - val_loss: 0.6554\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4362 - val_loss: 0.6543\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4456 - val_loss: 0.5639ss: 0.\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4219 - val_loss: 0.6757\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4243 - val_loss: 0.5689\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4430 - val_loss: 0.5441\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4207 - val_loss: 0.4942\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4035 - val_loss: 0.4500\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4008 - val_loss: 0.4330\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4001 - val_loss: 0.3921\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4098 - val_loss: 0.4515\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3994 - val_loss: 0.5076\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3880 - val_loss: 0.4000\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3926 - val_loss: 0.5026\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3760 - val_loss: 0.3896\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3939 - val_loss: 0.3860\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3930 - val_loss: 0.3697\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3761 - val_loss: 0.4129\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3997 - val_loss: 0.3968\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3966 - val_loss: 0.3642\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4090 - val_loss: 0.3773\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3839 - val_loss: 0.3478\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3842 - val_loss: 0.3462\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3865 - val_loss: 0.3557\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3821 - val_loss: 0.3511\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3809 - val_loss: 0.3896\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3753 - val_loss: 0.3575\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3825 - val_loss: 0.3656\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3685 - val_loss: 0.3553\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3837 - val_loss: 0.3660\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3743 - val_loss: 0.3692\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3756 - val_loss: 0.3507\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3564 - val_loss: 0.3416\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3714 - val_loss: 0.3388\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3643 - val_loss: 0.3368\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3786 - val_loss: 0.3375\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3632 - val_loss: 0.3551\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3938 - val_loss: 0.3720\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3750 - val_loss: 0.3664\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3616 - val_loss: 0.3424\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3680 - val_loss: 0.3520\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3647 - val_loss: 0.3388\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3798 - val_loss: 0.3370\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3775 - val_loss: 0.3431\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3749 - val_loss: 0.3524\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3654 - val_loss: 0.3394\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3742 - val_loss: 0.3450\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3623 - val_loss: 0.3448\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3633 - val_loss: 0.3407\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3731 - val_loss: 0.3521\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3750 - val_loss: 0.3714\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3606 - val_loss: 0.3565\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3602 - val_loss: 0.3340\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3707 - val_loss: 0.3599\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3537 - val_loss: 0.3837\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3617 - val_loss: 0.3404\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3580 - val_loss: 0.3421\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3458 - val_loss: 0.3681\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3606 - val_loss: 0.3481\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3548 - val_loss: 0.3298\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3523 - val_loss: 0.3258\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3736 - val_loss: 0.3388\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3898 - val_loss: 0.3521\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3648 - val_loss: 0.3401\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3808 - val_loss: 0.3475\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3836 - val_loss: 0.3368\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3537 - val_loss: 0.3391\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3671 - val_loss: 0.3422\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3623 - val_loss: 0.3378\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3687 - val_loss: 0.3525\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3659 - val_loss: 0.3403\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3527 - val_loss: 0.3373\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3596 - val_loss: 0.3448\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3645 - val_loss: 0.3379\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3700 - val_loss: 0.3686\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3510 - val_loss: 0.3372\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3726 - val_loss: 0.3389\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3561 - val_loss: 0.3422\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3633 - val_loss: 0.3476\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3622 - val_loss: 0.3368\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3693 - val_loss: 0.3426\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3665 - val_loss: 0.3369\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3503 - val_loss: 0.3446\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3671 - val_loss: 0.3401\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3556 - val_loss: 0.3462\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3565 - val_loss: 0.3559\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3659 - val_loss: 0.3380\n",
      "Epoch 00103: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 4.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.4938 - val_loss: 0.3558\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4280 - val_loss: 0.3554\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3649 - val_loss: 0.4187\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1179 - val_loss: 0.5651\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9673 - val_loss: 0.8547\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9123 - val_loss: 1.1019\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8716 - val_loss: 1.5794\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7902 - val_loss: 1.1592\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6741 - val_loss: 0.8309\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6573 - val_loss: 1.0648\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5826 - val_loss: 0.9314\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5725 - val_loss: 0.8578\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5423 - val_loss: 0.7383\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5236 - val_loss: 0.9712\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4764 - val_loss: 0.6678\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4806 - val_loss: 0.7710\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4580 - val_loss: 0.7222\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4824 - val_loss: 0.5582\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4333 - val_loss: 0.5293\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4228 - val_loss: 0.4947\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4319 - val_loss: 0.5674\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4286 - val_loss: 0.4831\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4218 - val_loss: 0.5166\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4262 - val_loss: 0.4307\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4108 - val_loss: 0.4774\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3906 - val_loss: 0.4467\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4085 - val_loss: 0.4011\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 1.2min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 2.3682 - val_loss: 0.4112\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3271 - val_loss: 0.3608\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1082 - val_loss: 0.3911\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0863 - val_loss: 0.3966\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9329 - val_loss: 0.8131\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7722 - val_loss: 0.6280\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7706 - val_loss: 0.7865\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7167 - val_loss: 0.6997\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6561 - val_loss: 0.6762\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5936 - val_loss: 0.8841\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5528 - val_loss: 0.6942\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5687 - val_loss: 0.8484\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5219 - val_loss: 0.6583\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5062 - val_loss: 0.8579\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4562 - val_loss: 0.6654\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4238 - val_loss: 0.6307\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4357 - val_loss: 0.4805\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4409 - val_loss: 0.5411\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4159 - val_loss: 0.4614\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4229 - val_loss: 0.4407\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3992 - val_loss: 0.5002\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4123 - val_loss: 0.5304\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4100 - val_loss: 0.4162\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3969 - val_loss: 0.4816\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4155 - val_loss: 0.3441\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3974 - val_loss: 0.4621\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3944 - val_loss: 0.3627\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4102 - val_loss: 0.3691\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3855 - val_loss: 0.3564\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3923 - val_loss: 0.3912\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4021 - val_loss: 0.3842\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3951 - val_loss: 0.3594\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3902 - val_loss: 0.3410\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3748 - val_loss: 0.3647\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3871 - val_loss: 0.3555\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3714 - val_loss: 0.3883\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3809 - val_loss: 0.3677\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3893 - val_loss: 0.3410\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3933 - val_loss: 0.3506\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3925 - val_loss: 0.3848\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3737 - val_loss: 0.3549\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3733 - val_loss: 0.3566\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3740 - val_loss: 0.3655\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3847 - val_loss: 0.3461\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3790 - val_loss: 0.3516\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3901 - val_loss: 0.3383\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3879 - val_loss: 0.3482\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3799 - val_loss: 0.3487\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3712 - val_loss: 0.3615\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3673 - val_loss: 0.3398\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3713 - val_loss: 0.3584\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3814 - val_loss: 0.3465\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3705 - val_loss: 0.3448\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3730 - val_loss: 0.3765\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3736 - val_loss: 0.3393\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3743 - val_loss: 0.3378\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3630 - val_loss: 0.3677\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3696 - val_loss: 0.3369\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3726 - val_loss: 0.3401\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3664 - val_loss: 0.3369\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3672 - val_loss: 0.3368\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3683 - val_loss: 0.3387\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3680 - val_loss: 0.3684\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3723 - val_loss: 0.3382\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3767 - val_loss: 0.3407\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3713 - val_loss: 0.3594\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3701 - val_loss: 0.3431\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3740 - val_loss: 0.3459\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3627 - val_loss: 0.3458\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3661 - val_loss: 0.3369\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3698 - val_loss: 0.3378\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3687 - val_loss: 0.3371\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3765 - val_loss: 0.3439\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3715 - val_loss: 0.3575\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3676 - val_loss: 0.3373\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3668 - val_loss: 0.3439\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3781 - val_loss: 0.3483\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3542 - val_loss: 0.3370\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3661 - val_loss: 0.3646\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3725 - val_loss: 0.3395\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3673 - val_loss: 0.3383\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3518 - val_loss: 0.3441\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3655 - val_loss: 0.3486\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3635 - val_loss: 0.3478\n",
      "Epoch 00083: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=2, total= 3.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 5s - loss: 1.5955 - val_loss: 1.2260\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.0682 - val_loss: 0.8154\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.9788 - val_loss: 1.5288\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.8596 - val_loss: 1.3111\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.7480 - val_loss: 1.4476\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.6914 - val_loss: 1.2592\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5872 - val_loss: 1.0452\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 1s - loss: 0.5933 - val_loss: 0.9169\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.5124 - val_loss: 0.9343\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4984 - val_loss: 0.8745\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4873 - val_loss: 0.7126\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4493 - val_loss: 0.6720\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4299 - val_loss: 0.8579\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4246 - val_loss: 0.5787\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4264 - val_loss: 0.5502\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4176 - val_loss: 0.4955\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.4094 - val_loss: 0.4152\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3972 - val_loss: 0.4396\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3921 - val_loss: 0.3778\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3959 - val_loss: 0.3894\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3764 - val_loss: 0.4163\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3873 - val_loss: 0.4317\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3725 - val_loss: 0.3571\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3554 - val_loss: 0.3993\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3736 - val_loss: 0.3614\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3632 - val_loss: 0.3618\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3740 - val_loss: 0.3431\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3694 - val_loss: 0.3545\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3787 - val_loss: 0.3606\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3680 - val_loss: 0.3645\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3815 - val_loss: 0.3370\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3709 - val_loss: 0.3394\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3744 - val_loss: 0.3828\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3610 - val_loss: 0.3885\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3463 - val_loss: 0.3630\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3807 - val_loss: 0.3402\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3691 - val_loss: 0.3557\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3644 - val_loss: 0.3369\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3656 - val_loss: 0.3558\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3484 - val_loss: 0.3438\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3519 - val_loss: 0.3515\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3648 - val_loss: 0.3462\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3456 - val_loss: 0.3374\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3614 - val_loss: 0.3455\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3617 - val_loss: 0.3523\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3475 - val_loss: 0.3370\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3757 - val_loss: 0.3370\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3641 - val_loss: 0.3659\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3564 - val_loss: 0.3488\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3473 - val_loss: 0.3445\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3468 - val_loss: 0.3368\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3672 - val_loss: 0.3366\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3743 - val_loss: 0.3485\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3653 - val_loss: 0.3368\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3539 - val_loss: 0.3472\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3568 - val_loss: 0.3428\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 2s - loss: 0.3615 - val_loss: 0.3660\n",
      "Epoch 00056: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 2.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.7667 - val_loss: 2.7859\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 1s - loss: 1.1911 - val_loss: 1.1102\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9956 - val_loss: 1.2805\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8812 - val_loss: 1.0297\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.8387 - val_loss: 1.0114\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7078 - val_loss: 1.3958\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7090 - val_loss: 1.3051\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.5907 - val_loss: 1.0483\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5992 - val_loss: 0.7741\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5511 - val_loss: 0.7730\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5253 - val_loss: 0.7913\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4508 - val_loss: 0.8733\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4456 - val_loss: 0.6146\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4296 - val_loss: 0.7698\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4374 - val_loss: 0.5541\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4493 - val_loss: 0.5390\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4021 - val_loss: 0.5427\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3941 - val_loss: 0.4952\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3943 - val_loss: 0.5478\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4049 - val_loss: 0.3947\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4145 - val_loss: 0.4216\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3921 - val_loss: 0.4159\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3903 - val_loss: 0.3551\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3824 - val_loss: 0.4155\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3803 - val_loss: 0.3925\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3896 - val_loss: 0.4141\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3773 - val_loss: 0.3783\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3798 - val_loss: 0.3519\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3729 - val_loss: 0.4011\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3670 - val_loss: 0.3636\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3843 - val_loss: 0.4284\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3654 - val_loss: 0.3686\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3754 - val_loss: 0.3656\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3638 - val_loss: 0.3404\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3777 - val_loss: 0.3368\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3761 - val_loss: 0.3402\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3724 - val_loss: 0.3534\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3782 - val_loss: 0.3369\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3605 - val_loss: 0.3515\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3727 - val_loss: 0.3423\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3600 - val_loss: 0.3881\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3763 - val_loss: 0.3368\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3526 - val_loss: 0.3672\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3622 - val_loss: 0.3377\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3849 - val_loss: 0.3431\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3555 - val_loss: 0.3424\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3611 - val_loss: 0.3399\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3600 - val_loss: 0.3674\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3783 - val_loss: 0.3434\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3529 - val_loss: 0.3378\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3597 - val_loss: 0.3414\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3715 - val_loss: 0.3726\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3798 - val_loss: 0.3368\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3610 - val_loss: 0.3383\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3666 - val_loss: 0.3435\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3686 - val_loss: 0.3519\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3633 - val_loss: 0.3471\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3694 - val_loss: 0.3393\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3767 - val_loss: 0.3390\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3507 - val_loss: 0.3756\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3537 - val_loss: 0.3426\n",
      "Epoch 00060: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 2.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 5s - loss: 1.6746 - val_loss: 2.1656\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1431 - val_loss: 1.5087\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0802 - val_loss: 1.1071\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.9715 - val_loss: 2.1851\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8425 - val_loss: 1.4324\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7256 - val_loss: 1.2736\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6652 - val_loss: 0.9775\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6378 - val_loss: 1.0340\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6031 - val_loss: 0.9264\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5126 - val_loss: 0.9116\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5139 - val_loss: 0.7103\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4801 - val_loss: 0.8549\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4938 - val_loss: 0.9266\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4450 - val_loss: 0.5583\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4265 - val_loss: 0.5445\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4187 - val_loss: 0.6025\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4050 - val_loss: 0.4771\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4048 - val_loss: 0.4904\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4068 - val_loss: 0.4527\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3929 - val_loss: 0.3862\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4115 - val_loss: 0.4677\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3934 - val_loss: 0.4079\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4104 - val_loss: 0.4342\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4109 - val_loss: 0.4448\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4142 - val_loss: 0.4360\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4040 - val_loss: 0.3434\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3902 - val_loss: 0.4089\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3816 - val_loss: 0.3701\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3812 - val_loss: 0.3880\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3915 - val_loss: 0.3540\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3867 - val_loss: 0.3502\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3728 - val_loss: 0.3567\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3789 - val_loss: 0.3401\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3776 - val_loss: 0.3594\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3913 - val_loss: 0.3768\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3795 - val_loss: 0.3818\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3704 - val_loss: 0.3473\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3947 - val_loss: 0.3488\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3827 - val_loss: 0.3372\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3815 - val_loss: 0.3421\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3898 - val_loss: 0.3617\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3670 - val_loss: 0.3494\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3863 - val_loss: 0.3450\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3756 - val_loss: 0.3445\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3776 - val_loss: 0.3683\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3779 - val_loss: 0.3561\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3614 - val_loss: 0.3519\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3632 - val_loss: 0.3580\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3749 - val_loss: 0.3436\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3641 - val_loss: 0.3601\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3578 - val_loss: 0.3386\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3722 - val_loss: 0.3760\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3795 - val_loss: 0.3398\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3638 - val_loss: 0.3382\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3676 - val_loss: 0.3441\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3653 - val_loss: 0.3535\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3707 - val_loss: 0.3438\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3593 - val_loss: 0.3383\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3755 - val_loss: 0.3406\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3626 - val_loss: 0.3368\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3573 - val_loss: 0.3577\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3620 - val_loss: 0.3375\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3716 - val_loss: 0.3388\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3707 - val_loss: 0.3573\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3841 - val_loss: 0.3403\n",
      "Epoch 00064: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 2.8min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.7297 - val_loss: 0.5837\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3553 - val_loss: 1.1217\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1573 - val_loss: 1.1657\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8519 - val_loss: 1.6937\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8206 - val_loss: 1.4004\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7198 - val_loss: 0.8673\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6489 - val_loss: 1.2797\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6187 - val_loss: 1.1513\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6039 - val_loss: 0.7416\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5078 - val_loss: 0.9057\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5172 - val_loss: 0.9086\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4968 - val_loss: 0.7831\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5004 - val_loss: 0.6615\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4827 - val_loss: 0.5424\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4317 - val_loss: 0.5559\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4358 - val_loss: 0.5052\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4362 - val_loss: 0.4931\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4227 - val_loss: 0.4463\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4294 - val_loss: 0.3981\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4170 - val_loss: 0.4372\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4072 - val_loss: 0.3698\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3966 - val_loss: 0.4486\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4024 - val_loss: 0.4191\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3886 - val_loss: 0.4186\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4036 - val_loss: 0.3678\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4058 - val_loss: 0.4027\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3887 - val_loss: 0.4199\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3860 - val_loss: 0.3556\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3899 - val_loss: 0.4107\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3805 - val_loss: 0.3446\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3972 - val_loss: 0.3623\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3826 - val_loss: 0.3609\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3978 - val_loss: 0.3379\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.4025 - val_loss: 0.3428\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3917 - val_loss: 0.3630\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3892 - val_loss: 0.3581\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3779 - val_loss: 0.3435\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3766 - val_loss: 0.3454\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3974 - val_loss: 0.3374\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3848 - val_loss: 0.3446\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3862 - val_loss: 0.3537\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3804 - val_loss: 0.3522\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3990 - val_loss: 0.3528\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3848 - val_loss: 0.3368\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3776 - val_loss: 0.3567\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3699 - val_loss: 0.3416\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3943 - val_loss: 0.3587\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3898 - val_loss: 0.3492\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3842 - val_loss: 0.3368\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3866 - val_loss: 0.3603\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3853 - val_loss: 0.3368\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4036 - val_loss: 0.3569\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3821 - val_loss: 0.3420\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3711 - val_loss: 0.3584\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3793 - val_loss: 0.3375\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3755 - val_loss: 0.3386\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3815 - val_loss: 0.3394\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3815 - val_loss: 0.3377\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3804 - val_loss: 0.3441\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3917 - val_loss: 0.3461\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3563 - val_loss: 0.3385\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3699 - val_loss: 0.3421\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3638 - val_loss: 0.3392\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3769 - val_loss: 0.3369\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3597 - val_loss: 0.3394\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3730 - val_loss: 0.3375\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3744 - val_loss: 0.3370\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3862 - val_loss: 0.3519\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3736 - val_loss: 0.3374\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3929 - val_loss: 0.3425\n",
      "Epoch 00069: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 3.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 6s - loss: 1.7753 - val_loss: 1.4042\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2195 - val_loss: 1.4050\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9879 - val_loss: 0.8784\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9560 - val_loss: 1.3407\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8117 - val_loss: 0.8738\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7427 - val_loss: 1.0844\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7048 - val_loss: 0.9049\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6487 - val_loss: 0.8783\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5747 - val_loss: 1.0175\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5594 - val_loss: 0.7414\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5211 - val_loss: 0.7619\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4997 - val_loss: 0.7168\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4568 - val_loss: 0.6642\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4455 - val_loss: 0.7686\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4426 - val_loss: 0.4953\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4194 - val_loss: 0.5596\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3988 - val_loss: 0.5484\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4158 - val_loss: 0.5354\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4183 - val_loss: 0.4701\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3979 - val_loss: 0.4588\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4174 - val_loss: 0.4128\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4023 - val_loss: 0.4257\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4019 - val_loss: 0.4308\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4072 - val_loss: 0.3701\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3966 - val_loss: 0.4060\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3873 - val_loss: 0.3831\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3739 - val_loss: 0.4122\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3901 - val_loss: 0.4312\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3839 - val_loss: 0.3498\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3822 - val_loss: 0.3909\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3992 - val_loss: 0.3961\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4004 - val_loss: 0.3612\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3793 - val_loss: 0.3473\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3864 - val_loss: 0.3607\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3692 - val_loss: 0.3396\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3828 - val_loss: 0.3405\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3673 - val_loss: 0.3525\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3699 - val_loss: 0.3409\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3960 - val_loss: 0.3567\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3918 - val_loss: 0.3406\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3844 - val_loss: 0.3467\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3658 - val_loss: 0.3472\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3802 - val_loss: 0.3368\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3633 - val_loss: 0.3372\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3853 - val_loss: 0.3641\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3806 - val_loss: 0.3425\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3648 - val_loss: 0.3642\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3745 - val_loss: 0.3532\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3894 - val_loss: 0.3524\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3565 - val_loss: 0.3636\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3661 - val_loss: 0.3386\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3723 - val_loss: 0.3377\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3642 - val_loss: 0.3404\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3706 - val_loss: 0.3513\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3841 - val_loss: 0.3735\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3837 - val_loss: 0.3373\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3851 - val_loss: 0.3526\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3752 - val_loss: 0.3738\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3737 - val_loss: 0.3371\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3664 - val_loss: 0.3642\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3733 - val_loss: 0.3370\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3698 - val_loss: 0.3432\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3630 - val_loss: 0.3567\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3749 - val_loss: 0.3448\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3835 - val_loss: 0.3377\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3592 - val_loss: 0.3372\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3643 - val_loss: 0.3553\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3642 - val_loss: 0.3365\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3588 - val_loss: 0.3366\n",
      "Epoch 00068: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=128, num_hidden_layers=3, total= 3.0min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 92.9668 - val_loss: 20.6650\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 6.4694 - val_loss: 0.5060\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8815 - val_loss: 0.3398\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8473 - val_loss: 0.3370\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8426 - val_loss: 0.3377\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7798 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8460 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7889 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7951 - val_loss: 0.3410\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7774 - val_loss: 0.3374\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7595 - val_loss: 0.3377\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7278 - val_loss: 0.3369\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7170 - val_loss: 0.3368\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7762 - val_loss: 0.3369\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6889 - val_loss: 0.3377\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6750 - val_loss: 0.3381\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7036 - val_loss: 0.3401\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7173 - val_loss: 0.3375\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6557 - val_loss: 0.3368\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6585 - val_loss: 0.3407\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5828 - val_loss: 0.3377\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.6169 - val_loss: 0.3368\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5818 - val_loss: 0.3376\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5934 - val_loss: 0.3369\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5589 - val_loss: 0.3386\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5729 - val_loss: 0.3376\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5419 - val_loss: 0.3374\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5371 - val_loss: 0.3377\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5134 - val_loss: 0.3418\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5168 - val_loss: 0.3442\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 131.0501 - val_loss: 37.9877\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 13.3080 - val_loss: 1.3599\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1531 - val_loss: 0.3340\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9455 - val_loss: 0.3368\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8651 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8567 - val_loss: 0.3372\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8799 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8677 - val_loss: 0.3371\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8497 - val_loss: 0.3368\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8972 - val_loss: 0.3376\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8106 - val_loss: 0.3367\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7385 - val_loss: 0.3372\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7668 - val_loss: 0.3366\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7688 - val_loss: 0.3369\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7561 - val_loss: 0.3370\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7608 - val_loss: 0.3369\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7323 - val_loss: 0.3369\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6904 - val_loss: 0.3381\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6721 - val_loss: 0.3373\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6591 - val_loss: 0.3383\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7082 - val_loss: 0.3387\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6489 - val_loss: 0.3372\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6562 - val_loss: 0.3384\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6296 - val_loss: 0.3369\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6066 - val_loss: 0.3396\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6114 - val_loss: 0.3370\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5954 - val_loss: 0.3399\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5736 - val_loss: 0.3412\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5838 - val_loss: 0.3371\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 130.0359 - val_loss: 39.8174\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 14.3502 - val_loss: 1.6609\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2044 - val_loss: 0.3388\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9161 - val_loss: 0.3371\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8894 - val_loss: 0.3373\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8461 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8839 - val_loss: 0.3377\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8228 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8372 - val_loss: 0.3378\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8562 - val_loss: 0.3369\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8102 - val_loss: 0.3373\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8034 - val_loss: 0.3375\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7885 - val_loss: 0.3372\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7529 - val_loss: 0.3374\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7697 - val_loss: 0.3384\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7728 - val_loss: 0.3354\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7036 - val_loss: 0.3335\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7306 - val_loss: 0.3346\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7204 - val_loss: 0.3370\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6557 - val_loss: 0.3307\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7088 - val_loss: 0.3299\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6657 - val_loss: 0.3281\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6177 - val_loss: 0.3285\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6525 - val_loss: 0.3257\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6101 - val_loss: 0.3243\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6116 - val_loss: 0.3257\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5721 - val_loss: 0.3304\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5806 - val_loss: 0.3223\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5556 - val_loss: 0.3252\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5458 - val_loss: 0.3262\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5538 - val_loss: 0.3367\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5250 - val_loss: 0.3369\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5053 - val_loss: 0.3366\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5406 - val_loss: 0.3368\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5201 - val_loss: 0.3429\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4828 - val_loss: 0.3373\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4847 - val_loss: 0.3384\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4882 - val_loss: 0.3372\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4691 - val_loss: 0.3406\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4487 - val_loss: 0.3371\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4719 - val_loss: 0.3365\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4395 - val_loss: 0.3313\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4416 - val_loss: 0.3297\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4285 - val_loss: 0.3307\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4178 - val_loss: 0.3242\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4073 - val_loss: 0.3282\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4079 - val_loss: 0.3222\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3970 - val_loss: 0.3263\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3795 - val_loss: 0.3275\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3860 - val_loss: 0.3220\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3844 - val_loss: 0.3192\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.3196\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3584 - val_loss: 0.3150\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3547 - val_loss: 0.3151\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3417 - val_loss: 0.3153\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3514 - val_loss: 0.3181\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3505 - val_loss: 0.3186\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3508 - val_loss: 0.3093\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3242 - val_loss: 0.3130\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3272 - val_loss: 0.3120\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3397 - val_loss: 0.3102\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3310 - val_loss: 0.3119\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3373 - val_loss: 0.3277\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3169 - val_loss: 0.3163\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3039 - val_loss: 0.3043\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3081 - val_loss: 0.3046\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2913 - val_loss: 0.3126\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3031 - val_loss: 0.2988\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3003 - val_loss: 0.3130\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2937 - val_loss: 0.2964\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3015 - val_loss: 0.3040\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3157 - val_loss: 0.2997\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2923 - val_loss: 0.3017\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2891 - val_loss: 0.3105\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2789 - val_loss: 0.3076\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2877 - val_loss: 0.3304\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2742 - val_loss: 0.3206\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2896 - val_loss: 0.3052\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2736 - val_loss: 0.3101\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2939 - val_loss: 0.3056\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2730 - val_loss: 0.3098\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2876 - val_loss: 0.2925\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2717 - val_loss: 0.3062\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2691 - val_loss: 0.2953\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2787 - val_loss: 0.3488\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2914 - val_loss: 0.2901\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2745 - val_loss: 0.2904\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2636 - val_loss: 0.2909\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2829 - val_loss: 0.3095\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2776 - val_loss: 0.3284\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2876 - val_loss: 0.3034\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2734 - val_loss: 0.2997\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2813 - val_loss: 0.2895\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2634 - val_loss: 0.3218\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2726 - val_loss: 0.3334\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2856 - val_loss: 0.3513\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2766 - val_loss: 0.3249\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2824 - val_loss: 0.3047\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2690 - val_loss: 0.3270\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2743 - val_loss: 0.2918\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2794 - val_loss: 0.3146\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2831 - val_loss: 0.3162\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2779 - val_loss: 0.3272\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2707 - val_loss: 0.3218\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2721 - val_loss: 0.3098\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2645 - val_loss: 0.3137\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2693 - val_loss: 0.3086\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2711 - val_loss: 0.3004\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2604 - val_loss: 0.3293\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2631 - val_loss: 0.3078\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2632 - val_loss: 0.3068\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2665 - val_loss: 0.3134\n",
      "Epoch 00111: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 8.4min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 151.0285 - val_loss: 50.4621\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 19.1678 - val_loss: 2.5612\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5309 - val_loss: 0.3450\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9751 - val_loss: 0.3364\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9008 - val_loss: 0.3375\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9727 - val_loss: 0.3371\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8990 - val_loss: 0.3366\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9112 - val_loss: 0.3377\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9532 - val_loss: 0.3378\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8774 - val_loss: 0.3377\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8719 - val_loss: 0.3391\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8670 - val_loss: 0.3380\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8376 - val_loss: 0.3382\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7976 - val_loss: 0.3377\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8025 - val_loss: 0.3370\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7741 - val_loss: 0.3369\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8296 - val_loss: 0.3379\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7761 - val_loss: 0.3371\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7748 - val_loss: 0.3371\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7401 - val_loss: 0.3368\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6892 - val_loss: 0.3377\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7290 - val_loss: 0.3381\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7081 - val_loss: 0.3370\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6805 - val_loss: 0.3376\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6711 - val_loss: 0.3376\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6390 - val_loss: 0.3391\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6496 - val_loss: 0.3369\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6734 - val_loss: 0.3370\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6260 - val_loss: 0.3378\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6026 - val_loss: 0.3380\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 136.7412 - val_loss: 44.7900\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 16.3312 - val_loss: 2.1113\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3014 - val_loss: 0.3411\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8616 - val_loss: 0.3370\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9343 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8731 - val_loss: 0.3368\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8851 - val_loss: 0.3369\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8643 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8997 - val_loss: 0.3368\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8353 - val_loss: 0.3368\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8229 - val_loss: 0.3373\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7793 - val_loss: 0.3369\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7856 - val_loss: 0.3386\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8381 - val_loss: 0.3383\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7964 - val_loss: 0.3388\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7726 - val_loss: 0.3368\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7723 - val_loss: 0.3378\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7510 - val_loss: 0.3370\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7452 - val_loss: 0.3386\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7123 - val_loss: 0.3371\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7098 - val_loss: 0.3378\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6867 - val_loss: 0.3374\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7142 - val_loss: 0.3373\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6099 - val_loss: 0.3375\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6306 - val_loss: 0.3421\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.6660 - val_loss: 0.3370\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6089 - val_loss: 0.3374\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5969 - val_loss: 0.3370\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6055 - val_loss: 0.3425\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5649 - val_loss: 0.3369\n",
      "Epoch 00029: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=1, total= 2.3min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 8s - loss: 3.7919 - val_loss: 0.3972\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.4077 - val_loss: 0.3868\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.3415 - val_loss: 1.9054\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.2024 - val_loss: 0.5061\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.0497 - val_loss: 0.7966\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9516 - val_loss: 0.4712\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9439 - val_loss: 0.4861\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8102 - val_loss: 0.3413\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7378 - val_loss: 0.9009\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6750 - val_loss: 0.5765\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5907 - val_loss: 0.7932\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5559 - val_loss: 0.5991\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5433 - val_loss: 1.0143\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4854 - val_loss: 0.6519\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4598 - val_loss: 0.7682\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4455 - val_loss: 0.8145\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4331 - val_loss: 0.7261\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4123 - val_loss: 0.5386\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4005 - val_loss: 0.5585\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4015 - val_loss: 0.7117\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4074 - val_loss: 0.6068\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3618 - val_loss: 0.4774\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3651 - val_loss: 0.4657\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3825 - val_loss: 0.6156\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3839 - val_loss: 0.5591\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3765 - val_loss: 0.6026\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3508 - val_loss: 0.4316\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3684 - val_loss: 0.4735\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3582 - val_loss: 0.5181\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3644 - val_loss: 0.3722\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3523 - val_loss: 0.3853\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3570 - val_loss: 0.3511\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3604 - val_loss: 0.3801\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3544 - val_loss: 0.3954\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 2.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 3.6094 - val_loss: 0.3451\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5234 - val_loss: 0.4215\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4163 - val_loss: 0.6339\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2291 - val_loss: 0.4749\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1039 - val_loss: 0.5028\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0159 - val_loss: 0.7824\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8478 - val_loss: 0.9457\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8129 - val_loss: 0.3378\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7636 - val_loss: 0.4879\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6927 - val_loss: 0.7481\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6116 - val_loss: 0.7656\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5766 - val_loss: 0.7999\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5549 - val_loss: 0.7805\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5115 - val_loss: 0.6859\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4691 - val_loss: 1.0180\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4452 - val_loss: 0.6801\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4263 - val_loss: 0.6604\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4244 - val_loss: 0.7497\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4101 - val_loss: 0.7312\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3844 - val_loss: 0.6215\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3902 - val_loss: 0.5441\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3893 - val_loss: 0.5107\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3959 - val_loss: 0.7354\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3976 - val_loss: 0.4899\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3685 - val_loss: 0.4187\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3638 - val_loss: 0.4070\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3655 - val_loss: 0.4550\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3552 - val_loss: 0.4970\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3728 - val_loss: 0.5601\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3585 - val_loss: 0.4141\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3657 - val_loss: 0.3990\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3622 - val_loss: 0.3947\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3651 - val_loss: 0.3625\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3385 - val_loss: 0.3801\n",
      "Epoch 00033: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 2.6min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 3.1619 - val_loss: 0.7067\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.4829 - val_loss: 0.4381\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3440 - val_loss: 0.5699\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1538 - val_loss: 0.8188\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0310 - val_loss: 0.4337\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9717 - val_loss: 0.5517\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8123 - val_loss: 0.6492\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7283 - val_loss: 0.6146\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7309 - val_loss: 0.5539\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6302 - val_loss: 0.7483\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6374 - val_loss: 0.4634\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5597 - val_loss: 0.7510\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5025 - val_loss: 0.5398\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4516 - val_loss: 0.6165\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4698 - val_loss: 0.6310\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4555 - val_loss: 0.5001\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4076 - val_loss: 0.5740\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4113 - val_loss: 0.5014\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4064 - val_loss: 0.5746\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4087 - val_loss: 0.5844\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3875 - val_loss: 0.5994\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3814 - val_loss: 0.7344\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3861 - val_loss: 0.3865\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3927 - val_loss: 0.4565\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4032 - val_loss: 0.5062\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3801 - val_loss: 0.4422\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3787 - val_loss: 0.4425\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3626 - val_loss: 0.3918\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3700 - val_loss: 0.3985\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3757 - val_loss: 0.3909\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3687 - val_loss: 0.4006\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3723 - val_loss: 0.4228\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3668 - val_loss: 0.4472\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3661 - val_loss: 0.3713\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3607 - val_loss: 0.3884ss: 0.3\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3511 - val_loss: 0.4423\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3769 - val_loss: 0.4183\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3633 - val_loss: 0.3807\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3639 - val_loss: 0.3773\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3659 - val_loss: 0.3452\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3601 - val_loss: 0.3826\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3677 - val_loss: 0.3916\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3793 - val_loss: 0.3522\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3565 - val_loss: 0.3617\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3598 - val_loss: 0.3427\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3642 - val_loss: 0.3626\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3573 - val_loss: 0.3401\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3729 - val_loss: 0.4461\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3787 - val_loss: 0.3655\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3595 - val_loss: 0.3596\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3686 - val_loss: 0.3424\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3608 - val_loss: 0.3460\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3497 - val_loss: 0.3730\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3657 - val_loss: 0.3421\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3595 - val_loss: 0.3457\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3544 - val_loss: 0.3579\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3695 - val_loss: 0.3518\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3504 - val_loss: 0.3689\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3605 - val_loss: 0.3394\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3437 - val_loss: 0.3767\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3771 - val_loss: 0.3370\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3436 - val_loss: 0.3680\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3619 - val_loss: 0.3403\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3603 - val_loss: 0.3501\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3578 - val_loss: 0.3763\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3575 - val_loss: 0.3711\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3446 - val_loss: 0.3370\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3550 - val_loss: 0.3434\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3493 - val_loss: 0.3528\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3585 - val_loss: 0.3459\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3448 - val_loss: 0.3377\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3522 - val_loss: 0.3383\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3538 - val_loss: 0.3401\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3535 - val_loss: 0.3512\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3420 - val_loss: 0.3416\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3688 - val_loss: 0.3632\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3468 - val_loss: 0.3643\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3505 - val_loss: 0.3373\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3586 - val_loss: 0.3421\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3528 - val_loss: 0.3447\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3372 - val_loss: 0.3381\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3560 - val_loss: 0.3440\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3368 - val_loss: 0.3375\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3483 - val_loss: 0.3435\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3514 - val_loss: 0.3509\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3594 - val_loss: 0.3369\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3654 - val_loss: 0.3524\n",
      "Epoch 00086: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 6.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 3.4640 - val_loss: 0.3390\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.6783 - val_loss: 0.6625\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3497 - val_loss: 0.4348\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2662 - val_loss: 0.3494\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1642 - val_loss: 0.4045\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9929 - val_loss: 0.6153\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9758 - val_loss: 0.4472\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8124 - val_loss: 0.6061\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7600 - val_loss: 0.3453\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6905 - val_loss: 0.5149\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6222 - val_loss: 0.6245\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5887 - val_loss: 0.4309\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5479 - val_loss: 0.5038\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5331 - val_loss: 0.4068\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5078 - val_loss: 0.4298\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4807 - val_loss: 0.4964\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4311 - val_loss: 0.4837\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4556 - val_loss: 0.6294\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4354 - val_loss: 0.5542\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4272 - val_loss: 0.4626\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4041 - val_loss: 0.3696\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4139 - val_loss: 0.4759\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3786 - val_loss: 0.5003\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3945 - val_loss: 0.4282\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3755 - val_loss: 0.5081\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3905 - val_loss: 0.4122\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3855 - val_loss: 0.4201\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 2.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 4.3359 - val_loss: 0.3689\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.5608 - val_loss: 0.3732\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2964 - val_loss: 0.6732\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1952 - val_loss: 1.4837\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0585 - val_loss: 0.8843\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0027 - val_loss: 0.7809\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9551 - val_loss: 0.4963\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8313 - val_loss: 0.5019\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7632 - val_loss: 0.4951\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6879 - val_loss: 0.6073\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6857 - val_loss: 1.2282\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5791 - val_loss: 0.7523\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5521 - val_loss: 0.8126\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4982 - val_loss: 0.7478\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5058 - val_loss: 0.5536\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4628 - val_loss: 0.8169ss\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4772 - val_loss: 0.8407\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4393 - val_loss: 0.5996\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4330 - val_loss: 0.5598\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4110 - val_loss: 0.6475\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4269 - val_loss: 0.5101\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3928 - val_loss: 0.7024\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4067 - val_loss: 0.7879ss: \n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3903 - val_loss: 0.6181\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3677 - val_loss: 0.5004\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3787 - val_loss: 0.5275\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3811 - val_loss: 0.5226\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=2, total= 2.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 1.8437 - val_loss: 0.9601\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 1.2279 - val_loss: 0.6730\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9989 - val_loss: 0.6406 ETA: 0s - loss: 1.003\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9080 - val_loss: 0.9299\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7687 - val_loss: 0.9373\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7181 - val_loss: 0.8836\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5901 - val_loss: 0.8556\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5348 - val_loss: 0.6151\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5006 - val_loss: 0.9143\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4847 - val_loss: 0.5176\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4392 - val_loss: 0.5566\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4184 - val_loss: 0.4922\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4128 - val_loss: 0.5553\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3952 - val_loss: 0.4377\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3951 - val_loss: 0.5392\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3726 - val_loss: 0.5892\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3708 - val_loss: 0.5389\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3612 - val_loss: 0.4840\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3682 - val_loss: 0.3824\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3587 - val_loss: 0.4420\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3702 - val_loss: 0.4394\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3461 - val_loss: 0.3996\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3647 - val_loss: 0.4240\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3545 - val_loss: 0.3873\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3671 - val_loss: 0.3712\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3464 - val_loss: 0.4069\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3532 - val_loss: 0.3558\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3550 - val_loss: 0.3847\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3567 - val_loss: 0.4301\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3543 - val_loss: 0.4726\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3495 - val_loss: 0.4023\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3655 - val_loss: 0.3582\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3579 - val_loss: 0.3396\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3542 - val_loss: 0.3697\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3586 - val_loss: 0.3517\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3511 - val_loss: 0.3385\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3604 - val_loss: 0.3861\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3246 - val_loss: 0.3416\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3440 - val_loss: 0.3386\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3496 - val_loss: 0.3515\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3467 - val_loss: 0.3388\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3479 - val_loss: 0.3451\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3501 - val_loss: 0.3444\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3462 - val_loss: 0.3604\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3542 - val_loss: 0.3779\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3589 - val_loss: 0.3386\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3456 - val_loss: 0.3395\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3489 - val_loss: 0.3474\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3456 - val_loss: 0.3384\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3534 - val_loss: 0.3383\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3344 - val_loss: 0.3598\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3448 - val_loss: 0.3368\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3460 - val_loss: 0.4899\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3475 - val_loss: 0.3586\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3414 - val_loss: 0.3472\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3516 - val_loss: 0.3368\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3352 - val_loss: 0.3422\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3505 - val_loss: 0.3793\n",
      "Epoch 59/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3393 - val_loss: 0.3436\n",
      "Epoch 60/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3402 - val_loss: 0.3821\n",
      "Epoch 61/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3528 - val_loss: 0.3795\n",
      "Epoch 62/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3467 - val_loss: 0.3399\n",
      "Epoch 63/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3479 - val_loss: 0.3420\n",
      "Epoch 64/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3431 - val_loss: 0.3585\n",
      "Epoch 65/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3337 - val_loss: 0.3414\n",
      "Epoch 66/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3371 - val_loss: 0.3375\n",
      "Epoch 67/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3446 - val_loss: 0.3419\n",
      "Epoch 68/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3395 - val_loss: 0.3504\n",
      "Epoch 69/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3453 - val_loss: 0.3590\n",
      "Epoch 70/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3449 - val_loss: 0.3543\n",
      "Epoch 71/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3457 - val_loss: 0.3395\n",
      "Epoch 72/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3453 - val_loss: 0.4004\n",
      "Epoch 73/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3334 - val_loss: 0.3933\n",
      "Epoch 74/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3460 - val_loss: 0.3741\n",
      "Epoch 75/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3382 - val_loss: 0.3385\n",
      "Epoch 76/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3497 - val_loss: 0.3416\n",
      "Epoch 77/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3471 - val_loss: 0.3368\n",
      "Epoch 78/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3377 - val_loss: 0.3409\n",
      "Epoch 00077: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 6.0min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 2.0466 - val_loss: 0.3671\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3879 - val_loss: 1.5726\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1725 - val_loss: 0.5932\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0290 - val_loss: 0.8100\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9288 - val_loss: 0.4983\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7387 - val_loss: 1.0094\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6817 - val_loss: 1.2447\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6188 - val_loss: 0.5704\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6114 - val_loss: 0.7677\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5171 - val_loss: 0.7077\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4718 - val_loss: 0.8564\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4439 - val_loss: 0.7151\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4380 - val_loss: 0.6269\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4223 - val_loss: 0.7207\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3901 - val_loss: 0.5330\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3900 - val_loss: 0.5930\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3729 - val_loss: 0.7717\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3909 - val_loss: 0.4002\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3741 - val_loss: 0.5102\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3619 - val_loss: 0.4799\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3610 - val_loss: 0.3701\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3773 - val_loss: 0.3957\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3663 - val_loss: 0.4159\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3607 - val_loss: 0.4341\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3562 - val_loss: 0.4582\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3826 - val_loss: 0.4354\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3679 - val_loss: 0.3919\n",
      "Epoch 00026: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 2.1min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 2.0561 - val_loss: 1.4078\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.3627 - val_loss: 2.1613\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1434 - val_loss: 0.6627\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9506 - val_loss: 1.0640\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8328 - val_loss: 0.9075\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7654 - val_loss: 0.9733\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6633 - val_loss: 1.0339\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6048 - val_loss: 0.6526\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5395 - val_loss: 0.9207\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5066 - val_loss: 0.6984\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4993 - val_loss: 0.7078\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4260 - val_loss: 0.7141\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4344 - val_loss: 0.6997\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4237 - val_loss: 0.4968\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3828 - val_loss: 0.5428\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4014 - val_loss: 0.6620\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3792 - val_loss: 0.6191\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3743 - val_loss: 0.4571\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4059 - val_loss: 0.5035\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3757 - val_loss: 0.4458\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3827 - val_loss: 0.4644\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3710 - val_loss: 0.4806\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3713 - val_loss: 0.3776\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3734 - val_loss: 0.4717\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3750 - val_loss: 0.3581\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3835 - val_loss: 0.3517\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3855 - val_loss: 0.4231\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3644 - val_loss: 0.3681\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3593 - val_loss: 0.3754\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3678 - val_loss: 0.3402\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3599 - val_loss: 0.4787\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3622 - val_loss: 0.3658\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3628 - val_loss: 0.4379\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3567 - val_loss: 0.3861\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3566 - val_loss: 0.4155\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3546 - val_loss: 0.3495\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3590 - val_loss: 0.3484\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3673 - val_loss: 0.3674\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3686 - val_loss: 0.3734\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3588 - val_loss: 0.3493\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3709 - val_loss: 0.3754\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3617 - val_loss: 0.4019\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3890 - val_loss: 0.3488\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3506 - val_loss: 0.3587\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3544 - val_loss: 0.3459\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3586 - val_loss: 0.3393\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3639 - val_loss: 0.3374\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3505 - val_loss: 0.3590\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3476 - val_loss: 0.3398\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3524 - val_loss: 0.3626\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3609 - val_loss: 0.3946ss:\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3645 - val_loss: 0.3559\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3726 - val_loss: 0.3806\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3516 - val_loss: 0.3755\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3609 - val_loss: 0.3712\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3660 - val_loss: 0.3674\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3576 - val_loss: 0.3553\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3548 - val_loss: 0.3392\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3546 - val_loss: 0.3525\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3617 - val_loss: 0.3750\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3651 - val_loss: 0.3543\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3542 - val_loss: 0.3394\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3595 - val_loss: 0.3516\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3667 - val_loss: 0.3917\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3654 - val_loss: 0.3395\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3782 - val_loss: 0.3407\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3616 - val_loss: 0.3453s\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3566 - val_loss: 0.3974\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3566 - val_loss: 0.3393\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3580 - val_loss: 0.3436\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3552 - val_loss: 0.3382\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3520 - val_loss: 0.3571\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3454 - val_loss: 0.3707\n",
      "Epoch 00072: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 5.7min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 1.9226 - val_loss: 1.1319\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2478 - val_loss: 0.7615\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1464 - val_loss: 0.5438\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0578 - val_loss: 0.7309\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9192 - val_loss: 0.5980\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8019 - val_loss: 1.3475\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7369 - val_loss: 0.6646\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6111 - val_loss: 0.7097\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5878 - val_loss: 0.7119\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5527 - val_loss: 0.5351s\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4824 - val_loss: 0.5870\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4824 - val_loss: 0.7002\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4674 - val_loss: 0.6974\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4288 - val_loss: 0.5767\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4102 - val_loss: 0.4969\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4188 - val_loss: 0.4266\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3991 - val_loss: 0.4773\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.4005 - val_loss: 0.4691\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3992 - val_loss: 0.4154\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3861 - val_loss: 0.4024\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3781 - val_loss: 0.4841\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3694 - val_loss: 0.4352\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3928 - val_loss: 0.3603\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3860 - val_loss: 0.4988\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3869 - val_loss: 0.3954\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3842 - val_loss: 0.3880\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3782 - val_loss: 0.3553\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3794 - val_loss: 0.3556\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3822 - val_loss: 0.3403\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3793 - val_loss: 0.4104\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3789 - val_loss: 0.3387\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3733 - val_loss: 0.3393\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3855 - val_loss: 0.3370\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3711 - val_loss: 0.4030\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3778 - val_loss: 0.4346\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3685 - val_loss: 0.3382\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3716 - val_loss: 0.3439\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.3618\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3619 - val_loss: 0.3531\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3684 - val_loss: 0.3558\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3703 - val_loss: 0.3514\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3683 - val_loss: 0.3527\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3607 - val_loss: 0.3498\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3669 - val_loss: 0.3505\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3743 - val_loss: 0.3629\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3662 - val_loss: 0.3506\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3645 - val_loss: 0.3525\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3661 - val_loss: 0.3772\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3687 - val_loss: 0.3933\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3695 - val_loss: 0.3380\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3807 - val_loss: 0.3543\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3715 - val_loss: 0.3700\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3788 - val_loss: 0.3532\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3698 - val_loss: 0.3500\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3610 - val_loss: 0.3376\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3606 - val_loss: 0.3581\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3722 - val_loss: 0.3389\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3685 - val_loss: 0.3431\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3555 - val_loss: 0.3391\n",
      "Epoch 00058: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 4.5min\n",
      "[CV] activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 1.9611 - val_loss: 0.4708\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.2830 - val_loss: 1.8276\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0268 - val_loss: 0.3742\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9614 - val_loss: 0.4402\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8462 - val_loss: 0.4059\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7517 - val_loss: 1.0066\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6520 - val_loss: 0.7422\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5810 - val_loss: 1.1118\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5274 - val_loss: 0.8464\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5017 - val_loss: 0.5129\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4634 - val_loss: 0.7602\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4632 - val_loss: 0.8979\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4354 - val_loss: 0.7403\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4285 - val_loss: 0.7493\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4002 - val_loss: 0.5715\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3916 - val_loss: 0.5311\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3819 - val_loss: 0.5063\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3571 - val_loss: 0.4918\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.5135\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3752 - val_loss: 0.5559s\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3705 - val_loss: 0.4438\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3718 - val_loss: 0.4498\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3607 - val_loss: 0.4364\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3685 - val_loss: 0.4012\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3660 - val_loss: 0.5489ss: 0.36\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3686 - val_loss: 0.3909\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3571 - val_loss: 0.3498\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3694 - val_loss: 0.3694\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3726 - val_loss: 0.4001\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3678 - val_loss: 0.4781\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3350 - val_loss: 0.4390\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3745 - val_loss: 0.3969\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3491 - val_loss: 0.4334\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3574 - val_loss: 0.3688\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3641 - val_loss: 0.3857\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3479 - val_loss: 0.4418\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3535 - val_loss: 0.4234\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3330 - val_loss: 0.6647\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3527 - val_loss: 0.3271\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3646 - val_loss: 0.4361\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3579 - val_loss: 0.3595\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3537 - val_loss: 0.3476\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3593 - val_loss: 0.3646\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3374 - val_loss: 0.4169\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3370 - val_loss: 0.4042\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3521 - val_loss: 0.4864\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3220 - val_loss: 0.3524\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3570 - val_loss: 0.3885\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3764 - val_loss: 0.3357\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3536 - val_loss: 0.3569\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3612 - val_loss: 0.3672\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3564 - val_loss: 0.3512\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3579 - val_loss: 0.3567\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3556 - val_loss: 0.3480\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3560 - val_loss: 0.4057\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3570 - val_loss: 0.3757\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3535 - val_loss: 0.3674\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3415 - val_loss: 0.3524\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3670 - val_loss: 0.3412\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3564 - val_loss: 0.3803\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3619 - val_loss: 0.3465\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3521 - val_loss: 0.3589\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3541 - val_loss: 0.3350\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3549 - val_loss: 0.3488\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3636 - val_loss: 0.4130\n",
      "Epoch 00064: early stopping\n",
      "[CV]  activation_function=tanh, hidden_layer_size=256, num_hidden_layers=3, total= 5.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed: 720.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 9s - loss: 11.2438 - val_loss: 0.3625\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.8811 - val_loss: 0.3404\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.8141 - val_loss: 0.3388\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.7413 - val_loss: 0.3381\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.7384 - val_loss: 0.3374\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.7181 - val_loss: 0.3399\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.6417 - val_loss: 0.3396\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.6388 - val_loss: 0.3373\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.6050 - val_loss: 0.3381\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.5589 - val_loss: 0.3397\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.5483 - val_loss: 0.3315\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.5059 - val_loss: 0.3177\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.4733 - val_loss: 0.3118\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.4694 - val_loss: 0.3123\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.4172 - val_loss: 0.3030\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3989 - val_loss: 0.3153\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.4054 - val_loss: 0.3087\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3777 - val_loss: 0.3083\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3631 - val_loss: 0.2967\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3408 - val_loss: 0.3082\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3377 - val_loss: 0.3000\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3150 - val_loss: 0.2930\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2933 - val_loss: 0.3040\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3008 - val_loss: 0.2979\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2943 - val_loss: 0.2945\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2837 - val_loss: 0.2965\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2692 - val_loss: 0.2964\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2555 - val_loss: 0.2975\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2535 - val_loss: 0.3054\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2302 - val_loss: 0.3231\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2358 - val_loss: 0.2872\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2244 - val_loss: 0.2992\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2207 - val_loss: 0.3092\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2075 - val_loss: 0.2988\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2132 - val_loss: 0.2876\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2109 - val_loss: 0.3016\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2195 - val_loss: 0.3024\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1955 - val_loss: 0.3033\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2085 - val_loss: 0.3015\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2008 - val_loss: 0.3084\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1916 - val_loss: 0.2994\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2120 - val_loss: 0.3018\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2037 - val_loss: 0.3047\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1994 - val_loss: 0.2935\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2008 - val_loss: 0.3061\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2065 - val_loss: 0.2942\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1928 - val_loss: 0.2994\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2022 - val_loss: 0.2906\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2139 - val_loss: 0.3120\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1923 - val_loss: 0.2923\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2041 - val_loss: 0.2903\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2007 - val_loss: 0.2891\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2017 - val_loss: 0.2976\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1793 - val_loss: 0.3018\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 4s - loss: 0.1871 - val_loss: 0.3326\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1766 - val_loss: 0.2914\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.1771 - val_loss: 0.2899\n",
      "Epoch 00056: early stopping\n",
      "The parameters of the best model are: \n",
      "{'activation_function': 'sigmoid', 'hidden_layer_size': 256, 'num_hidden_layers': 1}\n",
      "CPU times: user 8h 28min 13s, sys: 1h 55min 27s, total: 10h 23min 40s\n",
      "Wall time: 12h 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier = KerasRegressor(make_model, batch_size=32, epochs=200)\n",
    "\n",
    "params = [{'num_hidden_layers': [0],\n",
    "          'hidden_layer_size': [0],\n",
    "          'activation_function': ['linear', 'sigmoid', 'relu', 'tanh']},\n",
    "          {'num_hidden_layers': [1,2,3],\n",
    "          'hidden_layer_size': [64, 128, 256],\n",
    "          'activation_function': ['linear', 'sigmoid', 'relu', 'tanh']}]\n",
    "\n",
    "\n",
    "\n",
    "grid = GridSearchCV(classifier,\n",
    "                         param_grid=params,\n",
    "                         scoring='neg_mean_squared_error', #sklearn optimizing by maximizing negative MSE\n",
    "                         n_jobs=1,\n",
    "                         verbose=2,\n",
    "                         cv=5,# Number of folds for CV\n",
    "                         fit_params={'callbacks': [EarlyStopping(monitor='val_loss', \n",
    "                                                                 min_delta=0.001, \n",
    "                                                                 patience=25, \n",
    "                                                                 mode='min',\n",
    "                                                                 verbose=2)],\n",
    "                                    'validation_data': (np.array(X_test), np.array(y_test))\n",
    "                                    }\n",
    "                   )\n",
    "\n",
    "grid.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "print('The parameters of the best model are: ')\n",
    "print(grid.best_params_)\n",
    "\n",
    "best_model = grid.best_estimator_ #scikit-wrapped best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation_function': 'sigmoid',\n",
       " 'hidden_layer_size': 256,\n",
       " 'num_hidden_layers': 1}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The scores can the be extracted to view performance of every model on every fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([  13.50287156,    8.680127  ,  123.19230566,    9.90049596,\n",
       "         172.57024045,  694.71887217,   91.73476901,  361.96847048,\n",
       "         227.30850124,  623.26062694,  503.05254025,  240.81850038,\n",
       "         307.06533241,   66.34633126,   61.0761929 ,  120.8118094 ,\n",
       "         160.49777765,  237.58355951,  292.46093793,  220.76900277,\n",
       "         289.8215333 ,  339.33780003,  108.67911186,   72.78769679,\n",
       "          68.70184565,  325.41063762,  183.56481323,  131.0811676 ,\n",
       "         608.06070356,  195.96893563,  353.25112143,   43.06144466,\n",
       "          90.88812938,   88.37709479,   80.82804704,  206.07331543,\n",
       "         165.87386575,  209.66857367,  189.9257256 ,  275.6188179 ]),\n",
       " 'mean_score_time': array([ 0.06588287,  0.11164269,  0.15543766,  0.18913403,  0.23757229,\n",
       "         0.38218937,  0.36307201,  0.52320662,  0.5346004 ,  0.57172098,\n",
       "         0.72572899,  0.86915226,  0.86179481,  0.80138822,  0.86530061,\n",
       "         1.01587982,  1.18948011,  1.49805346,  1.54392328,  1.31741905,\n",
       "         1.40340447,  1.46243653,  1.41577864,  1.473318  ,  1.57212133,\n",
       "         1.67440538,  1.86076121,  1.92149663,  1.9882874 ,  1.95664811,\n",
       "         2.08905492,  1.99451542,  2.08671541,  2.20619264,  2.30296021,\n",
       "         2.3367382 ,  2.46858263,  2.55909138,  2.64816723,  2.70898576]),\n",
       " 'mean_test_score': array([ -2.58491371,  -3.62577388,  -7.22786566,  -3.62577388,\n",
       "         -0.28960392,  -0.27558248,  -0.30121865,  -0.27999121,\n",
       "         -0.26941098,  -0.25987762,  -0.5421486 ,  -1.95803687,\n",
       "        -27.59925544,  -0.29798273,  -0.30580356,  -0.29134322,\n",
       "         -0.27710452,  -0.28626172,  -0.28149191,  -0.25592989,\n",
       "         -0.26592856,  -0.26632251,  -0.49776187,  -0.3508851 ,\n",
       "         -0.31501135,  -0.25983106,  -0.56539634,  -0.32975541,\n",
       "         -0.32472559,  -0.85209867,  -0.51959983,  -0.3104727 ,\n",
       "         -0.30942205,  -0.31005718,  -0.30920817,  -0.30873735,\n",
       "         -0.31607359,  -0.30425217,  -0.3788651 ,  -0.33962673]),\n",
       " 'mean_train_score': array([ -2.28181444e+00,  -3.62577572e+00,  -7.25996898e+00,\n",
       "         -3.62577572e+00,  -2.81930643e-02,  -3.45452798e-02,\n",
       "         -9.57863529e-02,  -1.80963308e-02,  -3.83502608e-02,\n",
       "         -4.46084427e-02,  -4.43494953e-01,  -2.19776859e+00,\n",
       "         -5.87150301e+01,  -2.52775344e-01,  -2.90910909e-01,\n",
       "         -2.44391909e-01,  -1.43823017e-01,  -2.24621198e-01,\n",
       "         -1.68210570e-01,  -5.91398177e-02,  -1.70242977e-01,\n",
       "         -1.24748139e-01,  -3.32311204e-01,  -3.39332138e-01,\n",
       "         -3.14104339e-01,  -1.14633316e-01,  -4.21015259e-01,\n",
       "         -3.12958490e-01,  -1.56339816e-01,  -7.01212950e-01,\n",
       "         -4.66597814e-01,  -3.10449299e-01,  -3.10618633e-01,\n",
       "         -3.11085567e-01,  -3.10105424e-01,  -2.92137124e-01,\n",
       "         -3.15277520e-01,  -2.90043644e-01,  -3.77480259e-01,\n",
       "         -3.38441949e-01]),\n",
       " 'param_activation_function': masked_array(data = ['linear' 'sigmoid' 'relu' 'tanh' 'linear' 'linear' 'linear' 'linear'\n",
       "  'linear' 'linear' 'linear' 'linear' 'linear' 'sigmoid' 'sigmoid' 'sigmoid'\n",
       "  'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'sigmoid' 'relu' 'relu'\n",
       "  'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'relu' 'tanh' 'tanh' 'tanh'\n",
       "  'tanh' 'tanh' 'tanh' 'tanh' 'tanh' 'tanh'],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_hidden_layer_size': masked_array(data = [0 0 0 0 64 64 64 128 128 128 256 256 256 64 64 64 128 128 128 256 256 256\n",
       "  64 64 64 128 128 128 256 256 256 64 64 64 128 128 128 256 256 256],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_num_hidden_layers': masked_array(data = [0 0 0 0 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3\n",
       "  1 2 3],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False\n",
       "  False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': ({'activation_function': 'linear',\n",
       "   'hidden_layer_size': 0,\n",
       "   'num_hidden_layers': 0},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 0,\n",
       "   'num_hidden_layers': 0},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 0,\n",
       "   'num_hidden_layers': 0},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 0,\n",
       "   'num_hidden_layers': 0},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'linear',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'sigmoid',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'relu',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 64,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 128,\n",
       "   'num_hidden_layers': 3},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 1},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 2},\n",
       "  {'activation_function': 'tanh',\n",
       "   'hidden_layer_size': 256,\n",
       "   'num_hidden_layers': 3}),\n",
       " 'rank_test_score': array([36, 37, 39, 37, 12,  7, 15,  9,  6,  3, 32, 35, 40, 14, 17, 13,  8,\n",
       "        11, 10,  1,  4,  5, 30, 28, 23,  2, 33, 26, 25, 34, 31, 22, 20, 21,\n",
       "        19, 18, 24, 16, 29, 27], dtype=int32),\n",
       " 'split0_test_score': array([ -2.86822835,  -3.57610294,  -8.16727941,  -3.57610294,\n",
       "         -0.33356067,  -0.30444092,  -0.30259463,  -0.30816162,\n",
       "         -0.29880712,  -0.30096209,  -0.33327254,  -7.75947145,\n",
       "        -63.70302446,  -0.35718261,  -0.35506028,  -0.35274344,\n",
       "         -0.29388663,  -0.30770487,  -0.3035878 ,  -0.29697278,\n",
       "         -0.2910533 ,  -0.3107634 ,  -0.32746734,  -0.3524011 ,\n",
       "         -0.35546403,  -0.30178511,  -0.57815151,  -0.35217747,\n",
       "         -0.29078379,  -1.39331666,  -0.51196262,  -0.35197404,\n",
       "         -0.35240228,  -0.35202643,  -0.35210509,  -0.29508077,\n",
       "         -0.38418061,  -0.35791705,  -0.41477241,  -0.35502799]),\n",
       " 'split0_train_score': array([ -2.64712414e+00,  -3.63822824e+00,  -8.29346423e+00,\n",
       "         -3.63822824e+00,  -2.62362388e-02,  -2.78696849e-02,\n",
       "         -5.16486306e-02,  -1.04318909e-02,  -2.76865908e-02,\n",
       "         -2.89616601e-02,  -2.92362387e-02,  -9.07371615e+00,\n",
       "         -1.02901472e+02,  -3.08910965e-01,  -2.98591449e-01,\n",
       "         -2.98055235e-01,  -7.74184253e-02,  -1.87101252e-01,\n",
       "         -1.07260828e-01,  -6.71289295e-02,  -1.19700590e-01,\n",
       "         -1.59075256e-01,  -6.26970337e-02,  -3.00838360e-01,\n",
       "         -3.03686068e-01,  -1.47535898e-01,  -3.94389206e-01,\n",
       "         -2.99920336e-01,  -1.10852059e-01,  -1.20461276e+00,\n",
       "         -3.78624576e-01,  -2.99258411e-01,  -2.98162210e-01,\n",
       "         -2.98628423e-01,  -2.99961817e-01,  -1.47180265e-01,\n",
       "         -3.19455682e-01,  -3.10010125e-01,  -3.45749762e-01,\n",
       "         -3.05667394e-01]),\n",
       " 'split1_test_score': array([ -2.67113198,  -3.68842183,  -8.3550885 ,  -3.68842183,\n",
       "         -0.29240932,  -0.32626978,  -0.30267459,  -0.3068782 ,\n",
       "         -0.27518788,  -0.27157209,  -0.27951641,  -0.297238  ,\n",
       "        -70.17032115,  -0.32843868,  -0.32802416,  -0.27051921,\n",
       "         -0.28439825,  -0.26889224,  -0.27492732,  -0.28541398,\n",
       "         -0.28125008,  -0.27924225,  -0.69718704,  -0.33332609,\n",
       "         -0.34231061,  -0.28088436,  -0.58889421,  -0.33793893,\n",
       "         -0.28147614,  -0.96618086,  -0.3298481 ,  -0.33185623,\n",
       "         -0.32745712,  -0.3284937 ,  -0.3284193 ,  -0.32857606,\n",
       "         -0.32952711,  -0.3274595 ,  -0.35932983,  -0.36962012]),\n",
       " 'split1_train_score': array([ -2.17681111e+00,  -3.61012344e+00,  -8.24645357e+00,\n",
       "         -3.61012343e+00,  -2.25202584e-02,  -7.07141208e-02,\n",
       "         -5.14899935e-02,  -2.39790305e-02,  -2.48604461e-02,\n",
       "         -2.29166729e-02,  -2.13817946e-02,  -4.34280311e-02,\n",
       "         -1.82670345e+02,  -3.04605714e-01,  -3.04522357e-01,\n",
       "         -1.47552339e-01,  -9.58590942e-02,  -1.41928712e-01,\n",
       "         -1.17363441e-01,  -9.27781139e-02,  -1.99259197e-01,\n",
       "         -7.24171272e-02,  -4.70692525e-01,  -3.08291796e-01,\n",
       "         -3.15913741e-01,  -1.12246215e-01,  -4.04271592e-01,\n",
       "         -3.12130011e-01,  -7.36416334e-02,  -7.21336512e-01,\n",
       "         -3.05638546e-01,  -3.06840549e-01,  -3.04408629e-01,\n",
       "         -3.06853871e-01,  -3.04587643e-01,  -3.04814735e-01,\n",
       "         -3.08272897e-01,  -3.04127288e-01,  -3.42046690e-01,\n",
       "         -3.53166959e-01]),\n",
       " 'split2_test_score': array([-3.14308179, -3.63311209, -8.2850295 , -3.63311209, -0.28584682,\n",
       "        -0.2767652 , -0.31567201, -0.29737223, -0.32710716, -0.27029686,\n",
       "        -0.29115033, -0.3974694 , -0.2648943 , -0.25774226, -0.30364538,\n",
       "        -0.27785838, -0.259097  , -0.29626804, -0.2724569 , -0.25371126,\n",
       "        -0.28314075, -0.26364801, -0.94665022, -0.30328522, -0.30221292,\n",
       "        -0.26536107, -0.57008041, -0.3067056 , -0.26267539, -0.64969316,\n",
       "        -0.29918145, -0.3009527 , -0.29941673, -0.3008404 , -0.29900611,\n",
       "        -0.29914947, -0.3003756 , -0.27058179, -0.30964306, -0.32532295]),\n",
       " 'split2_train_score': array([-2.7131936 , -3.62394068, -8.26395542, -3.62394068, -0.01292469,\n",
       "        -0.01768326, -0.05672774, -0.0118742 , -0.05855095, -0.0685505 ,\n",
       "        -0.0123503 , -0.30510027, -0.05887126, -0.11335003, -0.31539535,\n",
       "        -0.22940468, -0.12177132, -0.24689746, -0.16509305, -0.0577577 ,\n",
       "        -0.20948296, -0.10859543, -0.69060863, -0.31506723, -0.31409923,\n",
       "        -0.10922518, -0.40091126, -0.31813061, -0.07119238, -0.52789786,\n",
       "        -0.31156606, -0.31298733, -0.31222713, -0.31289033, -0.31148106,\n",
       "        -0.31186739, -0.31338266, -0.204496  , -0.32343408, -0.33981489]),\n",
       " 'split3_test_score': array([-2.37308196, -3.66998525, -3.15567156, -3.66998525, -0.2226527 ,\n",
       "        -0.23327288, -0.30749445, -0.23971646, -0.21485816, -0.22792413,\n",
       "        -0.23825791, -0.22258874, -0.24762254, -0.24317731, -0.27808967,\n",
       "        -0.25424118, -0.24786885, -0.25878736, -0.2990046 , -0.21725655,\n",
       "        -0.22427687, -0.23757983, -0.21812796, -0.27436132, -0.2751518 ,\n",
       "        -0.22099898, -0.59804228, -0.27303038, -0.55836876, -0.6502439 ,\n",
       "        -0.75167924, -0.26720029, -0.26803052, -0.26584248, -0.2655123 ,\n",
       "        -0.31069962, -0.26665529, -0.26549431, -0.32675704, -0.27342544]),\n",
       " 'split3_train_score': array([-2.14780311, -3.61472918, -3.20415146, -3.61472918, -0.01656637,\n",
       "        -0.01905542, -0.19394529, -0.02885396, -0.04287084, -0.06449027,\n",
       "        -0.02127793, -0.05543733, -0.20962385, -0.21949109, -0.3265081 ,\n",
       "        -0.23219623, -0.11084696, -0.23542645, -0.34317349, -0.035977  ,\n",
       "        -0.15985378, -0.15682703, -0.12625512, -0.32385931, -0.32440434,\n",
       "        -0.1289362 , -0.49592308, -0.32296774, -0.41982596, -0.53819688,\n",
       "        -0.66709803, -0.31985134, -0.32619536, -0.31982678, -0.32026459,\n",
       "        -0.37843934, -0.32385525, -0.320164  , -0.39668909, -0.32322631]),\n",
       " 'split4_test_score': array([-1.86820875, -3.56139381, -8.1734882 , -3.56139381, -0.31342042,\n",
       "        -0.23707849, -0.27765352, -0.24774445, -0.23100786, -0.22851173,\n",
       "        -1.56916195, -1.0963034 , -3.50391393, -0.30319814, -0.26405301,\n",
       "        -0.30117275, -0.30022238, -0.29959284, -0.25741778, -0.22617381,\n",
       "        -0.24984768, -0.24024794, -0.29987913, -0.49104728, -0.29979808,\n",
       "        -0.23000201, -0.49177566, -0.37885853, -0.23042397, -0.59946228,\n",
       "        -0.70535029, -0.30025782, -0.29967681, -0.30295908, -0.30087149,\n",
       "        -0.31022113, -0.29942843, -0.2996499 , -0.48371723, -0.3746917 ]),\n",
       " 'split4_train_score': array([-1.72414024, -3.64185704, -8.29182019, -3.64185704, -0.06271776,\n",
       "        -0.03740391, -0.12512011, -0.01534257, -0.03778248, -0.0381231 ,\n",
       "        -2.1332285 , -1.51116116, -7.73483814, -0.31751893, -0.20953729,\n",
       "        -0.31475106, -0.31321929, -0.31175211, -0.10816205, -0.04205734,\n",
       "        -0.16291836, -0.12682584, -0.31130271, -0.448604  , -0.31241831,\n",
       "        -0.07522309, -0.40958115, -0.31164376, -0.10618705, -0.51402074,\n",
       "        -0.67006186, -0.31330886, -0.31209983, -0.31722843, -0.31423201,\n",
       "        -0.3183839 , -0.31142111, -0.31142081, -0.47948167, -0.37033419]),\n",
       " 'std_fit_time': array([  3.83628888e+00,   1.48128945e+00,   2.24582425e+02,\n",
       "          9.03482000e-01,   3.01122509e+01,   1.13262419e+03,\n",
       "          3.06696651e+01,   7.36970395e+01,   4.06733674e+01,\n",
       "          8.07434834e+02,   1.71992987e+02,   1.24494045e+02,\n",
       "          1.22957988e+02,   3.64782586e+01,   3.36504298e+01,\n",
       "          7.00141984e+01,   5.08890211e+01,   7.64521329e+01,\n",
       "          1.46496744e+02,   4.99870129e+01,   5.15570140e+01,\n",
       "          1.40246430e+02,   6.95335198e+01,   2.34895253e+00,\n",
       "          1.68816822e+01,   4.06572789e+01,   6.74558532e+01,\n",
       "          4.49951416e+01,   2.58665590e+02,   6.03855948e+01,\n",
       "          1.14510033e+02,   5.29201815e+00,   5.74546681e+00,\n",
       "          7.52582787e+00,   1.59039562e+00,   7.53075473e+01,\n",
       "          1.42457430e+01,   1.45879509e+02,   1.00495270e+02,\n",
       "          8.24021587e+01]),\n",
       " 'std_score_time': array([ 0.01023344,  0.06329315,  0.03296369,  0.01331995,  0.01668657,\n",
       "         0.16898433,  0.0160843 ,  0.09849648,  0.04829416,  0.06796754,\n",
       "         0.04713527,  0.21538581,  0.05256117,  0.02060498,  0.02505666,\n",
       "         0.11559419,  0.17517058,  0.2000434 ,  0.23971748,  0.01323223,\n",
       "         0.05952614,  0.00652356,  0.01818649,  0.02588861,  0.01960232,\n",
       "         0.02847773,  0.21827611,  0.04143184,  0.10887614,  0.0781797 ,\n",
       "         0.03568294,  0.10295892,  0.01138829,  0.03717285,  0.0450891 ,\n",
       "         0.02770192,  0.06277337,  0.09007364,  0.0360971 ,  0.15496412]),\n",
       " 'std_test_score': array([  4.37598666e-01,   5.00901847e-02,   2.03656869e+00,\n",
       "          5.00901847e-02,   3.74311125e-02,   3.65365286e-02,\n",
       "          1.27054573e-02,   2.99338895e-02,   4.16523603e-02,\n",
       "          2.80740214e-02,   5.14210015e-01,   2.92160006e+00,\n",
       "          3.22255305e+01,   4.26316736e-02,   3.29840972e-02,\n",
       "          3.42529060e-02,   2.02380398e-02,   1.89446085e-02,\n",
       "          1.73191641e-02,   3.14383751e-02,   2.51225768e-02,\n",
       "          2.70509069e-02,   2.78381402e-01,   7.49148089e-02,\n",
       "          2.95565401e-02,   3.04438043e-02,   3.79967559e-02,\n",
       "          3.66807080e-02,   1.18588893e-01,   3.00688378e-01,\n",
       "          1.85962661e-01,   2.91536141e-02,   2.85794981e-02,\n",
       "          2.89631358e-02,   2.93087660e-02,   1.16465118e-02,\n",
       "          3.94824155e-02,   3.48724938e-02,   6.35039828e-02,\n",
       "          3.72831398e-02]),\n",
       " 'std_train_score': array([  3.63187116e-01,   1.25224716e-02,   2.02798549e+00,\n",
       "          1.25224725e-02,   1.78676694e-02,   1.94174332e-02,\n",
       "          5.64473684e-02,   7.14666988e-03,   1.20375650e-02,\n",
       "          1.85791482e-02,   8.44883684e-01,   3.48031735e+00,\n",
       "          7.31843826e+01,   7.82004955e-02,   4.17913272e-02,\n",
       "          5.92982584e-02,   8.59987246e-02,   5.73595232e-02,\n",
       "          9.00309583e-02,   2.01275842e-02,   3.19306599e-02,\n",
       "          3.22836430e-02,   2.29398651e-01,   5.51612329e-02,\n",
       "          6.64450190e-03,   2.39802616e-02,   3.77766831e-02,\n",
       "          7.73749584e-03,   1.32739188e-01,   2.62857226e-01,\n",
       "          1.66901153e-01,   6.94659909e-03,   9.39300179e-03,\n",
       "          7.62218403e-03,   7.14798463e-03,   7.70706966e-02,\n",
       "          5.63136753e-03,   4.30804549e-02,   5.64918029e-02,\n",
       "          2.25455671e-02])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The scores are easier to interpret if we convert them to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def grid_scores_to_df(grid_scores):\n",
    "    \"\"\"\n",
    "    Convert a sklearn.grid_search.GridSearchCV.grid_scores_ attribute to a tidy\n",
    "    pandas DataFrame where each row is a hyperparameter-fold combinatination.\n",
    "    \"\"\"\n",
    "    rows = list()\n",
    "    for grid_score in grid_scores:\n",
    "        for fold, score in enumerate(grid_score.cv_validation_scores):\n",
    "            row = grid_score.parameters.copy()\n",
    "            row['fold'] = fold\n",
    "            row['score'] = abs(score) # Take abs since sklearn uses negative MSE\n",
    "            rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_function</th>\n",
       "      <th>fold</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.868228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.671132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.143082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.373082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.868209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activation_function  fold  hidden_layer_size  num_hidden_layers     score\n",
       "0              linear     0                  0                  0 -2.868228\n",
       "1              linear     1                  0                  0 -2.671132\n",
       "2              linear     2                  0                  0 -3.143082\n",
       "3              linear     3                  0                  0 -2.373082\n",
       "4              linear     4                  0                  0 -1.868209"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = grid_scores_to_df(grid.grid_scores_)\n",
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The best performing models (based on the grid-search) can then be identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activation_function</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.214858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.217257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.218128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.220999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.222589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.222653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.224277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.227924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.228512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>relu</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.230002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.230424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.231008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.233273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>linear</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.237078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.237580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.238258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.239716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.240248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.243177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.247623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>linear</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.247744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.247869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.249848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.253711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.254241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.257418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.257742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.258787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.259097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.751679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>relu</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.946650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.966181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.096303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>relu</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.393317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.569162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.868209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.373082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.671132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.868228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.143082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.155672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-3.503914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.561394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.561394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.576103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.576103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.633112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.633112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.669985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.669985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sigmoid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.688422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tanh</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.688422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>-7.759471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.167279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.173488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.285029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>relu</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-8.355088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-63.703024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>linear</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>-70.170321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    activation_function  hidden_layer_size  num_hidden_layers      score\n",
       "43               linear                128                  2  -0.214858\n",
       "98              sigmoid                256                  1  -0.217257\n",
       "113                relu                 64                  1  -0.218128\n",
       "128                relu                128                  1  -0.220999\n",
       "58               linear                256                  2  -0.222589\n",
       "23               linear                 64                  1  -0.222653\n",
       "103             sigmoid                256                  2  -0.224277\n",
       "99              sigmoid                256                  1  -0.226174\n",
       "48               linear                128                  3  -0.227924\n",
       "49               linear                128                  3  -0.228512\n",
       "129                relu                128                  1  -0.230002\n",
       "144                relu                256                  1  -0.230424\n",
       "44               linear                128                  2  -0.231008\n",
       "28               linear                 64                  2  -0.233273\n",
       "29               linear                 64                  2  -0.237078\n",
       "108             sigmoid                256                  3  -0.237580\n",
       "53               linear                256                  1  -0.238258\n",
       "38               linear                128                  1  -0.239716\n",
       "109             sigmoid                256                  3  -0.240248\n",
       "68              sigmoid                 64                  1  -0.243177\n",
       "63               linear                256                  3  -0.247623\n",
       "39               linear                128                  1  -0.247744\n",
       "83              sigmoid                128                  1  -0.247869\n",
       "104             sigmoid                256                  2  -0.249848\n",
       "97              sigmoid                256                  1  -0.253711\n",
       "78              sigmoid                 64                  3  -0.254241\n",
       "94              sigmoid                128                  3  -0.257418\n",
       "67              sigmoid                 64                  1  -0.257742\n",
       "88              sigmoid                128                  2  -0.258787\n",
       "82              sigmoid                128                  1  -0.259097\n",
       "..                  ...                ...                ...        ...\n",
       "153                relu                256                  3  -0.751679\n",
       "112                relu                 64                  1  -0.946650\n",
       "146                relu                256                  2  -0.966181\n",
       "59               linear                256                  2  -1.096303\n",
       "145                relu                256                  2  -1.393317\n",
       "54               linear                256                  1  -1.569162\n",
       "4                linear                  0                  0  -1.868209\n",
       "3                linear                  0                  0  -2.373082\n",
       "1                linear                  0                  0  -2.671132\n",
       "0                linear                  0                  0  -2.868228\n",
       "2                linear                  0                  0  -3.143082\n",
       "13                 relu                  0                  0  -3.155672\n",
       "64               linear                256                  3  -3.503914\n",
       "19                 tanh                  0                  0  -3.561394\n",
       "9               sigmoid                  0                  0  -3.561394\n",
       "15                 tanh                  0                  0  -3.576103\n",
       "5               sigmoid                  0                  0  -3.576103\n",
       "17                 tanh                  0                  0  -3.633112\n",
       "7               sigmoid                  0                  0  -3.633112\n",
       "8               sigmoid                  0                  0  -3.669985\n",
       "18                 tanh                  0                  0  -3.669985\n",
       "6               sigmoid                  0                  0  -3.688422\n",
       "16                 tanh                  0                  0  -3.688422\n",
       "55               linear                256                  2  -7.759471\n",
       "10                 relu                  0                  0  -8.167279\n",
       "14                 relu                  0                  0  -8.173488\n",
       "12                 relu                  0                  0  -8.285029\n",
       "11                 relu                  0                  0  -8.355088\n",
       "60               linear                256                  3 -63.703024\n",
       "61               linear                256                  3 -70.170321\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This shows the best performing models at the fold level\n",
    "scores_df.sort_values(['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This can be further tidied up by using a groupby operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "del scores_df['fold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped = scores_df.groupby(['num_hidden_layers','hidden_layer_size','activation_function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped_ = grouped.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>activation_function</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">0</th>\n",
       "      <th>linear</th>\n",
       "      <td>-2.584747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-7.227311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-3.625803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-3.625803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">64</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.289578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.497862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.297948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.310448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.279975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.259806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.277095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.309183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">256</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.542272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.324746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.255906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.304221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">64</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.275565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.350884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.305775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.309397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.269394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.565389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.286249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.308745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">256</th>\n",
       "      <th>linear</th>\n",
       "      <td>-1.954614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.851779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.265914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.378844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"4\" valign=\"top\">64</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.301218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.314987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.291307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.310032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">128</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.259853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.329742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.281479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.316033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">256</th>\n",
       "      <th>linear</th>\n",
       "      <td>-27.577955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>-0.519604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.266296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>-0.339618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             score\n",
       "num_hidden_layers hidden_layer_size activation_function           \n",
       "0                 0                 linear               -2.584747\n",
       "                                    relu                 -7.227311\n",
       "                                    sigmoid              -3.625803\n",
       "                                    tanh                 -3.625803\n",
       "1                 64                linear               -0.289578\n",
       "                                    relu                 -0.497862\n",
       "                                    sigmoid              -0.297948\n",
       "                                    tanh                 -0.310448\n",
       "                  128               linear               -0.279975\n",
       "                                    relu                 -0.259806\n",
       "                                    sigmoid              -0.277095\n",
       "                                    tanh                 -0.309183\n",
       "                  256               linear               -0.542272\n",
       "                                    relu                 -0.324746\n",
       "                                    sigmoid              -0.255906\n",
       "                                    tanh                 -0.304221\n",
       "2                 64                linear               -0.275565\n",
       "                                    relu                 -0.350884\n",
       "                                    sigmoid              -0.305775\n",
       "                                    tanh                 -0.309397\n",
       "                  128               linear               -0.269394\n",
       "                                    relu                 -0.565389\n",
       "                                    sigmoid              -0.286249\n",
       "                                    tanh                 -0.308745\n",
       "                  256               linear               -1.954614\n",
       "                                    relu                 -0.851779\n",
       "                                    sigmoid              -0.265914\n",
       "                                    tanh                 -0.378844\n",
       "3                 64                linear               -0.301218\n",
       "                                    relu                 -0.314987\n",
       "                                    sigmoid              -0.291307\n",
       "                                    tanh                 -0.310032\n",
       "                  128               linear               -0.259853\n",
       "                                    relu                 -0.329742\n",
       "                                    sigmoid              -0.281479\n",
       "                                    tanh                 -0.316033\n",
       "                  256               linear              -27.577955\n",
       "                                    relu                 -0.519604\n",
       "                                    sigmoid              -0.266296\n",
       "                                    tanh                 -0.339618"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "grouped_.to_csv('model_params_and_results.csv') # Save csv so it can be used as a table in the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I find the top 5 best performing models and look more closely at their performance. \n",
    "\n",
    "Note that they all have very similar scores, all of which are far better than we would expect (none of the leaderboard scores are better than 0.38). This suggests that there is some overfitting in these models, despite the use of dropout, cross-validation, and early stopping using validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_hidden_layers</th>\n",
       "      <th>hidden_layer_size</th>\n",
       "      <th>activation_function</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>256</th>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.255906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <th>relu</th>\n",
       "      <td>-0.259806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>128</th>\n",
       "      <th>linear</th>\n",
       "      <td>-0.259853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>256</th>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.265914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>256</th>\n",
       "      <th>sigmoid</th>\n",
       "      <td>-0.266296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            score\n",
       "num_hidden_layers hidden_layer_size activation_function          \n",
       "1                 256               sigmoid             -0.255906\n",
       "                  128               relu                -0.259806\n",
       "3                 128               linear              -0.259853\n",
       "2                 256               sigmoid             -0.265914\n",
       "3                 256               sigmoid             -0.266296"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_.sort_values(['score'],ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now to retrain the 5 best models and assess the out-of-sample performance of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m1 = {'num_hidden_layers': [1],\n",
    "          'hidden_layer_size': [256],\n",
    "          'activation_function': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m2 = {'num_hidden_layers': [1],\n",
    "          'hidden_layer_size': [128],\n",
    "          'activation_function': ['relu']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m3 = {'num_hidden_layers': [3],\n",
    "          'hidden_layer_size': [128],\n",
    "          'activation_function': ['linear']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m4 = {'num_hidden_layers': [2],\n",
    "          'hidden_layer_size': [256],\n",
    "          'activation_function': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m5 = {'num_hidden_layers': [3],\n",
    "          'hidden_layer_size': [256],\n",
    "          'activation_function': ['sigmoid']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "final_models = [(m1,'model_1'),(m2,'model_2'),(m3, 'model_3'),(m4, 'model_4'), (m5, 'model_5')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "I can use the same gridsearch with a single set of parameters to iterate over the models and get predictions. The only changes I'm making are the inclusion of additional callback parameters to store the results and a slight decrease in the `patience` parameter to help prevent overfitting.\n",
    "\n",
    "This time I also store each estimator, its predictions, and its history in a dictionary.\n",
    "\n",
    "***Note: It takes at least 2 hours to run these models.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 10s - loss: 11.3449 - val_loss: 0.4504\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9219 - val_loss: 0.3378\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.9630 - val_loss: 0.3369\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8268 - val_loss: 0.3346\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8264 - val_loss: 0.3343\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7811 - val_loss: 0.3360\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.7493 - val_loss: 0.3339\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6935 - val_loss: 0.3282\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6791 - val_loss: 0.3172\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6315 - val_loss: 0.3179\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5768 - val_loss: 0.3178\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5740 - val_loss: 0.3205\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5443 - val_loss: 0.3160\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5222 - val_loss: 0.3024\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4803 - val_loss: 0.3036\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4509 - val_loss: 0.2991\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4311 - val_loss: 0.2989\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3930 - val_loss: 0.3000\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3974 - val_loss: 0.2942\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3282 - val_loss: 0.2992ss\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3374 - val_loss: 0.2971\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3275 - val_loss: 0.2915\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3074 - val_loss: 0.2929ss: 0. - ETA: 0s - lo\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3103 - val_loss: 0.2904\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2904 - val_loss: 0.2912\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2837 - val_loss: 0.2952\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2797 - val_loss: 0.2911\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2368 - val_loss: 0.2965\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.2702 - val_loss: 0.2990\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2403 - val_loss: 0.2973\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2433 - val_loss: 0.3068\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2389 - val_loss: 0.2943s\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2211 - val_loss: 0.2909\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2187 - val_loss: 0.2960\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2215 - val_loss: 0.2927\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2261 - val_loss: 0.2867\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2112 - val_loss: 0.2877\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2245 - val_loss: 0.2905\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2076 - val_loss: 0.2886\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2001 - val_loss: 0.2904\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2085 - val_loss: 0.2984\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2059 - val_loss: 0.2882\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1932 - val_loss: 0.2974\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1906 - val_loss: 0.2931\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1985 - val_loss: 0.3000\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1878 - val_loss: 0.2895\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1776 - val_loss: 0.2985\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1788 - val_loss: 0.3046\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1994 - val_loss: 0.2911\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1842 - val_loss: 0.3160\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.1719 - val_loss: 0.2906\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.1861 - val_loss: 0.2947\n",
      "Epoch 00051: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.3min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  4.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s - loss: 7.0565 - val_loss: 0.3546\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0011 - val_loss: 0.3266\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0699 - val_loss: 0.3078\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9053 - val_loss: 0.3000\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8293 - val_loss: 0.3012\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7446 - val_loss: 0.2992\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6728 - val_loss: 0.3024\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6223 - val_loss: 0.2962\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5776 - val_loss: 0.2914\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5535 - val_loss: 0.2870\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4822 - val_loss: 0.2881\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4795 - val_loss: 0.2803\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4722 - val_loss: 0.2760\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4002 - val_loss: 0.2822\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3547 - val_loss: 0.2808\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3389 - val_loss: 0.2840ss: 0.\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3307 - val_loss: 0.2822\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2895 - val_loss: 0.2789\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2724 - val_loss: 0.2827\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2647 - val_loss: 0.2868\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2509 - val_loss: 0.2950\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2316 - val_loss: 0.2988\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2224 - val_loss: 0.2860\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1901 - val_loss: 0.2908\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2106 - val_loss: 0.2865\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2055 - val_loss: 0.2898\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1911 - val_loss: 0.2973\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1859 - val_loss: 0.2875\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1873 - val_loss: 0.2929\n",
      "Epoch 00028: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 2.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s - loss: 10.9789 - val_loss: 0.5441\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8416 - val_loss: 0.3414\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7864 - val_loss: 0.3368\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7991 - val_loss: 0.3385\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7318 - val_loss: 0.3369\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7213 - val_loss: 0.3372\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6848 - val_loss: 0.3368\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7024 - val_loss: 0.3413ss: 0.701\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6305 - val_loss: 0.3340\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5812 - val_loss: 0.3278\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5500 - val_loss: 0.3275\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5905 - val_loss: 0.3210\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4945 - val_loss: 0.3209\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4906 - val_loss: 0.3204\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4942 - val_loss: 0.3183\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4435 - val_loss: 0.3078\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4051 - val_loss: 0.3044\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4104 - val_loss: 0.2953\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3943 - val_loss: 0.2997\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3594 - val_loss: 0.2903\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3285 - val_loss: 0.2924\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3264 - val_loss: 0.2979\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3171 - val_loss: 0.2885\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3122 - val_loss: 0.2965\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2927 - val_loss: 0.2965\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2685 - val_loss: 0.2896\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2681 - val_loss: 0.3102\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2661 - val_loss: 0.2999\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2327 - val_loss: 0.3015\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2385 - val_loss: 0.2992\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2363 - val_loss: 0.2973\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 6s - loss: 0.2229 - val_loss: 0.2897\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2249 - val_loss: 0.2956\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2338 - val_loss: 0.2858\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2223 - val_loss: 0.2900\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2147 - val_loss: 0.2928\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2106 - val_loss: 0.3001\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2026 - val_loss: 0.2987\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1983 - val_loss: 0.2888\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2199 - val_loss: 0.2922ss: 0.22\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2087 - val_loss: 0.2850\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2094 - val_loss: 0.2911\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2086 - val_loss: 0.2915\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2120 - val_loss: 0.2955\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2122 - val_loss: 0.3216\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2012 - val_loss: 0.2952\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2045 - val_loss: 0.3038\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1863 - val_loss: 0.2905\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1923 - val_loss: 0.3017\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1959 - val_loss: 0.3160\n",
      "Epoch 00049: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 14.7576 - val_loss: 0.6355\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.1564 - val_loss: 0.3373\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.9946 - val_loss: 0.3336\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 1.0377 - val_loss: 0.3284\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9352 - val_loss: 0.3263\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9671 - val_loss: 0.3280 ETA: 1s - loss:  - ETA: 0s - loss\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8563 - val_loss: 0.3253\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7935 - val_loss: 0.3169\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7762 - val_loss: 0.3226\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7498 - val_loss: 0.3076\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7155 - val_loss: 0.2999\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6305 - val_loss: 0.2974\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6288 - val_loss: 0.2991\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5835 - val_loss: 0.2994\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5567 - val_loss: 0.2931\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5109 - val_loss: 0.2930\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5075 - val_loss: 0.2879\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4526 - val_loss: 0.2960\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4309 - val_loss: 0.2860\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3663 - val_loss: 0.2952\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3567 - val_loss: 0.2928\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3442 - val_loss: 0.2805\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3237 - val_loss: 0.2845\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3199 - val_loss: 0.2815\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2975 - val_loss: 0.2889\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2658 - val_loss: 0.3096\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2618 - val_loss: 0.2874\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2398 - val_loss: 0.3341\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2318 - val_loss: 0.2898\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2215 - val_loss: 0.2938\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2244 - val_loss: 0.2916\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2179 - val_loss: 0.2921\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1988 - val_loss: 0.2872\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1957 - val_loss: 0.2881\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2079 - val_loss: 0.2982\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1962 - val_loss: 0.2966\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1716 - val_loss: 0.3080\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1848 - val_loss: 0.3001\n",
      "Epoch 00037: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 3.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 11s - loss: 13.0823 - val_loss: 0.4108\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.9162 - val_loss: 0.3382\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8557 - val_loss: 0.3356\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.8206 - val_loss: 0.3340\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7548 - val_loss: 0.3054\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.7268 - val_loss: 0.3085\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6705 - val_loss: 0.3058\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6254 - val_loss: 0.3231\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6586 - val_loss: 0.3148\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5627 - val_loss: 0.3030\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5692 - val_loss: 0.2962\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5297 - val_loss: 0.2945\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4881 - val_loss: 0.2884\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4805 - val_loss: 0.3037\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4369 - val_loss: 0.3033\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4180 - val_loss: 0.2910\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3974 - val_loss: 0.2976ss:\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3711 - val_loss: 0.2907\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3493 - val_loss: 0.2882\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3532 - val_loss: 0.2931\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2932 - val_loss: 0.3036\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2980 - val_loss: 0.2933\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2755 - val_loss: 0.2862\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2704 - val_loss: 0.2847\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2439 - val_loss: 0.2934\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2405 - val_loss: 0.2916\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2409 - val_loss: 0.2985\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2134 - val_loss: 0.2923\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2086 - val_loss: 0.2947\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2038 - val_loss: 0.3034\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2010 - val_loss: 0.2896\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1904 - val_loss: 0.3088\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.1920 - val_loss: 0.2811\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2039 - val_loss: 0.2898\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1934 - val_loss: 0.2870\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1833 - val_loss: 0.2933\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1631 - val_loss: 0.3021\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1901 - val_loss: 0.2824\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.1761 - val_loss: 0.2886\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1685 - val_loss: 0.2908\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1794 - val_loss: 0.3131\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1636 - val_loss: 0.2915ss\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1818 - val_loss: 0.3003\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1724 - val_loss: 0.2924\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1767 - val_loss: 0.3387ss: 0.17\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1713 - val_loss: 0.3061\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1711 - val_loss: 0.3022\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1725 - val_loss: 0.2872\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.1717 - val_loss: 0.2870\n",
      "Epoch 00048: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=1, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 18.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 11s - loss: 8.9745 - val_loss: 0.3379\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.9289 - val_loss: 0.3229\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.8683 - val_loss: 0.3379\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.8310 - val_loss: 0.3223\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.8243 - val_loss: 0.3194\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.7384 - val_loss: 0.3187\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.6854 - val_loss: 0.3186\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.6084 - val_loss: 0.3085\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.6117 - val_loss: 0.3031\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.5513 - val_loss: 0.3037\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.5129 - val_loss: 0.2991\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.5112 - val_loss: 0.3261\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4457 - val_loss: 0.2954\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.4066 - val_loss: 0.3039\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3994 - val_loss: 0.3071\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4039 - val_loss: 0.3044\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3500 - val_loss: 0.2945\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3267 - val_loss: 0.2937\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3188 - val_loss: 0.2989\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3051 - val_loss: 0.2984\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2991 - val_loss: 0.3049\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2668 - val_loss: 0.2943\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2737 - val_loss: 0.2899\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2421 - val_loss: 0.2879\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2364 - val_loss: 0.3068\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2161 - val_loss: 0.2972\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2232 - val_loss: 0.3167\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2271 - val_loss: 0.3002\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2146 - val_loss: 0.3025\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2157 - val_loss: 0.2788\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2065 - val_loss: 0.2980\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2124 - val_loss: 0.3119\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2075 - val_loss: 0.2984\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2020 - val_loss: 0.2923\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1770 - val_loss: 0.2916\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.1816 - val_loss: 0.2933\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1935 - val_loss: 0.2929\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1921 - val_loss: 0.2818\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2048 - val_loss: 0.3025\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1929 - val_loss: 0.2920\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1856 - val_loss: 0.2883\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.1900 - val_loss: 0.2999\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1926 - val_loss: 0.2977\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1715 - val_loss: 0.3192\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.1723 - val_loss: 0.2978\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.1934 - val_loss: 0.3022\n",
      "Epoch 00045: early stopping\n",
      "Out-of-sample MSE:  0.302232599543\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 11.6963 - val_loss: 0.5783\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 3s - loss: 2.1952 - val_loss: 0.4301\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.4105 - val_loss: 0.8366\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.3312 - val_loss: 0.5247\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.1880 - val_loss: 0.7673\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2303 - val_loss: 0.7765\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.1678 - val_loss: 0.6325\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0387 - val_loss: 0.4426\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.2148 - val_loss: 0.8245\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 2.0475 - val_loss: 0.6207\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.9486 - val_loss: 0.6125\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.9102 - val_loss: 0.7970\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.9237 - val_loss: 0.7052\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.7757 - val_loss: 0.7790\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.8943 - val_loss: 0.5077\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.7464 - val_loss: 0.4859\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.6569 - val_loss: 0.8169\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 1.6639 - val_loss: 0.6407\n",
      "Epoch 00017: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total=  56.1s\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   56.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 21.9738 - val_loss: 8.1194\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.0887 - val_loss: 7.9556\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.9138 - val_loss: 7.7731\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.7263 - val_loss: 7.5834\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.5337 - val_loss: 7.3899\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.3384 - val_loss: 7.1966\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.1437 - val_loss: 7.0027\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.9499 - val_loss: 6.8101\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.7579 - val_loss: 6.6205\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.5683 - val_loss: 6.4338\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.3816 - val_loss: 6.2497\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.1977 - val_loss: 6.0683\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.0169 - val_loss: 5.8902\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.8393 - val_loss: 5.7160\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.6654 - val_loss: 5.5440\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.4946 - val_loss: 5.3766\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.3278 - val_loss: 5.2125\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1644 - val_loss: 5.0519\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.0045 - val_loss: 4.8947\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.8482 - val_loss: 4.7416\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.6956 - val_loss: 4.5922\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5465 - val_loss: 4.4453\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.4005 - val_loss: 4.3030ss: 4.3\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.2584 - val_loss: 4.1630\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1195 - val_loss: 4.0272\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9842 - val_loss: 3.8942\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.8521 - val_loss: 3.7649\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7235 - val_loss: 3.6391\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5980 - val_loss: 3.5165\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4758 - val_loss: 3.3964\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3566 - val_loss: 3.2800\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2408 - val_loss: 3.1664\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.1279 - val_loss: 3.0563\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0179 - val_loss: 2.9494\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9112 - val_loss: 2.8442\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8072 - val_loss: 2.7430\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7065 - val_loss: 2.6447\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6085 - val_loss: 2.5486\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5132 - val_loss: 2.4564\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4209 - val_loss: 2.3664\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3314 - val_loss: 2.2789\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 1s - loss: 2.2444 - val_loss: 2.1943\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1603 - val_loss: 2.1120\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0787 - val_loss: 2.0333\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0001 - val_loss: 1.9569\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9239 - val_loss: 1.8819\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8498 - val_loss: 1.8103\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7784 - val_loss: 1.7411\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7093 - val_loss: 1.6741\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6426 - val_loss: 1.6092\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5782 - val_loss: 1.5468\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5161 - val_loss: 1.4867\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4562 - val_loss: 1.4289\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3985 - val_loss: 1.3730\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3428 - val_loss: 1.3190\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2891 - val_loss: 1.2670\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2376 - val_loss: 1.2176\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1881 - val_loss: 1.1695\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1404 - val_loss: 1.1233\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0947 - val_loss: 1.0795\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0508 - val_loss: 1.0376\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0088 - val_loss: 0.9969\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9686 - val_loss: 0.9581\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9301 - val_loss: 0.9211\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8933 - val_loss: 0.8860\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8580 - val_loss: 0.8523\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8244 - val_loss: 0.8203\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7923 - val_loss: 0.7894\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7615 - val_loss: 0.7601\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7323 - val_loss: 0.7320\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7044 - val_loss: 0.7056\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6782 - val_loss: 0.6805\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6531 - val_loss: 0.6568\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6294 - val_loss: 0.6343\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6069 - val_loss: 0.6129\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5855 - val_loss: 0.5929\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5654 - val_loss: 0.5739\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5463 - val_loss: 0.5557\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5283 - val_loss: 0.5390\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5114 - val_loss: 0.5227\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4953 - val_loss: 0.5081\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4805 - val_loss: 0.4940\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4664 - val_loss: 0.4811\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4533 - val_loss: 0.4688\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4410 - val_loss: 0.4572\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4294 - val_loss: 0.4468\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4188 - val_loss: 0.4365\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4086 - val_loss: 0.4275\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3993 - val_loss: 0.4189\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3907 - val_loss: 0.4109\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3827 - val_loss: 0.4035\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3752 - val_loss: 0.3969\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3685 - val_loss: 0.3906\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3621 - val_loss: 0.3850\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3564 - val_loss: 0.3799\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3512 - val_loss: 0.3752\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3463 - val_loss: 0.3709\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3419 - val_loss: 0.3669\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3378 - val_loss: 0.3635\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3342 - val_loss: 0.3602\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3309 - val_loss: 0.3573\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3278 - val_loss: 0.3548\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3252 - val_loss: 0.3525\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3226 - val_loss: 0.3504\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3204 - val_loss: 0.3486\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3185 - val_loss: 0.3469\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3168 - val_loss: 0.3455\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3152 - val_loss: 0.3442\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3138 - val_loss: 0.3431\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3125 - val_loss: 0.3421\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3114 - val_loss: 0.3412\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3104 - val_loss: 0.3405\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3096 - val_loss: 0.3398\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3089 - val_loss: 0.3393\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3082 - val_loss: 0.3388\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3076 - val_loss: 0.3384\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3072 - val_loss: 0.3381\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3068 - val_loss: 0.3378\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3064 - val_loss: 0.3376\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3061 - val_loss: 0.3374\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3058 - val_loss: 0.3372\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3055 - val_loss: 0.3371\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3053 - val_loss: 0.3370\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3052 - val_loss: 0.3369\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3051 - val_loss: 0.3369\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3049 - val_loss: 0.3368\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3048 - val_loss: 0.3368\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3048 - val_loss: 0.3368\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3047 - val_loss: 0.3368\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3046 - val_loss: 0.3368\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3046 - val_loss: 0.3368\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3046 - val_loss: 0.3368\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.3368\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.3368\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.3368\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.3368\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.3368\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3045 - val_loss: 0.3369\n",
      "Epoch 00137: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 6.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s - loss: 15.9719 - val_loss: 2.8153\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.3108 - val_loss: 2.1967\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.0500 - val_loss: 2.4168\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9857 - val_loss: 2.2470\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.0772 - val_loss: 2.3122\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.8345 - val_loss: 2.1360\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9059 - val_loss: 2.1008\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.8301 - val_loss: 2.0992\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6589 - val_loss: 1.8822\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5589 - val_loss: 1.8936\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6563 - val_loss: 2.0407\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2512 - val_loss: 1.7559\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4198 - val_loss: 1.8748\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2395 - val_loss: 1.7849\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0482 - val_loss: 1.6726\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0373 - val_loss: 1.6255\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8356 - val_loss: 1.6944\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8587 - val_loss: 1.5634ss: 2.\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7779 - val_loss: 1.4934\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6945 - val_loss: 1.5384\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6155 - val_loss: 1.5695\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5064 - val_loss: 1.4348\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4436 - val_loss: 1.3716\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5601 - val_loss: 1.4842\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4379 - val_loss: 1.3332\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2265 - val_loss: 1.3171\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1154 - val_loss: 1.2200\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1040 - val_loss: 1.2215\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9463 - val_loss: 1.2044\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9883 - val_loss: 1.1517\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0350 - val_loss: 1.1447\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8115 - val_loss: 1.1359\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8543 - val_loss: 1.1113\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6426 - val_loss: 1.0806\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6777 - val_loss: 1.0452\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6139 - val_loss: 0.9899\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5968 - val_loss: 0.9794\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5469 - val_loss: 0.9606\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5277 - val_loss: 0.9586\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3859 - val_loss: 0.9023\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3314 - val_loss: 0.8840\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2620 - val_loss: 0.8634\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2135 - val_loss: 0.8259\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2447 - val_loss: 0.8096\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1507 - val_loss: 0.8046\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1653 - val_loss: 0.7768\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1248 - val_loss: 0.7456\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0373 - val_loss: 0.7378\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9802 - val_loss: 0.7212\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0131 - val_loss: 0.6978\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9214 - val_loss: 0.7017\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9266 - val_loss: 0.6775\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9049 - val_loss: 0.6380\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8714 - val_loss: 0.6329\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8079 - val_loss: 0.6220\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7825 - val_loss: 0.6015\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7851 - val_loss: 0.5906\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7169 - val_loss: 0.5824\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6962 - val_loss: 0.5650\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6967 - val_loss: 0.5510\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6358 - val_loss: 0.5412\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6664 - val_loss: 0.5274\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5941 - val_loss: 0.5153\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5398 - val_loss: 0.5030s\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5633 - val_loss: 0.4970\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5081 - val_loss: 0.4848\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4997 - val_loss: 0.4723\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4730 - val_loss: 0.4631\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4943 - val_loss: 0.4598\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4629 - val_loss: 0.4422\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4414 - val_loss: 0.4471\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4283 - val_loss: 0.4324\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4358 - val_loss: 0.4175\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4214 - val_loss: 0.4099\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3946 - val_loss: 0.4087\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3816 - val_loss: 0.4076\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3700 - val_loss: 0.3951\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3501 - val_loss: 0.3961\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.3424 - val_loss: 0.3822\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3221 - val_loss: 0.3829\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3192 - val_loss: 0.3998\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3054 - val_loss: 0.3904\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3023 - val_loss: 0.3616\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2944 - val_loss: 0.3644\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2692 - val_loss: 0.3405\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2919 - val_loss: 0.3398\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2836 - val_loss: 0.3200\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2863 - val_loss: 0.3388\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2707 - val_loss: 0.3295\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2547 - val_loss: 0.3368ss: 0\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2795 - val_loss: 0.3380\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2445 - val_loss: 0.3323\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2559 - val_loss: 0.3252\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2268 - val_loss: 0.3302\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2457 - val_loss: 0.3272\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2487 - val_loss: 0.3235\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2245 - val_loss: 0.3168\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2241 - val_loss: 0.3196\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2347 - val_loss: 0.3163\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2229 - val_loss: 0.3152\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2173 - val_loss: 0.3145\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2268 - val_loss: 0.3132\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2338 - val_loss: 0.3121\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2242 - val_loss: 0.3106\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2289 - val_loss: 0.3111\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2225 - val_loss: 0.3089\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2305 - val_loss: 0.3088\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2185 - val_loss: 0.3073\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2164 - val_loss: 0.3066\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2290 - val_loss: 0.3074\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2173 - val_loss: 0.3076\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2099 - val_loss: 0.3066\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2200 - val_loss: 0.3052\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2168 - val_loss: 0.3049\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2207 - val_loss: 0.3055\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2228 - val_loss: 0.3037\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2285 - val_loss: 0.3059\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2204 - val_loss: 0.3040\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2172 - val_loss: 0.3036\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2078 - val_loss: 0.3073\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2264 - val_loss: 0.3089\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2246 - val_loss: 0.3030\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2218 - val_loss: 0.3075\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2269 - val_loss: 0.3032\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2141 - val_loss: 0.3036\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2262 - val_loss: 0.3081\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2180 - val_loss: 0.3041\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2142 - val_loss: 0.3020\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2173 - val_loss: 0.3029\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2187 - val_loss: 0.3031\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2175 - val_loss: 0.3033\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2218 - val_loss: 0.3044\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2185 - val_loss: 0.3032\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2162 - val_loss: 0.3045\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2213 - val_loss: 0.3058\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2197 - val_loss: 0.3031\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2135 - val_loss: 0.3041\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2223 - val_loss: 0.3056\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2256 - val_loss: 0.3029\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2040 - val_loss: 0.3042\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2160 - val_loss: 0.3054\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2093 - val_loss: 0.3050\n",
      "Epoch 143/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2106 - val_loss: 0.3067\n",
      "Epoch 144/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2185 - val_loss: 0.3057\n",
      "Epoch 00143: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 6.0min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s - loss: 20.0942 - val_loss: 0.8136\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0030 - val_loss: 0.9603\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7806 - val_loss: 1.2271\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8729 - val_loss: 1.7879\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8358 - val_loss: 0.9619\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9414 - val_loss: 0.8750\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8121 - val_loss: 1.6118\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7477 - val_loss: 0.9961\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7338 - val_loss: 0.9893\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.6366 - val_loss: 1.1184\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 3s - loss: 2.5476 - val_loss: 0.8421\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5194 - val_loss: 0.5527\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4755 - val_loss: 1.0787\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2527 - val_loss: 0.8256\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2855 - val_loss: 0.8438\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2753 - val_loss: 1.0116\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3225 - val_loss: 0.8034\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0521 - val_loss: 0.7980\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0907 - val_loss: 0.9968\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0527 - val_loss: 1.0174\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9950 - val_loss: 0.8992\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0365 - val_loss: 0.9435\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9572 - val_loss: 1.2391\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9480 - val_loss: 1.0281\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8967 - val_loss: 0.8584\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.8395 - val_loss: 0.6997\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7277 - val_loss: 0.7194\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7544 - val_loss: 0.5657\n",
      "Epoch 00027: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 1.4min\n",
      "[CV] activation_function=relu, hidden_layer_size=128, num_hidden_layers=1 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 8s - loss: 20.6864 - val_loss: 1.7017\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.0112 - val_loss: 2.2236\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1670 - val_loss: 2.3042\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.2021 - val_loss: 2.2948\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7283 - val_loss: 2.0460\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9767 - val_loss: 1.9477ss: 3.\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7836 - val_loss: 1.9012\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.7922 - val_loss: 2.0150\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6238 - val_loss: 1.9004\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.6609 - val_loss: 1.9019\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.5374 - val_loss: 1.8315\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4960 - val_loss: 1.6796\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3543 - val_loss: 1.8568\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3308 - val_loss: 1.6294\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3930 - val_loss: 1.7287\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 3.1001 - val_loss: 1.6300\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9770 - val_loss: 1.6842\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9242 - val_loss: 1.5927\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8149 - val_loss: 1.4629\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8756 - val_loss: 1.6235\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7163 - val_loss: 1.4570\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7231 - val_loss: 1.3556\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4787 - val_loss: 1.5156\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4960 - val_loss: 1.4560\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5068 - val_loss: 1.3245\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.3018 - val_loss: 1.3199\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1922 - val_loss: 1.3325\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1677 - val_loss: 1.2519\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2212 - val_loss: 1.1755\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9987 - val_loss: 1.2055\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0158 - val_loss: 1.1610\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.1583 - val_loss: 1.1574\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9273 - val_loss: 1.0946\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7795 - val_loss: 1.0132\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7969 - val_loss: 1.0307\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6793 - val_loss: 1.0101\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6320 - val_loss: 1.0118\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5946 - val_loss: 0.9837\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4721 - val_loss: 0.9486\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5734 - val_loss: 0.9095\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3828 - val_loss: 0.9163\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3723 - val_loss: 0.8936\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3452 - val_loss: 0.8589\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2582 - val_loss: 0.8267\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2600 - val_loss: 0.8149\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1720 - val_loss: 0.7848\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1260 - val_loss: 0.7715\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1597 - val_loss: 0.7514\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0478 - val_loss: 0.7525\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1260 - val_loss: 0.7183\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9989 - val_loss: 0.7087\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9589 - val_loss: 0.6834\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9415 - val_loss: 0.6610\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8610 - val_loss: 0.6514\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8923 - val_loss: 0.6334\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8623 - val_loss: 0.6181\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8057 - val_loss: 0.6026\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7124 - val_loss: 0.5914\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.7721 - val_loss: 0.5786\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7100 - val_loss: 0.5642\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6777 - val_loss: 0.5550\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6786 - val_loss: 0.5372\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6465 - val_loss: 0.5298\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6268 - val_loss: 0.5118\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5982 - val_loss: 0.4955\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5727 - val_loss: 0.4830\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5362 - val_loss: 0.4737\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5767 - val_loss: 0.4703\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5350 - val_loss: 0.4550\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4815 - val_loss: 0.4535\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4761 - val_loss: 0.4415\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4878 - val_loss: 0.4384\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4261 - val_loss: 0.4295\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4327 - val_loss: 0.4038\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4155 - val_loss: 0.4065\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4031 - val_loss: 0.4019\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3788 - val_loss: 0.4104\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3722 - val_loss: 0.3983\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3545 - val_loss: 0.4060\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3601 - val_loss: 0.3859\n",
      "Epoch 81/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3510 - val_loss: 0.3799\n",
      "Epoch 82/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3333 - val_loss: 0.3778\n",
      "Epoch 83/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3242 - val_loss: 0.3705\n",
      "Epoch 84/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3062 - val_loss: 0.3670\n",
      "Epoch 85/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3140 - val_loss: 0.3575\n",
      "Epoch 86/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2966 - val_loss: 0.3492\n",
      "Epoch 87/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3019 - val_loss: 0.3474\n",
      "Epoch 88/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2825 - val_loss: 0.3552\n",
      "Epoch 89/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2883 - val_loss: 0.3478\n",
      "Epoch 90/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2600 - val_loss: 0.3374\n",
      "Epoch 91/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2483 - val_loss: 0.3456\n",
      "Epoch 92/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2704 - val_loss: 0.3369\n",
      "Epoch 93/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2665 - val_loss: 0.3347\n",
      "Epoch 94/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2440 - val_loss: 0.3315\n",
      "Epoch 95/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2436 - val_loss: 0.3249\n",
      "Epoch 96/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2238 - val_loss: 0.3273\n",
      "Epoch 97/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2466 - val_loss: 0.3259\n",
      "Epoch 98/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2326 - val_loss: 0.3246\n",
      "Epoch 99/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2339 - val_loss: 0.3225\n",
      "Epoch 100/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2402 - val_loss: 0.3182\n",
      "Epoch 101/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2193 - val_loss: 0.3207\n",
      "Epoch 102/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2475 - val_loss: 0.3175\n",
      "Epoch 103/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2299 - val_loss: 0.3133\n",
      "Epoch 104/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2330 - val_loss: 0.3181\n",
      "Epoch 105/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2270 - val_loss: 0.3151\n",
      "Epoch 106/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2184 - val_loss: 0.3133\n",
      "Epoch 107/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2248 - val_loss: 0.3094\n",
      "Epoch 108/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2299 - val_loss: 0.3143\n",
      "Epoch 109/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2244 - val_loss: 0.3100\n",
      "Epoch 110/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2229 - val_loss: 0.3101\n",
      "Epoch 111/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2093 - val_loss: 0.3103\n",
      "Epoch 112/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2177 - val_loss: 0.3118\n",
      "Epoch 113/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2184 - val_loss: 0.3091\n",
      "Epoch 114/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2146 - val_loss: 0.3081\n",
      "Epoch 115/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2104 - val_loss: 0.3080\n",
      "Epoch 116/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2241 - val_loss: 0.3084\n",
      "Epoch 117/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2124 - val_loss: 0.3099\n",
      "Epoch 118/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2245 - val_loss: 0.3092\n",
      "Epoch 119/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2033 - val_loss: 0.3090\n",
      "Epoch 120/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2171 - val_loss: 0.3082\n",
      "Epoch 121/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2281 - val_loss: 0.3069\n",
      "Epoch 122/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2160 - val_loss: 0.3073\n",
      "Epoch 123/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2131 - val_loss: 0.3063\n",
      "Epoch 124/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2064 - val_loss: 0.3071\n",
      "Epoch 125/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2105 - val_loss: 0.3077\n",
      "Epoch 126/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2143 - val_loss: 0.3049\n",
      "Epoch 127/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2255 - val_loss: 0.3074\n",
      "Epoch 128/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2108 - val_loss: 0.3070\n",
      "Epoch 129/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2173 - val_loss: 0.3073\n",
      "Epoch 130/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2201 - val_loss: 0.3083\n",
      "Epoch 131/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2200 - val_loss: 0.3070\n",
      "Epoch 132/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2211 - val_loss: 0.3058\n",
      "Epoch 133/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2203 - val_loss: 0.3079\n",
      "Epoch 134/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2137 - val_loss: 0.3059\n",
      "Epoch 135/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2182 - val_loss: 0.3083\n",
      "Epoch 136/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2194 - val_loss: 0.3076\n",
      "Epoch 137/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2204 - val_loss: 0.3068\n",
      "Epoch 138/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2181 - val_loss: 0.3063\n",
      "Epoch 139/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2183 - val_loss: 0.3053\n",
      "Epoch 140/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2221 - val_loss: 0.3068\n",
      "Epoch 141/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2194 - val_loss: 0.3089\n",
      "Epoch 142/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.2177 - val_loss: 0.3081\n",
      "Epoch 00141: early stopping\n",
      "[CV]  activation_function=relu, hidden_layer_size=128, num_hidden_layers=1, total= 6.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 21.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 9s - loss: 13.6476 - val_loss: 0.6872\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 4s - loss: 2.4768 - val_loss: 0.8707\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 4s - loss: 2.2315 - val_loss: 0.6842\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 4s - loss: 2.3325 - val_loss: 0.7052\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 4s - loss: 2.3027 - val_loss: 0.9155\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 4s - loss: 2.1025 - val_loss: 0.7699\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 4s - loss: 2.1375 - val_loss: 1.1550\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.1610 - val_loss: 0.4546\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.0047 - val_loss: 1.1185\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.0176 - val_loss: 0.6559\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.9981 - val_loss: 0.5126\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.9078 - val_loss: 0.6119\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.7814 - val_loss: 0.7711\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.8407 - val_loss: 0.7360\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.8079 - val_loss: 1.0445\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.7135 - val_loss: 0.7640\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.5760 - val_loss: 0.6845\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.6785 - val_loss: 0.3925\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.5505 - val_loss: 0.7255\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.4701 - val_loss: 0.4985\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.4639 - val_loss: 0.7109\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.3541 - val_loss: 0.4971\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.3935 - val_loss: 0.5776\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.3901 - val_loss: 0.4620\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.3574 - val_loss: 0.5689\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.1866 - val_loss: 0.7071\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.2633 - val_loss: 0.4688\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.1484 - val_loss: 0.5108\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.1497 - val_loss: 0.5948\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.1233 - val_loss: 0.5096\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.0669 - val_loss: 0.5594\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.9831 - val_loss: 0.6693\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.9518 - val_loss: 0.4957\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.9402 - val_loss: 0.4824\n",
      "Epoch 00033: early stopping\n",
      "Out-of-sample MSE:  0.482352497173\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 7s - loss: 271.5993 - val_loss: 6.3965\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 2s - loss: 40.9068 - val_loss: 0.6698\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 2s - loss: 27.5639 - val_loss: 0.3895\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 2s - loss: 27.5557 - val_loss: 0.6857\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 2s - loss: 30.6489 - val_loss: 3.8001\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 2s - loss: 35.1099 - val_loss: 2.4604\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 2s - loss: 34.6040 - val_loss: 0.9332\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 2s - loss: 24.6559 - val_loss: 0.9138\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 2s - loss: 22.6367 - val_loss: 1.0496\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 2s - loss: 18.7675 - val_loss: 1.1982\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 2s - loss: 15.8159 - val_loss: 0.4659\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 2s - loss: 14.1896 - val_loss: 1.5614\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 2s - loss: 13.9081 - val_loss: 0.4470\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 2s - loss: 15.4336 - val_loss: 0.5483\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 2s - loss: 11.0941 - val_loss: 0.4812\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 2s - loss: 11.3753 - val_loss: 0.9850\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 2s - loss: 9.8470 - val_loss: 1.1346\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 2s - loss: 13.9509 - val_loss: 0.4493\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 2s - loss: 10.3348 - val_loss: 0.7294\n",
      "Epoch 00018: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total=  58.9s\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   59.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 225.3927 - val_loss: 1.7458\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 46.4668 - val_loss: 1.7449\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 1s - loss: 27.3879 - val_loss: 2.5573\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 1s - loss: 27.2611 - val_loss: 1.2608\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 32.0289 - val_loss: 0.9102\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 31.0040 - val_loss: 0.7881\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 43.3092 - val_loss: 5.3709\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 1s - loss: 29.5363 - val_loss: 2.2555\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 28.3173 - val_loss: 1.4563\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.7437 - val_loss: 0.4135\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.0850 - val_loss: 0.6719\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.5266 - val_loss: 0.5742\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.7126 - val_loss: 0.8677\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.4216 - val_loss: 2.5056\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 9.6249 - val_loss: 0.7844\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.9601 - val_loss: 0.6341\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.0076 - val_loss: 0.9086\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.4407 - val_loss: 1.1788\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.4480 - val_loss: 1.2337\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.7367 - val_loss: 0.4014\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 7.5058 - val_loss: 0.4606\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5399 - val_loss: 0.3842\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5486 - val_loss: 0.4569\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.9693 - val_loss: 0.5159\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3620 - val_loss: 0.4588\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.0635 - val_loss: 0.5640\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.8712 - val_loss: 0.3552\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9451 - val_loss: 0.3937\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4188 - val_loss: 0.3479\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2394 - val_loss: 0.3362\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.5547 - val_loss: 0.4151\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0056 - val_loss: 0.3868\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6913 - val_loss: 0.3907\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.7690 - val_loss: 0.4195\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.0429 - val_loss: 0.5888\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.6782 - val_loss: 0.5283\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5070 - val_loss: 0.5353\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.4937 - val_loss: 0.4047\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3483 - val_loss: 0.3880\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2712 - val_loss: 0.3201\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1820 - val_loss: 0.3686\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1317 - val_loss: 0.3955\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1876 - val_loss: 0.3071\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9755 - val_loss: 0.3309\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8729 - val_loss: 0.3830\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9260 - val_loss: 0.4843\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7970 - val_loss: 0.3909\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9049 - val_loss: 0.3129\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7220 - val_loss: 0.2991\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7425 - val_loss: 0.2974\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7550 - val_loss: 0.2996\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6992 - val_loss: 0.3756\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7003 - val_loss: 0.3093\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6516 - val_loss: 0.3085\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5656 - val_loss: 0.3394\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5985 - val_loss: 0.3083\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5408 - val_loss: 0.3046\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5300 - val_loss: 0.3530\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5078 - val_loss: 0.3180\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4808 - val_loss: 0.3070\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4821 - val_loss: 0.3532\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4994 - val_loss: 0.3064\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.3998 - val_loss: 0.3192\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5066 - val_loss: 0.3061\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4377 - val_loss: 0.3052\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4213 - val_loss: 0.2997\n",
      "Epoch 00065: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 3.0min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 148.7861 - val_loss: 0.4699\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 42.6374 - val_loss: 0.9092\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 32.0879 - val_loss: 0.6550\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 30.7871 - val_loss: 0.7940\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 27.4643 - val_loss: 0.4926\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 23.0424 - val_loss: 0.6467\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 18.0975 - val_loss: 1.2226\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.0014 - val_loss: 1.2299\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.0978 - val_loss: 1.8773\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.1567 - val_loss: 1.5869\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.6174 - val_loss: 1.0646\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.5883 - val_loss: 0.8809\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 8.7535 - val_loss: 0.5608\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.3641 - val_loss: 0.5538\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.1215 - val_loss: 0.4983\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.3527 - val_loss: 0.9001\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5712 - val_loss: 0.7410\n",
      "Epoch 00016: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total=  54.7s\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 156.2382 - val_loss: 2.0916\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 36.3979 - val_loss: 1.8298\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 31.1670 - val_loss: 0.8657\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 27.6167 - val_loss: 2.7381\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 28.6850 - val_loss: 2.1677\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 28.1631 - val_loss: 1.0619\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 21.4809 - val_loss: 1.6355\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 16.8200 - val_loss: 1.7032\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.6841 - val_loss: 1.6403\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.9519 - val_loss: 0.5791\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.1423 - val_loss: 1.2834\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 11.2333 - val_loss: 0.4401\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.8970 - val_loss: 0.4672\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 6.0040 - val_loss: 0.3267\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 5.7500 - val_loss: 1.4136\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.8828 - val_loss: 0.8745\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.5937 - val_loss: 0.3597\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.4470 - val_loss: 0.3605\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.3990 - val_loss: 0.4065\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 2s - loss: 3.2934 - val_loss: 0.3126\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 2s - loss: 4.1216 - val_loss: 0.7047\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.7961 - val_loss: 0.7148\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.9332 - val_loss: 0.3857\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.4102 - val_loss: 0.3525\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 2s - loss: 2.2445 - val_loss: 0.6766\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9190 - val_loss: 0.4868\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5935 - val_loss: 0.3902\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.9991 - val_loss: 0.3497\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5569 - val_loss: 0.3373\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.5833 - val_loss: 0.4863\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.3707 - val_loss: 0.4006\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.2671 - val_loss: 0.3849\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0670 - val_loss: 0.4087\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1916 - val_loss: 0.2960\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.1429 - val_loss: 0.4832\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 2s - loss: 1.0375 - val_loss: 0.3185\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.9372 - val_loss: 0.3097\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7828 - val_loss: 0.2981\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.8653 - val_loss: 0.3107\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7870 - val_loss: 0.3060\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 1s - loss: 0.7599 - val_loss: 0.3143\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6788 - val_loss: 0.3479\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.7837 - val_loss: 0.3019\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6608 - val_loss: 0.3316\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6105 - val_loss: 0.3573\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.6135 - val_loss: 0.3080\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5602 - val_loss: 0.3184\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5457 - val_loss: 0.3424\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.5035 - val_loss: 0.3131\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 2s - loss: 0.4926 - val_loss: 0.3082\n",
      "Epoch 00049: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total= 2.3min\n",
      "[CV] activation_function=linear, hidden_layer_size=128, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 7s - loss: 257.7542 - val_loss: 13.2533\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 2s - loss: 38.7108 - val_loss: 0.4955\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 2s - loss: 23.2300 - val_loss: 1.0285\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 2s - loss: 22.8338 - val_loss: 1.1044\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 2s - loss: 29.9621 - val_loss: 0.7832\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 2s - loss: 26.8795 - val_loss: 0.6549\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 2s - loss: 48.4833 - val_loss: 0.7120\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 2s - loss: 36.4572 - val_loss: 1.2612\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 2s - loss: 45.1984 - val_loss: 1.2043\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 2s - loss: 36.9177 - val_loss: 1.4479\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 2s - loss: 29.5352 - val_loss: 4.2531\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 2s - loss: 15.7616 - val_loss: 1.5548\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 2s - loss: 13.1885 - val_loss: 0.8973\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 2s - loss: 14.5885 - val_loss: 1.6754\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 2s - loss: 12.9520 - val_loss: 1.9051\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 2s - loss: 17.8403 - val_loss: 10.4006\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 2s - loss: 32.6616 - val_loss: 0.5164\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 2s - loss: 10.7463 - val_loss: 2.1092\n",
      "Epoch 00017: early stopping\n",
      "[CV]  activation_function=linear, hidden_layer_size=128, num_hidden_layers=3, total=  56.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  8.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 8s - loss: 190.0287 - val_loss: 1.6548\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 3s - loss: 36.6705 - val_loss: 2.9221\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 3s - loss: 32.7086 - val_loss: 1.3917\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 3s - loss: 25.3583 - val_loss: 0.4931\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 3s - loss: 28.8232 - val_loss: 0.4222\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 3s - loss: 23.0341 - val_loss: 0.6656\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 3s - loss: 20.1709 - val_loss: 0.6974\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 3s - loss: 16.7607 - val_loss: 0.4527\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 3s - loss: 17.0711 - val_loss: 0.4426\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 3s - loss: 16.4228 - val_loss: 1.1499\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 3s - loss: 12.1735 - val_loss: 1.1959\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 3s - loss: 11.1546 - val_loss: 1.1466\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 3s - loss: 9.3424 - val_loss: 0.9990\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 3s - loss: 8.2301 - val_loss: 0.9487\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 3s - loss: 6.9460 - val_loss: 0.4348\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 3s - loss: 6.5076 - val_loss: 0.5245\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 3s - loss: 5.5328 - val_loss: 0.5431\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 3s - loss: 4.2503 - val_loss: 0.4062\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 3s - loss: 3.5445 - val_loss: 0.3620\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 3s - loss: 3.4325 - val_loss: 0.4181\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 3s - loss: 3.0313 - val_loss: 0.5553\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.7626 - val_loss: 0.5556\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.5402 - val_loss: 0.7438\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.4219 - val_loss: 0.5444\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 3s - loss: 2.1198 - val_loss: 0.3897\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.9433 - val_loss: 0.3935\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.7011 - val_loss: 0.4063\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.7143 - val_loss: 0.3602\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.5711 - val_loss: 0.3405\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.7251 - val_loss: 0.3335\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.7341 - val_loss: 0.4376\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.3404 - val_loss: 0.3385\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.3397 - val_loss: 0.3717\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.0750 - val_loss: 0.3174\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.0628 - val_loss: 0.3160\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 3s - loss: 1.0468 - val_loss: 0.3492\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.9385 - val_loss: 0.3221\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.9337 - val_loss: 0.4239\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.8221 - val_loss: 0.3294\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.8110 - val_loss: 0.3886\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.7256 - val_loss: 0.3119\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.7496 - val_loss: 0.3261\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.6694 - val_loss: 0.3110\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.6276 - val_loss: 0.3679\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.6489 - val_loss: 0.3236\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.5850 - val_loss: 0.3185\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.6157 - val_loss: 0.3240\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.5462 - val_loss: 0.3884\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.5091 - val_loss: 0.3153\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.5014 - val_loss: 0.3261\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.4460 - val_loss: 0.3194\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.4591 - val_loss: 0.3084\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.4738 - val_loss: 0.3905\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.4245 - val_loss: 0.3149\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.4344 - val_loss: 0.3115\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3961 - val_loss: 0.3604\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.4183 - val_loss: 0.3466\n",
      "Epoch 58/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3744 - val_loss: 0.3121\n",
      "Epoch 59/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3584 - val_loss: 0.3239\n",
      "Epoch 60/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3575 - val_loss: 0.3250\n",
      "Epoch 61/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3409 - val_loss: 0.3128\n",
      "Epoch 62/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3375 - val_loss: 0.3132\n",
      "Epoch 63/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3470 - val_loss: 0.3103\n",
      "Epoch 64/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3149 - val_loss: 0.4246\n",
      "Epoch 65/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3079 - val_loss: 0.3340\n",
      "Epoch 66/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.3136 - val_loss: 0.3892\n",
      "Epoch 67/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.2976 - val_loss: 0.3204\n",
      "Epoch 68/200\n",
      "1696/1696 [==============================] - 3s - loss: 0.2980 - val_loss: 0.3179\n",
      "Epoch 00067: early stopping\n",
      "Out-of-sample MSE:  0.317887099487\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 9s - loss: 1.7821 - val_loss: 0.4064\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.8315 - val_loss: 0.3550\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.6277 - val_loss: 0.3722\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.5098 - val_loss: 0.3196\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4527 - val_loss: 0.3130\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4118 - val_loss: 0.3162\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4152 - val_loss: 0.3572\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4344 - val_loss: 0.3217\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.4063 - val_loss: 0.3079\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3842 - val_loss: 0.3258\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3733 - val_loss: 0.3022\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3508 - val_loss: 0.3268\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3657 - val_loss: 0.3038\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3612 - val_loss: 0.3108\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3521 - val_loss: 0.3107 ETA: 0s - loss: 0\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3458 - val_loss: 0.2948 1s -\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3548 - val_loss: 0.2979\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3471 - val_loss: 0.2877\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3306 - val_loss: 0.3023\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3354 - val_loss: 0.3217\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3264 - val_loss: 0.2883\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3283 - val_loss: 0.2827\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3267 - val_loss: 0.2938\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3201 - val_loss: 0.2984\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3164 - val_loss: 0.3153\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3260 - val_loss: 0.2847\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3146 - val_loss: 0.2983\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3066 - val_loss: 0.3017\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3087 - val_loss: 0.2870\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 3s - loss: 0.3031 - val_loss: 0.2967\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3038 - val_loss: 0.2825\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3096 - val_loss: 0.2893\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3062 - val_loss: 0.3097ETA: 1s -\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2969 - val_loss: 0.2925\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2998 - val_loss: 0.3016\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2895 - val_loss: 0.2867\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2734 - val_loss: 0.2839\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.2922 - val_loss: 0.2967\n",
      "Epoch 00037: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 3.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  3.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 1.1785 - val_loss: 0.3978s: 1\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7087 - val_loss: 0.3855\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6004 - val_loss: 0.3375\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4818 - val_loss: 0.3375\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4539 - val_loss: 0.3655\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4353 - val_loss: 0.3411\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4221 - val_loss: 0.3322\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4107 - val_loss: 0.3264\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4083 - val_loss: 0.3299\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3922 - val_loss: 0.3485\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3863 - val_loss: 0.3315\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3761 - val_loss: 0.3277\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3720 - val_loss: 0.3373 0s - loss\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3669 - val_loss: 0.3948\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3809 - val_loss: 0.3337\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3733 - val_loss: 0.3924\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3740 - val_loss: 0.3101\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3755 - val_loss: 0.3095\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3742 - val_loss: 0.3035\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3738 - val_loss: 0.3054ss: \n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3468 - val_loss: 0.3127\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3510 - val_loss: 0.3118\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.3052\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3463 - val_loss: 0.3121\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3271 - val_loss: 0.3021\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3282 - val_loss: 0.2976\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3359 - val_loss: 0.3006ss: 0 - ETA: 0s - los\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3274 - val_loss: 0.3037\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3271 - val_loss: 0.3019\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3266 - val_loss: 0.3039\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3186 - val_loss: 0.3094\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3237 - val_loss: 0.3154\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3262 - val_loss: 0.3219\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3197 - val_loss: 0.3058\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3299 - val_loss: 0.3038\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3046 - val_loss: 0.3007\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3312 - val_loss: 0.3170\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3330 - val_loss: 0.3179\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3244 - val_loss: 0.2979\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3056 - val_loss: 0.2944ss: \n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3123 - val_loss: 0.3169\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2957 - val_loss: 0.3078\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3151 - val_loss: 0.3092\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3010 - val_loss: 0.3024\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3019 - val_loss: 0.3003\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2954 - val_loss: 0.3404\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3105 - val_loss: 0.3036\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3018 - val_loss: 0.3045\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3045 - val_loss: 0.3028\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.2915 - val_loss: 0.2923\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3040 - val_loss: 0.3002\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2943 - val_loss: 0.2937\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2794 - val_loss: 0.3032ss: 0.28\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2785 - val_loss: 0.3008\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2995 - val_loss: 0.3010\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2766 - val_loss: 0.2936\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2691 - val_loss: 0.3027\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2815 - val_loss: 0.2893\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2855 - val_loss: 0.2930\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2813 - val_loss: 0.2826\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2606 - val_loss: 0.3085\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2679 - val_loss: 0.3279\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2782 - val_loss: 0.2987\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2631 - val_loss: 0.2959\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2675 - val_loss: 0.2967\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2660 - val_loss: 0.3185\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2617 - val_loss: 0.3014\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2508 - val_loss: 0.2974\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2690 - val_loss: 0.2884\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2661 - val_loss: 0.2997\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2444 - val_loss: 0.3017\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2641 - val_loss: 0.2852\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2497 - val_loss: 0.3001\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2521 - val_loss: 0.2964ss: 0 - ETA: 1s - loss: 0 - ETA: 1s - loss: 0.25 - ETA: 1s -\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2448 - val_loss: 0.2908\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2525 - val_loss: 0.3385\n",
      "Epoch 00075: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 6.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s - loss: 1.2511 - val_loss: 0.3772\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7147 - val_loss: 0.3312\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5624 - val_loss: 0.3611\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4798 - val_loss: 0.3330ss: 0\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4664 - val_loss: 0.3226ss: \n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4200 - val_loss: 0.3259ss: 0.418\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4045 - val_loss: 0.3380\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4107 - val_loss: 0.3132\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3871 - val_loss: 0.3095\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3767 - val_loss: 0.3039\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3694 - val_loss: 0.3196ss: - ETA: 2s - ETA: 0s - loss\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3872 - val_loss: 0.3193\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3780 - val_loss: 0.3257\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3843 - val_loss: 0.3215\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3660 - val_loss: 0.3216\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3677 - val_loss: 0.3312\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3691 - val_loss: 0.3356\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3539 - val_loss: 0.3023\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3696 - val_loss: 0.2984\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3438 - val_loss: 0.3046\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3298 - val_loss: 0.2912ss: 0.\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3279 - val_loss: 0.2942\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3239 - val_loss: 0.2853\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3178 - val_loss: 0.2944\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3156 - val_loss: 0.2820\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3077 - val_loss: 0.2874\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3196 - val_loss: 0.3215\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2993 - val_loss: 0.2893\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2929 - val_loss: 0.3101\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3006 - val_loss: 0.2949\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2866 - val_loss: 0.2949\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2902 - val_loss: 0.3230\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2958 - val_loss: 0.3372\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2984 - val_loss: 0.2811\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2760 - val_loss: 0.2914ss: 0\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2749 - val_loss: 0.3163\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2872 - val_loss: 0.2975ss: 0.288\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2876 - val_loss: 0.3007\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2828 - val_loss: 0.3050\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2668 - val_loss: 0.2963\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2802 - val_loss: 0.3018\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 3.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 9s - loss: 1.1775 - val_loss: 0.5131\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7663 - val_loss: 0.3384\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5656 - val_loss: 0.3302\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5351 - val_loss: 0.3579ss: 0.\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4439 - val_loss: 0.3257A: 0s - loss: \n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4443 - val_loss: 0.3081\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3969 - val_loss: 0.3104\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 6s - loss: 0.3994 - val_loss: 0.3134\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3952 - val_loss: 0.2930\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3838 - val_loss: 0.3183\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3751 - val_loss: 0.3092\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3719 - val_loss: 0.3009\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3710 - val_loss: 0.2946\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3658 - val_loss: 0.2905\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3519 - val_loss: 0.3104\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3678 - val_loss: 0.3000\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3655 - val_loss: 0.3048\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3460 - val_loss: 0.3015\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3205 - val_loss: 0.2946\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3203 - val_loss: 0.2919\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3121 - val_loss: 0.3283\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3087 - val_loss: 0.2951\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3149 - val_loss: 0.3343\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3096 - val_loss: 0.3198\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3049 - val_loss: 0.2761\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3088 - val_loss: 0.3333\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3155 - val_loss: 0.2840\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2951 - val_loss: 0.3066\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2729 - val_loss: 0.2806\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2671 - val_loss: 0.2903\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2745 - val_loss: 0.2835\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2840 - val_loss: 0.2836\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2662 - val_loss: 0.2850\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2854 - val_loss: 0.2865\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2614 - val_loss: 0.3005\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2767 - val_loss: 0.2950\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2701 - val_loss: 0.3105\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2654 - val_loss: 0.3012\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2613 - val_loss: 0.2872\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2585 - val_loss: 0.2910\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2526 - val_loss: 0.2969\n",
      "Epoch 00040: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 3.8min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 1.0328 - val_loss: 0.3419\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6484 - val_loss: 0.3368\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5251 - val_loss: 0.3435\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4741 - val_loss: 0.3376\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4102 - val_loss: 0.3377\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4256 - val_loss: 0.3342\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4255 - val_loss: 0.3696\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4134 - val_loss: 0.3390\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4029 - val_loss: 0.3284\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3896 - val_loss: 0.3292\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4041 - val_loss: 0.3384\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4008 - val_loss: 0.3304\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3936 - val_loss: 0.3275\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3622 - val_loss: 0.3307\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3655 - val_loss: 0.3669\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 3s - loss: 0.3695 - val_loss: 0.3203\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3647 - val_loss: 0.3265\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3698 - val_loss: 0.3186\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3681 - val_loss: 0.3136\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3645 - val_loss: 0.3188\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3542 - val_loss: 0.3140\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3564 - val_loss: 0.3253\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3595 - val_loss: 0.3206\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3624 - val_loss: 0.3154\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3398 - val_loss: 0.3132\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3320 - val_loss: 0.3057\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3367 - val_loss: 0.3369\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3031 - val_loss: 0.3317\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3133 - val_loss: 0.3037\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3206 - val_loss: 0.2980\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3123 - val_loss: 0.3158\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3320 - val_loss: 0.3124\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3104 - val_loss: 0.3136\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3144 - val_loss: 0.3100\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2868 - val_loss: 0.3154\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2890 - val_loss: 0.3052\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2737 - val_loss: 0.3167\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3021 - val_loss: 0.3207\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2914 - val_loss: 0.3226\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2728 - val_loss: 0.3055\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2949 - val_loss: 0.3156\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2901 - val_loss: 0.3122\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2693 - val_loss: 0.3239\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2746 - val_loss: 0.3215\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2597 - val_loss: 0.3217\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2866 - val_loss: 0.3382\n",
      "Epoch 00045: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=2, total= 4.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 20.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 12s - loss: 1.4798 - val_loss: 0.4951\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.7226 - val_loss: 0.3699\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.6122 - val_loss: 0.3387\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4847 - val_loss: 0.3303\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4476 - val_loss: 0.3289\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4183 - val_loss: 0.3285\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4346 - val_loss: 0.3304\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4204 - val_loss: 0.3336\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4088 - val_loss: 0.3404\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.4045 - val_loss: 0.3408\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3868 - val_loss: 0.3160\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3883 - val_loss: 0.3299\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3817 - val_loss: 0.3156\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3718 - val_loss: 0.3116\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3631 - val_loss: 0.3551\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3709 - val_loss: 0.3061\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3432 - val_loss: 0.3188\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3584 - val_loss: 0.3261\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3606 - val_loss: 0.3174\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3551 - val_loss: 0.2993\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3510 - val_loss: 0.3057\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3431 - val_loss: 0.2981\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3252 - val_loss: 0.3059\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3427 - val_loss: 0.3130\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3273 - val_loss: 0.3140\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3256 - val_loss: 0.3043\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3170 - val_loss: 0.2888\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3127 - val_loss: 0.3025\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3233 - val_loss: 0.2949\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3227 - val_loss: 0.3204\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3139 - val_loss: 0.3140\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3045 - val_loss: 0.3087\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3077 - val_loss: 0.3134\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3257 - val_loss: 0.3074\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3193 - val_loss: 0.2978\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3143 - val_loss: 0.2983\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3062 - val_loss: 0.3043\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3120 - val_loss: 0.2988\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3103 - val_loss: 0.3053\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3013 - val_loss: 0.3056\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.3059 - val_loss: 0.3103\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2999 - val_loss: 0.3097\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2773 - val_loss: 0.2853\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2796 - val_loss: 0.3173\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2842 - val_loss: 0.2839\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2775 - val_loss: 0.2964\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2700 - val_loss: 0.2851\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2714 - val_loss: 0.3111\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2949 - val_loss: 0.3038\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2629 - val_loss: 0.2876\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2708 - val_loss: 0.2801\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2660 - val_loss: 0.2982\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2759 - val_loss: 0.2831\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2860 - val_loss: 0.2881\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2595 - val_loss: 0.2882\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2554 - val_loss: 0.2935\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2718 - val_loss: 0.2973\n",
      "Epoch 58/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2603 - val_loss: 0.2793\n",
      "Epoch 59/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2527 - val_loss: 0.3100\n",
      "Epoch 60/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2563 - val_loss: 0.2895\n",
      "Epoch 61/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2618 - val_loss: 0.2999\n",
      "Epoch 62/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2543 - val_loss: 0.2914\n",
      "Epoch 63/200\n",
      "1696/1696 [==============================] - 7s - loss: 0.2433 - val_loss: 0.2930\n",
      "Epoch 64/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2589 - val_loss: 0.3015\n",
      "Epoch 65/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.2533 - val_loss: 0.3119\n",
      "Epoch 66/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2541 - val_loss: 0.3008\n",
      "Epoch 67/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2432 - val_loss: 0.3158\n",
      "Epoch 00066: early stopping\n",
      "Out-of-sample MSE:  0.315795403041\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1356 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1356/1356 [==============================] - 11s - loss: 1.3136 - val_loss: 0.3439\n",
      "Epoch 2/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.6761 - val_loss: 0.3783\n",
      "Epoch 3/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.5914 - val_loss: 0.3439\n",
      "Epoch 4/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.5077 - val_loss: 0.3369\n",
      "Epoch 5/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4629 - val_loss: 0.3452\n",
      "Epoch 6/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4154 - val_loss: 0.3387\n",
      "Epoch 7/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4147 - val_loss: 0.3361\n",
      "Epoch 8/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4120 - val_loss: 0.3867\n",
      "Epoch 9/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4076 - val_loss: 0.3619\n",
      "Epoch 10/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.4001 - val_loss: 0.3466\n",
      "Epoch 11/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3764 - val_loss: 0.3356\n",
      "Epoch 12/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3919 - val_loss: 0.3356\n",
      "Epoch 13/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3870 - val_loss: 0.3670\n",
      "Epoch 14/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3930 - val_loss: 0.3345\n",
      "Epoch 15/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3595 - val_loss: 0.3373\n",
      "Epoch 16/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3962 - val_loss: 0.3343\n",
      "Epoch 17/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3839 - val_loss: 0.3350\n",
      "Epoch 18/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3651 - val_loss: 0.3329\n",
      "Epoch 19/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3772 - val_loss: 0.3349\n",
      "Epoch 20/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3616 - val_loss: 0.3298\n",
      "Epoch 21/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3626 - val_loss: 0.3430\n",
      "Epoch 22/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3649 - val_loss: 0.3276\n",
      "Epoch 23/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3569 - val_loss: 0.3735\n",
      "Epoch 24/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3758 - val_loss: 0.3320\n",
      "Epoch 25/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3542 - val_loss: 0.3249\n",
      "Epoch 26/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3602 - val_loss: 0.3235\n",
      "Epoch 27/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3478 - val_loss: 0.3393\n",
      "Epoch 28/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3368 - val_loss: 0.3195\n",
      "Epoch 29/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3519 - val_loss: 0.3265\n",
      "Epoch 30/200\n",
      "1356/1356 [==============================] - 4s - loss: 0.3456 - val_loss: 0.3290\n",
      "Epoch 31/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3559 - val_loss: 0.3246\n",
      "Epoch 32/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3461 - val_loss: 0.3074\n",
      "Epoch 33/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3388 - val_loss: 0.3096\n",
      "Epoch 34/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3292 - val_loss: 0.3151\n",
      "Epoch 35/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3297 - val_loss: 0.3234\n",
      "Epoch 36/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3183 - val_loss: 0.3175\n",
      "Epoch 37/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3355 - val_loss: 0.3079\n",
      "Epoch 38/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3251 - val_loss: 0.3138\n",
      "Epoch 39/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3289 - val_loss: 0.3067\n",
      "Epoch 40/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3328 - val_loss: 0.3042\n",
      "Epoch 41/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3164 - val_loss: 0.3313\n",
      "Epoch 42/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3170 - val_loss: 0.2986\n",
      "Epoch 43/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3233 - val_loss: 0.3360\n",
      "Epoch 44/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3229 - val_loss: 0.3290\n",
      "Epoch 45/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3158 - val_loss: 0.3549\n",
      "Epoch 46/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3065 - val_loss: 0.3004\n",
      "Epoch 47/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3077 - val_loss: 0.3188\n",
      "Epoch 48/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.2930 - val_loss: 0.3118\n",
      "Epoch 49/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3106 - val_loss: 0.3030\n",
      "Epoch 50/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3290 - val_loss: 0.3233\n",
      "Epoch 51/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3064 - val_loss: 0.3074\n",
      "Epoch 52/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3107 - val_loss: 0.3133\n",
      "Epoch 53/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3019 - val_loss: 0.3062\n",
      "Epoch 54/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.2975 - val_loss: 0.3184\n",
      "Epoch 55/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3009 - val_loss: 0.3272\n",
      "Epoch 56/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3018 - val_loss: 0.3131\n",
      "Epoch 57/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.2997 - val_loss: 0.3621\n",
      "Epoch 58/200\n",
      "1356/1356 [==============================] - 5s - loss: 0.3064 - val_loss: 0.3028\n",
      "Epoch 00057: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 5.2min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 1.1285 - val_loss: 0.4279\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6429 - val_loss: 0.3600\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5621 - val_loss: 0.3391\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4744 - val_loss: 0.3473\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4434 - val_loss: 0.3422\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4183 - val_loss: 0.3551\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4109 - val_loss: 0.3420\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4071 - val_loss: 0.3360\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3820 - val_loss: 0.3577\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3874 - val_loss: 0.3931\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3885 - val_loss: 0.3340\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3719 - val_loss: 0.3301\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3919 - val_loss: 0.3446\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3698 - val_loss: 0.3485\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3915 - val_loss: 0.3265\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3853 - val_loss: 0.3786\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3709 - val_loss: 0.3285\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3578 - val_loss: 0.3283\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3719 - val_loss: 0.3238\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3729 - val_loss: 0.3134\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3633 - val_loss: 0.3207\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3731 - val_loss: 0.3128\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3398 - val_loss: 0.3064\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3405 - val_loss: 0.2970\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3339 - val_loss: 0.2961\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3410 - val_loss: 0.3278\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3311 - val_loss: 0.2987\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3244 - val_loss: 0.2952\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3352 - val_loss: 0.3398\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3186 - val_loss: 0.3066\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3333 - val_loss: 0.2942\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3168 - val_loss: 0.2899\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3309 - val_loss: 0.3247\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3152 - val_loss: 0.2932\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3165 - val_loss: 0.2901\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3011 - val_loss: 0.2897\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3051 - val_loss: 0.2873\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2948 - val_loss: 0.3057\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2858 - val_loss: 0.2884\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2864 - val_loss: 0.2858\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2758 - val_loss: 0.3097\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2788 - val_loss: 0.2866\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2868 - val_loss: 0.3137\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2780 - val_loss: 0.3024\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2632 - val_loss: 0.2983\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2734 - val_loss: 0.3026\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2655 - val_loss: 0.2916\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2583 - val_loss: 0.3279\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2661 - val_loss: 0.3014\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2401 - val_loss: 0.3018\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2581 - val_loss: 0.3069\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2607 - val_loss: 0.3028\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2510 - val_loss: 0.3052\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2286 - val_loss: 0.2952\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2539 - val_loss: 0.3149\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2345 - val_loss: 0.3078\n",
      "Epoch 00055: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 5.0min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 1.0560 - val_loss: 0.3505\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.6551 - val_loss: 0.3411\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.5560 - val_loss: 0.3404\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4544 - val_loss: 0.3388\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4443 - val_loss: 0.3360\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4324 - val_loss: 0.3407\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4337 - val_loss: 0.3342\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4131 - val_loss: 0.3376\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4160 - val_loss: 0.3366\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3958 - val_loss: 0.3555\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3934 - val_loss: 0.3328\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.4003 - val_loss: 0.3411\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3827 - val_loss: 0.3405\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3704 - val_loss: 0.3264\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3601 - val_loss: 0.3406\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3593 - val_loss: 0.3190\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3637 - val_loss: 0.3486\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3773 - val_loss: 0.3658\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3615 - val_loss: 0.3175\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3564 - val_loss: 0.3092\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3580 - val_loss: 0.3252\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3780 - val_loss: 0.3328\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3522 - val_loss: 0.3202\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3533 - val_loss: 0.3005\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3277 - val_loss: 0.2985\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3330 - val_loss: 0.3121\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3191 - val_loss: 0.3329\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3298 - val_loss: 0.3044\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3193 - val_loss: 0.2972\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3121 - val_loss: 0.3003\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3331 - val_loss: 0.3256\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3313 - val_loss: 0.3154\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3101 - val_loss: 0.2999\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3111 - val_loss: 0.3093\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2937 - val_loss: 0.3020\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3051 - val_loss: 0.3248\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3338 - val_loss: 0.4008\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3172 - val_loss: 0.2987\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2831 - val_loss: 0.3050\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3023 - val_loss: 0.2966\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2913 - val_loss: 0.2825\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.3085 - val_loss: 0.3090\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2955 - val_loss: 0.3057\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2768 - val_loss: 0.3101\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 5s - loss: 0.2812 - val_loss: 0.3114ss: 0.2\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2690 - val_loss: 0.2922\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2822 - val_loss: 0.3130\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2691 - val_loss: 0.3051\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2581 - val_loss: 0.3169\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2767 - val_loss: 0.3365 ETA: 2s - loss: 0. - ET\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2552 - val_loss: 0.3079\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2546 - val_loss: 0.3215\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2362 - val_loss: 0.3104ss: \n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2484 - val_loss: 0.3097\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2344 - val_loss: 0.3185\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2477 - val_loss: 0.3035\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2284 - val_loss: 0.3059\n",
      "Epoch 00056: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 5.1min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 2.1770 - val_loss: 0.6432\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.7870 - val_loss: 0.3697\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6606 - val_loss: 0.3624\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5870 - val_loss: 0.3408ss:\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4941 - val_loss: 0.3383\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5021 - val_loss: 0.3442\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4449 - val_loss: 0.3366\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4445 - val_loss: 0.3368\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4358 - val_loss: 0.3549\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4178 - val_loss: 0.3733\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4264 - val_loss: 0.3460ss: 0.42\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4323 - val_loss: 0.3406\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4155 - val_loss: 0.3373\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4211 - val_loss: 0.3585\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3904 - val_loss: 0.3372\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4247 - val_loss: 0.3525\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4088 - val_loss: 0.3508ss: 0.4\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4192 - val_loss: 0.3363\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3918 - val_loss: 0.3410ss: 0.\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3990 - val_loss: 0.3387\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3943 - val_loss: 0.3659\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3936 - val_loss: 0.3353\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4118 - val_loss: 0.3381\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3933 - val_loss: 0.3546\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3871 - val_loss: 0.3492\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4090 - val_loss: 0.3476\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3842 - val_loss: 0.3332\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4007 - val_loss: 0.3337\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4108 - val_loss: 0.3303\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3996 - val_loss: 0.3295ss: 0.4 - ETA: 1s - l\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3813 - val_loss: 0.3307\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3915 - val_loss: 0.3330\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3790 - val_loss: 0.3393\n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3703 - val_loss: 0.3413\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3760 - val_loss: 0.3459\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3588 - val_loss: 0.3194: 2s - loss:  - ETA\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3590 - val_loss: 0.3113\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3679 - val_loss: 0.3135\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3543 - val_loss: 0.3066\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3521 - val_loss: 0.2972\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3599 - val_loss: 0.3004\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3423 - val_loss: 0.3230\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3434 - val_loss: 0.2988\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3328 - val_loss: 0.2989\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3400 - val_loss: 0.3006\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3291 - val_loss: 0.3005\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3133 - val_loss: 0.2985\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3251 - val_loss: 0.2953\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3117 - val_loss: 0.3231\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2955 - val_loss: 0.3222ss: 0.295\n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2948 - val_loss: 0.3137\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3029 - val_loss: 0.3250\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3078 - val_loss: 0.3091\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2753 - val_loss: 0.3000\n",
      "Epoch 55/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2886 - val_loss: 0.2925\n",
      "Epoch 56/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2862 - val_loss: 0.3054\n",
      "Epoch 57/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2704 - val_loss: 0.3184\n",
      "Epoch 58/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2748 - val_loss: 0.3202\n",
      "Epoch 59/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2991 - val_loss: 0.3263\n",
      "Epoch 60/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2937 - val_loss: 0.2989\n",
      "Epoch 61/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2873 - val_loss: 0.3357\n",
      "Epoch 62/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2796 - val_loss: 0.3062\n",
      "Epoch 63/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2790 - val_loss: 0.3164\n",
      "Epoch 64/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2535 - val_loss: 0.2867oss: 0.253\n",
      "Epoch 65/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2806 - val_loss: 0.3202\n",
      "Epoch 66/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2565 - val_loss: 0.3152\n",
      "Epoch 67/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2669 - val_loss: 0.3106\n",
      "Epoch 68/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2643 - val_loss: 0.3167\n",
      "Epoch 69/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2651 - val_loss: 0.3309ss: 0.\n",
      "Epoch 70/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2601 - val_loss: 0.3036\n",
      "Epoch 71/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2577 - val_loss: 0.3074\n",
      "Epoch 72/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2263 - val_loss: 0.3215\n",
      "Epoch 73/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2363 - val_loss: 0.3115\n",
      "Epoch 74/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2486 - val_loss: 0.3108\n",
      "Epoch 75/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2421 - val_loss: 0.2977\n",
      "Epoch 76/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2428 - val_loss: 0.3262ss: 0.243\n",
      "Epoch 77/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2457 - val_loss: 0.3196\n",
      "Epoch 78/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2407 - val_loss: 0.3162\n",
      "Epoch 79/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2427 - val_loss: 0.3127\n",
      "Epoch 80/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2537 - val_loss: 0.3104\n",
      "Epoch 00079: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 6.4min\n",
      "[CV] activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3 \n",
      "Train on 1357 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1357/1357 [==============================] - 10s - loss: 1.3321 - val_loss: 0.3485\n",
      "Epoch 2/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.6996 - val_loss: 0.3386\n",
      "Epoch 3/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5752 - val_loss: 0.3380\n",
      "Epoch 4/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.5306 - val_loss: 0.3448\n",
      "Epoch 5/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4501 - val_loss: 0.3357\n",
      "Epoch 6/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4294 - val_loss: 0.3375\n",
      "Epoch 7/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4183 - val_loss: 0.3392\n",
      "Epoch 8/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4043 - val_loss: 0.3361\n",
      "Epoch 9/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4231 - val_loss: 0.3433\n",
      "Epoch 10/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3979 - val_loss: 0.3396s\n",
      "Epoch 11/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.4061 - val_loss: 0.3329ss: 0.404\n",
      "Epoch 12/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3772 - val_loss: 0.3358\n",
      "Epoch 13/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3826 - val_loss: 0.3519\n",
      "Epoch 14/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3839 - val_loss: 0.3296\n",
      "Epoch 15/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3887 - val_loss: 0.3351ss: 0.39\n",
      "Epoch 16/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3875 - val_loss: 0.3326ss: 0.3\n",
      "Epoch 17/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3662 - val_loss: 0.3237\n",
      "Epoch 18/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3818 - val_loss: 0.3252\n",
      "Epoch 19/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3766 - val_loss: 0.3158\n",
      "Epoch 20/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3762 - val_loss: 0.3308\n",
      "Epoch 21/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3737 - val_loss: 0.3202\n",
      "Epoch 22/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3557 - val_loss: 0.3128\n",
      "Epoch 23/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3280 - val_loss: 0.3244\n",
      "Epoch 24/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3586 - val_loss: 0.3142\n",
      "Epoch 25/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3497 - val_loss: 0.3154\n",
      "Epoch 26/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3490 - val_loss: 0.3065\n",
      "Epoch 27/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3362 - val_loss: 0.3111\n",
      "Epoch 28/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3502 - val_loss: 0.3359ss: 0.35\n",
      "Epoch 29/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3226 - val_loss: 0.3022\n",
      "Epoch 30/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3279 - val_loss: 0.3112\n",
      "Epoch 31/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3239 - val_loss: 0.2948\n",
      "Epoch 32/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3261 - val_loss: 0.3001\n",
      "Epoch 33/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3211 - val_loss: 0.2964 \n",
      "Epoch 34/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3013 - val_loss: 0.3466ss: 0.30\n",
      "Epoch 35/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3187 - val_loss: 0.3099\n",
      "Epoch 36/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3045 - val_loss: 0.3047\n",
      "Epoch 37/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3012 - val_loss: 0.2869\n",
      "Epoch 38/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3170 - val_loss: 0.2853\n",
      "Epoch 39/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2923 - val_loss: 0.2900\n",
      "Epoch 40/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3100 - val_loss: 0.3034ss: 0.\n",
      "Epoch 41/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2740 - val_loss: 0.2899\n",
      "Epoch 42/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2844 - val_loss: 0.2902ss: 0.2\n",
      "Epoch 43/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2946 - val_loss: 0.2988\n",
      "Epoch 44/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2788 - val_loss: 0.2869\n",
      "Epoch 45/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2684 - val_loss: 0.2961\n",
      "Epoch 46/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2782 - val_loss: 0.2963ss: 0.278\n",
      "Epoch 47/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2784 - val_loss: 0.2915ss: 0. - - ETA: 0s - loss:\n",
      "Epoch 48/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2819 - val_loss: 0.3336 - ETA: 0s - loss: 0.2\n",
      "Epoch 49/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2856 - val_loss: 0.2957s\n",
      "Epoch 50/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2758 - val_loss: 0.3111ss: \n",
      "Epoch 51/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2685 - val_loss: 0.2923\n",
      "Epoch 52/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2990 - val_loss: 0.3081\n",
      "Epoch 53/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.3061 - val_loss: 0.2934\n",
      "Epoch 54/200\n",
      "1357/1357 [==============================] - 4s - loss: 0.2805 - val_loss: 0.2961\n",
      "Epoch 00053: early stopping\n",
      "[CV]  activation_function=sigmoid, hidden_layer_size=256, num_hidden_layers=3, total= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 26.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1696 samples, validate on 425 samples\n",
      "Epoch 1/200\n",
      "1696/1696 [==============================] - 12s - loss: 0.8977 - val_loss: 0.3495\n",
      "Epoch 2/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.5599 - val_loss: 0.3408\n",
      "Epoch 3/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4851 - val_loss: 0.3430\n",
      "Epoch 4/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4202 - val_loss: 0.3612\n",
      "Epoch 5/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4316 - val_loss: 0.3389\n",
      "Epoch 6/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3951 - val_loss: 0.3472\n",
      "Epoch 7/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4148 - val_loss: 0.3684\n",
      "Epoch 8/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4041 - val_loss: 0.3488\n",
      "Epoch 9/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4035 - val_loss: 0.3499\n",
      "Epoch 10/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3933 - val_loss: 0.3463\n",
      "Epoch 11/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3883 - val_loss: 0.3359\n",
      "Epoch 12/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3774 - val_loss: 0.3426\n",
      "Epoch 13/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3991 - val_loss: 0.3429\n",
      "Epoch 14/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3782 - val_loss: 0.3387\n",
      "Epoch 15/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3658 - val_loss: 0.3405\n",
      "Epoch 16/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3878 - val_loss: 0.3366\n",
      "Epoch 17/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.4008 - val_loss: 0.3468\n",
      "Epoch 18/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3829 - val_loss: 0.3337\n",
      "Epoch 19/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3761 - val_loss: 0.3658\n",
      "Epoch 20/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3844 - val_loss: 0.3333\n",
      "Epoch 21/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3846 - val_loss: 0.3395\n",
      "Epoch 22/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3676 - val_loss: 0.3338\n",
      "Epoch 23/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3682 - val_loss: 0.3375\n",
      "Epoch 24/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3739 - val_loss: 0.3373\n",
      "Epoch 25/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3839 - val_loss: 0.3297\n",
      "Epoch 26/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3653 - val_loss: 0.3437\n",
      "Epoch 27/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3596 - val_loss: 0.3263\n",
      "Epoch 28/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3616 - val_loss: 0.3357\n",
      "Epoch 29/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3626 - val_loss: 0.3301\n",
      "Epoch 30/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3576 - val_loss: 0.3429\n",
      "Epoch 31/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3570 - val_loss: 0.3240\n",
      "Epoch 32/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3484 - val_loss: 0.3173\n",
      "Epoch 33/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3433 - val_loss: 0.3197\n",
      "Epoch 34/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3520 - val_loss: 0.3455\n",
      "Epoch 35/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3477 - val_loss: 0.3226\n",
      "Epoch 36/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3463 - val_loss: 0.3580\n",
      "Epoch 37/200\n",
      "1696/1696 [==============================] - 5s - loss: 0.3529 - val_loss: 0.3148\n",
      "Epoch 38/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3421 - val_loss: 0.3202\n",
      "Epoch 39/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3371 - val_loss: 0.3151\n",
      "Epoch 40/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3339 - val_loss: 0.3273\n",
      "Epoch 41/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3411 - val_loss: 0.3242\n",
      "Epoch 42/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3323 - val_loss: 0.3400\n",
      "Epoch 43/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3039 - val_loss: 0.3167\n",
      "Epoch 44/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3050 - val_loss: 0.3194\n",
      "Epoch 45/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3146 - val_loss: 0.3139\n",
      "Epoch 46/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3246 - val_loss: 0.3157\n",
      "Epoch 47/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3259 - val_loss: 0.3350\n",
      "Epoch 48/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3210 - val_loss: 0.3197\n",
      "Epoch 49/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3163 - val_loss: 0.3036\n",
      "Epoch 50/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3011 - val_loss: 0.3156\n",
      "Epoch 51/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3126 - val_loss: 0.2976\n",
      "Epoch 52/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3154 - val_loss: 0.3150\n",
      "Epoch 53/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3177 - val_loss: 0.3178\n",
      "Epoch 54/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3311 - val_loss: 0.3081\n",
      "Epoch 55/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3131 - val_loss: 0.3027\n",
      "Epoch 56/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3021 - val_loss: 0.2971\n",
      "Epoch 57/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3017 - val_loss: 0.3043\n",
      "Epoch 58/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3009 - val_loss: 0.3007\n",
      "Epoch 59/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3068 - val_loss: 0.3551\n",
      "Epoch 60/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3074 - val_loss: 0.3109\n",
      "Epoch 61/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2980 - val_loss: 0.3229\n",
      "Epoch 62/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3096 - val_loss: 0.3189\n",
      "Epoch 63/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3003 - val_loss: 0.3205\n",
      "Epoch 64/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3012 - val_loss: 0.3059\n",
      "Epoch 65/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.3030 - val_loss: 0.3183\n",
      "Epoch 66/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2841 - val_loss: 0.3099\n",
      "Epoch 67/200\n",
      "1696/1696 [==============================] - 6s - loss: 0.2916 - val_loss: 0.3164\n",
      "Epoch 00066: early stopping\n",
      "Out-of-sample MSE:  0.316432194806\n",
      "CPU times: user 1h 38min 46s, sys: 21min 21s, total: 2h 8s\n",
      "Wall time: 2h 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_info = {}\n",
    "for i, m in enumerate(final_models):\n",
    "    history = History() # History callback\n",
    "    model_name = 'model_'+str(i)\n",
    "    grid = GridSearchCV(classifier,\n",
    "                             param_grid=m[0],\n",
    "                             scoring='neg_mean_squared_error', #sklearn optimizing by maximizing negative MSE\n",
    "                             n_jobs=1,\n",
    "                             verbose=2,\n",
    "                             cv=5,# Number of folds for CV\n",
    "                             fit_params={'callbacks': [EarlyStopping(monitor='val_loss', \n",
    "                                                                     min_delta=0.001, \n",
    "                                                                     patience=15, # Reducing patience param\n",
    "                                                                     mode='min',\n",
    "                                                                     verbose=2),\n",
    "                                                      CSVLogger('logs/'+model_name+'.csv', separator=',', append=True),\n",
    "                                                      history], # Added a history callback\n",
    "                                        'validation_data': (np.array(X_test), np.array(y_test))\n",
    "                                        }\n",
    "                       )\n",
    "\n",
    "    grid.fit(np.array(X_train), np.array(y_train))\n",
    "    y_hats = grid.predict(np.array(X_test))\n",
    "    print(\"Out-of-sample MSE: \", mean_squared_error(y_test, y_hats))\n",
    "    y_hats_full = grid.predict(np.array(X))\n",
    "    model_info[model_name] = {'grid_obj': grid,\n",
    "                              'keras_model': grid.best_estimator_.model,\n",
    "                              'preds': y_hats_full,\n",
    "                              'history': history.history}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To assess how the different models performed we can plot their performance on the training and test set at each epoch in the learning process. Since the first couple of epochs generally have a very high loss (thus increasing the size of the y-axis and obscuring the future epochs) I present the learn from the results from the second epoch onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [1], 'hidden_layer_size': [256], 'activation_function': ['sigmoid']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMaaOJQVjjDF1LCkYY4ypY0nBGGNMnf8PE5xNAfJdPesAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4605a1f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [1], 'hidden_layer_size': [128], 'activation_function': ['relu']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDDMzK8QJw8zMCnHCMDOzQv4LulxgQHbSTMIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x464b8e9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [3], 'hidden_layer_size': [128], 'activation_function': ['linear']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYXGWV+PHvqaX3fUl3J510Z5MsBLLJvskOCuiowzDC\nIKDRGcdlUEd0/CmCM+IsKgrIwBgBQVAHGRARhLAoi0ASQvaQhSyddCedXtKd3qqr6vz+uLeTSqfX\n0NW3lvN5nnrq7vdU1a177vu+dxFVxRhjTPryeR2AMcYYb1kiMMaYNGeJwBhj0pwlAmOMSXOWCIwx\nJs1ZIjDGmDRnicCkLRG5WUQe9DqOVCYi60TknLGe1owtSwRJSES2i0hIRMr6DX9LRFREar2JzKQK\nEal1t6XAe1mOqs5V1RfHeloztiwRJK93gav6ekRkHpDjXTjeeq87rLFe97HEIyL+sYlo1Os9pu/O\ny+/cjC1LBMnrF8DfxfRfCzwQO4GIZIrIf4rIThHZKyJ3i0i2O65YRJ4UkUYRaXG7q2PmfVFEbhWR\nV0SkXUT+2L8EEjNtmTt/q4g0i8ifRcTnjlsgIivdZfxKRB4Rke+64z4pIi/3W5aKyAy3+4NuKadN\nRHaJyM0x0/Udsd4gIjuB593hp4jIq24sb8dWNYjIVBF5yY3lWWDAzxMz/YdEZJW7rFdF5ISYcdtF\n5GsishroEJHAIMNmu99lq1v1cXnMMu4TkZ+KyFMi0gF8YIAYJorIE+73ukVEPh0zvEtESmKmXSAi\n+0Uk6PZfLyIb3N/3GRGp6fc9f05ENgObB/j4f3LfW0XkoIic6v5er4jID0WkCbhZRKaLyPMi0uSu\n+yERKer3PZ3vdt8sIr8WkQfc32CdiCw+xmkXuttGu4j8xt22vjvU72mGoKr2SrIXsB04H9gEzAb8\nQB1QAyhQ6073Q+AJoATIB34HfM8dVwp8FKcUkQ/8Bvi/mHW8CGwF3gdku/23DRLP94C7gaD7OhMQ\nIAPYAfyTO/xjQC/wXXe+TwIv91uWAjPc7nOAeTgHLCcAe4EPu+Nq3WkfAHLdGCcBTcCl7jwXuP3l\n7jyvAT8AMoGzgHbgwUE+0wJgH3Cy+/1e637vmTG/wSpgMpA90DD3M28BvuF+F+e66zzOnf4+4ABw\nuhtv1gBx/Am4C8gC5gONwLnuuOeBT8dM+x/A3W73Fe66ZwMB4JvAq/2+52fdbSN7gPX2fb+BmGGf\nBMLA591lZgMz3O85Eyh34/1R/23V7b4Z6HZ/Hz/OdvOX0U7L4e3qi+53/FdACHe7stcx7FO8DsBe\nx/CjHU4E33T/IBe7f+qA++etxdkRdwDTY+Y7FXh3kGXOB1pi+l8EvhnT/w/A04PMewvwOO4OPGb4\nWcAeQGKGvcoIE8EA6/kR8EO3u29HNS1m/NeAX/Sb5xmcnfgUdyeWGzPulwyeCH4K3Npv2Cbg7Jjf\n4PoBfpfrY/rPBBoAX8ywh4Gb3e77gAeG+J0nAxEgP2bY94D73O5PAc+73QLsAs5y+/8A3BAznw/o\nBGpivudzh1h33/fbPxHsHGbb/DDwVv9t1e2+GXguZtwcoGu007rb1e5+29XLWCI45pdVDSW3XwB/\ni/MHfaDfuHKco/0VbrVEK/C0OxwRyRGR/xaRHSLShnMkVyRH1lM3xHR3AnmDxPEfOEeffxSRbSJy\nkzt8IrBb3X+qa8dIP5yInCwiL4hTfXUA+CxHV+fsiumuAT7e93ndz3wGUOXG0qKqHSOMpQb4cr9l\nTXaXM9C6Bxo2EdilqtF+65w0zDJi529W1fZB5n8UOFVEqnB2jlHgzzHx3x4TezNOshjpugdzxDwi\nUuFW9+12t6MHGbrKrf82lSWDtzUMNu1A29WxfBbjskSQxFR1B06j8aXAb/uN3g90AXNVtch9Fapq\n3878y8BxwMmqWoCzIwFnZzHaONpV9cuqOg24HLhRRM4D6oFJIhK7zCkx3R3ENHCLSGW/Rf8Sp2pr\nsqoW4lQ/9Y+v/87gFzGft0hVc1X1NjeWYhHJHSSW/nYB/9pvWTmq+vAg6x5o2B5gsrjtJTHr3D3M\nMmLnLxGR/IHmV9UW4I/AlTgHBI/E7Bx3AZ/pF3+2qr46wnUPNq7/8H9zh81zt6OrOYZtaJQG2q4m\nx3mdKc0SQfK7AaeIH3uki3sUei/wQxGZACAik0TkIneSfJxE0eo2OH77WANwG1VnuH/MAzjVGVGc\nOvkw8AURCYrIXwEnxcz6NjBXROaLSBZOdUCsfJwj4m4ROQlnZzeUB4HLROQiEfGLSJaInCMi1W7S\nXA58R0QyROQM4LIhlnUv8Fm3VCIikitO43X+EPP09zrOkew/u5//HHedj4xkZlXdhVOV9j33s5yA\n83vHXvvwS5yTBj7mdve5G/i6iMwFEJFCEfn4KGJvxPkNpw0zXT5wEDggIpOAr45iHcfqNZxt7B/F\naZC/giO3KzNKlgiSnKpuVdXlg4z+Gk6VzV/cYvtzOKUAcOrbs3FKDn/BqTY6VjPdZR/E+ZPepaov\nqGoIpyHvkzhVE1cSU3JR1Xdw2heewzlz5eUjF8s/ALeISDvwLeDXQwXh7jivwGmcbcQ5Kv4qh7fz\nv8Vp/G3GSXz9q9Nil7Uc+DRwB9CC8z1+cqj1D7CMEM6O/xKc7/ku4O9UdeMoFnMVTn39HuAx4Nuq\n+lzM+Cdwvv8GVX07Zt2PAd8HHnF/+7VuHCONvRP4V+AVt3rplEEm/Q6wEOcA4PccXTIdczHb1Q1A\nK04p5EmgJ97rTlVyZDWbMfElIvcBdar6Ta9jMalDRF7HOWPq517HkoysRGCMSToicraIVLpVQ9fi\nnF78Xkq1ac2uDDTGJKPjcKoKc4FtwMdUtd7bkJKXVQ0ZY0yas6ohY4xJc0lRNVRWVqa1tbVeh2GM\nMUllxYoV+1W1fLjpkiIR1NbWsnz5YGdIGmOMGYiIjOhKfqsaMsaYNGeJwBhj0pwlAmOMSXNJ0UYw\nkN7eXurq6uju7vY6lHGRlZVFdXU1wWDQ61CMMSkmaRNBXV0d+fn51NbWcuRNCFOPqtLU1ERdXR1T\np071OhxjTIpJ2qqh7u5uSktLUz4JAIgIpaWlaVP6McaMr6RNBEBaJIE+6fRZjTHjK6kTwXDaunrZ\n125H0cYYM5SUTgQHe8Lsa4vPLcqbmpqYP38+8+fPp7KykkmTJh3qD4VCI1rGddddx6ZNm+ISnzHG\njFTSNhaPRNAvRFWJRKP4fWOb80pLS1m1ahUAN998M3l5eXzlK185YppDD4YeZN0//7ndOt0Y472U\nLhEE/M7H642M3x1Wt2zZwpw5c/jEJz7B3Llzqa+vZ8mSJSxevJi5c+dyyy23HJr2jDPOYNWqVYTD\nYYqKirjppps48cQTOfXUU9m3b9+4xWyMSW8pUSL4zu/WsX5P21HDI1GluzdCVtCP3ze6xtY5Ewv4\n9mVzjymejRs38sADD7B48WIAbrvtNkpKSgiHw3zgAx/gYx/7GHPmzDlingMHDnD22Wdz2223ceON\nN7J06VJuuummY1q/McaMRkqXCPr2/eP9xIXp06cfSgIADz/8MAsXLmThwoVs2LCB9evXHzVPdnY2\nl1ziPFJ20aJFbN++fbzCNcakuZQoEQx25B6JKuv2HKCyIIsJBVnjFk9ubu6h7s2bN3P77bfzxhtv\nUFRUxNVXXz3g9QAZGRmHuv1+P+FweFxiNcaYlC4R+H2C3yf0Rr17CltbWxv5+fkUFBRQX1/PM888\n41ksxhgzkJQoEQwl6PMRjkQ9W//ChQuZM2cOs2bNoqamhtNPP92zWIwxZiBJ8czixYsXa/8H02zY\nsIHZs2cPO++2xoNEFWZMyItXeONmpJ/ZGGMARGSFqi4ebrqUrhoCCPp99HpYIjDGmESXBolACEec\nC7uMMcYcLQ0SgQ9FCXvYYGyMMYks5RPB4auLrXrIGGMGkvKJIOh3rioLj+NtJowxJpnELRGISJaI\nvCEib4vIOhH5jju8RESeFZHN7ntxvGIAp2oIrERgjDGDiWeJoAc4V1VPBOYDF4vIKcBNwDJVnQks\nc/vjJuATBBnzG8+NxW2oAZYuXUpDQ8OYxmaMMaMRtwvK1DlN56DbG3RfClwBnOMOvx94EfhavOIQ\nEQJ+GfMSwUhuQz0SS5cuZeHChVRWVo5pfMYYM1JxvbJYRPzACmAGcKeqvi4iFapa707SAFQMMu8S\nYAnAlClT3lMc430twf3338+dd95JKBTitNNO44477iAajXLdddexatUqVJUlS5ZQUVHBqlWruPLK\nK8nOzuaNN9444p5DxhgzHuKaCFQ1AswXkSLgMRE5vt94FZEB62xU9R7gHnCuLB5yRX+4CRrWDDq6\nujdCFIXgKD5u5Ty45LaRT+9au3Ytjz32GK+++iqBQIAlS5bwyCOPMH36dPbv38+aNU6cra2tFBUV\n8ZOf/IQ77riD+fPnj3pdxhgzFsblXkOq2ioiLwAXA3tFpEpV60WkCoj7E1hEQMepQPDcc8/x5ptv\nHroNdVdXF5MnT+aiiy5i06ZNfOELX+CDH/wgF1544fgEZIwxw4hbIhCRcqDXTQLZwAXA94EngGuB\n29z3x9/zyoY5cj/Q1k1DWzfHTyzEN8oH1IyWqnL99ddz6623HjVu9erV/OEPf+DOO+/k0Ucf5Z57\n7olrLMYYMxLxPGuoCnhBRFYDbwLPquqTOAngAhHZDJzv9sfVeJ5Cev755/PrX/+a/fv3A87ZRTt3\n7qSxsRFV5eMf/zi33HILK1euBCA/P5/29va4x2WMMYOJ51lDq4EFAwxvAs6L13oHEnAvKuuNKplx\nXte8efP49re/zfnnn080GiUYDHL33Xfj9/u54YYbUFVEhO9///sAXHfddXzqU5+yxmJjjGdS/jbU\nAN29Ed7Z286UkhyKco7c0YYjUepauphUlE0wkNgXWtttqI0xo2G3oY7Rd5uJgaqG2rvDtHX3crDH\nHg1pjElPaZEI/D4fPhn46uLOkJMAQnYLCmNMmkrqRDCaaq3BLirrDEUACIUTOxEkQxWeMSY5JW0i\nyMrKoqmpacQ7yKD/6BJBJKp09zoJIJETgarS1NREVlaW16EYY1JQ0j68vrq6mrq6OhobG0c0fXNH\niFA4Sm/T4Z1pT2+ExoMh/D5hPxBqStwdbVZWFtXV1V6HYYxJQUmbCILBIFOnTh3x9Lf9YSM/e3kb\n73z3EkScxuO7XtzCvz+9g+tOr+Xnr2xn460XkxX0xytkY4xJSElbNTRaFQWZ9EaU5o7Dt4heuaOV\naWW5nFhdBEBdS6dX4RljjGfSJhFUFjjVPg1t3YBT7/7WzhYWTClmckkOALuauzyLzxhjvJI2iaCi\n0EkEe91EsLO5k6aOEAtripjiJoKdzVYiMMakn/RJBAV9iaAHgLd2tgKwYHIxZXkZZAf9lgiMMWkp\nbRLBhPxMRKDhgFMiWLmzhdwMP8dV5iMiTCnJsURgjElLaZMIgn4fpbmZh6qGVu5s4cTJRfjd21JP\nLslhlyUCY0waSptEAFBZmElDWzedoTAb6ttZMKXo0Li+EoFdwWuMSTdplQgq8rPY29bDmroDRKLK\nwinFh8ZNKcmmMxShKeb0UmOMSQfplQgKs9jb1s3Kvobi2ERQamcOGWPSU1olgsqCLJo7QvxlWxNT\ny3IpyT38bIIph64lsERgjEkvaZcIAF7dup8Fk4uOGFdd7JYImiwRGGPSS1olggkFzoMqeyPKgpri\nI8ZlBf1MyM+0qiFjTNpJq0RQWXj47qILpxQdNd6uJTDGpKP0SgRu1VBOhp/jKvKPGj/FriUwxqSh\nuCUCEZksIi+IyHoRWSciX3SH3ywiu0Vklfu6NF4x9FeYHSQz4OOE6kIC/qM/+uSSHOrbuukJR8Yr\nJGOM8Vw8n0cQBr6sqitFJB9YISLPuuN+qKr/Gcd1D0hEuOaUGuYPUC0ETolAFXa3dDGtPG+cozPG\nGG/ELRGoaj1Q73a3i8gGYFK81jdS3/zQnEHHxV5LYInAGJMuxqWNQERqgQXA6+6gz4vIahFZKiLF\ng8yzRESWi8jykT6O8r2yawmMMeko7olARPKAR4EvqWob8FNgGjAfp8TwXwPNp6r3qOpiVV1cXl4e\n7zABKM/LJDPgszOHjDFpJa6JQESCOEngIVX9LYCq7lXViKpGgXuBk+IZw2j4fMJkO4XUGJNm4nnW\nkAA/Azao6g9ihlfFTPYRYG28YjgWzrUE9shKY0z6iOdZQ6cD1wBrRGSVO+wbwFUiMh9QYDvwmTjG\nMGpTSnJ4891mVBUnlxljTGqL51lDLwMD7Umfitc6x8Lkkhzae8K0dvZSHHNTOmOMSVVpdWXxSNiD\n7I0x6cYSQT+WCIwx6cYSQT+TS7IBSwTGmPRhiaCfnIwAZXmZdlGZMSZtWCIYwJSSbCsRGGPShiWC\nAdhzCYwx6cQSwQCml+exu7WL1s6Q16EYY0zcWSIYwGkzSlGFV7c2eR2KMcbEnSWCAZxQXUReZoCX\nt+z3OhRjjIk7SwQDCPp9nDKtlJc3WyIwxqQ+SwSDOHNmGTubO9nZZI3GxpjUZolgEKfPKAOw6iFj\nTMqzRDCI6eW5VBVm8fKW8Xk6mjHGeMUSwSBEhNNnlPHq1iYiUfU6HGOMiRtLBEM4c2YZrZ29rNtz\nwOtQjDEmbiwRDOG06U47wZ/t7CFjTAqzRDCE8vxMZlXm84o1GBtjUpglgmGcObOM5dtb6ApFvA7F\nGGPiwhLBME6fUUYoEuWN7c1eh2KMMXFhiWAYJ08tJcPvs+ohY0zKskQwjOwMP4tqiq3B2BiTsiwR\njMAZM8vYUN/G/oM9XodijDFjLm6JQEQmi8gLIrJeRNaJyBfd4SUi8qyIbHbfi+MVw1g5w73dhFUP\nGWNSUTxLBGHgy6o6BzgF+JyIzAFuApap6kxgmduf0I6fVEhhdtASgTEmJcUtEahqvaqudLvbgQ3A\nJOAK4H53svuBD8crhrHi9wmLa4pZvqPF61CMMWbMjUsbgYjUAguA14EKVa13RzUAFYPMs0RElovI\n8sZG72/8trCmmG2NHbR02OMrjTGpJe6JQETygEeBL6lqW+w4VVVgwDu6qeo9qrpYVReXl5fHO8xh\nLapxmjLe2mWlAmNMaolrIhCRIE4SeEhVf+sO3isiVe74KmBfPGMYKydUF+L3CSt3tHodijHGjKl4\nnjUkwM+ADar6g5hRTwDXut3XAo/HK4axlJMRYE5VASusncAYk2LiWSI4HbgGOFdEVrmvS4HbgAtE\nZDNwvtufFBbVFLNqVyvhSNTrUIwxZswE4rVgVX0ZkEFGnxev9cbTgilF3PfqdjY2tHP8pEKvwzHG\nmDFhVxaPQl+D8cqdVj1kjEkdlghGYVJRNhUFmdZOYIxJKZYIRkFEWDil2EoExpiUYolglBbVFLOr\nuYt9bd1eh2KMMWPCEsEoLbR2AmNMirFEMEpzJxaQ4fexcqddWGaMSQ2WCEYpM+BnXnWhNRgbY1LG\nkIlARK6O6T6937h/jFdQiW5RTTFrdh+gJ2wPtDfGJL/hSgQ3xnT/pN+468c4lqSxcEoRoXCUdXva\nhp/YGGMS3HCJQAbpHqg/bSyc4jYYW/WQMSYFDJcIdJDugfrTxoSCLKqLs486cygSVdq6ez2Kyhhj\njs1w9xqaJSKrcY7+p7vduP3T4hpZgltUU8xftjWhqjS29/CrN3fxyJu7aOro4Qd/PZ9L51V5HaIx\nxozIcIlg9rhEkYQW1RTz+Ko9XH/fm/x5837CUeWMGWWU52fyDw+t5KsXHcc/nDMd527cxhiTuIZM\nBKq6I7ZfREqBs4CdqroinoElupOnlgLwdt0BbjhjKledNIXasly6eyPc9Ohq/uOZTWzdd5DvfXQe\nmQG/x9EaY8zghkwEIvIkcJOqrnWfJrYSWI5TTXSPqv5oPIJMRMdV5vPcjWczuST7iB19VtDPD6+c\nz7TyPH7w7Dvsaunk7qsXUZqX6WG0xhgzuOEai6eq6lq3+zrgWVW9DDiZND59tM+MCXkDHu2LCF84\nbyY/uWoBq+sO8K0n1nkQnTHGjMxwiSD2FJjzgKcAVLUdsMd0DeOyEydy4dxKVtntKIwxCWy4RLBL\nRD4vIh8BFgJPA4hINhCMd3CpYFZlPrtbu+y0UmNMwhouEdwAzAU+CVypqn2HtqcAP49jXCljdlU+\nAJsa2j2OxBhjBjbcWUP7gM8OMPwF4IV4BZVKZlcVALChvo3315Z4HI0xxhxtuLOGnhhqvKpePrbh\npJ7KgiwKs4NsqLcSgTEmMQ13QdmpwC7gYeB1RnF/IRFZCnwI2Keqx7vDbgY+DTS6k31DVZ8aZcxJ\nRUSYVZnPxga7QZ0xJjEN10ZQCXwDOB64HbgA2K+qL6nqS8PMex9w8QDDf6iq891XSieBPrOrCtjU\n0E40mra3ZzLGJLAhE4GqRlT1aVW9FqeBeAvw4kieRaCqfwKaxybM5Da7Kp/OUISdzZ1eh2KMMUcZ\n9gllIpIpIn8FPAh8Dvgx8Nh7WOfnRWS1iCwVkeIh1rtERJaLyPLGxsbBJksKsyqdBmOrHjLGJKLh\nnlD2APAazjUE31HV96vqraq6+xjX91Ocu5bOB+qB/xpsQlW9R1UXq+ri8vLyY1xdYnhfRT4+wRqM\njTEJabjG4quBDuCLwBdi7qQpgKpqwWhWpqp7Dy1A5F7gydHMn6yyM/zUluWyod5KBMaYxDPcdQRj\n+nB7EalS1Xq39yPA2qGmTyWzKwtYs/uA12EYY8xRhisRHDMReRg4BygTkTrg28A5IjIf5+lm24HP\nxGv9iWZWZT6/X1PPwZ4weZlx+9qNMWbU4rZHUtWrBhj8s3itL9HNcq8w3tTQzqKaQdvIjTFm3I1p\n1Y8ZXN89h6ydwBiTaCwRjJNJRdnkZwbsFFJjTMKxRDBORIRZVflstFNIjTEJxhLBOJpdVcDGhnZU\n7VYTxpjEYYlgHM2qLOBgT5i6li6vQzHGmEMsEYyjWdZgbIxJQJYIxtFxFfmIwEZ7WpkxJoFYIhhH\nuZkBakpyrERgjEkolgjG2azKAisRGGMSiiWCcTarKp/tTR10hsJeh2KMMYAlgnE3q7IAVXhn70Gv\nQzHGGMASwbibV10IwG+W7/I4EmOMcVgiGGeTirL59JlTeej1nTy5eo/X4RhjjCUCL/zzxbNYMKWI\nmx5dw7v7O7wOxxiT5iwReCDo93HH3y4k4Bc+99BKunsjXodkjEljlgg8Mqkomx/89Ymsr2/jlifX\nex2OMSaNWSLw0LmzKvjM2dP45es7eXzVbq/DMcakKUsEHvvKhcexuKaYb/x2DS0dIa/DMcakIUsE\nHgv6ffzrR+bREYrwKzul1BjjAUsECeC4ynxOnVbKL17bQSRqzyowxowvSwQJ4trTatjd2sWyDXu9\nDsUYk2YsESSI82dXMLEwi/tf2+51KMaYNBO3RCAiS0Vkn4isjRlWIiLPishm9704XutPNgG/j0+c\nUsMrW5rYss/uTmqMGT/xLBHcB1zcb9hNwDJVnQksc/uN62/eP5mMgI8HXtvhdSjGmDQSt0Sgqn8C\nmvsNvgK43+2+H/hwvNafjErzMrnshIk8uqKO9u5er8MxxqSJ8W4jqFDVere7AagYbEIRWSIiy0Vk\neWNj4/hElwCuPa2GjlCER1fUeR2KMSZNeNZYrKoKDHqupKreo6qLVXVxeXn5OEbmrROqi1gwpYgH\nXttB1E4lNcaMg/FOBHtFpArAfd83zutPCteeWsu2/R28vGW/16EYY9LAeCeCJ4Br3e5rgcfHef1J\n4dJ5VZTlZXLXi1twCk7GGBM/8Tx99GHgNeA4EakTkRuA24ALRGQzcL7bb/rJCPj40vkz+cu2Zn7x\nFzuDyBgTX4F4LVhVrxpk1HnxWmcq+cTJU3h2/V7+7akNnD6jjOnleV6HZIxJUXZlcYISEf79YyeQ\nFfRz46/fJhyJeh2SMSZFWSJIYBUFWXz3w8fz9q5W7nxhq9fhGGNSlCWCBPehEyZyxfyJ/Pj5zayu\na/U6HGNMCrJEkARuufx4yvMy+adfrbLnGxtjxpwlgiRQmBPkPz5+AlsbO/jRc5u9DscYk2IsESSJ\nM2eW89GF1fzs5W1sbTzodTjGmBRiiSCJ3HTJLLKCfm5+Yp1daGaMGTOWCJJIeX4mN17wPv68eT9P\nr23wOhxjTIqwRJBkrjmlhlmV+dz65Ho6Q2GvwzHGpABLBEkm4PdxyxXHs+dAN3e+sMXrcIwxKcAS\nQRI6aWoJH1kwiXv/9C7v7u/wOhxjTJKzRJCkvn7JLDICPr71+Fq7/YQx5j2xRJCkJhRk8ZULnYbj\nS27/My+9kz5PcTPGjC1LBEns2tNq+e9rFhGKRLl26Rtc9/M32LLPrjEwxoyOJYIkJiJcNLeSP/7T\nWXzj0lks397CxT/6Ez9ZZlcfG2NGzhJBCsgM+Fly1nRe+Oo5XHx8Jf/17Ds89lad12EZY5KEJYIU\nUpaXyQ+vnM/JU0v4+m/XsH5Pm9chGWOSgCWCFBP0+7jjbxdSlJ3BZx5cTmtnyOuQjDEJzhJBCirP\nz+SuqxfScKCbL/1qFdGo3ZfIGDM4SwQpauGUYr592Vxe3NTIj6zx2BgzBEsEKewTJ0/h44uq+fGy\nzbywaZ/X4RhjEpQniUBEtovIGhFZJSLLvYghHYgIt374eGZOyOP//d9ae7qZMWZAXpYIPqCq81V1\nsYcxpLysoJ9brjieupYu7npxq9fhGGMSkFUNpYFTp5dy+YkTufulrexospvUGWOO5FUiUOA5EVkh\nIksGmkBElojIchFZ3tho99F5r/7lg7MJ+oRbfrfe61CMMQnGq0RwhqrOBy4BPiciZ/WfQFXvUdXF\nqrq4vLx8/CNMMRUFWXzx/Jks27iPZRv2eh2OMSaBeJIIVHW3+74PeAw4yYs40s11p09lxoQ8vvO7\n9dZwbIw5ZNwTgYjkikh+XzdwIbB2vONIR0G/j1sun8vO5k7++6VtXodjjEkQXpQIKoCXReRt4A3g\n96r6tAdxpKXTZpTxoROquOvFLby+rcnrcIwxCWDcE4GqblPVE93XXFX91/GOId1967I5VBdn83dL\n3+C59dZrKlZiAAAR3UlEQVReYEy6s9NH09CE/Cx+89nTmFWZz2ceXMH/rrBbVhuTziwRpKmS3Awe\n+vQpnDqtlK/85m3+58/WZmBMugp4HYDxTl5mgJ99cjE3/uptvvv7Daza1cr8yUVMK8+ltjSXySU5\nBP12rGBMqrNEkOYyA35+fNUCqgqz+PXyXTy5uv7QOL9PuGhuBTde8D5mTMj3MEpjTDyJauLfq37x\n4sW6fLndmy7eVJWWzl7e3d/B9v0drNvTxq/e3ElXb4SPLKjmS+fPZHJJjtdhGmNGSERWjOR+bpYI\nzJCaO0L89MUt3P/aDlSVK98/matOmsKcqgJExOvwjDFDsERgxlT9gS5+8vwWfv3mLsJRZcaEPC4/\ncSKXnziR2rJcr8MzxgzAEoGJi+aOEE+tqeeJt/fwxrvNABw/qYBzZ1XwgePKOaG6CL/PSgrGJAJL\nBCbu9rR28bu39/DH9Xt5a2cLUXVOSz37feUsmFLEtLI8pk/IpbIgy6qRjPGAJQIzrlo6QvxpcyMv\nbmrkpXcaae4IHRqXk+Fn5oQ8Lp1XxUcXVVOWl+lhpMakD0sExjOqyr72HrbuO8jW/R1sazzIql2t\nvLWzlaBfuGBOBX/z/imcMaMMn1UjGRM3I00Edh2BGXMiQkVBFhUFWZw2o+zQ8C372nnkjV08urKO\np9Y0UJ6fyftri1lUU8LimmLmTCywC9iM8YCVCMy46wlH+OO6vTy7fi8rdrSwu7ULgOygn1OmlXDh\n3ErOn11Beb5VIRnzXljVkEka9Qe6WLGjheXbW1i2cS+7mrsQgcU1xZw7q4K8rADhSJRIVOmNKFlB\nH7MqC5hTVUBhTvDQclSVnc2drNl9gI317XT1RohElagqkahSnJPBNafWUFGQ5eGnNWb8WCIwSUlV\n2djQzjPrGnhm3V421LcNOf2komxmV+XT1RthTd0B2rrDgHN7jKyAD59P8PsEvwitXb0EfMI1p9Tw\n2XOmW6O1SXmWCADqlsP2l+GML419UGZctHSECEeVoN/ZoQd8Ptp7etlY3876+jbW72ljQ30bWUE/\n86oLmTfJeb2vIp+MwJHtDTubOrl92WYee6uOrKCfa0+r5ZLjK/HFnNrq9wkzJuRZW4VJCZYIAH7/\nFXjzXrjiLljwibEPbCSiUehuhZ426D4A3W0QOgjBbMgqhKwi970QfH5vYkwzWxsP8qPnNvPk6j0M\ntPkX5wS5ZF4Vl50wkZOmltgFciZpWSIAiPTCQx+D7a/ANY/B1DPHPrihtO2BX/41NKwZflp/BkyY\nDZUnQNWJzqtkmpMg/MHh5zejtrXxINsaOwCnSgqgqzfCsg37eHb9Xrp6I0zIz+QDx00gNzNA4FCp\nxCmZBPxC0C8E/T6Cfh9VhVnUlOYyuSSbzIAldeM9SwR9ulph6UXQ3gCfeg7KZo5tcINp2gq/+DB0\nNsNZX4HcCe6RfwFk5EFvl1NS6D7gxNi+x0kY9auhq/nIZQVzIbsIsktg8Sdh0fXgs6qLeOoMhXl+\n4z5+595KIxxRwlGn0bk3Gh2wJNFHBCYWZjOpKJuAXxDhUPVTQXaQqaW51JblMtV95WUGCPjErqkw\nY84SQayW7XDveZCZD59aBrmlQ0+vCh2NThVOqNPZafd2QslUKJoy/Prq34YHPwoahasfhYkLRh6r\nKrTtdpZxYLeTLLrchNG4EXYvh6lnwxV3jCyW8RTqhLo3YdfrkFMK085xSjUpeHsJ5wymKOGoEo5E\n6QlH2dPaxY6mTt7d38GOpg72HOhGVYkqh95bOkPUtXQRiQ78vwv4hIyAj4qCLCoLsqgqyqKqMIv8\nrCChcJSecISeXmd9+VkBKguzDk07oSCTgqwgORl+u6WHASwRHG3Xm3D/h6BqPvzd4xDsdwphJAw7\nXoENv4ONv3eO0AdSdSLMugxmXwblxx29k9v+Cjz8N87R/zWPjW0JRBVW3Ad//KbTf+GtsOi6wzH0\nHHSSSGczREJO1VgkBNFeKKyG8tmQcYzPE+hshr3roHkrRCNHjjtQBztehd0rnHXFKpjkJK6pZ8Kk\nxVA6I+1LM6FwlLoWJ2Fsb+qkKxQmEoVINEpEle7eKA1t3TQc6Ka+tYu97T2HEkfAJ2QGfGQEfLR3\nhwkPkFBEIC8jQF5WgIyAz00gUULhKKFIlJwMPyW5GZTmZlCSm0FRdga90ShdoQhdvRG6Qs7vW5af\nSXleJmV5GZTlZVKYHSQ3M0Bupp+cjAA5GX4Cfh8+Ab8IIk4Sy88MWOkmQVgiGMja38L/XufUx+dV\nQG658x7IhHdfgq4WCGTB9PNg6llONU4wBzJynWn2vOUkiro3neUVT4W8CSB+p6FXfM7RcFGNkwQK\nJ733mAfSsgOe+LwTc+U8UODALqf0MCRxjtAr5kL5LMgudj5jZoFTWhJxvoPOZqd6qrMZ9m92EsBg\niRGczz9xAdSeDjVnwJSToWM/bHsR3v2T8+qr7srId5LpxPmHSwsa5VBdSzTiJJNo2H1Fne+/r1qt\nL1Z/hvOb+IPgzwRfwPn+xeckGlUnQbVsh5Z3nfeuVichFtdAUa3zHsx2S30dznu4y6m6yy52quKy\niwZvo4mED8/X2+nEEMx2tqFgthvDLjcG9xWNQNFkKJzslOgKq53P2dl0+BXqgJwyyK+E/Eoi2aX0\nRJQMv49A39lMqkSjyv7OEHsP9LC3rZt97T20d/UQ6Wgh0un+fpEeIsE8Ihn5RDMKiWTm0RESmjtC\nNHX00HQwRGtXLxl+HzkZfrIz/GQF/QSjIcLt+9DO/WSFWiihnRABGrWIRgrZp8V00v96DEVQRISi\nnEyKsoMU5QQJ+n1OycktPUWiSiTcS0GkhZLIfooj+8mjk+6MUnqyygnnViC5ZQQCAaJRJeJeB6IK\nmQGhOCNCsa+TEl8nudJDSH10R4SeqI/uiJ+oP4PMnHwycwrIzckmPytIZsBpx+lr1wn4fEcdw/mk\nr73ncLuPT5y/jeBU8QkciicSVaJREI2Q111PzsHtZLRuQ1redbaBwmrndy6sdvYzoYPO/6CrxdkW\nI73uPqjcqTrOLRvz9sCETgQicjFwO+AH/kdVbxtq+jG9jmDT07DzVTjYCAf3wsF90HMAppwKsz4E\nM85zdjxDaauHTb+HrS84P2404rw0AgUT4YM/gJySsYl3MKqwfCmsesjZmAqrD2942cXuTjLD2bDE\n7+yE9q2HvWth73po3oaTQYYQzIXSaTBhrpM8KuZC2fuc5cbKzB+6pBGNOtVae95yXvWrnPaQcPd7\n/RZGLrvYOUOrbbdTShqNQLaTYOBw6SsSGv1y/JnOAUNv5+jm8wWcbTIacXYe0V4neQL4gs5v7As6\nsfW0HR43KDmcNMXnJmN1E7L7Gm7bAMK+LBBBNIxoFJ8eLilG8aEIUXzOS/xExI+6w/OibfgYPM4w\nPrrIAie1oAgCZNNFkPCwsfXpVT9dONeL+IgSIIKfKEGJDDp9BB9hnHdl4JKNE5Pznkc3mXK4JNyh\nWQQlTMYo4uwTOnTXHzm0ju3n38usMz486mVBAicCEfED7wAXAHXAm8BVqrp+sHnsgrI4iISdnUZP\nu3tqaxugzlFwTsnhZBK39fc6pQbpO+Ry331+Z8fnDzrviJNs+59+27cjDocg0uMm4pgdmSoUVDml\ntuJa58genKR0sMEpVbXugHCPs5MN5jjJLJDtHrm1HH51Hzg6fp/fSZQZuc58wRznyL63y0lwvd1O\nHIXVTttScS3kVTqfs7MZDuyE1p1OO5A/6LSp5JQ6331GLnQ0QXu9c5LDwQan2s8fdL8f97vRqJMU\nIm4JSqNOssspOfw7+oPOb9zddvh37ksksTv/IxKDDwIZTqkkt8w50Mgpdb7vvoOn9ganHU3ELREH\n3FKZHPk79B0gRaOHS3kadZZZUOVUHeZXOQcTHfudz3xwr/Me6nBLinq4xJiZd+h063CwgJA/m4Ao\nASL4NOxs1+FuIj0dhLra6O06SG93h1OyEB8R/ITxE1Ufemgf73RoNIpGI2g0TDQShkhvzEkBeig1\nCuATxYezu+7159CcNYXGzGrqA9U0aSHhaJScUDMFPQ0UhBrI7W2ix59HdyCf7kAR3YECIvjICjWT\nHWoiJ9RMTm8zAe2NSTHOGmsv+Cwz5yw8pr9ZIieCU4GbVfUit//rAKr6vcHmsURgjDGjN9JE4EWr\n3SRgV0x/nTvsCCKyRESWi8jyxsbGcQvOGGPSTcKevqGq96jqYlVdXF5e7nU4xhiTsrxIBLuByTH9\n1e4wY4wxHvAiEbwJzBSRqSKSAfwN8IQHcRhjjMGDJ5SpalhE/hF4Buf00aWqum684zDGGOPw5FGV\nqvoU8JQX6zbGGHOkhG0sNsYYMz4sERhjTJpLinsNiUgjsOMYZy8D9o9hOOPJYvdGssaerHGDxR4v\nNao67Pn3SZEI3gsRWT6SK+sSkcXujWSNPVnjBovda1Y1ZIwxac4SgTHGpLl0SAT3eB3Ae2CxeyNZ\nY0/WuMFi91TKtxEYY4wZWjqUCIwxxgzBEoExxqS5lE4EInKxiGwSkS0icpPX8QxFRJaKyD4RWRsz\nrEREnhWRze57sZcxDkREJovICyKyXkTWicgX3eHJEHuWiLwhIm+7sX/HHZ7wsfcREb+IvCUiT7r9\nSRG7iGwXkTUiskpElrvDEj52ESkSkf8VkY0iskFETk2GuIeTsonAfSTmncAlwBzgKhGZ421UQ7oP\nuLjfsJuAZao6E1jm9ieaMPBlVZ0DnAJ8zv2ekyH2HuBcVT0RmA9cLCKnkByx9/kisCGmP5li/4Cq\nzo85Bz8ZYr8deFpVZwEn4nz3yRD30FQ1JV/AqcAzMf1fB77udVzDxFwLrI3p3wRUud1VwCavYxzB\nZ3gc53nUSRU7kAOsBE5OlthxnuWxDDgXeDKZthlgO1DWb1hCxw4UAu/inmSTLHGP5JWyJQJG+EjM\nBFehqvVudwNQ4WUwwxGRWmAB8DpJErtbtbIK2Ac8q6pJEzvwI+CfgWjMsGSJXYHnRGSFiCxxhyV6\n7FOBRuDnbnXc/4hILokf97BSORGkFHUONxL2XF8RyQMeBb6kqm2x4xI5dlWNqOp8nKPrk0Tk+H7j\nEzJ2EfkQsE9VVww2TaLG7jrD/d4vwalOPCt2ZILGHgAWAj9V1QVAB/2qgRI07mGlciJIhUdi7hWR\nKgD3fZ/H8QxIRII4SeAhVf2tOzgpYu+jqq3ACzjtNMkQ++nA5SKyHXgEOFdEHiQ5YkdVd7vv+4DH\ngJNI/NjrgDq31AjwvziJIdHjHlYqJ4JUeCTmE8C1bve1OPXvCUVEBPgZsEFVfxAzKhliLxeRIrc7\nG6dtYyNJELuqfl1Vq1W1Fmfbfl5VryYJYheRXBHJ7+sGLgTWkuCxq2oDsEtEjnMHnQesJ8HjHhGv\nGyni+QIuBd4BtgL/4nU8w8T6MFAP9OIcedwAlOI0Bm4GngNKvI5zgLjPwCkKrwZWua9LkyT2E4C3\n3NjXAt9yhyd87P0+xzkcbixO+NiBacDb7mtd338zSWKfDyx3t5n/A4qTIe7hXnaLCWOMSXOpXDVk\njDFmBCwRGGNMmrNEYIwxac4SgTHGpDlLBMYYk+YsERgDiEjEvRNm32vMbhwmIrWxd5U1JtEEvA7A\nmATRpc4tD4xJO1YiMGYI7n3z/929d/4bIjLDHV4rIs+LyGoRWSYiU9zhFSLymPuMg7dF5DR3UX4R\nudd97sEf3SuZjUkIlgiMcWT3qxq6MmbcAVWdB9yBc8dPgJ8A96vqCcBDwI/d4T8GXlLnGQcLca6c\nBZgJ3Kmqc4FW4KNx/jzGjJhdWWwMICIHVTVvgOHbcR5es829uV6DqpaKyH6ce9D3usPrVbVMRBqB\nalXtiVlGLc4trme6/V8Dgqr63fh/MmOGZyUCY4ang3SPRk9MdwRrnzMJxBKBMcO7Mub9Nbf7VZy7\nfgJ8Aviz270M+Hs49NCbwvEK0phjZUclxjiy3SeV9XlaVftOIS0WkdU4R/VXucM+j/Okqq/iPLXq\nOnf4F4F7ROQGnCP/v8e5q6wxCcvaCIwZgttGsFhV93sdizHxYlVDxhiT5qxEYIwxac5KBMYYk+Ys\nERhjTJqzRGCMMWnOEoExxqQ5SwTGGJPm/j+D3Lbw748B6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x464c23b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [2], 'hidden_layer_size': [256], 'activation_function': ['sigmoid']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\neMFwzjkXiRcM55xzkXjBcM45F8n/AYo3tS3MACggAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x37cf68630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'num_hidden_layers': [3], 'hidden_layer_size': [256], 'activation_function': ['sigmoid']}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x45f1c4eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, k in enumerate(list(model_info.keys())): \n",
    "    print(final_models[i][0])\n",
    "    plt.plot(model_info[k]['history']['loss'][2:])\n",
    "    plt.plot(model_info[k]['history']['val_loss'][2:])\n",
    "    plt.title('Mean squared error over training')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The first and third models both show evidence of overfitting, as training performance continued to improve as validation performance plateaued (as seen when the blue line goes below the orange line). This suggests that these models will perform worse on the out-of-sample data.\n",
    "\n",
    "Now I store and upload the predictions of each model to obtain the results on the true held out data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i, k in enumerate(list(model_info.keys())):\n",
    "    predictions['gpa'] = model_info[k]['preds']\n",
    "    name = 'final_predictions_model_'+str(i)+'.csv'\n",
    "    predictions.to_csv(name)\n",
    "    # csvs were then uploaded to the challenge website: https://codalab.fragilefamilieschallenge.org/#participate-submit_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It is useful to compare to the predicted values for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.302232599543\n",
      "0.482352497173\n",
      "0.317887099487\n",
      "0.315795403041\n",
      "0.316432194806\n"
     ]
    }
   ],
   "source": [
    "# Printing performance on validation set\n",
    "for k,v in model_info.items():\n",
    "    print(mean_squared_error(y_test, v['grid_obj'].predict(np.array(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Store all five model objects\n",
    "for k,v in model_info.items():\n",
    "    v['keras_model'].save(k+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Scores on held out challenge set\n",
    "\n",
    "0.41737 (Submission 27)\n",
    "\n",
    "\n",
    "0.64386  (Submission 28) Unsurprising since it looks like it didn't have enough time before it stopped and also performed poorly on the test set\n",
    "\n",
    "\n",
    "0.42533  (Submission 29)\n",
    "\n",
    "\n",
    "0.43441 (Submission 30)\n",
    "\n",
    "\n",
    "0.37975 (Submission 31)\n",
    "\n",
    "The fifth model with 3 hidden layers, each consisting of 256 units, with a sigmoid activation worked best."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
